- Artificial Intelligence
    - 
    - **Lecture 1 **(Intro)
        - Artificial intelligence around since 1956, still a young field.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/g0yS9euandH2WRZtceJWTd_bVUf7BS1x06YZlheLJ1nm7RDQRUgXy-oIdq-PcSXfjr6EGYYjTVdXlozWcum0eFiHzqYwd-4rtgzHYmm40tJQRXKKtMKzTEFNzN6G6Q7f.png) 
        - No AI on earth can form a good understanding of "Sleep that knits up the ragged sleeve of care".
        - What is are the three versions of AI? ↓ 
            - One version is **acting like a human**. A test for this being the Turing Test. The Turing test is very hard - a human child would probably not pass it. 
Why would we want humanlike thinking? Perhaps we don't need it to give a reason, only a correct response.
            - Another version is **thinking like a human**. To write such an AI we need introspection and psychological experiments to figure out how people think. We then mimic that process. 
CompSci + Psychology = Cognitive Science
            - The final version is that intelligence reduces to **Rational thinking**. We record facts about the world, and the AI derives the effects of it's actions on the world.
It has obstacles with uncertainty, tripped up with computational complexity, acting fast and needing to act without logic.
        - Agents 
            - What is an agent?―A mechanism which can sense it's environment and act on it's environment.
            - Agent Performance 
                - Any measure of performance is likely to be problem-specific. Additionally, measure of performance can conflict - i.e. an autonomous car want's to reach it's destination as fast as possible - but it also want's to be safe.
                - Why are we usually interested in **expected, long-term performance**? ↓ 
                    - Expected: because an AI model is not omniscient. You can't know when you walk into a lecture that the roof will fall - a model that could detect that would be more performant, but not more rational. 
                    - long-term: Because that usually leads to a better approximation of what we'd consider rational behaviour. 
            - Environment features 
                -  _Accessible/inaccessible_  environment. Do we have perfect knowledge about our env?
                -  _Deterministic/non-determinstic _ environment.
                -  _Episodic/non-episodic_ : is the agent run in independent episodes. E.g. Chess
                -  _Static/dynamic_ : Can the world change while AI is deciding what to do? 
                -  _Discrete/continuous_ : Infinite percepts and actions.
                -  _Competitive or cooperative_  with multiple agents - is communication required? 
            - Programming Agents 
                - Is there a sensible way to structure an agent?
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AYQBAkORBU5GZQpfO304RPM1zRtBoYinx230thA693z8JVBgVqIVwUqbnDLh6Ys3Lh90MoAtfdUA0pAejfGxOHI8W2lKeydLp4QF80_YIXA4ca5oQFW0GfQqYHSggWcs.png) 
                - What 3 things should an agent maintain in memory about the environment? ↓ 
                    - A description of the current environment
                    - Knowledge on how the agents actions affect the environment 
                    - Knowledge of how the environment changes independent of the agent
                - This requires knowledge representation and reasoning.
                - Additionally, an agent acting towards a goal should have some idea of Planning - thus we might search through the action space to find a plan.
            - Utility-based agents 
                - What is a goal?―A goal is achieved when the environment is in some desired state. E.g. the gold bar is in the robots hand.
                - However, goals are not the end of the story. We can have multiple goals, conflicting goals requiring trade-offs (and utility functions).
                - What are utility functions?―A utility function maps a state to a number, representing the desirability of that state.
                - Maximising expected utility forms a fundamental model for the design of agents.
            - Learning Agents 
                - Feedback from actions are fed back into the description of the effects of actions and the behaviour of the environment.
                - What is the trade-off associated with learning agents?―**Exploitation vs Exploration**: Time spent exploiting found knowledge, vs time spent trying new things that will initially be less effective. **Local minima**. 
    - **Lecture 2 **(Searching)
        - Search Algorithms 
            - What four things are required by a search algorithm?  ↓ 
                - A set of states including an initial state.
                - A set of actions (transition function) $$\text{action}: A \times S \rightarrow S$$ 
                - A goal test. $$\text{goal}: S \rightarrow \{\text{true, false}\}$$ 
                - A path cost $${cost}:A \times S \rightarrow \R$$ 
            - We generally want to find a path with the minimum cost.
            - Depth-first, breadth-first and iterative deepening don't generally work in AI. Too many options.
            - Problem solving by search useful for deciding where to place things on chip. 
        - Search Tree vs Search Graph 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jQDVzFxjfnLxwr59_kTcpdNkfhI79BqRexdlpgDETSpAGec_q4H6wE6ng7pST-QGK7_v9t95CH2j4mDEQ2PCeXEPG1aqsbqMVEU54BiBQ4GbO3RZfzBcq37uJWeqXRKR.png) 
            - What's the difference between a search tree and a search graph? ↓ 
                - In a tree, only one path can lead to a given state on a given layer. But a state can appear multiple times
                - In a graph, a given state is only in one node but there might be multiple paths to it.
                - Graphs can have cycles (trees can as well, but they're less obvious - we could keep looping between states) & redundant paths (where multiple paths lead to the same point).
            - What 3 factors are most important for search techniques? ↓ 
                - Whether a solution is found
                - Whether the solution found is optimal/ a good one 
                - The cost in terms of time & memory
        - Basic tree-search algorithm 
            - ```c
expand(s) = {s' | s' = action(a,s) where a is an action possible in s}
```
            - Expand fills a set with possible actions from a state, we then use this to search the tree:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JhH3CFxBUhdvUzAW5KngcS4wHUbszAiQuxk1-XlPRxhx-OFh0ptOCvEcJhmZ-I5Xk0S-MJauSxuhM_9FjOSsQsjpYrkux13yXRFB1qiiawP2e96_mpWIUhA_bbviF-i0.png) 
            - The search strategy is set using a priority queue to implement **remove() **of the fringe. The definition of priority then sets the way in which the tree is searched. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cycJro62ngUhbO0dLCQaKh3WgYt7oyFt_8yDNdqgAS15VYD8XaDBipMv7AqtqFuSTNK71Ea5xEji3RhJ6EmAiCB927hfHrhuqOvyGrwVeJa4ph6-e3kMZ9xJqaGZLwlz.png) 
        - Graph search 
            - Need to make sure each state is visited once - need to add a closed list and add a state when it is **first seen**. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/u-_Kqx75iks16OGcEI7dWMXLc4DA0wGopVPYAdh8luFoevbQaCmwYgAi_GYH9AmA8jlBkclY0Gg_qiuBGVzZ8GQO77755vnVq-oGSguh3H0grKT6lo2ipnQPM3TbUjiZ.png) 
            - The closed list contains all expanded states - can be implemented using a hash table
            - Worst case time and space proportional to the LARGE state space.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3YiCgh5Bm4kjKi8Jl0-Mnejmi6USkpoBcsabo_7nl78GpWcGLl5aiiSaJCUumQv4cBriRbCgZObHEfb-t-5WMFxgVXTycpnwt2WJcu9q-on_4gechXwqBo58KTvN6xVG.png) 
            - 
            - Graph search builds a tree on the graph. Furthermore the graph becomes separated, any path from the start to an unexplored node **has to pass through a fringe node.** 
            - Note that - we're discarding a node the next time it's found, even if the {{new path you took to reach it is shorter.}} We may need to {{modify path costs}} of the repeated state.
        - Performance of search techniques 
            - $$\text{total cost = path cost + search cost}$$ 
Why is search cost a factor?―Problems in AI are at least NP hard, soo searching time becomes a factor. We might choose a sub-optimal solution to quell search time.
            - How do you form depth first and breadth first from tree search?―Depth first when you add the nodes to be explored at the front of the Queue. Breadth first when you add them at the back. Testing them for the goal before you place them in breadth first saves you time, as you then need not search the rest of your current layer.
            - BFS is complete, it's wlil find an optimal path but it's exponential in time **and space**. And space is the main issue. 
            - DFS - not complete for tree search because of loops. Complete for graph search **if the number of states is finite, **but not otherwise. 
            - What is the DFS time & memory complexity for a tree with branching factor b and depth d?―For a depth d and a branching factor b. The memory complexity: $$\text{memory:} \ \ O(bd)$$
$$\text{tree search time:} \ \ O(b^d)$$ (If you know you have to go to depth d)
$$\text{graph search time:} \ \ \text{size of search space}$$ 
        - Uniform-cost search 
            - Change tree search to try and get an optimal solution, while limiting the time and memory needed.
            - What is uniform-cost search?―Tree search with a twist. Uniform cost no longer just distinguishes between goal/non-goal. Tries to pick the best state to explore by using the path cost as the priority for the priority queue.
            - How do we modify the graph algorithm in uniform-cost search?―If the fringe has a longer path to a node than the current path you took (to that same node), replace the fringe node with the lower path cost version.
            - **Uniform cost search is optimal, when we select a node it must have the shortest path to that node. **
It is complete, provided we cannot get stuck in an infinite path.
Costs must be >0 and branching factor must be finite.
            - Is uniform cost search optimal? If so/not, why?―Yes! When we select a node it **must be the shortest path to that node**. 
Because we search in order of path, any nodes that we explore past our goal node would have a longer/the same path length to it.
            - In practise it doesn't work very well. Gives us the idea of an evaluation function - a function attempting to measure the desirability of each state.
        - Heuristics 
            - Why is path cost not a good evaluation function?―It is not directed in any sense, towards the goal 
            - A heuristic function is one that estimates the cost of the best path from any state s to a goal. $$h(\text{goal state}) = 0$$ 
            - This is a problem-dependent measure. We are required to either design it using our knowledge of the problem, or by some other means. 
            - Example route-finding:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b98xuixLiyExt74HUubIrRpnJ4YC1JdzwsYqQbTMuaPuZ645iCEVOxHM54QMUsSVVbdWVFrHsEhEWlc-FfYNPYS5qJbuK9eBHS4IH-03S0559btAkFsahaZ6wiJy4AF_.png) 
        - A* Search
            - How is A* different from other search methods?―A* combines the good points of using p(s) to know how far we've gone, and h(s) to know how far we have to go. 
We then form an estimated cost: $$f(s) = h(s)\  + \ p(s)$$
Note, we need monotonicity for A* graph search. 
            - What is an admissible heuristic?―One which never overestimates a given path to the goal$$\forall s. \  h(s) \le p(s, goal)$$ 
            - If $h(s)$ is admissible, then tree search A* is optimal. 
            - 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vrTK0VzqRAVvyyTtOXFi2wlgJrpJ2JIXvEPCclAxPSmRbzvX2yAau6J2vDuDiR66gobgGqprmOh6T3s0A2UrWkpDj1xaVOwKU2FzybPQMd80-2VoiPnffkm1SC3ZjsDx.png) 
            - We say:$$f(Goal_2) = p(Goal_2) = f_2$$ 
            - Assume that this goal 2 is less optimal than f_opt:$$f_2 > f_{opt}$$ 
            - If A* is not optimal, then it can find Goal2 before Goal_opt - assume that's the case - then Goal2 is chosen for expansion **before s**:
$$f_{goal2} < f(s)$$ 
            - We then note that:
$$f_{opt} = p(Goal) + 0$$
Then - as the path to the goal is longer than the path to s and h(s) underestimates.
$$f_{opt} \ge p(s) + h(s) = f(s)$$
We can then form the contradiction: 
$$f_{opt} \ge f_{goal2}$$ 
        - A* Graph Search 
            - For graph search the situation is trickier - as we can discard an optimal route if it's not the first one generated.
            - What is monotonicity?―This is a condition on $h(s)$ which forces the  __best path to a repeated state to be generated first__ . 
Note that
$$\text{monotonicity} \implies \text{admissibility}$$
It is always the case (for a monotonic h(s)), that for a state s - a state further down (call it s) has the following property: $$f(s') \ge f(s)$$
 h(s) is monotonic iff it obeys:$$h(s) \le \text{cost}(s, s') + h(s')$$
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cEd7S8V98DK8tRHoWWLjAxgbfYpO1rNc2xEQ80Mtcmsi2K_LIxYB7jCs7sCB2gt7Rzy4DbljlxqMfTFzrkOVrmcVVMhi3PYaUKkQvGowgOQdxHb2hKBXIFM01HBI_6DE.png)
The logic behind monotonicity: If a path through s has a length of at least 9 (shown above) - how can a path through s' - **which is a path through s **- have a lower path cost?  
            - Give a convincing (but not too complicated) argument that A* graph cost is optimal with a monotonic heuristic―Because $f(s)$ is increasing, in order to find a non-optimal path first it would have to have a lower f cost than our optimal path - but that would mean it's the optimal path. Contradiction. 
            - A* is complete with a finite branching factor, and finite positive constant such that each action has a cost at least $\epsilon$. 
            - A* Complexity 
                - Optimally efficient, no other optimal algorithm that works by constructing paths from the root can guarantee to examine fewer paths
                - Still exponential in time and space.
        - 
    - **Lecture 3 **(More searching - including Local Search)
        - Iterative Deepening A* Search 
            - Uses a depth first search, with a limit on depth that is gradually increased. IDA* does the same -  __with a limit on f cost__ . 
            - Explain this code![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/acS2baAgT7vMYSUhudd_In4_rkCrDRN-sKDnbv8LtLm0TXiAc_rPx969TIplEx-5pRvMqgSFwdIrS0iiKREvxAKGY-6_twTO6tJvUtNkyCAiYDb6e6h6yy6g2mHp4Imh.png)   ↓ 
                - NOTE - WE ALSO NEED A RETURN ([], nextF) AFTER THE FOR LOOP I THINK - CHECK YT RESPONSES
                - First set nextF to infinity, meaning we don't know our smallest path above our pathLimit. 
                - Then we check if we're currently above our limit, and return []
                - If we're a goal we return our path to us. 
                - Otherwise, for every vertex reachable from us, try and find a path from that vertex to the goal - if the newpath is not [] then we've succeeded and can return.
                - If newpath is [], then we'll try and update nextF.
            - if newPath ≠ [] then we must have found a goal, meaning we can finish. Otherwise, we'll update our nextF.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WCOAvQZQY8XNA5DzcAX2QDF719t-QBoDeM0fB0u9i6X5t7OkngF0tc31pqkcsWvqWTVNlxOz2vaVGJJVtph_v056DFNrmX-24JxWPfHtblM63lYbzadkbeb3WVCugOTI.png) 
            - Propereties of IDA*:
                - Does not require us to maintain a sorted queue of nodes
                - Only requires space proportional to the longest path
                - Time taken depends on the number of values h can take. If h takes enough values to be problematic, we can increase f by a fixed $\epsilon$ at each state - guaranteeing a solution at most $\epsilon$ worse than the optimum. 
        - Recursive best-first search 
            - This tries to use f, in tandem with a depth-first search with a few alterations.
            - Describe recursive best-first search  ↓ 
                - Continually explore the best $f(s)$ at each node you come across. 
                - Store the $f(s')$, the best possible alternative you've met.
                - If you find an s such that $f(s) > f(s')$, backtrack to $s'$ and update any nodes we meet with a cost of $f(s)$ - so we remember the cost of a path so we can easily re-tread it. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9XR8QAG1r5CQY5QYcXrvVCf6bT90dQMPrawc-9SQiyX8hSHPfmPdXXrzRFqFAFXyQwUPFX6DHmNkMe_52Pi5DarxcQy7B_vopkYA5MIHoRS0rnUXATBupjFNE6kyOT8c.png)
What does the $$\text{for each s}' \in \text{expand(s)} ...$$ 
do (the entire for, not just the first part)―This is a solution for a non-monotonic f, if one or more of the states has a reduced f cost - use the older one instead.
            - Properties:
                - Good: If h is admissible, then RBFS is optimal
                - Good: Memory requirements is $O(bd)$ 
                - Good: Generally more efficient than IDA*
                - Bad: Time complexity exponential
                - Bad: Can spend a lot of time re-generating nodes
        - Local search 
            - Instead of trying to find a path from start state to goal, we explore the  __local area __ of the graph, meaning those states one edge away from the one we're at.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YGY2QD1QGEtTRuKQmbAOGnSTE-ZbJKclhA4Eumu3iiEQpHml6zP12hoDbLX8fqi9CZSEJvODgPR-da4JcJgXwTzhsJAMzEzdeYBJsFlOGfgJQkKSnBSAAvYMPwXER1Hv.png) 
        - The M-Queens problem 
            - Take a state s for an m by m board (with m queens) to be m numbers draw from the set $\{1,..., m \}$.
            - We move from one state to another by moving a **single queen **from one row to another. 
            - We define $f(s)$ to be the number of pairs of queens attacking one-another in the new position. 
        - Hill-climbing search 
            - Describe Hill-climbing search―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_UWRwdfqDpsBWbq_SaFcKQGuLeJDz6JGty3SzPiKFYWsSQQY8KtfHeB6UlL-KVzJ6xft41XLz7sGFjRX0zfRLejtYQBs7yXPUC6HnY5S12RigVEHCdga4NZdqBEJu79u.png) 
            - The reality of Hill climb search
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/srmpDAa2DQ5u3Uf96tvrl1qJKebOKlKHA8hSV8D2qoWGLVFd-5cQfbH4WZAsYykpS4ygOm6TO9RKyccASrufZ7tAc772mjXJGKgRvb0MQ9SUfyGdW8tNSqPBcvs68JRe.png)
We can find ourselves in local maxima! 
        - Stochastic Hill climbing 
            - Describe stochastic hill climbing―We still cannot take a step to neighbours with a lower f. However, we make the **probability** of stepping to other neighbours proportional to the increase in f.
Means we can take a "less good" increase in f
            - Beam search: Maintain k states, at each search step find the successors of each and retain the best k from **all **successors. 
        - Gradient ascent and related methods 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AlORArcC5bLSmJ5P_QpQERZ63g_9PCrKtkLIj-gKjlJcrNjG5L-eSkqOmJxjOG9f-4EiUWED2j4RZuwv3Zy-rSfzO7J2LG257-HUTuUEICJ2txeWEu_T8DMltKJXso9V.png)
We have a function $f(\bold{x}):\R^n \rightarrow \R$ and we want to find $$\bold{x}_{opt} = \argmax_x f(\bold{x})$$ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hfOFzxbCagjstMzLq52SZEuI3yYTTbt0xiLiHPqxLVgfMhc_hLabbWJ0QtqHnHcVZjz1M6K0Na-2IXVBSZhq_Ul5Wl0qT95Sh7jrN6S4vFRYLDARTiuuRYMkDjk_VftR.png)
However solving the equations shown above is not usually **analytically tractable.** Regardless of dimensions. 
            - Describe gradient ascent ↓ 
                - Start with a random point $x_0$ 
                - Continually iterate the following with a step size $\epsilon$. $$\bold{x}_{i+1} = \bold{x}_i + \epsilon \  \nabla f(\bold{x}_i)$$ 
                - Note: If the gradient is negative, move opposite to the gradient. 
        - 
    - **Lecture 4 **(Games)
        - Solving games by search 
            - The problem is, the outcome of your actions **are not known **because you don't know what your opponent will do. Makes this a more realistic search problem.
            - Chess is a hard problem - average branching factor of $\approx35$. Games can reach 50 moves per player, rough calc gives $35^{100}$. 
            - In addition, uncertainty due to opponent - we can't find a complete search to find the best move.
        - Perfect decisions in a two-player game 
            - For noughts and crosses, the operators, terminal test and utility function are (respectively)―Add a nought or a cross, check if there are 3 noughts or 3 crosses and whether you've won or not.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YYeSJbR5jNjhZJF8TngrTGVF4qgZn_bwJXJlu_1ihr50hJy7hcojt3vGjf-rLrdD4dG11aYjWl2q7Joeag4ud5Kyd0fY3NZQRqVbUJOT3AIwdZKVbp0pgmfDs3wwQGYm.png) 
            - Give the basic idea of the minimax algo―Max wants to find the biggest utility, Min wants to minimize Max's utility.
So in the minimax algorithm, Max assumes Min will pick the choice to minimize his utility and works from there.
So Max picks the branch which **has the maximum, minimum child node utilities.** 
I.e. the biggest, smallest node as we know Min will always pick the smallest one. 
            - How do you generate the minimax tree? ↓ 
                - First generate the complete tree according the the utility function, e.g. generate all successors and number them. 
                - Work from the leaves upwards, label the nodes depending on if Max or Min will move
                - If it's Max's move label the one with max utility
                - If it's Min's move label the one with min utility.
        - Making imperfect decisions 
            - Cut-off test, instead of using the utility function - introduce an **evaluation function **a function that generates how likely it is Max will win. 
This evaluation function is critical - need some human ingenuity to generate this.
        - The evaluation function 
            - What is a category in an evaluation function?―A set of states where the evaluation function gives the same result for all. E.g. for a simply chess evaluator looking at material, all the states where white is one pawn up.
This is very naïve.
            - We could try and learn an evaluation function, construct a weighted linear evaluation function: $$\text{eval(position)} = \sum_{i=1}^n w_if_i$$
A sum over the weight times the **feature** where the feature could be the value of the i'th piece. 
        - Alpha-beta ($\alpha$-$\beta$) pruning 
            - We can prune the search tree, without affecting the outcome and without having to examine all of it.
            - Explain alpha-beta pruning―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/T6kuP9Z_pwRN7nawwWTJf6IX2ewtpE14dD4Ww6DTMeY2cw2xpiAxVw-heMYNMSGfk7H0FPHrEN73PJnVyzVnpEBqw1ysycQORN2yQxFrjMw3XSzT0wyX5-4UAcGtQEJ8.png)
We know Min will choose the lowest one, so no need to search those ones.
So we do left-to-right depth first search, and when we find a node lower than **any node along our (current depth first) path** don't examine it, as there is a better path earlier in the game.
$\alpha$ is the highest utility seen so far on the path.
$\beta$ is the lowest utility seen so far on the path. 
            - Explain this code
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MP76mRUCS0OakVm7HK8tC_rc_LzxZehAcf8E5gRF380f4k1t9tisF1xbZWzRuBzL3MwIryWd_ZMLJapU8h1EGEAg7IPkv8jrlhyqpx6u3807VOAdyeykkKxDtZbm6A4v.png)  ↓ 
                - First we check if the game is over or if we shouldn't search anymore.
                - Then we set the initial value of the position to negative infinity (so any larger value will update it).
                - Then for each successor, we find the max of the current value and the **opponents best move**. 
                - The opponents best move will be the move that minimizes our score at this position.
                - If our new value is better than the worst position the enemies seen so far, stop searching here - as our opponent won't let us get here. 
                - Also update the best value we've seen so far if we need to, this is to inform the enemy to prune elements worse than the best element we've seen so far.
                - Otherwise update the value.
        - Effectiveness of alpha-beta pruning 
            - If you always manage to pick the best moves first, AB pruning would be $O(q^{p/2})$ rather than $O(q^p)$. 
Allowing us to search ahead **twice as many moves as before**. 
            - If moves are arranged at random then: $$O((q/\log q)^p)$$
When q>1000.
For reasonable values of q:
$$\approx O(q^{3p/4})$$ 
            - In practice, simple ordering techniques can get close to the best case. E.g. captures, then threats, then moves forward etc.
            - Transposition table, we're really searching positions on a graph - so we might return to the same position multiple times. Hash the evaluation of the position in a table.
        - 
    - **Lecture 5 **(Constraint Satisfaction Problem)
        - Constraint satisfaction problem 
            - Previous methods had issues that  ↓ 
                - States were represented in problem-specific and arbitrary data structures. 
                - Heuristics were also problem specific.
            - So we would like to transform general search problems into a standard format.
            - CSP standardises the manner in which states and goal tests are represented. Meaning we can develop general purpose algorithms and heuristics.
            - What are the 3 main components of CSPs? ↓ 
                - Variables $V_1, ..., V_n$ 
                - For each $V_i$ a domain $D_i$ specifying the values that variable can take. 
                - Constraints $C_1, ..., C_m$, involves a set of variables and specifies an allowable collection of values. 
            - A state is an assignment of values to some or all variables.
            - An assignment is consistent if it obeys all constraints
            - An assignment is complete if it gives a value to every variabe
            - A solution is a consistent and complete assignment.
        - Node colouring Problem 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3l8fQv2tGPXrLOZU9t51TnPgwEDH0R_8IZ8CWZk6isR-z92NUiFrYHisTrckhYDUTHL2QRnXfE-_cALNC3aIleTjiDgkVCYUuiNr55x375DpWMr7OzzL7iTnDInujZc6.png) 
            - Variables are the colour of nodes, constraints are relationships between nodes sharing an edge. E.g. certain nodes cannot have the same colour. And the domains are {B, R, C} - black, red and Cyan.
            - We'll deal with binary constraints. Higher-order constraints can be considered, but when dealing with finite domains they can always be converted to sets of binary constraints by introducing extra auxiliary variables. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-O8DxnSGI0CtFnfzKONj5dRyctXXh5Qpc6zs8DevZvnzemNjN8t_HwUIjBYwiBIitoj2YXl62WVqCxd35le1FZrwtws3adVRbWafyv5TCM6aZjZYDOQ1wKyXl7X3CAal.png) 
        - Backtracking search with CSP
            - We can very simply do a backtracking search, where we assign variables at each step - and backtrack when an assignment would violate a constraint.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-QsFRWZH3ykZ48Zum0XMW137bW8q-_QAG6M4XVK9y1ZZHROJ7tpb_bBH2HRYEkZcMgrzaXos3CH5gOvibS2c0PLbZHEO8pSqzSJqww_lF6_xqvUwfZe0NCNn8O-9jagP.png) 
            - Note that choosing the {{next variable}} to assign is subject to a heuristic. Similarly, the {{order}} that we'll try and assign the variables can be subject to a Heuristic.
            - What effect might the values assigned so far have on later attempted assignments?
When forced to backtrack, is it possible to avoid the same failure later?
            - Can we try and force failures? 
            - Describe the minimum remaining values (MRV) heuristic―We choose the variable with the smallest available domain, so we fail earlier on.
            - Describe the degree heuristic.―Choose the variable with the greatest number of constraints, to get things started and so we can make the big failures early.
            - Describe the least constraining value heuristic.―Choose the variable which constrains other variables the least.  
        - Forward Checking and Constraint propagation
            - Describe forward checking and contrast against constraint propagation ↓ 
                - Forward checking means when we assign a value to ourselves, we also remove that value from other variables (that we are constrained withs) domain.
                - Constraint propagation uses forward checking, but also checks the values of the other variables - to check if their domains are now in conflict with their neighbours and they can no longer be satisfied.
            - Arc consistency 
                - Consider a constraint as being directed - i.e. $4 \rightarrow 5$. 
                - What is arc consistency?―If we have a directed constraint $i \rightarrow j$ (where i and j are variables), and the domain of i is $D_i$ and j is $D_j$.  
i and j are consistent, if for every variable in i's domain - there is a possible value in j's domain so $i \rightarrow j$ is valid. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Hdb0h41giFp-RIsGbSmgPxJ3dc7x-R-1vH6KDO3b_XZIfxTCCl-qCTTnOfD1GPbsUXByzy-Zk2Hzq-OqAOUuofn-mQfDihE_0dycn7NywkrwN7zKmXxRRgMbzAujAErS.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/R2gvLTpufGR6BjNFgaSvLEGOwUiIUMS4gHLLT4A5wPnZyDqSHjkVVONuojzW7bLdp8ArR9nK_taCwcbsHgHbqoVLZvMgPPs5bCHo23elWPXfgqChivmJTsNs6PchxBfX.png) 
                - In order to maintain arc consistency, what do we need to keep track of and why?―We need to keep track of a collection of arcs to be checked, because whenever we alter a domain to achieve consistency - we might be making a previous arc inconsistent: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jwREi0peRfLfe55kf3CRP0KiLPCXn1N24KNuqjUuohZcj7AW9kQe-2bqGrcYaLvy4N8sUvf9fW0fNjcnFm9ynL7w596X3_kMGYuq5crcoUzP1t-MBEbOZUkx_uHkrCTE.png)
So we would need to filter down and check all consequences - we're just backtracking... 
            - The AC-3 algorithm 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KGvBIGCEgwNDkOsSZP0kvMBVGVD_arVEPVsINW-orSB5ulC7wF99An6BkUijyjWLFHhatAtak5z-4C7ebmq8x6kiJBkMj8VLIxFKrJRoDd--MZgoTNLsOa1JWnOnsZHg.png)
Describe this code―We just check if there are inconsistencies, if there are then we need to check all the neighbours. Otherwise keep on truckin'.  
                -  _Complexity_ 
                    - We've likely done a bunch of deletions at each stage, reducing the size of the search tree. 
                    - Note a binary CSP with n variables can have $O(n^2)$ directional constraints. 
                    - Any $i \rightarrow j$, can be considered **at most** d times where $d = \max_k | D_k|$ because only d things can be removed from $D_i$. 
                    - Checking any single arc for consistency can be done in $O(d^2)$. 
                    - So the complexity is $O(n^2d^3)$. 
        - More powerful consistency (k-consistency)
            - k-consistency: Given any k-1 variables and any consistent assignment to those,  __can we find a consistent assignment to any __ $k^{\text{th}}$ variable? 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nXUHK8AWtIkKlwjd2Rt_PF9gtd-n7j5pFOuGprHKjWQfUjL7cPUzALmP8dU4UtUxwJQhaDDfAYjjSMAecl2g4l9ka3ow2ABNd6HOzpZKRkGm4NCm5JXwX75S6dKKsBzV.png) 
        - 
    - **Lecture 6 **(Backjumping in CSPs)  
        - Backjumping 
            - The basic backtracking algorithm backtracks to the most recent assignment, this is called chronological backtracking and is not always the best method.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/P6BieF_pJobtGcxzqp7lKnIPTboSDBslxoTJBqhIqFkKJZiK_PA407wKhhDQz3FBVPWDiPfFQ1PEvWOIk2F7aYFRbd45g3uVaUtTiqqU2ahKRCr8K7MOfJyOxbHGmob2.png)
Clearly ^^ trying to reassign 4 will have no effect, we would rather jump back to 5. 
            - Graph-based backjumping  works as follows: on  attempting to assign to a  variable V for which no  consistent assignments are  available we backjump to the  most recently assigned  variable that has a constraint  involving V.   
            - Notation:
                - Assignment: $A_i = (V_i \leftarrow d)$
We set our variable V to some d in the domain. 
                - Partial instantiation: $I_k = \{A_1, A_2,...,A_k \}$ is a consistent set of assignments for the first $k$ variables. 
                - Conversely, $I_k$ conflicts with a variable V if no value for V is consistent with $I_k$. 
                - We shall assume that variables are assigned in the order $V_1, V_2,...,V_n$. 
        - Gaschnig's Algorithm 
            - Describe Gaschnig's Algorithm you fuck [💯](💯.md)  ↓ 
                - When choosing a value for $V_{k+1}$ we need to ensure that the candidate value $d$ doesn't conflict with $I_k$.  
                - If there is a conflict (as there is likely to be) we must choose a different d. We record the most recent assignment $A_j$ for which there was a conflict. E.g. We note down which variable in $I_j$ conflicted with $V_{k+1}$! 
                - If we can't find a consistent value for $V_{k+1}$ with $I_{k}$ then we work back to $V_j$ - looking for the smallest $I_j$ where there is a conflict with $V_{k+1}$$$j = \min \{j \le k \ |\ I_j \ \text{conflicts with} \ V_{k+1} \}$$
E.g. EARLIEST NODE IN $I_j$ WHICH CONFLICTS WITH US. 
                - If we find no such values, we revert to backtracking chronologically 
        - Graph-based backjumping 
            - Can we do better than chronological backtracking after we find a conflict?
            - Given $V' = \{V_1, V_2, ..., V_k \}$, what does the ancestors of $V_{k+1}$ mean? And what does the parent mean?  ↓ 
                - Ancestors are the subset of $V'$ that are connected to $V_{k+1}$ by a constraint. 
                - The parent is the most recent ancestor of $V_{k+1}$. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UMhc3E-DBfhxkY6ZyNB2VxLP7cmGZtJMmzbPR7V1JhqTuhffEPczOwxrOWnqJ6jmb1MbCa53-iuOtvjMbmfOMagk4JhhzdP6YC9qhIR-YouNU7dOb5uJafDAhgFD-Iht.png) 
            - Why shouldn't we just jump back to a parent variable every time there are no assignments left?―If the parent has no other instantiations, then we then have to jump back to the parents parent - **but **crucially there might be an easier way to fix our variable, e.g. via v3 below.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uBqxiR83zlDYqezhboHLuer-0jfMTNBTn2WQGCBJZCuQO0wkLFjTFD_A8o3DDqUttK9bZluB0OyC0_QhG2X6FipA2SLy79FuZIJqrLiZ5q_cEfjurncQqU8EyC1MkFeq.png) 
            - What is a leaf dead-end variable and a leaf dead end?―A lead dead-end variable is a variable with no possible instantiations left. A leaf dead end is the partial instantiation of variables with a leaf dead-end variable.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KcBnFaBcV5rwJfO2lWiEG91tDP0eavEpdimNKqYpaqKmluf9NWOBqqlJ299TkEHrygA6AH3OUvQvt5fv6AQRxanikYplaiqr-TBkobpz31KpZDYTYTYkFtO4sagBZ2BI.png) 
            - What are internal dead end-variables and internal dead-ends?―If we backtrack from a leaf-dead end and we have no more instantiations - that's an internal dead-end variable. We call instantiation the internal dead-end.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OZ2ZVcYNRwvBATnAeMUbqPdxVNhcV4wtZwLEe8ImwaB9jeUj9ST55Fz3yabyLK5CnB6Lk-xFt6cmhyjDqxzPGonYLopXVzuJog91WWWXHQWaiCHrUVNBl_HCuSInIhFk.png) 
            - The session of a variable $V$ beings when the search algorithm {{visits it}} and ends when it {{backtracks through it to an earlier variable}}. 
            - The current session of a variable $V$ is the {{set of all variables visiting}} during it's session. This session will contain {{V.}} 
            - The relevant dead-ends for the current session $R(V)$ for a variable $V$ are―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/olzkhNnjWgyjb5GLAJ0agwWwoa51A6rm71m4antz0c247FYYaCbpq8Lek0kOTmmr0XGfw6-Rma8E20gOi4f8tE-4IXb-tkmp698Y-zbWgQxjL0TQYDyIfZvRDWtmceBU.png)
We accumulate all the dead ends in our session. 
            - Say $V_k$ is a dead-end, what are the  __induced ancestors __ $\text{ind}(V_k)$ of $V_k$ - in words or with maths ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hWvapoDX0308gphwK935Ev_D_08Xkh7Cqp5u68O5qcDUTMQ9bK2frycZAWMTBXGfpLuZrzi0H05snpgSX8hbrdi5n8dvIvU5aO6IzG5fDVrJvImbEJBASw5f5TvAKYeb.png) 
                - All the nodes before $V_k$, intersected with the set of all ancestors of the relevant dead end nodes. E.g. it's all the nodes before $V_k$ that are connected to a dead end. 
            - What is the culprit for $V_k$?―The most recent node in $\text{ind}(V_k)$. E.g. the most recent node that's connected to a dead end. 
            - What is graph-based backjumping?―We jump back to the **culprit **for $V_k$! 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i-dfz9O2Qi87pxapxusjLr7uDuPz1rseXxz4TT_0YxW_8xyQK2AE0IM1RB8k5S1l7tcVa8VIVhc0-KxyGgRnblG19WHV11GSN4XIRIVIV9X7znlhDnXOKPC-mFMLgoDO.png) 
        - Varieties of CSP 
            - There are CSP's beyond finite CSP's. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jaytuhmdyT-sy4nPSydv3QqBRysdVTHBYTWgVs9dkkxHrJC6UgPcwf7wes88yXHeJO6AcZlQqdL9H0md_J0Q9FlQ8XmJphLjvdYXMpU6GlljSy7H2wwaPIXX9bVT4AyT.png) 
        - 
    - **Lecture 7 **(Knowledge rep and reasoning 1) 
        - Knowledge Representation and reasoning 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LBb7i-_3rCY5wuDE_-3mD-eW6Dn3EM-RRNydd8A78Hv_FrUmWh68-ejiZi4yM42EHYEBP87FaDmFurnuNZFdGIgEwyrmO3MP7hB2Q5Wf2IpRuJS2MHUsBsOiYQT3wN32.png) 
            - First-Order-Logic seems a good way to represent the required kinds of knowledge - it is expressive, concise, unambiguous and can be adapted to different context. It even has inference procedure, although it is semi-decidable.
        - Logic for knowledge representation 
            - FOL is good for talking about things like set theory, but more complicated for representing real life situations.  
        - Wumpus world 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fspmnLmNVfylPmb2GALwKQB1tV40WlaTylZyckubjvXa2X4mZAnAghcXVfOtNEenYn_ccquA6iEFd60jzWtg9uqA3TLVuvupmrsYKJ5XfU-GmC1eJAf1AHQW3triDyTU.png) 
            - Cave contains pits. Cave contains Wumpus. Wumpus itself never falls into pit. 
            - If the robot is adjacent to the Wumpus, it can detect the Wumpus.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uwCxBfGEt3_hnkC2ZUjpVFUYYNf7AjHPkZXfVPDOdBHu1TDeDhfJHRdwmGD8eCm-DB5nPEfu2reCdrB0mBazcayCuQmyycDJLiOrpsvkqkVBNVudZ9v_ioKEjkZhcqOT.png) 
        - Logic for knowledge representation 
            - We want to construct a knowledge base, containing a collection of statements about the world expressed in FOL. So that useful things can be derived from it.
            - We want to generate sentences that are true, if the sentences in KB are true. 
            - What does KB entails $\alpha$ mean?―$$\text{KB} \models \alpha$$
This means, if all the statements in KB are true - then so is $\alpha$. 
            - What does $KB \vdash_i \alpha$ mean? What does it mean for i to be sound or complete? ↓ 
                - That means alpha is generated from KB using an inference procedure i. 
                - $i$ is sound if it can generate only **entailed **$\alpha$. 
                - $i$ is complete if it can generate any entailed $\alpha$. 
        - Prolog 
            - How does Prolog relate to knowledge representation?―When writing a Prolog program, you are generating a knowledge base. The Prolog program is the KB, it expresses some knowledge about lists. The query is the inference rule that derives new knowledge.
List notation is nothing but syntactic sugar for FOL - [1,2] = cons(1, cons(2, empty))
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/o4b2SwjuaYo8aaL2qNODZzGjUr2Ukx4N9UFXwtR6cg2kk4PgNX_A-Vt3R6TuDW8NeDePkyH4EzwJdrnI7do9xLSgWxqzgfzgeZimaznL2qze_bb_NG9UoWBKDgZeWzsu.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HVA62ZQkRHO52b7QLstAr7DA-Lq9wvHvUlZyx0Og5iqv7upRq6HrIDt2DCUOviZVnAn9qqUprKP1nZNSg-Bh_UHyma-CGtlMuIb5IJbvMV81mqCUI5UnNIQWZ001iy7z.png) 
            - What does Prolog try and prove if you pass it something like![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xBtSH9EYBY6O8Xfgh8KZRuXZ367hvrfxp4kWgbWIoXBKVQQ4JIvSVCgbeHBvnoQ1b8kzte3tiMRZsakniCLczx81T30gABgxdtbayqiASNouZPiFFqKvwRfT7ml5KVct.png) ?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BeKtOGdvxxVAj0G3RpvVJzgdwE7nUKowCRioNSni46qxGbrvNKieFuCZCNrTavHJUJtvZ7pF6lcE5KMOPJhKDHkq8MbUdLQxAnErmvyazPOOAfjOoUEoAIGnqvAWaeps.png) 
            - Prolog: Restricts you to using Horn clauses, its inference procedure is not a full-blown proof procedure, it does not deal with negation correctly.
        - The fundamental idea 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/515qGn4vvlOWgyY4c4aCyFvkccoIUiv3bVftDq3tIyL3wZaWBR5DjlSVzXfNUHiFNfw0C4_vOWDvcda_lVzh-9D53TMbUbUN5V4acuTqZBm4rVInCtWSn4rqujDz7Kjs.png) 
        - 
    - **Lecture 8 **(Knowledge rep and reasoning 2)
        - Situation calculus 
            - The world consists of sequences of situations, over time agents move from one situation to another. Situations change as a result of **actions**. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fhixOcvcxy3Qkr9o0MDVlPAlkCJifc556vaPQHFgJNdMu8M17kliQyHvCWlBre1eVVaEWvrdwPFoZvNj95jp-6UpIQ4XkvWjLO_6-dslcMuP0WkTUc6R4GhZR0Lp1pds.png) 
            - We have a function $\text{result(action, }s)$ which returns the new situation which occurred as a result of that action.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/F3_gPqmJPxKU7mZoqwvMOqO3W5Rebo9fhvmcELbNKdCdopnqwwwnqRWUBgglhYB3q4WcELccIylSHN6gUksVAylPagkPBRS6p03mREazUk5hBXJMcwDM6C2LuHRzfA2B.png) 
            - **Axioms I: Possibility axioms**
                - What is the Poss predicate? What are possibility axioms―$$\text{Poss(grab,}s)$$
This denotes that an action can be performed in situation $s$. 
We then need possibility axioms that decide if an action is possible:
$$\text{at(l, robot, s) } \land \text{at(l, gold, s)} \implies \text{Poss(grab, s)}$$ 
            - Axioms II: effect axioms 
                - Describe **effect axioms**  ↓ 
                    - These specify the properties of the new situation, that results from an action.
                    - $$\text{Poss(grab-gold, }s) \rightarrow \text{Have(gold, result(grab-gold,}s))$$ 
                    - These model the way in which the world changes.
            - **Axioms III: frame axioms**
                - Describe **frame axioms** ↓ 
                    - Frame axioms describe the way in which the **world stays the same.** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/q3QQW5z4c2TFkmUd9KOGuOvqLHb2kx4UV6AzTSrYfAZ1NMGiIf_Hg0vwF_TH8d7H21_X8AWoG_PvOYHiaMdQEl6bJ91qpD_euUbE4asweQfQjEWk1hnGLz5tapZV94Z4.png)
If I don't discard an object I still have it in the result. 
            - What is the frame problem?―Representing everything that doesn't change when I take an action can take up a lot of space.
Huge amount of frame axioms.
            - **Successor-state axioms**
                - Describe successor-state axioms and how many do we need?  ↓ 
                    - If an action a is possible, then some thing  __A is true__  in the new situation **IFF**
(You did something to make A true **OR** A was already true and you didn't make it false).
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Li_NyKnp3YmGJhNTv3f4JcvEMu7JCPEGRKMGdG7FaV9mIdswe53xbUzpJu2Xac431vOgwcNPXZSAZyaHD31TSvI5k7L1uvNwYdlJbLh9-3H8rKxml27jp6W0h2ldR8fK.png) 
                    - We need one for every predicate that can change
        - Knowing where you are (and more!) 
            - We can no easily add more rules. We can keep track of the position in the situation, the position the robot is facing, how motion affects location in axioms etc.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PBqYHZA7d1_tHPhfFJJf77IWOU3LQGxntn1mCb398d-4ZwUA2ZqwvxHUg_xJObnKyIbWmBySXSkXo5VwSx5y3SxW4WQiYjcnkNUyF5mltEPFXauezNtuZms8Jq74fFOz.png) 
        - The qualification and ramification problems 
            - The **Qualification problem: **We are never completely certain what conditions are required for an action to be effective. E.g. turning the key to start the car. 
            - The **Ramification problem: **Actions tend to have consequences beyond what it is intended to achieve. This can be solved by extending successor-state axioms. 
        - Deducing properties of the world 
            - What are causal and diagnostic rules?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZE7p82nr3UQJVFtLEIPEQRp5zJYZK4d5pWfe1fBbOdOFxdiOi0leLqhaZK9clw_UcWFmbhKRb8taTMUPfaglqnIjYiluJLq3QdHN9YSmAm_NK5DPW1_-eJN_4OGNIpuH.png)
Produce percepts VS infer percepts. 
        - General Axioms 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xP3IUlp58SkwaYOwMb6ca2e2I0NkeYmJjBchLDcYD_bZohm-eh9L8oisCb5JlUOkIYOzoULRGGPEMrnd0-ws6J7sFN8qUfPQENn2L5GpVr4cuWMO8w7xa9olUVNah8aF.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hLsaHK0x7PCxitZ4UsQcilYGJn78SoxAkek_vWmequT2NCzSy6QU-UGcZDdtqX0rKa0uTdHfMARoAmeD_WaZpyadReYNJ0vb02weU-eTuqkzeXAFMDnpVTRKmU4gT6VC.png) 
        - Sequence of actions 
            - What do these predicates define, and how could we use them?![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/G2yrqm6R9fixoRMe1S5Y6iiyCiPx9VUnFKDCuWmIXqi3H46fUxXQEHiX-r_T2A5UQd9DSxxTNdwy-EWWBBW5OcDaKJVt1OBBDK2oUSE7EL-xLX5EwRc8yEIubXUW2FRS.png)―These define the results of doing a sequence of actions. We could do the following: ```python
 Sequence(Actions, s_0, s), goal(s).
``` Or in formal logic:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fQRyIIu92zBaB00ByBX9hSan1yHh6wBu3YW09S_Ogv_s-naR_VPSeS75JD7xNZm3tB4VKj7W7WF4lGGBkooFIE-vsUK2dexcaA5-uUbjndcFg_h7A2MQoGA4cDFfycU9.png) 
        - Frames and semantic networks 
            - We'd like to maintain an **expressive **language while restricting it enough to make inference efficient. 
            - 
    - **Lecture 9 **(Planning Algorithms 1) 
        - Problem solving is different to Planning 
            - Consider generating a plan to 'go out and buy some pies': 
                - there are  __too many possible actions __ additionally **many are useless. **
                - A heuristic to rank states doesn't help me ignore useless actions (mow the lawn, have a nap etc.)
                - We have to work out  __how to get the pies __ whether that be, buy them online go to the shops etc (e.g. find a method of search) **before we can start to do it.** 
            - How do we relax our requirements to allow for more flexibility, and reduce the complexity of the search problem. 
        - Difference 1 
            - Planning algorithms use a special purpose language, often based on first order logic - to represent states, goals and actions. 
Actions are defined by preconditions and effects:
E.g. if we want $\text{Have(pie)}$
And action $\text{Buy(x)} \implies \text{Have(x)}$
Then we ought to $\text{Buy(pie)}$ 
        - Difference 2 
            - Planners can add actions, when?―At **any point **at all between the start state and end state. Not just a at the end of a sequence starting at the start state.
E.g. I might determine that $\text{Have(CarKeys)}$ is a good idea - might reduce backtracking later on.
            - So we can search forwards and backwards in the same problem.
        - Difference 3 
            - We solve the frame problem in planning algorithms by―We **assume** most elements in the environments are independent of most other elements.
        - Example plan 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ltnMaagx0VdpWcDQcX2KTnbS2bsTDJ0Gq2rDpVlAnAlfaybS7Ewna_aQsiqb9JYWG48C9c7nAO7bPHahpNnk84AaKy8Sfc7F2zWY0xIpbqOYotkMsIZpsnWbwrFA9-Sp.png) 
            - We start with
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/O8nWQLA9FaOq7E45ypYKNe-zg2VfUIgG8e13qAj2bEkp2o2JEJA0aaw8zKgrUiOjjVwOTQHNeRqNRqHAs1hX71wqBZNMGl5XfVVz-RdFAoOoIISUpOju6Czx4hh6cSQD.png)
We want:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NkJWawCsa4WXhrNOp0cALLEU2jhH0Ai6kSvvm4fxPXAQo-m-swCMNqQYi7sWc6_-dAXWtq3r3zrrQ1_Uj0dIGtSYodFOZk_OdLLM3sqLm1Rb0oAy9D5xwEFoMBdt_1JZ.png) 
            - Note that states are conjunctions of ground literals, they must not include function symbols.
Furthermore, goals are existentially quantified.
        - The STRIPS language 
            - Represent actions using operators:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/a87tgU77Ab3aAcj5uAvvPldMxiEf8ipvNBi7bPAcWmQ4KJVXpqeJer_Cl4_Li2VmC8AsTwsGzBe_kTY2l2ar3LRKqkF5g5BEnP9fJeutX7DnRG7A7WB2Ns6tgmaLBGu7.png)
Where the preconditions are at the top, the action is in the middle and the effects are at the bottom 
        - The Space of plans 
            - We search in plan space - start with an empty plan and modify it to obtain new plans. Incomplete plans are called partial plans. 
We continue this until we obtain a plan that solves our problem.
            - Three main operations on plans are, adding {{a step}}, instantiating {{a variable}} and imposing an {{ordering (places one step in front of another)}}.
            - It doesn't whether you put your right sock or left sock first, so we can reorder steps. Don't have a commitment to order.
            - What is the principle of least commitment?―We don't commit to any specific choice until we have to.
            - In a partial order planner―we only specify some parts come before others, not a specific order. Can linearize in many ways when we need to.
        - Partial order planner 
            - Contains a set of steps - each is one of the operators. 
            - Contains a set of ordering constraints - step $S_i$ must occur before $S_j$. $S_i < S_j$. 
            - Contains a set of variable bindings.
            - Contains a set of causal links or protection intervals $$S_i \xrightarrow{c} S_j$$
. What does this notation mean?―The reason for $S_i$ is to obtain some c which is a precondition for $S_j$. I need to get my keys, to use the keys to turn on the car.
        - The initial plan  
            - The initial plan contains Start and Finish, and the ordering constraint that Start < Finish. No variable bindings nor causal links. 
            - Start has no preconditions, it's effect is the start state for the problem. The step Finish has no effect and it's **precondition is the goal. ** 
        - Solutions to planning problems 
            - A plan is complete if―each precondition of each step is achieved by some step in the plan. AND there is no step in-between which removes that precondition.
            - A plan is consistent if―There are no contradictions in the binding constraints **or **the proposed ordering.  
        - Example of partial-order planning 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HLxd4YUSD5Z-WVc313ABN4NLSo1igyF6nCKNoPwrHfeYiHQrQr9Wi8tolB49zOFocfx8Gf_-dBMFovtcvYPjoVCkXsiRCzVbQTRwfMjHntfJETn5E1GKLEypweqbXgti.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AIqMVPboU2Y6vnx3oZqBAcrd9kQAUjipXfJs666jB_q6IXoJfi4q2QRP19Hs4GkyDfa84tAq1fsEENKcXRpxb49WmX2OTRsE_lLPvIPSf_3CP_yBq6DRzcHkkrjZxL8W.png) 
            - We first add a buy action, instantiating y to G in Buy.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BvdnWxUyOiIXnZ09tf9wfpMuKmoh-JC6-Uvl-9I7dtfTneAA24CTkx1WxeR__U_8CI9wKt2xAz-_G5h3MkrAWMzuiI6fH6cBr5pXTjWWLRhjkLYKiTOf0d-n-1922raX.png) 
            - We then match Sells(x,G) with Sells(JS, G), binding x to JS. Then we add a Go(JS) and make sure that happens after start:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Noe6oziLxTFsb5idhsw_hKKaNdHNwV8t6qHVc52jg6WNu7I4u3lRT85p2ECOU8C9kdbPTJ4GfCZl8lRP78mANWh7JFCREu5dsINnNFgCnTol0jWPPETs7z4ewwISwUO1.png) 
            - What's the problem with the following and how do we solve it?![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MfVXhrCRmkRGfar8m2gqzjMq-gS3tgetaDXjFTA8V2Wl_gzJ32oVHkxFONrsWAyIeSQ2ZFzbcu9zjIwWIRV1mzMNUS_JFko4FMuQBF34ww-Vvbr12jtpN8uylnPSAdoV.png)―We risk invalidating the Go(JS) if we Go(HS) as the binding of At would no longer be Home. 
E.g. Go(HS) **threatens **to **clobber **Go(JS).
The planner can try and solve this by introducing an ordering constraint: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Tl-Wy5V3OkEvyY4RfQQuHH8uyWySjPPvBN8JRfYydf8ZOdykZKlctswYYNNZWSxlxoIPioRThujkS9EH5WQ3Z5iAibzv-nZscaVFVF78Ggs5Kb7evOo5HI1XVW4Dc0dK.png)
E.g. we add a causal link from one to the other and add a precondition. 
        - General algorithm 
            - Describe the general algorithm for forming a partial-order plan (without variables but with a partially completed plan)  ↓ 
                - Select precondition $p$ that has not been achieved, but is associated with a plan $B$.  
                - At each stage the partially completed plan is expanded into a new collection of plans. 
                - Either use an action to get p, or create a new action ($A$) to get p. 
                - Then add Start < A, A < Finish, A < B and $A \xrightarrow{p} B$.  
                - If the resulting plan is inconsistent, generate all the possible ways of removing inconsistencies using promotion or demotion and keep any consistent plans. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bSKPU9JOS01HSIxsVjTxtVbP8k1LEeaToWHr-l-PNEwJA5kxHRwW_DqhcyL6V_zDjautCPPQdCZIsBZUBRAdavvtAPuvHdP2YePu-A34RtDiKPXZo0Mk8mLqJ0cfUw0u.png) 
            - What is a possible threat, and how do we deal with it? ↓ 
                - A possible threat is when an action would cause an inconsistency, **if **the variable associated with that action was instantiated a certain way.
E.g. $\lnot \text{At}(x)$ might pose a problem for $\text{At(JS)}$ 
                - We can handle threats by adding an inequality constraining, e.g. $x \ne \text{JS}$. If we would introduce a conflict, then we discard the partially completed plan as inconsistent.
        - 
    - **Lecture 10 **(Planning Algorithms 2)
        - Using heuristics as planning 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NBrHInkHb7-xkPRTPF5DDkVdm_o04Tt2dFsQgyWa4eaXiL7z6N96bGv0Y1MlwFlGEWouYUSWJOAj8hCIr98teHsISmJEInB2hbNu8ZAiIGVKerajLWf90CdOoeY46S1G.png) 
            - It's a lot harder to measure distance to goal, we don't know how much more work a plan needs. No representation of state to use.
            - One heuristic would be, choose the precondition with the smallest number of ways to satisfy it.
        - Planning graphs 
            - Planning graphs apply when it's possible to work entirely using propositional representation of plans.  STRIPS can always be propositionalised.
            - Describe the process of building a planning graph  ↓ 
                - First convert your predicate (action) to a proposition - by instantiating all the variables all the ways you can think of:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CSYpGSX1qZwN5Kl6IwkyHY7bWwAERQlXJ_UXTKtmpQgpnAMjNK5JRzvcrL0jYFtkMAwtXvShFsbUZwqEUT4EIM8UAXtQHdcAKZ5DpMOJRpcY9Ch5XtHmR2dgtvTZAxEf.png) 
                - We then first describe all the state we could have to start with, e.g. $\lnot\text{Have(G)}$, $\lnot\text{Inflate(G)}$. Then enumerate all the possible actions we could take, including the action of doing nothing.
Continue doing this until we get the combination we'd like.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6tHJLNrOMEQLilkHmrFzyBYfkljFNNjZ6QvQ7864WmJL1QlavzfQNLAK5IPHSofpMGST_oOKobbDqGJXsLinOuWLIe9gFk3Osj8_A6CdwIR_tSg6KeVCTM6SRHRQSxHd.png) 
        - Mutex links 
            - What are mutex links and what are the three types of mutex links for actions and the two types for states?  ↓ 
                - Mutex links describe which actions and propositions couldn't occur together. 
                - Type 1: The actions negate the effects of each other: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ju-Z9cSHnCeHby-VMUYvM-mdQpC24ZwC23kN1VNRccDva_wrBYGzvxX8Eo6KRX9WCphLBdrq2IHwDmGTgOQrZQow8TyfZ1T32zAFRg6gzXFYilDTB1BIguaDucF91uAG.png) 
                - Type 2: The actions interfere - e.g. the effect of one negates the precondition of another.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GKh23seyQT7fjzSE5o5JvJDiwval2I6WXSowHQa7dt9UhMvNHZQJa9My1pdi4ds_PITv9BJoII_PWF83sWYmBGfyBL1CkgzoBYymEi_udbgmpHBaxrlptFyErkUqFASs.png) 
                - Type 3: The precondition for one is mutually exclusive for the precondition for another.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/siws7YUqcQsr-ZzKETCdOvYyhpdHktcXKgzOAC_7MZWElbhiUme9X3DVQQfNWrHmlTD_rjJdF072nvZWETXFFlBRS98hpQfOjuNrrnNgyuU10XXL4ygVPZ_nu9P7oZUa.png) 
                - State Type 1: We mark a pair of propositions that cannot both be true simultaneously e.g.:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OGgaVa0qZReCNr2nq3LFzQRPbvofTF1kGz-xMj2iiCkWiTywAYXObxblv2Io3If4X0fXmw_C_yGtIrcSEje4VsElCOWmTCUPKFUrZwSYWAv4LC_sU5HnPjvOwsWP1PJ0.png) 
                - State Type 2: We mark a pair of propositions that were created by two mutually exclusive actions.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1xVBG3PVdlvBwqvYogrbM12JFVvqxs0hCC9U94f6xz_wDjn9mgeSXEWUowCd3PcLbEybSpDIxRLAK1A0NE8n8jcUTbT-fRLYyv7_OC55vj3JfXUzAfYpvEx5C4BrMl58.png) 
            - When do you stop building a planning graph?―When two levels are the same.
            - What do you know when you reach the end of a planning graph ↓ 
                - Anything not on there **cannot be reached.** 
                - The level cost of a proposition is the number of the level it first appears in. However, this could be an underestimate as you can have multiple action usages at each level. **It is an admissible heuristic.** 
        - Obtaining heuristics from a planning graph 
            - Describe the features of max-level, level-sum and set-level heuristics ↓ 
                - Max-level: Use the maximum level a proposition occurs at. Admissible, but can inaccurate. 
                - Level-sum: Use the sum of the levels a proposition occurs at. Can overestimate but not admissible, useful if goals decomposable
                - Set-level: Use the level where all propositions appear and there are no mutex. Can be accurate if goals tend not to be decomposable. NOT admissible.
        - Other points on Planning graphs 
            - What two things does a planning graph guarantee?  Explain the confusing one. ↓ 
                - A proposition that occurs in the graph **may **be achievable. This is true because we only look at pairs of items for mutexes. 
We could look for more, but the computation cost outweighs the gains.
                - A proposition that **doesn't **occur in the graph **cannot **be achievable. 
        - Graphplan 
            - Graphplan extracts a plan from the planning graph.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QCR1YCiSmsh8lcJScHBAef8U_2kteo0WO5Wj_aFkUwCab5sfE7pORsd7gYXSAbSRbvq8G-X5tsnUb5Fme04Qr53fSFQ7nmQRCcj8HeNQnMHwDjVgGuBGZb39u4ArwkGi.png) 
            - Explain how you extract a plan using the Graphplan algorithm  ↓ 
                - We start at our final state in the planning graph and take the desired state as our start state.
                - We then note that in a search problem, reversing actions will result in new state.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9pp7xdYyhYpMBLQJMeRWE6uLyOKNtgYszZl5M17fEaMbiebmN68X1e_dg1Y80Yr-z-MXhwjlXGU-1VU9moVJ2K4Up57A1qIcFj4P79x91v0PqszpyG-yAEJETNwaGp3s.png) 
                - So we choose actions that will result in new state, move to that new state and repeat.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pqXgOnMc0gjdZSytSkd7Wyt_uKKYhcwx-ehIRasKlVidjl5aJjpYG_PUW8UiqQXifSUbrZd-qPQd1FUtMCt07q_dYgfmozuRKZosgM8xWVvQJixWVlyIIw7f13nDWVGu.png) 
        - Planning using propositional logic 
            - Give the basic idea for using satisfiability testing for planning―Make a sentence of the form: ```java
Start State AND
	Description of possible Actions AND
	Description of Goal
```Then find a model of this sentence, e.g. instantiations of variables that make this sentence true. 
The possible actions will vary with time, so we iterate over the times and generate the possible actions up to that time. Then we find a model.
            - Start state:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZqKJDwTiDnCx0GEBKzn-mT3sfNnJAf0bBX3lGqONWOpFn7jgGRkXOJnOrMBCiAD8_qH_Mooc1N0tFA6ON3f43nhsYhB4wxvS6NZ7dxK4gUOKC-IwMdl6o9L0x9LeRAqW.png) 
            - Goal and actions:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U_Qu47WmAIv_hDP8p0SESJsFVls9NrnNwV7ZheHGk_W5yYIZFXeCPL0Cs62Aa-_W5tXbMxLG-59XERo0pXGACKM41ED5EiSbTAHV1XJEWIbxuWiI3AdGBv0H2-PNeiy3.png) 
            - We need actions to encode that each person cannot be in two places at once: So we need precondition axioms
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4QOcjcvEiv87_yxhZhGhEw5w00XeyQ0szmPNof9OcqV-liVBFobAX1qgDT1I9e65Kt4SneC-kRMIzxt9iDqq2ggsVgF3UpChfVsmIeoYlNB-70fXt_DBtbZiZ-riHoOO.png) 
            - If we have three places and want to ensure a person isn't at two places at once, what's the problem with simply doing:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bK0m6bN4f8Q43ii9pesf5d_ZLpimwnpW-LaExELOxFWw2neISIIDcFI78z5bJhuN_E4CfM_I673EeLNDO1cZYyd-6WV1QjGe5v26-Jz4mIF8TYoFh167CP16xsnUAorr.png)
?―This will generally result in totally ordered plans, things always occur in some exact order. 
        - The state-variable representation 
            - Another way of representing planning problems, which is easier to convert into a constraint satisfaction problem.
            - Domains in the state-variable representation are methods of {{organizing objects}}, e.g. $\mathfrak{D}_1 = \text{\{ climber1, climber2 \}}$.
Relations and functions have arguments chosen from {{unions}} of these domains. 
            - What do functions (state-variables) input and output in the state-variable representation?―The take a current state, and a domain - and output a subset of the domain. E.g.
$$at(x_1, s) : \mathfrak{D}^{at}_1 \times S \rightarrow \mathfrak{D}^{at}$$
E.g. we ask where the Gorilla is 'at' given a state of the world, and the function returns that the gorilla is at the Jokeshop. 
            - What are **rigid ****relations**?―Relations that don't change over time. $\text{sells(jokeShop, Gorilla)}$ will never change! 
            - This solves the issue we were having in SAT. We don't have to encode that an object can only be in one place at a time - our function will always return 1 place!
            - Actions have a name, a set of preconditions and a set of effects.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1wOanK-zs0IB-5mPWOudZeqS1zdxoLZQBWJmV2tt1gpH0reWaBXEWnh47XlYOqlz8Sw5OQBZkakeqAALnEJkAj_sWkFtJaHxKRjPxpnHaRfqy3xVihCdsN80WjzLsAsj.png) 
            - Goals are sets of expressions involving state variables, which we want to fulfil:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4bLtIRlVvU5EzATiOA3-fjaVaI5-XpVPMWxQ3loZuDBgVPj42z1XbVyv5Cn1ROA5ZhBGBadEVOQi8-UU1i3ea99X4fyGYM0nlrmPGCdI8YHzsCqJ_Sbf7R5_FaN0fxW9.png) 
            - What is the **state **in state-variable representation?―It's just a statement of what values the state variables take at a given time. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/umuDMYCowPbMAxh6ZwHVD19c57mo_2Spu_XdM8y7E5vvGN9k8mXQ6Xlg62Vg6dr3Qig4KYYrGFNgQ4bGeQcRsQtrnwa1u2drYvOE2t0GGxe6QDP7GDi2Oq5f7Q_NK6FL.png)
Exhaustive enumeration of all the functions with all their possible inputs. 
            - When we apply an action, we first check if all the {{rigid conditions}} match - then we check {{preconditions}} against the state. Finally, we {{update the state}}. Note that actions only update the state they effect, solving the frame problem (kind of).
        - Converting to a CSP 
            - **Step 1. **
Encode actions as CSP variables. We do this by―Encoding all the possible values of the function in the domain of the variable. E.g. {sells(jokeShop, climber), sells(jokeShop, Gorilla) } etc.
Additionally, an action can be none.
            - **Step 2**  
Encode ground state variables as CSP variables, and a complete copy of all state variables for each time step. How do we do this?―We have a CSP variable for each state-variable at each time t, who's domain is all the possible values it could take:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/n_yWZ8H3rO3wxl8DLT9c_8XKDwxMiDW4LPrtne6mjZewrfGedJl8rhhROquF9Ohys4eCKGh4YSswyoEcdhyJfng_UxLu_BSNvdQeMNuhhwsVmUD2ec_dfJQUFL7Vq3nF.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2s7mTsWTqdcIHIcjNMkNAWc44LmESqlwWZCAE0YFqU03Wg8jeD2hiHIDqEBRf62qytVP6aJQIUABsTO57SaXZKrGkI9EB9kC5-i7PTAo4FV9xfvYf44GkoV9F6aB6vb6.png) 
            - **Step 3
**Encode preconditions for actions in the planning problems as constraints in the CSP problem. How do we do this?―For each time step t, and each ground action t - encode preconditions for that argument using constraint pairs. E.g. for:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vEqavql9HhJZvF87dntE61NCmpdoFag9xtuYpD6jz5XTis5UyCGtgabFkLO9YJeNK3NA2HOZrPJ9vTbPI6MQ5sFVEZ-cGU5MGCConDZW5vnJTlZmBRmnp989dKLfxJIJ.png)
We'd have:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZZywqS3mAE09nl9sUv-7y931ITkkn33Kh1vsCK6mwALkk7awV9Z697s3eD2H0ZffIQagAbFmf7ZoSMFrrHmkSiy57aLIdnJO-xsaQlW43jHrjrivDwmDtRV0M_OLcary.png) 
            - **Step 4**
Encode the effects of actions as constraints in the CSP. How do we do this?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0TWra-F9CuksoTIyXC-9F9O6Mt2o77-_X7JFuauBqx5hm-hP9RYG-eFWsBzptIELoTYliwYR6XH3FdJXHp-0vqRkID1MwNMz2GVHxSjZbxU6tvhUARh2BJkroGhg-oWb.png) 
            - **Step 5**
Encode the frame axioms as constraints in the CSP
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_4GYupIADjdBENJO8fdo765TWfVhl_Kf2j1OyK8wvIRx0AoHI6gCRuVzYKAHNyk7ZSOJee9VstCYFElXPuJHCbYobcWBVHxpEBqSnkqZQlAuh8CB0jMsn7fkr7SE-Ed5.png)

            - 
    - **Lecture 11 **(Machine learning using NN)
        - Supervised learning with NNs 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NFxRwqGXC1u1nDsywfVj_VV1t3GYQ1O_UII6k23iumGubA-mP9DNYSsrSZnBqacKnlOVpfgGWLMZy29PQoZYvo_lob_YtIwbBdavhSgLWcLBiPF6T8n2fMahvMdzYwr5.png) 
            - Each collection of measurements can be written as a vector:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/C2rsFKJyDjTpWrJcVDczqGEbqBKDqhHVhz1p1C2KlXay4J8x6EP1vylytu4jb7t2z-C5eET2fY3KQayZI_L4F1tz9D1F_DYtpsuL7Iv5c8Zi0tLcZIOL4pj2yH0ySlMZ.png) 
            - A vector of this kind is called a feature vector, where the measurements are attributes or features.
            - Features will be:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cpHLnPQ_zAzyAQ3vXQZGFC_Fm4pO02NRS_meIsH9mWQqmbGj2MG4tikpI4zjTfsK9yt0tA4nnLKU801VBv3qa_nkdjelK3wn-2CIg7WKSdHcrXfIa0jvD_BBYhl4DqZv.png) 
            - We then combine the features, with a dataset of patient histories and whether they had the disease D. Forming a training sequence:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1bHSDnc-VD6Ohu0YgAj5EvfT06DpQwEXH2AkxZ5TwfGItM0yMgpsNkT8eheKfyZn1vWZeqTT7jT8-QN59JJt1FuRjwTgpUGXWTikJQKYnZZnNoo2wEWAPfHaE9RPhw-H.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yTr9utsAxe_z0gQ2e6w7RV0PAoSJipaR5twHTdNHt6TDDZOO0K8N6RJJ_mC2izX1ctYh-KYBVPmnoUO73Uc5Jv0fus2Lee1c_V6k2HsrsiZvPfTqt1bXNF27zWk2H5fW.png) 
            - So our hypothesis can be viewed as a function, takes a feature vector as input and outputs a hypothesis
        - Classification and regression 
            - Describe classification―We assign the feature vector to one of c classes  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3h7hEeekIN3SDfZThk8tLwfSqG4sA7z9ezINUNCoS_0qfVy7z2I9ZZU2XdU3xHpTONOK-faqwmMqh_q8wcwfUehPynHO0KbF0BHDZwBPIAPwo2njU7N_gAdUF9al-vHG.png)
These will contain, has the disease, doesn't have it AND importantly - The model doesn't know! 
They might also output a certainty - if uncertain then pass to human.
            - Describe regression―We assign a real number to our feature vector - we can then assign this to the closest class, or it could represent a physical quantity: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6tHD8rrx7-XhmJkPt_DAJ0Qiz-5h-9cm14fRzIlkJViaGi_llOgNhY0AjuZFFQJsxQ6AE5-g65NPFv4MtewA0oDQ8tqpHlAcmpa0xEeR01g1z9IoxHHakTm9S1nZdtPl.png) 
            - We don't want to design h explicitly
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LU4CromGKMgkvCyndauVTlb5XHIW6lSjMDPSFLebnutONmnAgIkArpM-2sPJVCYXKWctLwHVnxfHAutXb2VJ3ySkZR_9eVugP8EIKISV84t5G7OTbb4CK7IDLS8COm8k.png) 
            - There is generally a set of hypothesis **from which the learner can choose**. We call this the hypothesis space:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-eGAsW7qpd9fl1XGcxwn8FEvljsniM8q4NpnKg0DCEppxivkvPsi3Y1lxsyDQ2AnLWWX7ufPbIAqlOFexCamxzo-AiIX5nW2RDl_CwO9nxEIV0l-cdUySeGuUyUF73-w.png) 
        - Supervised learning = Curve fitting
            - Nature picks a function from the hypothesis case, we don't know what that function is and we only see points on that function (training set with noise added).
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nOb2l9ZSOpQ2VHVBNNZNNnQcVlLCCv5qpYautX0Cggl8_PpNLijmOfWUYgOEa11-Gl4jJnlWeRDH1GhF3Bvubj-h8dR8dpWrP32pCr6NZwIjJ4qcpJLggEwy0wSHTBgh.png) 
            - We want to infer h, based on s.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/d7ZsQ6x6ZuXOHC1dMz8btuzkJ35gJ4p1vj3Kk7YO5hnqMD0x-kwCyeS8YdTdbH2g1UW8J8JuW8Pf2JqLZF-AwmXksr-KibtTXC_xZ_SqT0ctophB05pH9H_X-RvWv0YA.png) 
            - Describe how we use the following function to choose a hypothesis:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mNflJQJtCPKAjHamBslxgs5df9AlyjibPLa3IqFajRgHUIAqYadvhRKGflauimpg68yJkeNNeoOyqAJLHDbKyfjB8-UINsX_8USQlHVsLyBsJDRSGy_8e4bo4hQf_Ce2.png)―We pick a h in the hypothesis space, that minimizes the mean squared error of the entire dataset.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VVS9ASsfaDAUCrLvzpx3XUD90MhV47dwCZeVVHDWLuwtWBvKT3Qc5lCjr8w7QjnQG_l-cudpzfO2cfGU-cPQAuqV-IvHkBSBNa5DidgChQRbYaTnt7npZMio-Z9LBAr2.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KIKez7RuO4sWWjrR1Mu2re5pWqoP4mhe4_6YkIL0JQcN92JLzWsPFnNtkCnmm__Tn1MWCYpLbYxj0d6ohKOPgGcEOuk5s3PrSgta_lH9lsXV7upmUcZV9Lq5Ad_e1ZyA.png) 
            - Problem: What hypothesis space do we use to choose h' from? If we choose a polynomial of a higher degree we might be okay, as long as we don't lose generalization (overfit). (We try and learn the noise)
        - The perceptron
            - In practise we'll have more than a single dimension, we'll want to do curve fitting in n-dimensional space.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uiTv0x6gipmpj5WdXyHLDWVVuOdp9Zh3cjN5tw4cLT3VEaGOsVlbbcG03yhH7Y99jEWWHCfV7f6TA9It1ymUzF8FfwJmFnO83j84uSNQhHfwm7O7MQeXyHJLDWjV6aEg.png) 
            - Describe a perceptron―A linear function modified by an activation function $\sigma$. Where the linear function is the sum of some weights and inputs and $\sigma$ is usually a step function. 
Now we use ReLU
        - Activation functions 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iXokJ8FMcsBF-W4WyRLh1-Jf70uRDq2cpNe7ha2R3K-MeeCeY0bEKnxZtPyQswks9UIccTfFRy0-GglgaQ5BbDaMKsyYru8egwhTGDf3m8zg34Gsec0I86fAJg0ShMWw.png) 
            - What is a Linear activation function forming geometrically? $$\sigma(z) = z$$―We form a line, plane, or hyperplane depending on the number of dimensions.
        - Sigmoid function 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8IWssj-aMg8ePxxDw9kXIcQxU5vN2SRGfv2KqwvFDb2BpcvKj3Hiax0z563FidA2ypfapNeYo12Wm43zy1IueVg8ZVkHBPSEVQ7MwT5IunL0Q9abN8yS_0y1KXd8aMk3.png) 
            - Give a reason to use sigmoid over step function―Sigmoid is differentiable, step ain't.
        - Gradient Descent 
            - Assume we're dealing with a regression function and $\sigma(z) = z$. Our error function is the mean squared error.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lJXOTkvBmJjbXYTlbV3USLxQNCYfKmqk6acosfRxP-psfVddlWr6Z2CH9R0XJ2hUhxrgDLMA6gtKt4JRmDE4NIxRsfyz_9Lcjn6Y_RruCPhprl_xXo6vwuk3qWgF2vsN.png)
We want to minimize this error, how do we do this?―We perform gradient descent with a set of weights. We compute: $$w_{t+1} = w_t - \eta \ \frac{\partial E(w)}{\partial w} \bigg | _ {w=w_t}$$
Where  
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/u5-P4H92v-qoq4W8_cOpI4FnbM2lK_Nfy-ENdLm54XmgwZ40CCRlC_XLRRMD1lded148U-4eXC9e9-xEUWMwj9czdfP0Mr68ETI0MjSLPuaKEPoRYxHTXq0kQxIbZxhY.png) 
            - Explain each step in this derivation: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5fRbe9IwVZwAfaBJ9r5RYDWFnAQun0TKxJmfyhCOrUB91VUCQDQb-Ic4aMPz3gWgbpUzSesDSR_JiIXk4PIp51QhxkBAqRmEhKFscS8bcan55KC9h6Uxn67D94IE-8CO.png)
(ignore the blue arrow)  ↓ 
                - From line 1 to line 2 is straight forward - as we can always swap derivative symbols and sums. 
                - From line 2 to line 1, we apply the normal chain rule. $\frac{d}{dx} (f(x)^2) = 2 ( f(x)) * \frac{df(x)}{dx}$ 
                - Finally we note that the j'th $w$ will differentiate to 1, leaving all other w's as zero - meaning only $x^{(j)}$ remains (remember x is a row vector so the j goes above).
            - What is the same for each weight and what varies in this (the derivative of the error w.r.t the weights): ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yhmelvT74db_ETT6NQftEseQMk2-9jdpfwZ-G4AxOUsFt5jB2S42rzjdO2A89ujixk4K2OJh8cypyNFkGfiB0AtrWa6Hv0M155qxaf0K89UIE9BVZDEr5lR7E4FOF6Fl.png)―Only $x_i^{(j)}$ changes - everything else stays the same. We thus gets:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V799jHKj7iaU_ObjFRJ6bsxd95NYF6CigOixlf_QW6wRXeDo28vsn9e8_p9UkTSeqUk_3DxUVe2FRYG95ioxU8XgYuKyck4DF0vrvxLlZ1ORpyhKAjnNh86RXcpN4-k1.png) 
            - E(W) is parabolic and thus has a unique global minimum and no local minima, so this works well.
    - **Lecture 12 **(Deriving Back prop)
        - The parity problem 
            - There are many problems a perceptron cannot solve:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J3r0UK724BtLVsALCgD45be3r5EbjA4T_VJ9KlY6bAv21sgLP-t7Nzycx1QzBaJ1k6YqCvT-TDO_2RzvhcNGdnfxj-daFMtPRMu6uc05h5Lp1Y3Q-AoBtN8cOzAIFXqr.png)
We cannot divide these! 
            - To solve this, we make each node in the network a perceptron: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FVtPngQUatZvYzTOaPbitWVDHaSwsKs-Mdm_zynGNeu2QVamRN1Osrhn60bkXvAppawd86ZhSr6dtPSGRFqHhOEJyB_FDDwx0VipN2bUvlOAdjpDLkCjC5KT2iUeWEbX.png) 
            - Directed acyclic graph or perceptrons forms The multilayer perceptron!
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8aS4Bh1x9u-Enhtb1VQ8So3BDj_vyOZgujQycUGdRtMnUDX0NnnVG2MA1E5PXX6lZ3EExxeGdlE_OPOhC4PmRrpTCC6ailquu1YMZnoj3UjERVFNteTcMqY1gSDwCobJ.png) 
        - Backpropagation derivation 
            - We want $\frac{\partial E(w)}{\partial w}$ which we calculate using $\frac{\partial E(w)}{\partial w_{i\rightarrow j}}$. E.g. for all the weights going into our output.
            - We can break down our E(w) into a sum of many E(w)'s and then sum that, meaning we can find: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Aa6kLp4wrr4GVSy_L_ShqhGfscb6qvtn5ERHV-24nw3i-TIOwYh-8SmTkq1blDDYI4UzogpI6jtVTGATjECEPCjsCEjb5f66-u23aJMTi1jOr-N-pCn-0jDqXNHUrkff.png) 
            - We start by saying ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FXF5prL6Yp0W21tcbmaPhtEHi1uuqDqqMYxdb_9xV-HZdosA8iDzV3eYkqLc4rRgmccyECCpHDAT1v3hFGEom4H2ZqWCFYRJJvv9jJeA90zFJwh-OMZOhbf3R3jNyxiy.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_WowIbcgamAWTRkkIknDHyjoj1cJQ7VmNXVcKSCC5PJ6ia9TcSUPTjyNcvz6rfwP0BLhElb9eGSJUqNeUGGLmpMPX9AlIOFcgjsOOlC8M5dGwRcSn8GvJwg3uJFEsFmZ.png). What is $a_j$ and why can we do this?―$a_j$ is the "activation", more straightforwardly it is the weighted result of all of node j's inputs.
Clearly the error relies on how we change the output of our node, and clearly the output of our node relies on it's input weights.
Note that $$\frac{\partial a_j}{\partial w_{i \rightarrow j}} = z_i$$ 
            - So if we combine these, we get:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Co4rqkkeEKhUskptVQ_SyFlGJXbJXyd083uUsoRS6vrgmPecOdvG1jKO1blEb8Pp0Zm4pxyHD5VI2VLoLo7U214wYhkvba4qQUuXq8-reH0bZT0ya0T2rW62CCmn4jn2.png) 
            - So we want to find the value of $\delta_j$ **when j is the output node! **That is the node producing output: $y = h(\bold w ;\bold x_p)$ of the network. We then find:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eOVk8B9IDB_hZo3cBdzFuzmYJu8B8uIFFcTSrwLdMJc_ltz8GlAZw4ePjjqMfoikDhxY5SmoOvD5wnFFPgawRNPAX74FWk3zcuWreD0zsnTRx8FQHsz1O02ixasmXpeO.png) 
            - We can easily find $\frac{\partial E_p(w)}{\partial y}$ - because the error is defined in terms of the output node:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/n3qKnS-T6LCEWyc79L-F49Nsf8KsgIX6cI0f3FUqlxs7scs77hz1-8XE3cnlD0peWFkJ_7WLobgmyvsjvNUmhae3oC3iEb_-I3FepvNc7_DId9OCU9-396KHQrGMC8JB.png)  
            - So we work backwards computing deltas, we assume **we know the deltas for all nodes further in the network.** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tOj5-_bijxt9Qcg-duK3Fs2iteQimMcUxBPcZQqyzQKBiE3_vI1zKWCQQNfVO8XlsI2x4NRTZqN1GppKJlMrof59jTMKC8zxLJIpvkfzJ2NesSgfcRTF0ZxyJd3hJ9dT.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3kR4hUEVHOe2COYgcilluLOaj__2X7HlbnM9ywL6ukeqlMfjyqWqz-pdrLnOlGvYO_OxSmvvMX20IXc_u-S6az0IAMj3jxEB-LHEIC2HyHjyU-3Mpp8paTKiO0ywE2H8.png)Explain this derivation―We start with the total error, with a partial derivative by the output of j (before the activation function).
We then note that this is the same as the sum of all the errors due to the connected nodes, multiplied by the derivative of each connected nodes output by our output.
Then we note that the first section is simply delta_k. Which we assume we've already computed.
            - Finally we have to compute the derivative of the activation of a connected node w.r.t the activation of our node. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GDMMeOSnvENZsHKVQXPot8K9K0YCTKwMGzOG8RLLITZfTCEyGwduyxoWSQV6i9Xhy4K-AWEV5xvlLt2oKZGRB_Rj1t8qFyH2tl3KSVgsVltjVCxEhOetHZj0adkVhxab.png) 
        - Batch vs Sequential gradient descent 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-VWPEafRfZsQPc8ndvZqWtVNHaJ7L-57iTGjDAaGAmxzzSNZV6ayZngUgG6WJvOs8sels1FKdKotaBBTzvjXOvWyaUJMGxyYJ9Bdzlvh1oTLfMFWgYT0YfqU9lHcCKEp.png) 
            - 
    - 
    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/55Eqle7fOUeSTnPmzPbkciG_m-ryibCPv6IAbY2sRBsQAnq79GQHblePjV2xWaWc0kuE_Cp9ShvVRtEiMVQeHUmP3G5hTufGlBzj6vOf6_PgMRm_LEQPgMvhn6tQaG49.png) 
    - **Supervision 1**
        - 
        - 3. Search 
        - Question 1 
            1. Explain why breadth-first search is optimal if path-cost is a non-decreasing function of node-depth.  
            - In breadth-first search we examine each node in the current depth, e.g. each node in a layer of a tree. So, if we find a non-optimal path - there must be a path with a lower path cost in a lower depth or at the current depth. 
For the first case, a node can only appear once for tree search and for graph search we'll search the whole layer before deciding. Thus we'll always find the best path to a node in the current layer.
For the second case, if a path is at a lower depth - then as path-cost is assumed to be a non-decreasing function of node-depth the path-cost must be more than or equal to the current path. 
Therefore, our current path is optimal and breadth-first search under these assumptions is optimal.
        - Question 2 
            - a.)$$f_1(b,d) = \sum_{i=0}^{d} b^i = \frac{b^{d+1}-1}{b-1}$$ 
            - b.) Iterative deepening first searches all the nodes in depth 1, then all the nodes in depths 1 and 2, then 1, 2 and 3 etc. This results in:
$$f_2(b,d)=\sum_{i=0}^d f_1(b,i)$$ 
            - c.) For large b $$\sum_{i=0}^d f_1(b,i) = \sum_{i=0}^d \frac{b^{i+1}-1}{b-1} \approx \sum_{i=0}^d \frac{b^{i+1}}{b} = \sum_{i=0}^d b^i$$ 
So they are negligibly different for large b. This is because a large proportion of the nodes in a tree are in the last layer, and thus this makes the largest impact.
        - Question 3 
            - This can result in a non-optimal goal - as we aren't ordering to path cost to the goal node. There could be another node in the fringe with a lower path to that goal.
            - Additionally, we'll have to re-tread our steps to those nodes later, when we calculate the path costs to those nodes - meaning if a goal is not on a layer we'll have visited every node in that layer twice as many times as we need to.
            - Consider this tree:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gYa9GCWpSaGVHgc0Ndp9EspdIY1hQrFNT4rXqEnzjLouC2bzs7QIqM-q_NFQnb4yXEaszrFstXC8PuS2792ov9UrEdSJq-Ghkvr1aRl6snzy5GHOWY8etQ_dcIGcfTN4.png) 
Using normal A* search we'd find the goal with cost 5, using this method we'll find the goal with cost 10.
        - Question 4 
            - a.) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2pdaZZ8AKr8yTFjSCKul8KfjxQQXbgvAT50oRLBnN9jqpaZRhznu9mfwI9JvkjbDfLE94bMAkNgNdaHYSlphe7EPqCcFZMH6JG53RhI0zimxSOfy3CTPMfRRIsJBEGzf.png) 
            - b.)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ukib90dcDeJeFydCyzlN-S63zk_dtQq12IYI2k_3B_-R5m2Pl5iqeKcWY01X0i6Env5JE7nLWP4AxFnSjbpoNA3lAccvy4nULX1sQ3sxQDjt0oOBHjPtJI3XHP4DTX75.jpeg) 
            - c.) No the converse isn't true, you could have consecutive nodes which both underestimate a heuristic but one increases. E.g.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LbRFDgmV1CJpgnoeB-fzmkkIcpeHIc_eINgI-9R7b-Dum5P_t-tK0uABGKAl4GhkjOMacH5HogudiEKgktPC-j-Ut9X_yVVBmqR0UEyVLrR6W9-icvvcEoPGHr2Kq9__.png) 
If the actual distance to the goal was 100 say, then h(s) and h(s') are both underestimates but $f(s') \lt f(s)$.
        - Question 6 
            - This might not always find the optimal path - consider a node $n$ where the two searches meet. That node might be the closest to the goal, but it could be very far from the start (which could happen if it was expanded and the edge from it to the very next consecutive node is very large.).
        - Question 7 
            - At every node, simply store the id of the next node to explore - and update that when you return to that node. Then you don't need to store any info about whether the other nodes have been searched as there is a strict ordering for DFS and you can always work out which node to search next.
        - 
        - Part IB 2013 Paper 4 Question 1
        - Part a.) 
            - Describe the basic algorithm for performing local search. Give an example of a search problem for which it is an appropriate solution, and an example of a search problem for which it is not. When would an algorithm such as A* search be preferred?  

Local search works by starting at a node on the graph, then expanding neighbours and recursively local searching the neighbouring node with the best f(s) (Usually the minimum for shortest paths). 
A problem where the optimal solution is not necessarily desired and instead a "good" solution is needed quickly are a good use of local search - e.g. NP-complete problems where they would otherwise take exponential time. For example, if we modified boolean satisfiability to instead be the maximum number of clauses we can satisfy local search could give a good solution.
Any search problem with cycles (that don't include the goal node) means local search is very unlikely to find the goal. Additionally, local search doesn't account for the total path cost - only considering the minimum path among its current neighbours (no backtracking), so best path algorithms will often result in a non-optimal solution and are thus not suitable.
A* would be preferred if we need an optimal solution, and a solution where the optimality relies on minimum path length. Additionally, A* handles the problem of getting stuck in a cycle.
        - Part b.) 
            - i.) If we reach a state where we are continually cycling between two game states (as they are both the best node of the other), **and **this is simply a local best and a global best can be found by travelling to a different node that isn't the best. In this case we could employ a technique used in stochastic hill climbing and give each node a **probability **of travelling to it proportional to the improvement in f it would provide. Thus, we'll mostly follow the best path but we can escape a local minimum if we get stuck. 
            - ii.) If the none of our nodes would lead to an improvement in our function, then we could employ restarts. I.e. when we reach a local minima where none of our neighbours improve us, we restart the local search somewhere else in the graph. We first store the best node we found so far, and when we've exceeded the total time allowance we will return the best of all the nodes we found. This would result in better coverage of the graph, and a higher likelihood of finding the optimal solution. 
        - Part c.) 
            - Constraint satisfaction problems at first glance rely only on the values of your neighbours (e.g. do the constraints conflict) but that is not the reality. The immediate reliance of a node is on it's neighbours, but it's neighbours relies on further their neighbours and so one - so the history of the path does matter making local search not well suited for this application. Local search would need a method of backtracking, as inevitably there would be conflicts, and would then need to be modified to include more than "local" state - as otherwise it will get in cycles where one node needs to be changed to change another, which would then cause a cycle and result in backtracking.
        - 
        - 2006 Paper 3 Question 3 
        - Part a.) 
            - The MiniMax algorithm uses a function f, which returns how good a given position is for a player Max - the higher the better. We then use this and note that Max will always want to follow a path that maximizes f and his opponent Min will always want to minimize it.
We start by enumerating all the possible series of moves in the game and storing them in a tree. Then we go through and mark all nodes in one Layer as Max and all nodes in the next as Min and repeat.
We continue until we reach end game states (or a cutoff) and record the value of f for each of these states. Then (working from the bottom up layer by layer) at each "Min" node we take the minimum of the values of its children and set that as our nodes value. Similarly, at any Max node we choose the max of our children and set that as our value.
E.g. the bottom left node is a Min node, thus we pick the smallest child to be our value (3) and continue.
This way the value of the root node will filter up, which will be the best possible f that Max can achieve. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sEW9XLrqtmPHOFemk9-JQR506aoujfHGPZUsfSy_qrqmD2d4J8cW70VKeLFHkruCNf7HbYFwrjCW9lK9ey5goaDFfHm0rxLLY_ObcbdlCCHenDL7r0WVohx4LSQuj3ge.png) 
        - Part b.) 
            - For a real game, we cannot explore every possible sequence of moves to reach the bottom of the tree. This would be infeasible in time and space. Thus a cutoff is required, we will apply minimax to a certain depth then apply f and work upwards from there.
            - However, this will mean we only look a few moves ahead. For a further improvement a evaluation function can be used to quickly gauge how good a position is (not necessarily with perfect accuracy), for example counting the combined piece cost in chess, using this if the evaluation function for a possible position is too high for Min or too low for Max we won't bother to explore it. The size would depend on other siblings. This evaluation function could be learnt using other AI algorithms.
        - Part c.) 
            - Alpha-beta pruning seeks to prune the search tree without affecting the outcome of the search. For a given breadth first search of the tree, we record the largest value seen by Max ($\alpha$) and the smallest value seen by Min ($\beta$). (Assume Max has the first turn, the sequence is very similar for Min): 
First Max checks if we're beyond the limit on search if so we return that limit. 
Otherwise we first initialize a value to -infinity. Then iterate through the neighbour nodes and for each node n set the value to the maximum of the current value and the result of a call to Min on n (passing $\alpha$ and $\beta$). Then if the value is greater than the largest value seen so far, return f(n) as Min will never let us get here anyway (e.g. prune the tree). Otherwise, update $\alpha$ if the value is large than $\alpha.$ 
Min's routine is similar, but we call Max's routine to find the value and we prune if the value found is less than $\beta$ as Max will never let us get here.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NNfHKTypxbeA9fm2p1gen8x5c4UvkQyuL59NNe_HeyK6kYv0vJsOa0_3pXhgpy-uLEh1E0lZlvUcxAuotaRRLaZPnr6kQXY_0jODBYgRl3R5cYX3ufitaCJttssnA3NF.png) 
    - **Supervision 2**
        - [2012 Paper 4 Question 2 ](https://www.cl.cam.ac.uk/teaching/exams/pastpapers/y2012p4q2.pdf)
        - Part a.) 
        - Gaschnig's algorithm works based on a partial instantiation $I_k$ and a variable $V_{k+1}$. Whenever we attempt to instantiate a variable and there is a conflict in a variable in $I_k$, we note down the variable in $I_k$ the conflict was with. Then if $V_{k+1}$ is a dead end, we back-jump to the earliest variable in $I_k$ which conflicted with $V_{k+1}$. Note that if that variable we jump back to is an internal dead end, we resort to chronological backtracking. 
        - This is an improvement on chronological backtracking, as it only backtracks to nodes whose change could immediately impact the instantiation of $V_k$. In chronological backtracking, we can backtrack to a node with no constraint with $V_k$ and it takes longer to reach a node that can actually affect $V_k$. 
        - Part b.) 
        - When we try and assign to 6, we first try R and find that 1 conflicts with us (we note this down for later usage) - then we try G and find that 2 is conflicting with us (we note this down for later usage) and finally we try B and find there is a conflict with 3. So we look through to find the earliest variable we conflicted with, and we find that's 1. So we back-jump to 1, and when we find 1 is a leaf dead-end we go chronologically. We'd have to change 2 though as there's nothing earlier. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tnZI1PtCCQ-NGnmrvWlv94foOUHP8uP-wsvGytK0YhYg9PL6SffOk8nU80G-_xyJ3XYKwO-yCNjW1QzdrDt_ONNr9XPA_RKulF7HTVUS4SCov4ONZxdqIBr73V2YN_nw.png) 
        - Part c.) 
        - In graph based back-jumping we'd try and find the culprit of 6 - that is the earliest variable in ind(6). As RV(6) = {6}, Ind(6) = {1,2,3,4,5} $\cap$ {1,2,4} = {1,2,4}. We'd then choose the most recent variable which would be 4 and back-jump there. First set RV(4) = {4} $\cup$ {6} 
Then see what assignments we can make to 4, we find that we can set 4 to R. Then we can set 6 to G! So it doesn't backjump to the same place.
Gaschnig’s algorithm always back-jumps to the variable furthest back in our partial instantiation, this can be detrimental as the further back we go the more effect changing that variable has (butterfly effect) - when there could be a variable that solves our issue inbetween. In graph-based backjumping we jump to the earliest ancestor instead.
        - Part d.) 
        - In forward checking, whenever we make an instantiation we remove that value from the domain of any variables we have a relevant constraint with. 
So we would first check 1, 2 and then 3 as indicated here:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/N6reRgPNHvnBccavUi5gE76S-AcnWlmkP_LulnR_0iKxMwUAdIJY7tivs2JoDbC3ctaOw1AC_M5l2Fn3WvY-rZWNUyTfRLJJ5SIPMUMsMYOSdkL8tgi5GO4Qou06g1x0.png)
But then at 3 we realize 6's domain is the empty set and we need to backtrack,
we would immediately back-jump to 1 and start from there.
Forward checking detects the problem much earlier than graph-based back-jumping - however we do also do the work of altering the domains in forward checking. However overall forward checking is better if combined with a graph-based back-jumping backtracking method.
        - ^^Isn't forward checking just the method of detecting inconsistencies - the notes doesn't mention how we fix those inconsistencies when we meet them - Be good to go through^^ 
        - 
        - [2010 Paper 4 Question 1 ](https://www.cl.cam.ac.uk/teaching/exams/pastpapers/y2010p4q1.pdf) 
        - Part a.) 
        - Each variable can represent a node, it's constraints can represent links to other nodes (variables) and each variables domain is {A,B,C}. Additionally, the constraint will be satisfied if a variable is not instantiated to the same value as another variable.  
        - Part b.) 
        - When we instantiate 5 to C - we immediately notice that the domain of 3 is now empty when using forward checking. This would then  __induce backtracking__ , as we know the assignment is inconsistent - so we don't need to wait until we reach node 3 to realize that we must back track. Thus, we have  __reduced branching __ as we don't need to explore all other variables until we reach 3 and realize it's inconsistent - we can backtrack earlier.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jgqT9TL7s4eiYvwJ-ulBJYmSyw89Ca1-r_uR4K3k4VCLbWxapNY_s3vEIdlYKe62gBX30O86ApOElmBIrA6yonEcNdaW2aQzQmAZ9QjCRDaOL3HzCKic9NemPxGna2pN.jpeg) 
        - Part c.) 
        - Arc consistency works as follows, for variables i and j in $i \rightarrow j$ - if for every node in i, there is a possible (non conflicting) assignment in j then the arc $i \rightarrow j$ is consistent. If a node in i cannot be satisfied by an assignment of j, we might as well remove that assignment from i's domain.
So we can seek to ensure arc consistency using the AC-3 algorithm, in this algorithm we start with a list of arcs to check - and if an arc $i \rightarrow j$ is inconsistent we remove the offending assignments from $i$'s domain. However, we must then add all the arc's ending in $i$ to be checked - as they may have now been made inconsistent as the removed assignment may have been the only possible one for some of them. 
However, in this case we'll simply do forward checking with constraint propagation checking the arcs to ensure no inconsistencies, when we update an arc we add the corresponding node to be checked - we'll then check all of their arcs for consistency.
We get the following:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kaLhDpBlUxm-ox4s8K15kmpSboiTlDZddVaE9WBogJTRj4C43KEE-6JKCiMJfQZPz8yeGe3KjGb5a4rckd36gGVb6kmIwfDdEY__NkM9Zm7ODpx7hepzy5o50QqVDSrm.jpeg)
We carry on find until the assignment of 6=B. We first update the domains of our connected nodes, then add the nodes we update to the list (3 did not get updated so we don't check it).
We first check $1 \rightarrow 5$ and find that it's inconsistent and A so 1 loses C from it's domain and get's added to the list to check.
We then check $3 \rightarrow 5$ and again find it's inconsistent, but when we remove C from 3's domain we now have an empty domain and we have to backtrack.  
Thus constraint propagation finds an inconsistency faster than backtracking and forward checking!
        - 
        - [2014 Paper 4 Question 1 ](https://www.cl.cam.ac.uk/teaching/exams/pastpapers/y2014p4q1.pdf)
        - Part a.) 
            - The Situation calculus is a method of describing a problem in FOL, complete with the actions that we can take and the current state of the world. The state changes each time an action is taken, so we need a Result predicate which takes an action and a state and returns the new state.
To ensure actions have consequences we need effect axioms which describe what happens to the state when an action is taken. To ensure the world doesn't change when it shouldn't, we implement frame axioms. To check if a given action is possible we have possibility axioms. 
Once we have all of these, solving the problem is equivalent to solving our first-order system of equations.
        - Part b.) 
            - Assume $s_0$ is the starting state. 
            - $$\text{at(home, }s_0)$$ 
            - $$\lnot \text{have(chocolateMuffin, } s_0)$$ 
        - Part c.) 
            - If we are at fat Finbar's in the current state and have a goldBar, it's possible for us to buy a muffin:
            - $$\text{at(robot, FatFinbars, s)} \land \text{have(goldBar, s)} \rightarrow \text{Poss(BuyMuffin, s)}$$ 
            - If we're at the cemetery and we see flowers, then we can steal the flowers there
            - $$\text{at(robot, Cemetery, s)} \land \text{see(robot, Flowers,s)} \rightarrow \text{Poss(StealFlowers, s)}$$ 
        - Part d.) 
            - $$\text{poss(a,s)} \rightarrow ( \text{have(flowers, result(a,s))} \iff   (\text{have(flowers, s)}  \lor \text{a=StealFlowers})$$ 
            - If I have the flowers, either I had them to begin with or I've just stolen them. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gjXfNjN2QntNjVqS5BObuF23sg-rI8GAxNOWSD61r8RThpk21vt5rnSgibAZsKGoDi8D-FuURBZRKHi10iqBcpN4hM6WcFdjzVPoH_U0iXwGPohtveFmGlX29eylLC0y.jpeg)
If we're at home in the next state, either we were there before we did our action or we travelled there. 
            - The ramification problem, is that you're actions can have many unforseen consequences. In this case, we handle the ramification that when we move to a new location everything we're carrying moves with us!
This successor state axioms handles this by also setting the location of any object the robot is holding.
        - Part e.) 
            - In FOL, two constants can be set to be the same thing in an interpretation. So to disallow the robot from getting muffins when they get flowers we have:
$$\text{muffins } \ne \text{flowers}$$ 
            - Similarly, we would like the go action to not have the same results as the jump action:
$$\text{go(l,l',s)} \ne \text{jump}$$ 
        - 
        - 
    - 
- Concurrent Systems
    - 
    -  _Concurrent Systems _    
    - Supervision 2
        1. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Swiev7gzpJr99rrNiwQ5TgxsXFzzJnb9TDsw3XEAIPEcszEutqMEGgth5IkZjGmHMjrbrsUpMTebpMmwY6gia6b6fzs4e40gkgUjNsAa24VjL1d4CfQ3xROkgAYKh1rb.png)  
                - Atomicity: Not necessarily true that we do all of the transaction or none of it, as we could crash during the system and we have no specific roll-back procedure. More work needs to be done to ensure rollback should we crash - could copy shadows of the data.
                - Consistency: Not necessarily, one could still for example remove money from a system - invariants not necessarily preserved.
                - Isolation: More work is needed, as we must implement strict 2PL to guarantee this. This falls out with strict 2PL, as our work on the objects is not affected by any other threads as only we can access those objects because we hold our locks.
                - Durability: The system can still crash while running commands, we now have the additional task of having to release locks after a crash. 
            - b.) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3www75KrC9L4l9rLhFcV3IN-01D-iZpqMqQg3uMdruRyWkCnPbJNPuERRhQogTsi0qvReyD3RoKQC_EPUjkAp8XfhCp67_aBwKbHr5S6_w5A3z7S0n1FF8nscRIkJgRr.png) 
                - ```c
Serial possible results: 
	T1: A = A + A * interest
	T2: A = A * (1 + interest) + 100; B = B + 100;
	(A,B) = (A*(1 + interest)+100, B + 100)
	OR
	T2: A = A+100; B = B+100;
	T1: A = (A+100) * (1 + interest)
	(A,B) = ((A+100)*(1 + interest), B+100)
``` 
                - ```c
Interleavings:
1: a = A.getBalance();
2: A.credit(Interest*a);
3: A.debit(100);
4: B.credit(100);

1,2,3,4: Serial
1,3,2,4: Result for A: A = A(1+interest) + 100. Conflict Serial
1,3,4,2: Result for A: A = A(1+interest) + 100. Conflict Serial

3,4,1,2: Serial
Below will be Conflict Serial: Doesn't matter who we arrange change in B, since 1&2 dont alter B
3,1,4,2: Conflict Serial
3,1,2,4: Conflict Serial
```
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tzUTAneZ0s9AsmnNR00hdVj71jlOLoBLAjVEsRjWBDQPY5L5USmZY5KjscqZIsDiqTD8jfVjRTYrvmwV1b8RUCJhAUkQTtrvbwM3XZjAplhqnONhEFVHbui1ZWRKevyf.png)
                    - Because with OCC works on local copies of the data, and only does its commit right at the end when all computations have completed. Thus, if a computation does not complete it is not committed. However, with 2PL commands that augment the dataset can occur before we commit - thus crashes can occur after augmenting commands have run. We would need to implement some form of a roll-back mechanism.  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZxmkFIv7FVtFhWDGJNEmNntWkAPkBx0ji8GPHQCqzvHfPji44haQVbAwjVhOwWcShYuKjSG_iE6O-BQG920FrNyxo199WYCRcGgZHxwgH-GGmlqjXWM_oMQorNyEzdjV.png)
                    - ```c
T1: 
	lock(A)
	a = A.getBalance()
	A.credit(a*INTEREST)
	unlock(A)
T2:
	lock(A)
	A.debit(100)
	lock(B)
	unlock(A)
	B.credit(100) // If T2 aborts here, T1 could have acquired the lock of A and done some work, T1 would then have to abort in sympathy with T2.
	unlock(B)
``` Strict 2PL would have avoided this problem because no work that could have caused an abort would occur while we're unlocking A & B - as we do our unlocks at the very end of the program. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zeXb8Y8jfZNbfPh9thhE-nn5c8NptqY5l3TRNLFjBN-_NmXcNv-ZlkWqE89Y2A32wrZ-0fW1nu3tr3ILAENnmP1Ce3ZIQfr_2lTbjlgcvWlwCc5lHaYQqKbnIpnVbWLP.png)  
                    - If the program crashes after having written some object updates to disk, as then the transaction hasn't completed but has still changed the state of the data. We would need a roll-back mechanism.  
        2. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8Gmm-oC6vjMBJtvL4PA9fP7zCsvZyUlL-qzd3B5wtClDSZDbUl5q09Pws4pc_mrRL3mN7NYIIt4d7PPbQQDrCecLxizAZhJgkym_3PnZWsJ3OqZv6xe6wz3Xm0-eaq9G.png)
                - ```c
T1.L1 // T1 now holds the lock for A
T2.L1 // T2 now holds the lock for B
T3.L1 // T3 now holds the lock for C
// A deadlock is now in effect, no further work can be done
```
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/A2Sp068a8HqNXoBYDmO99qWukv3ScfW2dHTrDsZ-xOUwZupjRty6_bn1htMfxrytwMjq1Bd2bc-rqRxZ3bZLMwdO5UgpqBvhTH5LqtcHKAdLzNZfx0_TrvbYcO0pBqox.png)
                - ```c
T1.L1 // T1 now holds the lock for A
T2.L1 // T2 now holds the lock for B
T3.L1 // T3 now holds the lock for C
A Deadlock will be detected at T1 all processes will abort.
T1.L1 // T1 now holds the lock for A
T2.L1 // T2 now holds the lock for B
T3.L1 // T3 now holds the lock for C

This process of all processes aborting and restarting will continue.
```
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FE29KtXxq3a2RPGt-6SQkq_ZmPfUGq4obesyhGD56B1hBGbiGG4E2FMBGdDaxaencwVoGQSKI0QUGaUewM1vpjHwiFFLuMjJKYsDaiHF1uXhuXkMGjBmefVzFzv66yXG.png) 
            - When deadlock is detected, we abort the next thread we operate on and continue. 
            - ```c
T1.L1 // T1 now holds the lock for A
T2.L1 // T2 now holds the lock for B
T3.L1 // T3 now holds the lock for C
A Deadlock will be detected at T1 and T1 will abort
// T2.L2 skipped, no lock for C
T2.L2 // T3 will acquire the lock for A, then release locks for C & A
T1.L1 // T1 acquires the lock for A
T2.L2 // T2 acquires the lock for C, then releases locks for B & C
T1.L2 // T1 acquires the lock for B and then releases locks for B & A
```   
        3. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vN_VbUS8amAxLCs-AOhqqxAur_W_tYyXlN2WybuBBo5j7uiEavHAl7gChERgXUax844uyMNik7Ls2WjWzgR_JehImsbRLJySqF3P5gUnieydjoYVyYrZJSH95wDSm42u.png)
                - ```c
T1:
	a = A.gb()
	b = B.gb()
	return a+b
T2:	
	A.debit(100)
	B.credit(100)

Interleaving:
A.debit(100)
a = A.gb()
B.credit(100)
b = B.gb()
return a+b

T2: timestamp 1. T1: timestamp 2.
 
A.debit(100)
a = A.gb() // Abort here, as V(T2) < W(A) but final result would have been correct
B.credit(100)
T1 -> Gets new timestamp 3
a = A.gb()
b = B.gb()
return a+b 
``` 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CPdhUdYYYwwg7iW6ACw3pMXPZmGXASdwc5aRJ4MdLmnuDbdz7WN9ACNex7r5uCM1tbFiRDOHXE4JoVgyk-DNkIAi0G-RnVexfzrWOclPFaUgPI8VyB1G8HHobO6nxjed.png) 
                - TSO can result in situations akin to an even worse spinlock - This occurs when a thread needs a resource a later thread has accessed before it, and thus the thread has to abort, like a spinlock the thread will be restarted but will be spinning over it's entire code contents rather than a single while loop - that is all computation before the abort needs to be recomputed (To to ACID requirements). So, if the mentioned resource is never freed the threads could continually 'spin' over their whole codebase - continually computing the same results and then throwing them away. 
                - Also, for a multiple resource case - a live lock could occur when multiple threads are trying to hold a lock on all the resources:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gJrEJWDYlmX2Q9E3k9-OCYAzelh1401QHiC5_6LVvhEBgXMmKidk9IVDW15tVHKE1PDebbVxV85pL9ojHgKOXuy31beFjQWPscTcmuqqTOPlGdfMEqvQFX_NTn6yAgno.png) 
                - Case where T1 gets lock of R1, T2 gets lock of R2 - T1 aborts meanwhile T3 gets the lock of R1... This pattern would continue.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QEfpCL6My-m7761W-3ZbSyaqMfX5WKrbxSg48JYQR1NDZXX__BAGkf5jkASIGBZG2nS7G7XjCNXMmeRvWUhep_U31MN9Ox7KQZ_9L6paneWAQ4_U67n1fdftT672yiRQ.png)
            - ```c
T1: 10
	A.debit(100)
	C.debit(100)
T2: 11
	A.debit(100)
	B.debit(100)
	

T1: A.getBalance() (0,0) 

T2: A.debit(100) ()

T1: B.getBalance()

T2: B.debit(100)

// As OCC distinguishes between write VS reads, while by default TSO doesn't
``` 
            - d.)  OCC executes transactions against local copies of data (‘shadows’) rather than globally visible 3 original copies, which avoids the need to explicitly handle cascading aborts. However, copying all objects at the start of the transaction is problematic if the set of objects to be operated on is determined as part of the transaction itself. Why does on-demand copying of objects complicate transaction validation?  
            - Because using our current system, the previous state that decided on demand the object should be loaded - could have been referring to an earlier version of the item that has since been changed (by another thread). And since we would be copying it on demand (and thus getting it's timestamp when we load it) we would have no way (within this system) of determining if this was the version the state referred to. So the transaction would be valid by our current system, even if the object had been changed to a different (unwanted) object just before we actually loaded it.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IHsATz-UZGEawcPlhHwr-fQBPo2GeTACbAb6eaeIyZlNZb2M1CPnhclXl_dtuQsY9L01l4AkOEF4_QID_hg0tOnjvjGX8jTB2cjuGwT0SbyXybhL1XMkkyK_ejpfoi_r.png)
                - Because TSO aborts simply when transactions don't follow it's one prescribed schedule, while OCC seeks only to abort conflicting commits. So as TSO aborts more, more live-lock situations will occur when perfectly correct schedules are disallowed.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gslF3mNNmDHVxaPjwqK3JmnsluwJTXFPvI39tdrA2MQg_Sp8cZXQCJVJw3CUryCqRKZ5IWDZml6eoKi6e5KVvT1q-qCptOaRxVa6gA7O_j7To72jCGQVF-Oy2sN6aBYE.png)
                - If a given transaction does a lot of computation in it's body, it may be slower than other threads who use the same resources - in such a case, the thread will continually find that once it's finished computation a faster thread has modified the used resources, forcing us to restart our slow computation. Consider a case where we're performing a statistical analysis of some database, this is a slow operation which will require shadows of multiple different fields - meanwhile one or many fast threads could change the values used in the statistical analysis, meaning once our slow thread has concluded it discovered it's used stale values and must restart. If a database is continually being added to, the slow thread could be starved forever.
        4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tt68NLsWYZBlsWdYWq-ZfTPlVMtMZMMxIeiiadDE8gkDHP1rrUj30jF_zmobxPhdwmMZ9LYWpyJMFLTYJgpBUFZwBW8QFW9gfS3OShawlETDGMD_se7_T7r6TeG6hnW-.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Fh51IxHMCTYmMkjSu0vg7Zr9psKsZquDCBnOGirStWM76-uwrBGw3Moa17c4hOgwhMUMZOMA0CCOevAty9w_g7YMxf9LjNugU7xThtFkM3Vf8LCSTmKMMXnSbAjFqIcT.png) 
                - Edges represent a "is-before" relationship between nodes.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/h-UuK42dzShBvMy6BZKKVy9nxj85tKJTgxX6fY000655jnaru8NGXJEZ94y2Oc_HSs75GiIB41jfWQcIrJ8M1ViUwOgwAsPRq-8zxfYAbFm13xzd7ivT_XLIPrjuX9B3.png) 
                - A Cycle will be present. I.e. both threads have operations that occur before operations in the other thread - a temporal impossibility.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/k9dHfdy-m5Bm1Eh4nEabAx6LZQo4HfDy5d7XcTZc9ZLOc87gNUEhqyyianbsfSc-0y-QXgxdDKkJ2j7dYa0nlJaeQScECu4ifV3BcNMKri-JIlFhwagPLhzuvDerZvxQ.png) 
                - Isolation & Atomicity
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lsFX9NuhzszQ6riLY5SF10nNuNddizzb2_KRElUbL73415zKh3CQen490K6g0gEZ4CQiU_un_kVQ4SUV86nbwqyTn4fm5gdJLjSqnvUsIpnjC6DVt5nohO5ezn8spbCN.png) 
                - Serial execution is when threads complete their whole execution before another thread can begin and complete it's whole execution. Serializable is when commands from threads are interleaved, but the result is the same as the serial execution. Serializable executions are a superset of serial executions, as serial executions clearly produce the same results as themselves. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uXFO19F5I8DmY5Z7OaAZvp1OCZxkVIdYFBPvVU3CH7wsdY0yXABb27KDwQhcXAxFWV2jDo0GdQCURa77rgG7UBmwHX_dZ0c8pnZJL5izrJX03bYhPyPSZjJKqTDaqw3v.png)
                - A dirty read is when a thread reads a value that has been modified by another thread, hear we could read the value of A after it's been debited (a dirty read) and read b before it's credited resulting in a result 'v' less than it should be.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qvlb9mw6AyME0cDsNXhKYb5hPJHHP8jZCC2YSiNwg5GH8MTA4oIHZkKCLgs7iQ96f0__8rfLHJIt3-RbJyDVpn7OgwFWnWGaM2Q2v11sn02SX-n2KRZcGzsCVF4CdFPm.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ah4OrMb9r7ElHo9fqdvI3fits0ZlHtYDXNv5C0LxsOnCMi1PEYfKS1j7Gxrpqo-ls1s3qoHqq-PmZrtfhIMZ6mGrOGESeSMf_yJsOOJKTdqEBziY9QtbWTdsHpa_Dadc.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Dq_JxVQqJdUaj6lqnlApNCeWstzIj_u0XzVkiOIVwyfUlxb8htFtTObOn340pTU-tVbtaVwprsSKa6GnLTKzquscQgSw3MDMfWTdDLQY5ql5am_9kJNZvcZ8XAfxDS6D.png)
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7rCJGSabjZmRl1LewnIgITcgke_b5wYjbn4wOGZI5HDIY7q-QNd6xKWmFnHA_yo6l9c3MpUV-stiEmAP05LuKZyyNJv6K0tPCmly-W2RnHqnq5noQABzyfvk_lr2qOia.png)
                - Not necessarily, after roll back the transactions could travel along the same execution path and cause the same commit error - resulting in livelock. However, there will be some cases which are solved by this addition, at the cost of large overhead of generating and testing this graph.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4KdOPCU5sQRPvkY0iFyRQMmkUlkcPEKxeLPdF1ldpMQ8VgM8VbJyiB3mSW_EUC4-b7hFhKs-EIeE1qpsdhuUYOW6H_Vvp-NE_8HZQhN_QyEdnDO-WFfeJGNuoCI_m9WJ.png)
                - It accepts more, because it will never reject a good schedule. While TSO accepts a single correct schedule as transactions come in.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/43Q_Ib1cOqV0P8xcRYdZMwJmJt1eP3PSh7ie0ZEadmfnt0Vw7ljIT6_I1Z5gf-uOtiOQ2C6u5Q4fk-Gg1ZeKTLjRxm6Yt4v3JnFy0jE7cqgbrX_V-5frhNiPZP7zgCs3.png)
                - This method accepts more schedules, so could result in less cascading aborts resulting in less wasted time. However, this scheme has a huge performance overhead of generating a history graph and checking it for cycles at every step.
        - 
        - 
    - Supervision 1
        1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sd2R5eXh_2n9qz1rlMJFYdNLd0tG-bE0UaLbKmCsWpDMrlH-pHYl-ZYXdacYEQIOuqaugFW1YRGzMEU9GQ6JOBONxdF-ugR7vRcWjB1AKZSipTorsRhQrosKThDmkULR.png) 
            - 0 - Condition synchronisation where one thread is producing items and another thread is consuming them. Initialising this to zero signifies that there are no items to consume and thus the producer must run. The consumer will wait for items to be produced (S > 0) and will then be signalled (whenever the producer produces an item it will call signal()).
            - 1 - If we have 1 resource available for use between multiple threads, in this case the first thread that arrives get's access to the resource - i.e. only one person can print from a printer at a time.
            - n - If we have n resources available between multiple threads (more than n threads), in this case the first n threads get access to the resource immediately - i.e. only n people can use the n printers at any one time.
        2. ```c
chopsticks = new Semaphore(2);
int chopstick_1, chopstick_2 = 0, 0;
// Thread 1
while (1) {
	if (chopstick_1 == 2) {
		eat();
		chopstick_1=0;
		signal(chopsticks);
		signal(chopsticks);
	} else {
		wait(chopsticks);
		chopstick_1 ++;
	}
}

// Thread 2
while (1) {
	if (chopstick_2 == 2) {
		eat();
		chopstick_2=0;
		signal(chopsticks);
		signal(chopsticks);
	} else {
		wait(chopsticks);
		chopstick_2 ++;
	}
}

// This can result in both threads getting one chopstick and starving
```
        3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hB68m6SGg36hFL_xPZrweB2Eqg7k_MVpuvzdel9hIGD09WTMEsLGbpsWbnxmyGvH09l_OM7wDs9nDkFSYcrrMckP0b-W4XChfeRFosc3SSgvINuuRlz1TegpO9zNM9qH.png) 
            - Yes, because if we have a context switch anywhere between the weights (including just after the wait command is run) the various producer/consumer threads have different conceptions of the state. For example, if a context-switch occurred (in the case of a producer) before we changed buffer[in] we could resume the thread when the list is full and cause an overflow. Alternatively, we could consume the wrong item by the same means.
        4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/D19kr_2Pf7_0ZafdDz9-dTMCRWKuzsTeC3BNISA9-vMa91p5xUIbPtkAcO-FvWKG-BOYddEfZNGpxymen8EKKA9v6OFpxc89bqDSu4Y6cYZwpsad_kCWmOu6P2Fstjta.png) 
            - In the implementation of wait & signal presented in the lectures, the problem would be making checking the queue and changing S atomic (for signal) or checking & changing S atomic (for wait) rather than the question posed above. This is because in the version presented in the lecture, only the first and last threads in the door change S.
            - Wait would be unaffected - this is because we only perform a decrement if S > 0 - and we only block a thread when S = 0. This means the two can never be in contention.
            - If signal's integer & scheduler operation were not atomic, we could have a race condition - in between the integer operation and the scheduler operation another thread could call wait on the semaphore and perform a computation. While that thread is running, we would complete our scheduler operation and our awoken thread would perform the same computation - this race condition could lead to anomalous behaviour. Waking up the thread first, and then incrementing the value would solve this.
            - 
        5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/33akS39qWNR2m71NzOgaRJBQFNkWyVBtTw06nG-8WkaHVY_RldW4gw2BUKle6mpGtR5l7Eizk96IOtfF0m8hj52Aznye1SsP6aGioBc16kDSvqDO1K60vUqc9_FwdWnM.png) 
            - Round-Robin - In a multi-core processor where each consumer thread is on a different core, we would spread the work to different cores to ensure temperatures of an individual core doesn't skyrocket which would result in a slowdown.
            - Prioritized Work - In a multi-CPU architecture where faster CPUs are in more demand for work, faster CPUs would be given a higher priority as they would complete faster and we'd like that time-save when those CPUs are available, while slower CPUs would be given a lower priority. 
            - MRU - If the CPU cores have caches that will have recent data stored in them, if a thread has been used recently it may happen that the required data to perform the computation is already in the cache (addresses of items etc.) meaning time will be saved which would have been spent fetching data from main memory.
        6. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RdrlWILK0E0bNwSv0LdF4PR9LSwMfofFUuoeUnN2zZ51HMYhG-COY7mcbZQY7g0NXtGGAgopnKwofrjQhkZ-RW5b53cxNVacz10Dj-fph_bN_LdPWE_SrBDgb1eLYKHN.png) 
            - ```c
int buffer[N]; int in = 0, out = 0;
spaces = new Semaphore(N);
items = new Semaphore(0);
producer_guard = new Semaphore(1);
consumer_guard = new Semaphore(1);
// Producer threads
while(true) {
	item = produce();
	wait(spaces);
	wait(producer_guard);
	buffer[in] = item;
	in = (in + 1) % N;
	signal(producer_guard);
	signal(items);
}
// Consumer threads
while(true) {
	wait(items);
	wait(consumer_guard);
	item = buffer[out];
	out =(out+1) % N;
	signal(consumer_guard);
	signal(spaces);
	consume(item);
}
``` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bPGP_gNXPzszZu0_q37-gatUw0H5dw8izVNFee9drU-pzJ-qJsaKuetdA0NFulnHZLxjr7CjpzZMpGvCJCxYpVZWCmMPIlAGMK-4SQrszI27PiIeOky3BPa_hlCHoaQN.png) 
            - We can consider that the consumer and the producer interact with different sections of the buffer in their "guarded" sections - the consumer deals with out and the producer deals with in. We can then consider that the whole design of the spaces & items was done to ensure the back and front of the list cannot affect each other, that is we can never add to a full list due to spaces and can never detract from a full one due to items. So as in & out are safely independent, we need only protect our consumers from other consumers and producers from other producers. 
        7. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/y6BGMYo6C6AtmnKq8ltCZY67Be2lsy6CI2hVWujhK59XcjEncDNTVw9qCa3N4l3fOIbd_kzM-OmGGOfOdTIkNrFe_W9laL-85ipJVFLlCulSOooNdRFDJ1ZLkqcR-Mw-.png) 
            - Because generally there will be multiple (low priority) consumer threads in the guard queue ahead of the producer thread, they will necessarily be popped from the queue ahead of any producer threads. However, if you were using a mutex:
            - ```c
while (! test-and-set(note));
``` The thread that gets access to the resource, is the thread that runs test-and-set(note) first after the resource is freed - if the producer threads are set to a higher priority by the OS, they are more likely to run the command first.
            - 
        8. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XtO2e4DqYfpL0B1gbYvMSEYqayEMkA50280I_JG5WD2FiCBcqtGMbZTY-fLOAmdiJLDuTOEe-alLzih8lCUPd9E7G_BCc0Dv_sxyKAGKcJd8IY8mq4XdPT6UXHgvTkhm.png) 
            - One could replace the queue structure with a priority-queue, rather than waking up the next thread in the queue in signal we would call popmin() (where a lower priority number signifies a higher priority) and the higher priority consumers would always go first.
        9. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Wy1sGRze451GrBUFtmUiDbaytnxBlC36EbdEbjjsWFZ2CaSDbQa78plAuoKq4hHoXQ5CslliK5YT_cJkEkuecGzqnKCKst6nEduav4Pibnv5blNuHzndlqfJqDSZCyOg.png) 
            - One solution would be to raise the priority of the producers (to high) whenever there's a high-priority consumer waiting - the wait() commands thus acts similarly to the signal() command, in that it allows another thread to run.
        10. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cjRL7x0rri8fzqS45tGSxJ_lTt-r8ZbvSkwSlM-jlu96XC0v3j76VAMtqfibLO0JJQMDupkzyO4in-M9lDVC3LpA_f5UZ8DUvR3fXWzaR68yH9UANntExc4So-IiYXSf.png) 
            - Each thread has its own stack, register file and scheduling state, thus there will be two instances of each of these.
            - Threads share the executable program and virtual address space, so there will be only one instance of each of these.
        11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gSeUH_wE-tW5DLaCuzxk0t7wair3fJw17i5FnYJAVLrFHH8d6hAQtJur1zWRVBjCKb5gsnuUcMNPlui8jIWfaKs-Wys6EhI_8toKLA9B3cFTitBM2p9WMPdN--zIbDxD.png) 
            - Consider the following case: 
            - ```c
if (!beer) {
	// printf(note);
	if (!note) {
		note = 1;
		get_beer();
		note = 0;
	}
}
``` A race condition can occur between checking for beer and checking the note - if another thread is just about to write to the note. However, as printf() takes a non-zero amount of time to execute that added time could result in the second thread changing note  in time, meaning the first thread will check the note once it's been changed (e.g. desired logic flow occurs).
        12. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/r9xDNEUd21vdFWgQV_oBu_b-yT79qFcKluEGCeipA0baCbUXBf4g13mns3lEDnAmLdZwxbOyLpKM8587Ae9iw3K87JXbLdhpE_C6FkpF5JD65RNQAfDJqyiWzg03192u.png) 
            1. n! As the OS is (modelled as) non-deterministic, we cannot know the order in which threads will be scheduled and execute thrprint.
        13. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rOmx9KUE6ei8U0fUQOOJT_dEeaW033n8VTJbWBYfwSH8oESnVDHu_5OpJl-KV63e0zBY8VNTCTXmF_RLMl1F0t5ujdZmkq99WLSKkC8Lk3_AKDNASEYiuUNcygfFIsWc.png) 
            - 1 - As pthread uses signal-and-continue style conditions, the if should be a while loop - as the value of the condition could have changed while the thread was waiting on the condidtion.
            - 2 - We do our printf after unlocking the mutex, this defeats the whole purpose of the safety - another thread could legally access the state and complete it's printf before we've completed ours (this could be due to a context switch or simply another core that's faster).
            - 3 - We never signal ordering_cv to wake up other threads.
            - ```c
int next_thread_id = 0; // Next ID to print
pthread_mtx_t ordering_mtx; // Lock protecting next ID
pthread_cond_t ordering_cv; // next_thread_id has changed

void ordered_thrprint(int thread_id, char *message) {
	pthread_mtx_lock(ordering_mtx);
	while(thread_id != next_thread_id) {
		pthread_cond_wait(ordering_cv, ordering_mtx);
	}
	next_thread_id = next_thread_id + 1;
	printf("Thread %d: %s\n", thread_id, message);
	pthread_mtx_unlock(ordering_mtx);
	pthread_cond_broadcast(ordering_cv);
}
``` 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gcADy-5emy1KJOIoJd595ND9GnD5-ptl-P6YS97lwBJayyx_m-ziHUyQeKJsIrMoEv3TZJd2euOaVtZE15SHtQdEbABINv6eTJNsILmfI65csyku1bmNsxdHQBmVlNKl.png) 
            - We could solve this problem using two additional pieces of state (and associated mutexes), an array of size N (number of threads) and a protected integer that starts as N. Whenever a thread is executed, it would do the following
                - First get control of the buffer and the protected integer
                - Then it would place it's debug message into the buffer at the index of it's thread ID.  
                - Then decrement the protected integer, if that integers value is now 0 print out all the debug messages and associated indexes and we're done.
                - Release the protected integer and the buffer.
    - 
    - **Concurrent Flashcards**  ↓ 
        - 
        - What is a Process, and what are they allocated? ↓ 
            - Processes are instances of programs inexecution
            - They are allocated one or more threads
            - virtual address space, local memory etc.
            - They are given OS unit of protection and memory allocation. 
        - What is shared between threads of a process, and what isn't?  ↓ 
            - The heap and code is shared
            - The stack and each threads program counter are not shared.
        - Describe 1:N threading, including it's benefits and downsides  ↓ 
            - The kernel only schedules processes, it doesn't generate threads. Threads are instead implemented by user-space libraries, e.g. the JVM implements threads.
            - Benefits: Lightweight thread creation, OS independence, more programmer freedom
            - Downside: Can't spread threads across multiple CPUs. Blocking syscalls or context switches are expensive.
        - Describe 1:1 threading, including it's benefits and downsides  ↓ 
            - Kernel provides all threads, processes are initially allocated with one thread but can call for more. Used by most OS's
            - Advantage: Pre-emption handled by OS. Straightforward to use multiple CPUS
            - Downsides: OS overhead added. Less flexible and portable.
        - Describe M:N threading  ↓ 
            - Kernel offers a small number M of activations. The user then schedules a large number N of threads to each activation. So OS controls maximum amount of concurrency N.
            - The OS upcalls a thread to userspace when it blocks or wakes up. Then userspace code can be used to schedule it.
        - What is a critical section, how does it relate to mutual exclusion?  ↓ 
            - A critical section is a piece of code that should only ever be executed by one thread at a time
            - Mutual exclusion is when if one thread is executing a critical section, no other threads can enter it.
        - Describe the code of the atomic read-and-set operation―```python
def read_and_set(note)
	while True:
		if (note == 0):
			note = 1
			return 1
``` 
        - Describe spin-locks and give pseudocode  ↓ 
            - Can be implemented to define a mutual exclusion zone. We start such a zone with a LOCK(L) call and end it with an UNLOCK(L) call. Note that the thread is continually doing useless work spinning.
            - ```python
def LOCK(L):
	while (!read_and_set(L)):
		continue
		
def UNLOCK(L):
	L= 0
``` 
        - Describe how a process moves between Running, ready to run and blocked under OS guidance. How does the OS store data about the processes? ↓ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dBHlW8_3iaVSPqMu4t2yjQ32cClI5OcsHlCjJA-OEV5M427R2XQ34RDzA3msfaSC_ChRJ-v9cnyfEgQ5BUtF-gV0q_mJfmFk8CTZbNeZg7Jb1zCDhUiLtE3i7D0C5XYA.png) 
            - TCB contains registers of non-running processes/tasks. The TCBs are stored in a queue handled by the OS. The blocked TCBs point to a semaphore or similar that they're waiting on.
        - Describe Atomic compare-and-swap (pseudocode or otherwise)  ↓ 
            - Check if the prior value equals the one currently stored, if so store the new value. Otherwise fail - in the fail case return the stored value.
For example we could check if mem_addr = 0 and store a 1 - to get an atomic read-and-set
            - ```python
def compare_and_swap(prior, new, mem_addr):
	if (prior == mem[mem_addr]):
		mem[mem_addr] = new
	else:
		return FAIL
``` 
        - Describe Load linked, store conditional. Why is it often preferred to Load-Linked ↓ 
            - We start with a load-linked of a memory address, which is moved into a register where it is operated one. 
            - The when we go to store that value back using store-conditional - store-conditional fails if the memory neighbourhood has been modified **or if an interrupt has occurred**. Otherwise it writes the register back to memory.
            - Doesn't lock up resources while an atomic action is taking place.
        - What are synchronous and asynchronous products of finite state machines?  ↓ 
            - Asynchronous means the actions of threads is interleaved - e.g. we can step multiple ways in the product.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/smCAxdGAVeidbbPWc18G6773tdKSEGCVPsyR47wcwyPx6Xs8qn-ydA5pNVjAZ0KMzrrr4cjCI_PtqvY6hLnqi3zil32y2jNJus3OouIGYemFA71K59Q13x3x8HuoNEdW.png) 
            - Synchronous means all threads move at once, via a diagonal step.
        - What is the reachable state algorithm used for?  ↓ 
            - The reachable state algorithm generates every possible reachable state by the system, e.g. each possible interleaving. We can then check if certain properties hold in every such reachable state - a safety property. 
        - Describe the **Lamport bakery algorithm **- why is ENTERING necessary? ↓ 
            - We enter a bakery, take a number and wait for everyone else to get their lock and for our number to be lexigraphically greater
            - ```python
ENTERING = [False * num_threads]
NUMBER = [0 * num_threads]
def lock(tid):
	ENTERING(tid) = 1
	my_number = max(NUMBER) + 1
	ENTERING(tid) = 0
	
	for j in range(0, num_threads):
		# While other nodes still getting numbers, spin
		while ENTERING[j]:
			continue
		
		# If the NUMBER[j] is zero then exit
		# If the NUMBER[j],j is lexically smaller than us
		# then exit 
		while (NUMBER[j] != 0) and 
			  ((NUMBER[tid],tid) < (NUMBER[j],j)):
			  continue
			  
def unlock(tid):
	Number[tid] = 0
``` 
            - ENTERING is necessary, as it ensures that even if another thread gets the same number as us and then get's pre-empted **before it can set it **then even though it's number would be zero it doesn't get skipped. 
        - Describe semaphores and give pseudocode for wait and signal ↓ 
            - Semaphores encode the amount of a given resource currently available. They avoid the wasted resources used in spin-locks by instead sleeping.
            - ```python
## NOTE THAT THE INSIDE OF WAIT and SIGNAL IS ATOMIC!!!!!!!
## VERY IMPORTANT

def wait(sem):
	if (sem > 0):
		sem -= 1
	else:
		suspend-calling thread
		add calling thread to queue
		
def signal(sem):
	if len(queue) == 0:
		sem += 1
	else:
		wake the first thread on the queue
``` 
        - Describe Inter-Process-Interrupts ↓ 
            - Thread marked as runnable
            - Interrupt sent to target CPU
            - IPI handler invokes **thread scheduler**, which preempts running thread. Triggers a context switch to target thread. 
        - Describe the producer consumer solution using semaphores. How would you change this solution if you had MULTIPLE producers and consumers. ↓ 
            - The producer wants to create items if there's space. The consumer wants to consume them if there's space. So the producer waits on space, and signals that there's another item when it's created one.
The consumer waits on items, and signals that theres space once it's consumed an item.
Note that the buffer (queue) is built on a circular array.
            - ```python
head, tail = 0, 0
space = new Semaphore(N)
items = new Semaphore(0)

def produce():
	while True:
		item = Produce()
		wait(space)
		buffer[tail] = item
		tail = (tail+1)%N
		signal(items)

def consume():
	while True:
		wait(items)
		buffer[head].remove()
		head = (head+1)%N
		signal(space)
	
``` 
            - If you have multiple, need to set the area inbetween wait and signal as mutual exclusion zones. Use a Semaphore(1) as a guard.
        - Describe invariants and when they can be violated?―Invariants are facts that should always hold true about your program. E.g. in a linked list a node should never have no links to it. 
Invariants can be violated in a mutual exclusion zone, but the invariant must be held true if other threads can view an inconsistent assignment of states.
        - Briefly describe multiple reader single writer solution―Mutual exclusion zone for writing, need a write Semaphore(1). Resource blocking semaphore for readers, can only have so many so need Semaphore(N). 
        - What's wrong with this 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7AtNr_WcgbY9WcPUlPc8qeaqGXNOXsHuNNN9caOfGkNCV4duIBzM6x7svZlf-wO_d8taq0BFrTtjlDXt2qPFX2nr45DBvWsejgx6N3YMP7Y4g3oQWxelv1b-TlE-iUM4.png)―Writer can starve. Solution is:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ro_eGgtYR044CvQ2JdjMxq9aKc0RromI0Cb3-YOL4Umzjpo-KWVZ7pNHok2d3T_inR7g_mKfG8rQ97hCKEssSsFoTXIgoRKNEGL-pKAjwcrktKRRXZyZP8zoobEvaMAi.png) 
        - Describe Conditional Critical Regions  ↓ 
            - Certain variables are set as 'shared'. The programmer can the define a region where certain variables are being used Then the compiler handles the mutual exclusion: 
            - ```python
shared int A,B,C;
region A,B {
	# use A,B safely
}
``` 
        - What do Conditional Critical regions do when an await expression isn't True?―They leave and try and re-enter the critical region - this is just spinning though, and is inefficient.
        - Describe the basic idea of monitors―Monitors encapsulate all the data and methods that a group of threads would want within itself. Then, whenever a thread calls a monitor method - the thread is blocked and added to the monitor queue. The monitor **only **allows one thread to execute in it at a time - thus ensuring mutual exclusion on it's methods. 
You condition on a certain set of pre-defined variables.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kHqv1H2SwKJOMW4s0zRPowSrEjiC2VF2OqqFT02OooFvM-IVkGYPk5uZTAofmkV6-P0JTDiz1fTyA-4dWfrKHCmNTBx55lQlPRu-2oJCDzcJ4_uwulXRq-RcTe2zsp-t.png) 
        - Describe what happens when a standard monitor calls $\text{wait(condVar)}$ or $\text{signal(condVar)}$   ↓ 
            - A call to wait, suspends the calling thread, **releases the monitor lock **and adds it to the condition thread
            - A call to signal releases the monitor lock and wakes up a thread in the CV queue.
        - Describe monitor condition variables/condition queues―If we need to wait for a condition, we need the standard wait and signal on that condition and associated queues (but no number like in semaphors). We also add broadcast which wakes all threads in the queue. 
Wait call:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SJ3VIJknxs1tHV2xDXD2bq8kZQGqyZv1jiXdKQfhOqDs3gl12-OYtp50L6XuuzY51cwxarnjFg-tueeGIZTXmiKsSqfdgnItCdjfOfj-CnoWc2xUz3YGv5RvsaCAHWIn.jpeg) 
        - Describe Signal-and-wait ("Hoare monitors") and what problem they solve ↓ 
            - Instead of having two queues you have three, a **condition queue C** an **entry queue E, **and the new **S queue**. Then when a thread T1 invokes **signal**() on some condition - the thread it would have woken up in C (T2) takes over the monitor and T1 is placed in **S**. 
            - Then when T1 leaves the monitor, some thread from the S queue is selected before the E queue.
            - This solves the issue where we could signal() and still have work to do, and then two threads would be within the monitor.
        - Describe signal-and-wait, how does it differ from signal and continue?―Signal-and-continue instantly pauses the signal()ing thread when it calls signal, thus the condition it checked before calling signal **must still be true**. Signal and continue on the other hand could add multiple threads to the E queue, and thus the condition it called one thread on could be violated before it is invoked. 
So we need to continually test on the condition in signa-and-continue.
        - What is a mutex―Essentially binary semaphore.
        - Describe barriers―All threads must reach a certain position in the code before they can continue. E.g. in a simulation, they all must reach the end of the day before continuing.
        - What is a re-entrant lock?―A re-entrant lock is a lock you can grab multiple times, without blocking yourself. You need to unlock it as many times as you've locked it before other threads can use it. 
Java uses them.
A usecase could be graph traversal, you want to lock a node but can't check if a previous recursive call already got the lock. So you grab it again (possibly) and unlock it after your recursive calls. 
        - Describe java wait and notify primitives. What are they used within?  ↓ 
            - Wait and notify are used within synchronized blocks, you can synchronize on a class or on state within that class - or you can synchronize a method. 
            - When you call wait, the thread drops the mutex it had on the state and sleeps
            - When you call notify, the sleeping thread gets awoken
            - Inspired by monitors, woken up threads go into a waiting queue - so need same signal-and-continue spinning on conditions. 
        - There area four conditions for deadlock, Mutual exclusion, Hold-and-wait, No Preemption and  circular wait - Describe them AND possible countermeasures ↓ 
            - Mutual exclusion - resources have **bounded **owners. 
We could allow anyone to access a resource but not very safe.
            - Hold-and-wait - A thread can hold lock X while waiting for lock Y
We could make sure to allocate all resources at the beginning of running, but we don't always know what we'll need.
            - No Preemption - A thread can hold a lock X until it chooses to release it.
Mutex timeout - or resource stealing both unsafe.
            - Circular wait - Cyclic dependency. A waiting on B waiting on C waiting on A
Impose a **partial order **on resource acquisition (need X before Y) , can work but is hard. 
        - What do thick vs dotted lines mean and what does a cycle mean in a resource allocation graph.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0afr7yxJXKXQE74LmtHCuGJ0pr_81-lQX5l3F0N6EnNVNFujerjYvuDWmaV_Q7F7qEvhjw_8AJwHfUnfDgKA_w1K6WHgBDRFzEBftcnf0YHeLe4x2xHEVzKw1ocf1Oa9.png)―Thick lines means a thread **holds **a resource. Dotted lines means a thread **wants **a resource. A cycle means we will have a deadlock. There's a cyclic dependency in the graph.
        - What is deadlock dynamic avoidance, what are the assumptions made?―We assume that if a process receives all required resources it will complete without error. We also assume the maximum possible resources required.
Thus, we track the resource usage and only grant requests if they won't cause deadlock.
        - Describe Baker's Algorithm and give a little description of why it works ↓ 
            - Start with an Allocation matrix for each resource and each thread, e.g. what they're currently using. And a request matrix, what each thread is requesting.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WfiXswtcWtAw08ZS6-bHFWKTB-t25vbhlFvuKCRiYrjaIEoAEAmwYZ8Kon8OXeM5rEUvn18EM8rcTPou1k1CaYRH2EUqtbnEwKKVoHS-BrymCwfmBGcUGMhbTgZNcKCx.png) (Ignore the red lines)
            - Additionally, we need a resource vector (amount of resources left) and a W matrix **initialized to v at the beginning**. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5Wtd_ciWF_GLnesBvcGE299NUmbuiUQTapOnsFKPP87QmkEiRmpZAcQ3UKoOlRv28fE7ngx3Xz4kzPXCgkTxV3LPBHdjg19dqwYQarmNxE-N0Cf7ixdIxgoHdottWWwL.png) W will be the same as V to start with.
            - Then repeatedly find requests that can be satisfied in R and add the corresponding A row to W. When you do, mark of that row in A. When all rows are marked then there is a path of no deadlock, if we cannot find an appropriate row in A then we'll have deadlock. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bfLHmtD15qEYwh7w4Sk_SZDSgwzU3fH-Ioya86zNW6SHvD6FE9iKTstQIpRmWcx3IRyidrXMw4URYxmKZRQAkf8t2dttfjAEczJTen7yC2nHpRkFSgbLpukM_RcpGxSl.jpeg) 
            - This works, because we assume if a threads resource desired can be fulfilled it will give back all it's currently used resources to the pool. We work out if there is a possible ordering which would lead to fulfilment. 
        - Describe priority inheritance, what does it solve? Give 2 problems with priority inheritance  ↓ 
            - Priority inheritance solves priority inversion, where a higher priority thread is waiting on a lower priority thread.
            - Priority inheritance means, when a thread T1 (high priority) is waiting on a thread T3 (low priority) in a critical section T3 takes on T1's priority. 
OTHERWISE, when T1 sleeps while it waits for the critical section - T2 would be queued first as it has a higher priority than T3.
            - Hard to reason about what will happen in the program. Much harder to implement with semaphores or similar, easier for locks as you know who holds them.
Avoid sharing between threads of differing priority, otherwise you get problems like these.
        - What is the available parallelism for:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ruH9smrhvVZGI5piYGfjtnNXHK3jf6UmN87SwMt7IlC3sntm0_Eawc6vM5_eT4jiDCYUpTgGFSHSW6FeffJGPhEefXANI0jzUX0QKovJjf2aqVOZySON8WacazgBLbaQ.png)―Time taken = 4+8+2 = 14
$$\text{parallelism} = \frac{35}{14} = 2.5$$ 
        - How do you do concurrency without shared data?―We ensure that every thread owns a particular piece of data, then when they need operations performed on other data - they request the thread that owns it. This "requesting" would need to be concurrency safe!
        - Describe Active Objects  ↓ 
            - Like monitors, but the threads request commands to be completed not time to use the monitor. Thread makes its methods, clients make requests and the active object returns a value when the request has been completed.
            - Need to queue requests. Need to manage mutual exclusion when needed. May need to **delay requests** pending conditions (e.g. if a buffer is full). 
        - What does the ! mean in :
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YAlEOujFZQU8dDm2DYaKVO7N8-ubW6llwbsp1bUJOkMen2T0T64HoGeRsgw03dDAL6imu3C_e3iXzK-7FsCtTIuun_r_zNNgQ6QqHGtz7zBnhKgcHZ81DW3qZ2ZCSsnx.png)―It means we're piping 18 as a message through c1:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ae2NczUC-PZ4EuBJWyuJz2Mosq3eHb2mp1Fp643rPcnELKPw9rtsBt-0L9Yo8JTmnA3ZynS8R9FHuSSbz1eCufZ-w-KWwiLw5UrHchhNfZiVs8Buxil7MRgnwyK0C2wr.png) 
        - Give 3 message passing advantages ↓ 
            - Flexible API - can batch messages, schedule them etc.
            - Copy semantics avoids race conditions (hides asynchrony)
            - Works between and within machines!
        - What are composite operations and how are transactions related?―Operations on multiple objects, which we want to be thread safe in their entirety:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eU4YjlosPq93AyGV79EtrtktyG9H6yyDsTrZrG05f1LdLtj-7C8XwQy8H8T7HXOx4kC3F4lEwMMKrR3_H2rhZs6V_aXVJv9bt4iaTFLFjAvVoZsNwmJHGwOpEMWD4kuZ.png) 
Transactions are "atomic" operations that either succeed, or have no effect - e.g. if we move money from one account to another, we either succeed or **no money get's moved**. We want to be fault tolerant, so this occurs regardless of any crashing. 
        - What are the 4 ACID properties?  ↓ 
            - Atomicity - this means either whole command passes or fails. 
            - Consistency - Want to preserve invariants.
            - Isolation - want the operation to not be affected by any other concurrency in the system.
            - Durability - want completed operations to survive subsequent crashes 
        - What does it mean for two transactions to be serialisable―It means we can execute the transactions concurrently (e.g. interleave computation), but get the same results as if they were executed serially.
Code is serialisable if we can swap the ordering of non-conflicting operations.
        - Describe when two processes are conflict serialisable―IFF we can rearrange the operations and no two conflicting operations change order. Conflicting being non-commutative e.g. load then store vs store then load.
        - How do you construct a history graph?―Nodes represent individual operations, edges represent the happens before relation. Insert nodes in program order with edges between them as normal. Then insert edges between nodes of different programs that don't commute.  
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pNKK4dPmKVhlAuU9wImIo11MK4OLeGxGFUTmFRa5MQrr9ecIm6NpC9C8IGnNoG-iIW7akRYyT3yCuLroEoa9t5ItCdSkrTbDQRhRwE9o7j7Gvyo5zxnLbiiua27zZvMM.png) 
        - Give 3 negative effects of bad schedules ↓ 
            - Dirty read - read an item in the middle of it being updated. Lack of isolation.
            - Unrepeatable reads - reads an item then updated by another thread, can't read that value again. Lack of isolation.
            - Lost updates - overwritten write. Lack of atomicity.
        - Describe two-phase locking and it's issues. What is strict 2pl? ↓ 
            - Expanding phase - where locks are acquired but none are released. 
Shrinking phase - where locks are released but no new ones are acquired.
This is to ensure isolation, but you must ensure you release and gain locks in the correct order - otherwise a dirty-read/write could occur elsewhere.
This guarantees serialisable execution!
            - Requires knowledge of which locks we need at the beginning. Can cause deadlock, but can abort if deadlock is detected.  
            - Strict-2pl release all locks at the end.
        - Describe Rollback - how does it help with deadlock?―Rollback is where we reverse the effects of an aborted transaction. It helps because we can delete processes in the case of deadlock, and safely perform a rollback.
        - Describe the two methods of implementing rollback  ↓ 
            - Undo - keep a log of all operations and undo them if we rollback.
This causes issues because if we undo a setBalance() what if we didn't read the previous balance? 
            - Copy - save the state of the object you're operating on before beginning our transaction, and if we need to rollback just restore the copy. High overhead, which we can reduce with partial copying. 
        - What is time-stamp ordering?―Give every transaction a number (think current time, or other increasing number) and objects record the transaction numbers that operated on them. When a new transaction tries to access an object, it must have an equal or higher transaction number than the previous transaction.
It would then have to abort and restart with a later timestamp if unsuccessful.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i_01BHOHJY7em6R7iZQdbZ2f5Xpyyu0UJXl7meKB5586Tj3MMK7REQkJMpc5Sh-vBGYT9-36wNo2sa3ASOLeT-0CZpMV64wLT7t3nFaE0TPwl0VP2ESUV03cMzX_p95E.png) 
        - Give code for read and writes for time-stamp ordering which distinguishes between reads & writes  ↓ 
            - ```python
def READ(O,T):
	if (V(T) < W(O)): abort # If written to after us, abort
	# do the read
	R(O) = max(V(T), R(O))
	
def WRITE(O,T):
	if (R(O) > V(T)): abort # if someone has read after us, abort
	if (W(O) > V(T)): return # if someone has written after us, they win
	# Do the write
	W(O) = V(T)
``` 
        - What are some problems with TSO? ↓ 
            - Struggles with contention, can have transactions repeatedly aborting and retrying
            - Imposes a single serialisation, even if others would have been possible 
            - Not strict isolation ⇒ cascading aborts. Needs a rollback mechanism.
Best for distributed systems, where conflicts are uncommon.
        - Describe the basics of optimistic concurrency control, what are it's advantages? ↓ 
            - OCC assumes conflicts are rare. And we work on shadow copies of the data, then when we're ready to commit make sure there are no conflict. E.g. No-ones committed any later changes to the data
            - No deadlock, no cascading aborts, and rollbacks area free.
        - Describe how OCC is implemented  ↓ 
            - Each object stores a timestamp of when it was last written to. Then when a thread wants to make a change they submit their edited shadow to a **validator**.
            - The validator then decides on the optimal subset of transactions such that maximal concurrency is achieved, the remaining transactions are sent back to be aborted.
        - What is Read validation and Serialisability validation in OCC?  ↓ 
            - Read validation - must ensure that the order of transactions reading objects is correct, the time they read them becomes their (tentative) start time. We'll then check if that time is correct or if there's a conflict. **E.g. read before the latest commit.** 
            - Serialisability validation - must ensure that committed transactions don't conflict. 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-bq1ANpOgQtKteQPeRzDpW6ylcjcY6jzssHK8I1n327vtVoeFZujbAUSMGujD7pFFWj-LcIuUWonAmYkcCNcPpIdjUd2G8b2PWF3Nj8RqgxvvCCEFvhF76xxipeLSbPF.png)
What will happen?  ↓ 
            - First T7 will make shadows of B and E with timestamps B@10, E@9. After doing it's work, it'll submit it for validation.
            - The validator will first check if the reads are in the correct order. We note that the latest commit was at 11, and both 10 and 9 are earlier than that.
Additionally, both B & E haven't been committed to since 10 & 9. So all is well.
            - The validator then performs serialisability validation and checks all "later" transactions, and finds that T7 is writing to E but T8 read the old E. And must then abort the transaction.
        - Give an issue and benefit of OCC validation ↓ 
            - Doesn't perform well under conflict, working for long periods with stale data. Starvation possible and the transaction system does not necessarily always make progress.
            - Will find more serialisable schedules than Time stamp ordering 
        - What's the problem with improving durability by just writing to disk, what's the solution? ↓ 
            - Writing to disk, could crash during a write. We won't know what data is correct and what's garbled.
            - Use write-ahead-logging - FIRST, write updates to a log. SECOND, commit those updates to disk. If we fail on 1, then the update isn't done (no problem). If we fail on 2, then we use the log to undo or redo. 
        - Describe the write-ahead log, and what happens when we move an item from the log to disk ↓ 
            - Write head logs store <transactionID, which_object_updated, OPTIONAL(operation_performed) ,old_version_of_obj, new_version_of_obj,  >. Note these logs are **append only.** 
            - When updating to disk, write the <txid, START> in the log. Then write lines describing the operations performed (Which bit of memory updated where etc.) then write <txid, COMMIT>. Always write the log BEFORE writing to disk - use fsync() or similar to force a write to disk
        - Describe updating a checkpoint to a write-ahead log, a necessary action to conserve space  ↓ 
            1. First flush your current log records to disk 
            2. Then start a new CHECKPOINT section, then record your still active transactions - e.g. latest reads/writes
            3. Flush any dirty objects to disk (Ensure values on disk are updated)
            4. Write the location of new checkpoint atomically in a known location on disk. Then truncate the log, and discard parts not need
        - What is the benefit of checkpoints?―In the event of a crash, it allows you to decide which transactions need to redo, and which need to be aborted (and which transactions are fine). 
If an transaction completed before checkpoint, we don't need to consider it.
If a transaction completed after the checkpoint but before the crash, then we need to redo it.
If a transaction hadn't completed by the crash, it needs to be aborted.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9y5K6Eqyt94keD6fg5cmxeD9WW-zmRlDV3fjeMuldyQ3TUndTNv1KtytaJu2Ces5YpWe541Lb1_hfelmvOlgyGPkDZ29bKHu-sxEAwaRs9aq3xCM-TIFrgZUuZLsirYo.png) 
        - 
        - Describe the Recovery algorithm with checkpoints ↓ 
            - Start with an UNDO set (initially filled with the currently active transactions) and a REDO set {empty}.
            - Move through the log, if we find a START message add that transaction to UNDO - if we meet a COMMIT message move that transaction from UNDO to REDO 
            - When we reach the bottom step back up, aborting anything in the UNDO set.
            - Then iterate down and redo everything we meet in the REDO set.
            - After recovery, we've effectively checkpointed - so truncate the log.
        - Give some problems with locks ↓ 
            - Easy to make a mistake
            - Don't scale well 
            - Don't compose well (deadlock)
            - Can cause cache slowdown (not spread out on the cache system, can have multiple threads all smashing the cache at once)
            - Can be expensive
            - Priority inversion!
        - Describe how the lock-free approach would work with a linked list with functions find() insert() and delete().  ↓ 
            - Iterate over with find as normal.
            - When a thread is running insert, we do a compare-and-swap with the pointer we're updating - so we don't get a write-after-write hazard.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BHSYSyHuDwtNh5YLlOAqVoTzifwBw_vUyu_jY4uSP6jU1R_u91e6rxnOAXKP4tPq9JUfsTMdg8HF5fhnE6-J3qXMHbW3m-T5pF_SU_IP4D1gzZ_FudgE_h116DEvtl03.png) 
If we fail, then we need to restart, and find the spot for our node again.
            - When running delete on 35, first remove the link from 35 - 47 then CAS the 21 pointer to point to 47. If we fail then return the link from 35 to 47 and retry.
Or CAS 21 to 47, not really sure lol.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TJsOYjHjxBV05RtGWNFbdKaSDQ2GHWM3PzgEx-GJRhoVMPRDWKUe74yQTvdHw8EMH74EWnq8l9MoJXYvL8i6FlgogAFj8TzyrbuZmoKnHV0X8fvzjYArPoVcVzuTSn4z.png) 
        - What is a linearizable schedule, how does this relate to lock-free data structures?―If all ordering of events, i.e. all changes and returns are consistent with some serial view.
Lock-free data structures must be able to handle multiple serial schedules, we can get read/write races - but we assume someone will handle this at a higher level of abstraction with locks or summat'.
        - What is transactional memory (TM)?  ↓ 
            - Convert: ```python
lock(&mutex)
sharedx[i] *= 3
unlock(&mutex)
```TO: ```python
atomic {
	sharedx[i] *=3
}
``` 
            - Under the hood, this is transactional: ```python
do {
	txid = tx_begin(&thd, sharedx)
	sharedx[i] *= 3
} while (!commit(txid))
``` 
        - Give two advantages of Transaction Memory (TM)  ↓ 
            - Easy to compose, as you can nest atomic commands in other atomic commands:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vsGZGynC1A1Tv2jyQcEAFpBKpiGIXaTJMb-Eazp2xruLmbj2F6iBFbhYA25OgYeaa6pzDFhqV6PvUXN92abwQ1B3iC08RM5jtymV6Rl_b5wEVrjsAI8D19Ni9bKOrhFq.png) 
            - Simple to use.
            - Can't deadlock, and no races
            - Very scalable - and fast because it's OCC.
        - 
- Compiler Construction
    -  _**Lecture 1**_  
        - Text > Compiler > **target **machine 
        - A good compiler should do these 5 things  ↓ 
            - Be **correct**, i.e. **meaning is preserved** - i.e. semantics preserved (source language and target language have different semantics)
            - Produce **good error messages** 
            - Generate **efficient** code
            - Itself be **efficient** 
            - Be **well structured **and **maintainable** - Programming languages evolve and change, should be as easy as possible to upgrade the compiler. 
            -  _The first 2 are REQUIRED, from the last 3 options generally 1/2 of them are achieved. Hard to have quick compilation while deeply optimizing code._ 
        - Pareto frontier of optimization - trade-offs, feasible solution region often common. Changing technology changes this frontier.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XoUFAUYcPtd3q4WN2ics6Z8Fc4ar-9Hc7_3E3s-3v3n2hWiz-r-kBSkC6pJWRPt7Ip1k0J7y_SCsgT5EFZIZ-YN5R1uLAVb2RkAlTifAnGBXIS4QJyjbhjwiC5IkU8jh.png) 
        - Divide and conquer is used in compiler construction by  ↓ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VUV7dcNkXjfhgwniatPtyGOsxPv5_ZX7yRJzMdNa7mYvl6ogT1-ds5rH56U8zXwwBQOezXWMQ-ljzK6Hk5fNqWoqZ9qeedo3l9rgBEqHVKOxL3C4ED6hB-RfR0GXCg69.png) 
            - Front end, checks for errors and warnings.
            - Middle, input is a legal program **in the source language** - the output of the middle end is target independent output, **Not yet in the target language**.
            - Back end, takes the target independent output and moulds it to target a certain VM (e.g bytecode is outputted) or OS etc. Result is the target language. 
        - What are the three parts of the front end, and what do they do?  ↓ 
            - Lexical analysis - code tokenised into lexical tokens. Based on finite automata and regular expressions.
            - Parsing - an AST is formed (an abstract syntax tree). Tradeoff of simple language easy to parse but hard to read for a human. Based on push-down automata and context free grammars.
            - Semantic analysis - enforces the static semantics of the language including type checking, functions etc.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Zi6yDdDhPNQoq5-7mCOVG8-OP02kn_Jsf1Rc3Gy8ZQ3BUv0hBYF_5oDSUnVd7ExsH-uBnyABJ1vPYFuyjUPNfXmURyUzbuQo42No9SL_KWBfdYfjXvcUSxlLDBhxHG_Y.png) 
        - What does the middle of a compiler do?―Takes the AST and other info and converts it to low-level, whilst performing some optimizations. The result is a low level retargetable representation.
        - The back-end takes the low-level {{retargetable }}code and aims it at a certain target machine. Requires intimate knowledge of {{Instruction set and details of target machine}}. Need to understand details of OS interface. {{Target dependent}} optimisations occur here.
        - 
        - 
        - 
        - The middle end also provides {{optimisation }}- with the trade-off that {{more optimizations}} result in a {{slower compiler.}} 
    -  _**Lecture 2**_   Lexing
        - **The problem to be solved** 
            - What does a **Lexer **do?―A lexer takes a **stream of characters**, breaks it into **tokens **and **tags them** without any context. It tags them with some datatype/constructor.
            - **Character Sequence**:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TaD32UcLpWln0wjca2pELJ4CCA0QO_gIjRxrKjzOr4bEef9YFYB2-INVyPOf6nrLsYwnkhIggCb2OqK2w297yidr3M6eV9B393j7E9jUV_ItD9iUH7mojdFUxj2tv-qF.png) 
            - Sequence of tokens:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QAOOXh0TiKvQWqr1XI4Xu5DMvlBetnQG4Voxzb2cwdtR_P6T8COG20TzAb84puq5e6AC13lldfixS9ZfIQRf59vlG9o82MaBuaQNlnVAIzhP9-TjIJnbWXEGE2iETgaD.png) 
            - Implemented in some data type:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PCouvqdW5sb9X6DiuBCbI6ag7iI1YYH6eOeTDZEN5ERx-f3EdD4g8BFqGJpFqRLXC0h8l-WhpIaJougOf8Iqb2eSjLndVC2pHRB0Yeo45dSmGTIbMFjigKFDGPnLLYjv.png) 
            - **Whitespace **ignored in this tokenization, as opposed to Python.
            - Having such a specification can be useful for testing, even if you write a faster implementation yourself.
        - **Regular Expressions** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VmIk_F1iXeNXSNyDhKl_RGWd16mvfgRzodqRxhWED8_5_cKOKKZYja7-1Pm6rTSDiF-WcZGZBuL3vPJ7vfvXCkgoYqrvBZmignQgEzUglP0X-0nnpkV3YlxU8UFW0IHp.png) 
            - What does $M(e_1 + e_2) = M(e_1) \ \cup \ M(e_2)$ mean?―This is just saying (for example) the **machine that satisfies** $M(e_1 + e_2)$ **accepts the strings** $M(e_1) \ \cup \ M(e_2)$. So we take e_1 OR e_2. 
            - M is the finite automaton - L(M) is the language accepted by the machine
        - **Finite automata**
            - DFA's have transition rules for every―state for every possible input symbol! E.g.: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GG0rDk6bh05DxAaavPAkjgzMoIQ211g8x2r-rC5h0WvqeYMEVtl0zOnMHx-YzVBE7HvQ52lRJc94ZORZBRrZEUzRwOpPSLAYjmLlQxiaShE6OasQq7mPvc4X3zNjxYFr.png) 
            - What do each of $M(Q, \Sigma, \delta, q_0, F)$ refer to? And what is this machine? ↓ 
                - Q = States 
                - $\Sigma$ = Alphabet 
                - $\delta$ = transition function. It takes the current state and the current symbol and maps to the next state.
                - $q_0$ = Start state 
                - F = final states 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qgMYA7FSfd9GEiQGkNwh5KpUa4_5HsHlHLHZoXf4x2XSLE1CgH2v8AuEMhrxkET0pbhklBmcivmiYN4fcu3ECE0l63ljVr3XKHINQPQtXj8BHGYwWfHAQVgPS02slOf2.png) 
Just says NFA, are DFA with epsilon transitions.
        - **Notation**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1FwrQ6R5ei__2Z7KKalr1whqWa5PZvpPfLJyGZbtDPb1DXzazUrIApR6ix_mzmRc_J3_tRUyPILjzpWCCyDnAKdtsovHTbvawNFq9Ps_4Q76OzGbvt4LMa6L4S9Znk9n.png) 
            - Just notation 
        - **RE ⇒ NFA**
            - We can prove that we can always build an NFA for a {{Regular Expression}}, by rule induction on the rules.
        - **Review of NFA ⇒ DFA**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aasRinDrSoRkEve-i9koOujN9l-DrAoeHoa7SuPw_hZWplVUjwvMVDGLmSTHsFBXmI0TsFlIRxi05B2ymul37zBmaC65lPMYjarijwvOIucSboS2M30anfsYcaSAmKm0.png) 
            - 
        - **How do we compute the **$\varepsilon$-closure(s)? 
            - **What **is the ** **$\varepsilon$-closure?―Similar to transitive closure, say **if there's a q in S that goes to q' - then q' is in **$\varepsilon$-closure: 
$\varepsilon$-closure= $\{q'\in Q \ | \ \exists q \in S, q \rightarrow q' \}$ 
I.e. **if we can reach q' from an element in q** - it's in the $\varepsilon \text{  closure}$ 
            - How do we **compute **the ** **$\varepsilon$-closure?―We just take our elements of S, stick them on a stack - the work through them, checking their transitions and if they're not in S - add them! If we find a value not in our results, stick them back on the stack to be evaluated.
        - **Traditional Regular Language Problem**
            - So if we want to solve the **lexing problem**, that is given a **word w and an regex e **- is w in the Language L(e) - i.e. to find the tokens in our word from our language of tokens.  _ __Can we simply construct an NFA from our expression, then run the NFA on our word to check?__ _ ―No, because what we have is a **collection of regular expressions, each representing a lexical class. **E.g. we have $$\text{given } \ e_1, e_2, ..., e_k  \ \text{  and  } \ w$$
Where one regular expression could represent the "then" keyword. 
            - When given $e_1, e_2, ..., e_k  \ \text{  and  } \ w$ , **what should a lexer output**?―Should output $$(i_1, w_1), (i_2, w_2),...,(i_n, w_n) \text{ where } w=w_1w_2...w_n \\\text{ and each i is a pointer to a regular expression (lexical class)}$$ 
            - In reality we have a **lexical class** for **all our keywords** - we want to break up w into a concatenation of each keyword. We also want to know which of the expression each section of the concatenation matches - also need **specification of whitespace **(might not pass on to the parser)
            - Why do we need a **priority order **of expressions?―need priority to resolve ambiguity! E.g. consider a variable ifif, that could be detected as two ifs. **We want to make the ** _**longest match**_ ** possible. **Results in most specific match. 
        - **Defining Tokens with Regex's**
            - **if: **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VHNu5TeH3fg_klhWwwrOPlmzrxjwU218RA5O4tTMWHXi3EpCGBXOb4_eBrrd3_qKE9Jv-Lo8Fj3Wj3UV7gKBZTZl96SGFM4hpzaiUqTPX_sQLInDHiKpjtt1UEXWdAmZ.png) 
            - **identifiers: **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eMp8Bf4ydWm_fC9N233ZG_XzBmNPxpc8HyVkPgN-8cSHtm4dlJ130fVwexzNNXlB5EjyvjVOyk3TGl72oS1UGwc3TMXiztYKMjmixWzwIR8jLZQ2HNuNPpY1y_KwgOj6.png) 
            - **number: **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/986Qre2nWAnT_cZyBIQo2RxyPyWvPCqyYnJLHHE4d0FCBF_7BVWtiMKfl5znRbcs-MmL0fnvt7_Q1N-3qC35CQFC2mTIG6w4GBsCBFM0Ulnm6fl5ocOKzrgQo_fijRFp.png) 
            - **float: **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ID1epqdeMU2T0_rQF9N3Ng8duyHHKVqypnLD0z-UTuovfRIAo5mmdNx3t7n0xrSCMbzqKo0sSErEx47vKQdbISwiudcQdTskKC1VKdIGqW7FM1Spm59M1Mwqb9lPjzce.png) 
        - **Constructing a Lexer**
            - At a high level, **how do we construct a lexer** given $e_1, e_2, ..., e_k  \ \text{  and  } \ w$?―We construct an **NFA **for the **union of all the lexical classes**, e.g. $e = e_1 + e_2 + ... + e_n$ . Where each $e_i$ is a deterministic machine, **where the final state is associated with the lexical class with highest priority.
**![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CW73Gpxt8FJpJcWKVFJXkRSmmmuMpQPZ63Zjxxe0M0knC1Hzfw8xizCkRTjBHIhG7ixbevuMVJ8I2m-VLAH7EcG2zdF_PifESVQ5tINbIfFw01BTRc5fD4R20zSj4TmT.png) 
            - At each state we store the possible identifier we could be dealing with. The priority rules are "baked-in" to the machine. This eliminates any ambiguity.
            - Algorithm for **Finding longest match** lexical class
                - Start in an initial state 
                - Repeat the following:
      **Read an input until a dead state is reached**, then **emit the last accepting state**.
      Then **reset to the start state**.
                - An example of a dead state would be a space **after **seeing a "then" - this takes us to a dead state. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fYtjPc8TaQ3Br_o2KZvj1ApcTVRs56oNqySfZGbeXFV48zxF3t_-U8sfj2n4Cc-aaSUj1E29N4pkth1mPYexBWv_WpBlchrb7fkmERCe4z-QfUvKSf9VML--6153_Epi.png) 
Note after we RESET, we step backwards one step - notice this is done on Whitespace
                - $ sign indicates end of buffer.
        - 
    -  _**Lecture 3**_   Context-free languages
        - **Context-Free Grammars**
            - What does the following represent: $G = (N,T,P,S)$ ↓ 
                - A context free grammar if build formed form the Following:
                - N: A set of non-terminals - syntactic variables
                - T: A set of terminals - elementary symbols. E.g. "+" or "*"
                - P: A set of productions - e.g. rules for building up our language. Combination of terminals and non-terminals
                - S: The start state - it is a non-terminal.
            - **N: **A set of **nonterminals**, these are― __symbols that can be replaced by groups of terminal symbols__  - could say that **nonterminals are syntactic variables**.
            - **T: **A set of **terminals**, these are―the  __elementary symbols of the language__ , **defined by a formal grammar.** 
            - **P: **A set of **productions, **these are―rules for building up the language, consist of a cartesian product of the initial input and the result: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LkxjB5QdhrWKyap3qRU-0SOfBois05g9GOuH3HeqqzikZZ3VmkH5-QvZUPG13vSiVT51Nz6lR3tnPRWZiJLpukqh0pjS5aTD4xX0bcAqEoU4afg2PvSyHhf-GyS6YwWZ.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9QXPQBnemC0c9buEzVZzwgGvbEfjC-kNO4-qlKNG5VH0dTZwoPA4P1Vezu2CSPf9Tt_h0k8f4mjm6qXnB5Rd23ej_7lP9yZgbph465De21vV2mQqsN7jNXgnvBRzP_Tu.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9K0cazjFPi70xnR0P1xDBscBXXuYWf0Cccn-q8YB8CVTQAyXTifnCjsBexYoqdBzZPiuOBD8UV7W1dcm0kc-dNdnEFLkik5ChW-6mSJhZru2_ELKr9X8ZZvj0W1ur9IT.png) 
            - **Example CFG:** 
                - N = { E } 
                - T = { +, *, (, ), id }
                - E ⇒ E+E | E*E | (E) | id
                - Note - the **order **that you present these rules **doesn't matter!** 
            - **When **is a grammar **ambiguous?**―When there is **more than 1 way of deriving a sentence**. 
            - **Derivations**
                - Why is this grammar called **context-free?**―Because when you perform a "derivation step": $$\alpha A \beta \implies \alpha \gamma \beta$$ 
We don't care about the context A is in, we can simply perform the rule.
                - Note: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/n3L4AHyrh9GMZNyCCQABaplv6f9c8vuVADavRxTWciVjb-HeXJ9aOiwpWYoOewP4HhZZShq9ifvxHLtBMePg6lgxJUIOiVyxbi2pO-FomBWilyNHmjnKGQpkSWbTH51N.png) 
                - 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/420uLV9nkM6UZE6edLdrjsTNkW7FYsPaHy1W4AOib4GHG1OeBuUhRm0MIJNvC_aINAAAV-SSXkRhp9SWJkuPb8w2fnY_FaN1EmjZ5yV86UW9ql9WAzpNmFyb9rig2ggg.png)
Note the variables, are an instance of an id! 
                - **Leftmost vs rightmost derivation**, work from the left/right until only **terminals **are left.
                - This **derivation **of a **sequence of terminals**, tells us―that **sequence is in the language**.
            - **Derivation Trees** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/orfRuAkuvetSkP97Br3uMm7hylr0NVXQz8P9sszzXWEAKzNASvVQmfsLGx2BPtc3XveaKmJZ8nkWDlY2FUBTSiPZS9tRTeS_43OluqBnYVhe7RfpoaVDVnqt9fA_Bu7M.png) 
                - The difference between a **Concrete and a Abstract Syntax Tree **is―an AST contains only the information needed to generate an intermediate representation.  
Brackets not needed so removed:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SEwDBSLQT_EAIA7AEDAr3JKpdszW1koFg-dD0Vr81UwWkBgE9FsjpQVUu2w-ImLiYGW6nZlBhk6rf8_dFG5t1GB7OGO3BoiJj_-2fCXFtw6q5Rp0qZeNOdAdzwt7IvgC.png) 
            - **The language generated by grammar G** 
                - What does this mean: $L(G) = \{w \in T^* | S \Rightarrow^+ w \}$ ?―It means the language generated by a grammar G, is **equal to all the finite sequences** of **non-terminals** generated by **starting from S** and **following multiple productions**.
                - Note, if we take:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OwvDsNfrYoMyfrV__rDcAxb3GnmpLzh-l4GIzWSXr4Ea9TG8-cTskrbPgursx7T3rR1FGSWQ9MG7osCu5yopn_88mQ-MmMQBEguTgJcJ32q8PoEd_NfkpNiMM1Is-f5a.png)
we get:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Zy5gI4f3tMtZFYUHd6h9LPP4WQHFAitFnGVUWY-MEEy61aD1Nx8wWOdEOUOWyTjwZaOLG5wfABTF7fo8iY-vgIzf87QLmBtImbQ0UzW4zOUhC5CryRZwNlGcZO1rXG4N.png) 
This is a language regular languages cannot generate!
            - **Pushdown Automata**
                - What is a Pushdown Automata?―A finite automata augmented with a stack
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ocYPLT91xqkWG2XWxGLgMnCrfH019ND4RitOMZ3AQaNemSSlS_Snk6tvhbyIPyHbDnFCsq0O7PIRe8kY6zjwa47YP94tFYSCdh7KnGzd-4VPwotTDoU9YgjcnjFMu5Eq.png) 
                - What does each element of  $M = (Q, \Sigma , \Gamma, q_0, S, Z)$ represent? Be sure to mention the input to $\delta$.  ↓ 
                    - Q : States 
                    - $\Sigma$ : Alphabet 
                    - $\Gamma$ : Stack symbols   
                    - $\delta$ : Transition function - takes the current state, the current symbol being read and the current symbol on top of the stack.
                    - $q_0$ : Start state 
                    - $Z$ : Initial stack symbol 
                - $\delta (q, a, X) \subseteq Q \times \Gamma^*$  Means―when we see an X on top of the stack, we can non-deterministically move into some other state (Q) with a different stack ($\Gamma^*$). 
                - Pushdown Automata are **nondeterministic**, so everything we do will be a heuristic - as we want our parser to be deterministic.
                - For **Pushdown Automata**, what does $(q', \beta) \in \delta ( q, a, X)$ mean in **English**?―It means, if we're in state q, reading input a and there's an X on top of the stack. We can transition to state q' with $\beta$ on top of the stack. (We pop X and push $\beta$.) 
                - What is an **instantaneous description**?―$(q, w,a)$ It's a description of the automaton in a instant of execution. At state q, reading the first symbol of the word w ($w \in \Sigma^*$), with $\alpha$ on the stack.  
                - **Language accepted by a PDA**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Lm_R-0OHo48effkENxE7LvY2OCRLvO4IbQ-VLLwrkpwU7OQvR9Vjg54s7NiVFHz62S3KQCnFuD3GIRFl3ZGwmSCgTPEv3BhGAWwlXrzEIbemK8qLPZt1bsBlY2-VxUiy.png) 
                    - When is a PDA finished computation?―When the input and stack have only the empty string. $$(q, \varepsilon, \varepsilon)$$ 
                    - For every Context Free Grammar, there exists a {{PDA }}that accepts it. Also, for every {{PDA }}there is a {{CFG }}that accepts it.
                    - The problem is **our PDA is not deterministic.** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/t4MmhDn-MGgk_H81BSIFIDM8OhBPTXwMQs7XRhEqq1YVOBtllBHMjpbgvv-OYoQn7e0BKRZoS2VSaFfhTrM4tWOjz6ynhkci5L6T0tSCdNJm-f9kn6FWwpXTIXzgXqJF.png) 
            - **Modifying grammar to eliminate ambiguity** 
                - Want to say times binds tighter than plus
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qvBsVVcqCz6dFLWHb2gbS1AoPhughxgpSsC9K5OStIlRMSxd8u99PuHVlvoWbjXgpwUMxXsK8G_zFoevtH02udwQr5QlHCdihnMb9i1ud030xXAWS1RJd5QS78CHp0nZ.png) 
                - Add to our non-terminants with a term and a factor. All over the place in Python
                - Note that there are **inherently ambiguous languages! : **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6qAO3aJ3K0Wgs76BFLKPZPeChkSXYX_d4D7l5IZZdn9M39VgVOxKB-0gV1KI-CWP0JAWI-j-w_ARzr0m96fgb-4hEyRVZarBS2Ag0P_UG4GpI9oChCmtvxM9rYtVEDRy.png) 
We would have to guess which of these languages we're in - even though both of those are non-ambiguous.
            - **Top Down vs Bottom up Parsing**
                - Top Down pasting attempts a left most derivation - using recursive decent and predictive parsing. 
                - Bottom-up parsing attempts a right-most derivation backwards. 
        - 
    -  _**Lecture 4**_   Top Down Parsing
        - **Recursive Descent Parsing**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vRiR0ZfUV7GlG-rF-mhJlRLWA7dGqqLnMuiASjxTt0NZmxya2nPQd6Km0VzRobIco-gvxOuN4OvXvS5kAvxWhKH5kcrXTTipIVZuuCXTuFqbgd00Dpu2oyNtxJi0F5B9.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/matwjiUUpN4Z_gWqgCSCLS22frtCYIIrb2pco-TSwJ82IYG1NVS0NSk7S1RYilWHR6Ztp1byMyPGTvGT9CW2k8Oj1QxrnaWG4R4JzzH5hnpLvjeFKACRiLHrztv7AmSv.png)  
            - 
        - **Eliminating left recursion**
            - Left recursion $E \rightarrow E+T$ in G_2 will lead to an infinite loop! 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/l8xOcaNeVGJrwKKY0g3IuMGJ9_qxKS_weT3s8iVeIIvPjuGo3YovnWfEy8mjS4rSZa8LF6U0c642zf67-04_2c4JggkQBvAYZfjCwuLrSxxOLWT3DSD6iYD55XJW8G53.png) 
            - We necessarily start with a BETA, followed by some number of ALPHAs.
        - **Recursive descent pseudocode**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/x8_vCjrei9LMET6yq894KYLsppl1CCQHG1bDwQzrESZuJBuQiJqWpnFFdqFG3fAp0dRJlxIdZ22JpLqJG57EBB_tLknoNZ9DfrzY4ilC0p43x1OUZUCHj0UTYb9FS1GF.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/un7DkTxktefxJAbUmLIM_h_rCY4fXT203PXKKJ31Cq0BbNOaMl_YBReakCfHEX9s-qyrYOPWpiCnvJtATPMOf_bt0eyLZOxAKZjq49FBmEJmdGhTA0ajRZHNCftTn-n9.png) 
            - **This pseudocode uses the runtime stack. **And thus a pushdown automata
        - **LL(k) and LR(k)** 
            - LL(k) : Left to right parsing k-symbol lookahead. Must predidct the next production
            - LR(k) : Postpone production until all of the right side has been seen
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RlybpOg2V-AKcMH8TxwIQNyAvMLkG8b228tY-D-g23tZMEt26vHrx4fQpvR-uYoA3KQw5_fSR9HFfW2h9yK-cpEOxKLEyqa-vM8-HIX5PlgArxAu3zBSGEttM4tbG-iC.png) 
        - **Leftmost derivations**
            - The left most non-terminal is replaced
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U54RRF83SgXbbPEbPlm4URcnEzSeAvFxiF5MGr2LoDpAyx0_2BKyVXotFdJl7_N-j8jmGZBBB6ZPV04ugyBUkspVbMTPnOv-KhzK0C-vLKwdElAtb2GDNq06GHN_lCMW.png) 
Where w is the part of the string we've already parsed.
        - **FIRST**
            - Steps backwards through the rules, 
            - It is a function that gives the set of terminals that begin the strings derived from the production rule.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TiywDcx4Vd_tDwBzHMrRWj2tYDTKY_5Xu7KdADnYFFbuRU6ID8QlAkgEWOm-_6KES8YSnlpIA11Oo9_V-wXb5SNdLCFVXKSTkaqSxyrVOWfcsVTz1MCezWMV1x4sSupl.png)
Should be T U {eps} 
        - **FOLLOW**
            - The set of terminals that can follow an A, in a derivation.
            - In other words, a terminal c is in FOLLOW (N) if c can follow N at some point in a derivation.  
        - **The LL(1) Parsing table M**
            - 
        - **Table M for grammar G_3**
            - 
        - **Nullable**
            - If a string boils down to the empty string - 
    -  _**Lecture 5**_   Bottom up parsing Part 1
        - **Non-deterministic Bottom up bloody fucking well parsing **
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/z0kTkFukBbmf4gx6h1YMgJMk9b_0prEfhm-OXBwa8DX1XUoEyCzrbeFizklYUDnp3D8i2jRv8CGC5x-8XPiwJm5CKA08SETWQc4aqXjZgoWJ6s-nVQr7IgLWtbLcY5Jf.png) 
            - E' added so theres a starting production.
        - **Rightmost derivations**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4gRCBEncNOvG6ofB0upbNMxhH8xudlKHdusqxGQFqPSibK0_Hew82kV1IxDVSqPzqOlnePftMKvGrie-zVBgvsnLNexMQf0WaaNMWrEu1eLUAPm4bK2lDku4OeVXFRfC.png) 
            - What is a **rightmost derivation**?―A rightmost derivation is a derivation in which the completed **collection of terminals** is **on the right**, and we **move in leftwards** applying derivation rules. The left contains terminals and non-terminals.
        - **Bottom up Parsers** 
            - What is a **bottom up parser?**―A bottom up parser **starts with a collection of terminals** and **works backwards** through the derivation rules, **ending with one or more non-terminals**. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hST6opXLlcHJ_i0K1gjXvVgLT3v8yD50iq-pTeYcyh2jOETBaOwUY83IOOMpNnMU0ct0Drs6tUVMRfX8DpheQ1WdprNzQU8CYTNLbfxERralrIH12Ocz6FbsQQEMxeeg.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i-XCjiPfwnOddgg_nwi6AShQVCXZD7-Fnp4WNIL-c5j_136FspYV05bPLn1JxnhzVdvrRs9CyDso9HrzHQPy_vk2Q0vepIvLaTndXEzgQKP0--6bQz8yi3EEt9sZGxh6.png) 
            - We find F⇒(E) when we've seen both parenthesis.
            - reduction other direction to reduction?
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LFC7XiJGo891JiI83PhG_EVXbh6YB7NGayxUPEZE-Dui8zDLkEet1mFlY7uPQ1e6N8GhaNN3KcDxl88Km71CWRjzHDwUYuwQ9Z3KkDYjlvp84dhvT3ZIOvfW1sWlO1hp.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4iv6pmse6cGhoscId8dX7VYvzZ6wPWdJmcXikq9pGUMwYSBJyMcM0vdDsXune1aDYez3qUNH_u9t0S3I6BoXG5UWg0wNuva0eBbiXGGi87NF2wvVxv5sjK5SUS36TXTY.png) 
            - What is a **reduction? **―The **opposite of a production**, move from a collection of terminals and non-terminals to a non-terminal. 
            - **Need an action that ** _**shifts **_ **a terminal onto the stack** 
                - We want to do the reverse of:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7WS-RBqGPEsOCJLOUK6iSVFNLZJNURA_DXbc5qBgLdrC7kd-2Pq7CFK-bB1x7G5MeLPSJYVA0CRt2EyvJEuRsB0NyAJ6STJi8iE3ZRuQPQ06ozu_ryfX6M6veaE3kWnR.png) 
                - So we need to move z **onto the top of the stack**
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ED2UutU9PdYLua9XcxCSzDbWkuj8EgRPml9MXVHCJsvOBsEBJmfb3p-2slQP41z70Z2UKk_3b62ttkJiPety1ORmNf42OBjxiYydtQQD2kJXRTzp_98tgT-3BIFh6b48.png) 
                - Where is the **nondeterminism in a LR parser**?―You **have to decide** **when to stop shifting** and to **reduce**. Note. Shift and reduce can completely reduce any derivation.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HED0s2RIepNj1LVCQOUVzkGvhn52BNAWg0SzevNYHkVFuUy1bQ73oocSO483LoWq9DjS-Z5nCuRE-ushbunxOB3x1PZddsUuJqJAp9DIpmxBg4QVSx8RiCuvkAwBBfrs.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Y0gSgqq5VyJ2IcZevjOmHyHwhDwio5wsl8Lmq71a7_fB0dXSeF0mA_CUHxrXSEkupFtiyN32jU1g4_WVJV3dG1CGFoLkT09G7GU1xlRONbQTC8t7c4m0VKmYiu-qRaHl.png) 
            - **How do we know when to shift and when to reduce?**
                - LR(0) Items:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/a5k3lOB6TaO4KMMIXaI83EBHj1OGzWtMHiIaz_mhvpgFsj_OVI5RswvnpLSoMg2qWxyEiDSd6uy_ivpyPh2jbsb1Yd8wfNkJjZVYPYhAm4---1-zism7jpMh-TrJ2UDD.png) 
                    - What are **LR(0) items**? What are they **useful for**?―For an LR(0) item like $$A \rightarrow \beta \bullet \gamma$$ 
this is a way of saying, **we've seen **$\beta$** in our stack - keep an eye out of a **$\gamma$**. If we have **$$A \rightarrow \beta \gamma \bullet$$
it means **we've seen **$\beta \gamma$** and we can reduce to an A**.
They are useful as the **parser can come up with a set of valid actions at each step, limits non-deterministic choices!** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U-WtX4715FMBEeuoChDh2oupKqhdHawp8AMJ3-1FqpHyluFxvVA-X05KErkbirUe0gqAhqdWZGApc0bWlwWx7OkuIoxHSdflIjIhoMjIxGInYE1XfzV1OjGJ2ZN5yBTN.png) 
                    - If an LR(0) item is {{**valid **}}that Implies {{**shifting **}}onto the stack is a reasonable thing to do.
                - In the following, **why does **$\bold{ A \rightarrow \beta \bullet B \gamma }$ **disappear? **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wZreS2bydh4vb2nfmL0eWLSADUEuAgcjbLViMDpphhxwI7SX6pBXDEo99UUvHQZBVoOwXkG1XYFHqShAUI1ELsfTYBxKhokvcLOyCP20798bvJs_iZyPF5P4LlrZnAg8.png)―Because **that LR(0) item is no longer valid,** we've no longer got a $\beta$ followed by nothing.  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zlvo4vorv-zSGWBViwZgpAIQH8p7h930m_mrtUHfIvH3uESxjLcOXFL2uv-xOzp_cgWrf8sZOnLGDuJuXYWtFsantYqXufGeE9_hGLu_WU7ItnZK977CdDzfCYa9CqcH.png) 
            - **The KEY idea in LR parsing**
                - How does our shift/reduce parser obtain these LR(0) items? ↓ 
                    - We **augment the parser with a finite automata** that **gives the set of valid items from the current contents** - the parser can then use this (non-deterministically).
                    - These LR(0) items then **become our states to move between.** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zakzdPujCx5zzR7nOoCFK9Cjylgd3kPVQANXxx4na3CySIulvgmugEgpJJXtpa3CShcRV7JN7fTAbwu44QB2djZ4N9XPvZqgBhR2EhBlAMS2RqcRYKUtkp4Uxu3UVovh.png) 
            - **Main LR parsing theorem**
                - Looking at the contents of the stack and reading it from the bottom to the top - that language is regular. **This is what allows this system to work - parsing a context free language but the stack holds a regular language.** 
                - Apparently thats what this says??? ?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6A0tc918QZY52ouOuo-wOPAVAMrnoh8gfUQoF_OdaLaaQBEQLtOHyMqMWF_9urmJ_r7dz0vpiQEvO82CzCX9QRsACPa6ULURclXdqMm16a0fRPVXtwkGLvMvokjD0N61.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/H1pCf0X6p8y2RxdCEFRG-i9sVbVOpJYx6ejScyxGfWBqFD_w_3dEMDrArN8zat81XoYEwGSoI_2PIr5KIqen8jAJJywxJVaXoA1C-2QNdmR8QZ69_YRFTrtw1gjQQ28V.png) 
            - **Nondeterministic LR Parsing algorithm**  
                - What are the **four (3+1) options** in the **non-deterministic LR Parsing algorithm**? And what order do you check these options in?
                    - If $A \rightarrow \beta \bullet$ **then **POP $\beta$ off the stack and push A onto the stack (i.e. reduce). 
                    - If $S \rightarrow \beta \bullet$ **AND **no more input, accept and exit. 
                    - If none of the above then ERROR!
                    - **YOU CHECK THE OPTIONS IN PARALLEL - THIS IS NON-DETERMINISTIC!!!**
                    - If $A \rightarrow A \bullet c \ \gamma$  **AND **c is the next input token. Then shift c onto the stack. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ed3SGPN-GNI0ANX1kZe7O-DUchJHvTWB4B-jElLFJWo2F6no15xrv5ymF87HEPsIbezf0w-DktcDYV9dURL9elXEwpP6UitLVLHZo333Om8t3tr64HGZqJ0kQ_eln2QO.png) 
        - 
    -  _**Lecture 6**_   Bottom up parsing Part 2
        - **How do we make our LR parsing algorithm deterministic?** 
            - We will examine two heuristics SLR(1) and LR(1). 
            - The 2 things we need to do to achieve determinism are ↓ 
                - Convert the NFA to a DFA (for getting the LR(0) items)
                - When there are shift/reduce or reduce/reduce conflicts, find some way of making a deterministic choice. 
                - To do this we can **peek into the input buffer. ** And use **FIRST and/or FOLLOW.** 
            - **First step NFA ⇒ DFA**
                - First we add a new **starting production, **$\bold {S \rightarrow S'}$ 
                - We then have the NFA start state, $E' \rightarrow \bullet E$ in our dummy grammar. 
                - The DFA start state is the epsilon closure of $E' \rightarrow \bullet E$ , namely:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E-i9h02pg34m_-tiHbBZ3Jea8wN2jJhSld0sFmwYvn2BPuaKmhPTYoNdBIW9_iPQYZLxTdVt9r8u0_AEQic7JcPsufyD7cnyAVNkGOm0wPcKwC3HtueqoquyvWy6p4ju.png) 
                - **GOTO (I,X)**
                    - GOTO computes the epsilon closure for the DFA and finds the new LR(0) items that can be produced from our current ones:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1CiObykv7UrVu0TA6Ari1p9DPSeHhFsxJ9U_JmTcmLYaxcbF4dnsUoWEJLuFWDAMdqpyF1kmHhlNMCkmyJkbKCP38GE4_lAZ0J2RZwUIxXsVhjPRteeXBwK2GhDbplzA.png) 
                - **Some DFA transitions:**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/khT7pbiVl5tIgymUdYd6LXg3Z8fcSIRw3FL3La7ZLHwmJ3Sep8UK72nnLAFp2TovkywyT80EO76WDdHOT8GI3JdfSff4yY8XB5qaBwAlq_8A1niu-Ba1nqwKDO6J7p7T.png) 
                - **Given the following full DFA: **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QLvlOjMyNj61xT01v3RIvYeCGmgXXHGt_cWqTqlZnqygRKASe-8B8sv8FA0_d_P2K3g4-y6hyQM4BzBxR2pjZ13Txtdzt9Mj0OT7Xt-EMkeT9n0aZd5pfFpz5anYVi3G.png) 
**Describe the procedure of parsing (x+y) using SLR(1)**  ↓ 
                    - We start at I0, and have (x+y) in our input buffer. So first we read a left parenthesis and shift to I4.
                    - Then at I4 we read a **id in our input buffer. **So move to I5. 
                    - In I5 we have **no transitions, so we transition our id to an F **(We may also have noted that a PLUS CAN FOLLOW A T_) **. **Meaning we have (F on our stack and +y) in our input buffer. **After computing a reduction we return to the start.** 
                    - We read a left paren and an F on our stack so we transition to I4 and then to I3. Transition our F to a T and go back to I0. Stack: (T  input: +y)
                    - Read left paren and T, so we transition to I4 and then I2. We use **FOLLOW and find + is in the follow set of E, **and see we have no * on our stack - so transition T to E. (E AND +y) 
                    - Read left parenthesis and E, so we reach I8. We shift our + to the stack and transition to I6 (We see no right parenthesis in the input so no conflict). STACK: (E+  INPUT: y)
                    - From I6 we shift an id onto the stack and transition to I4. We then repeat the previous procedure until we end up with STACK: (E+T   INPUT: )
                    - We then transition to I4 ⇒ I8 ⇒I6⇒I9. And our whole stack transitions to an E. STACK (E. INPUT: )  
                    - Then (E) ⇒ F⇒T⇒E⇒E' ⇒ ACCEPT
                - Whenever we perform a reduction, we need a {{reason }}to perform that reduction - usually examining the {{follow}} set of the state we're going to change to, and matching that with what's in the {{input buffer}}.
                - **SLR(1)**
                    - How does SLR(1) (Simply LR(1)) avoid shift/reduce conflicts? ↓ 
                        - Shift if the token directly after $\bullet$ is the next item in the input buffer. 
                        - Reduce with $E\rightarrow T$ if, the next token in the input buffer is in the **FOLLOW(E)** 
                - Is there a better method to storing the terminals and non-terminals derived on the stack? E.g. is there a better method than having (E+ ⇒ (E+id ⇒ ...―Yes! Instead store the state on the stack, means we don't have to start again each time and work through the derivation. We can just take one step backwards. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LZsARoFdyakEIEdHVWY_MEzGrCGtGzyPI4ucAZGnL4-F0rwDwisc8ouy5nXbG_ZTlpRIUogjMIFrxI1JBmgVsNnjg_CbNZCM7DnWaBlK2e0wKBsvreodVTE86WAUV783.png)  
(This is continuing from left to right)
                - **LR Parsing with DFA states on the stack**
                    - Describe what this code is doing: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/O5EGctEiAFIndq3J5tIlwMTZwGnRMdp6V1kCptFPa7und534__JfAcx2ia-5ShHnB8Vxztrz9vO6gmAo6nJtJJPNb0Ds4wdnaUgIpYzFTm8x8q_3JCfe_Wqa9r_GB_ri.png)  ↓ 
                        - ```python
 a = "first symbol of input"
 while (true)
 	s := TOP_PIECE_OF_STATE
 	# If we're at state s reading an a, 
 	# and there's a transition t to another state
 	if ACTION[s,a] = shift t: 
 		push(t)
 		a := "next input token"
 	# Otherwise we can reduce and step back down the states
 	elif ACTION[s,a] = reduce A => B:
 	 	# Step down the states as many symbols as we've popped
 		pop(sizeof(B))
 		t := "top of stack"
 		# GOTO gets the next state
 		# We then push that next state onto the stack
 		push(GOTO[t,A])
 	elif ACTION[s,a] = accept:
 		accept()
 		exit()
 	else:
 		ERROR()	 
```
                - **ACTION and GOTO for SLR(1)** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WIdoKHTtPBGHuRHMTek6LPUDQD_b3qoLNm-RBAPQLE6WQasCOQ47xVFSYt993d4Kxt5OukGKinKV-QVVw4ABqNaQqHMqmiEybzKLwZ_vUU0VW012-IQvsjDAb0JlszRu.png) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KDLBVJq5R0uKi788OvQo8DiPy0162kREb4mSSgpqTt2sSxigkuEVTDtIe1KQ9EMHYPnZeeWDs8IsWla1BJGmklJ4yXFgRP3w37f0v4Akq9dfs3c3AG-IMUXPPqAXRQg2.png) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dL0HJX1QDJt5ID-ehcs8sECQd4ADhRPtxbM4_W6NtCeN5sHX0TOyRtQCUh8D1LTAPKIYlZbH3e6JplRGee18r0gpiL7aSoe9Hrqv2diZF4V7i7u5kzbpfkEOo2_T3uWl.png) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eoSNGMD_X5YNsXA6TlFUlfKnqCe0bjkmyw_fbaGRNj6NgvIBNy9VqlKc6oYckdELH4UxRHqiiVMAdolE5kc-6j4FIZMkYcnRR_Mmo5_iKTQU59GLEHDdR9Mhy7X58FKz.png) 
                - We can have cases like this:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eH6twCP1i6wsOUTUnl15AqGxZK3wjaxnDTcaHetngzCb-i-Gn_JqzFnulw_I8e6JlI2xPRDd3NE1IbttNO0rlSB8p0hFd0e0JRgkKdBLSlBNe31y3zaKTsRUETG4MGP9.png) 
Where = can be shifted, **but equals is in the follow set of R. **So we have a shift/reduce conflict. 
                - **Beyond SLR(1) ⇒ LR(1)**
                    - LR(1) parsing has items of the form $$[A \rightarrow \alpha \bullet \beta, a]$$
where a is an explicit look-ahead token 
                    - In the SLR parse table, the AST links nodes when we reduce!   
        - 
        - 
    -  _**Lecture 7**_   SLANG Compiler Part 1
        - We'll start with a high-level interpreter based on semantics, and **derive **the stack machine by a sequence of semantics preserving transformations.
        - **Parsed AST vs AST** 
            - In the Parsed AST we have locations coming from he Lexer - points to the line and where in the line (of the input code) the token came from.
        - Parser needs to return the type of expr that will be returned e.g. ```haskell
 expr:
 | simple_expr 		{ $1 }
 ...
 // $1 is the AST built from expr 1, $3 is the AST from expr 3
 | expr MUL expr 	{ Past.Op(get_loc(), $1, Past.MUL, $3 }
```
        - Static Analysis type checking easy for Slang: ```haskell
let rec infer env e = 
	 match e with
	 -- bind the type with the expression
	 | Unit _		 -> (e, TEunit)
	 ...
	 | Deref(loc, e) -> make_deref loc (infer env e)
```
        - **High Level interpreter**
            - Built on top of OCaml:
            - ```haskell
type store = address -> value
and value = 
	| REF of address
	...
	-- Uses OCaml functions to build SLANG functions
	-- Note that Slang has assignment which we have to
	-- keep track of 
	-- I.e. we CHANGED the store so return it
	| FUN of ((value * store) -> ( value * store))
	
-- Evaluation environment, bind variables to their values
type env = Ast.var -> value

-- And expression, an environment and a store goes to 
-- some value, and a altered store
val interpret : Ast.expr * env * store -> (value * store) 
```
            - 
            - Actual interpreting: ```haskell
 let rec interpret (e, env, store) = 
 	match e with
 	| Unit 				-> (UNIT, store)
 	| Var x 			-> (env x, store)
 	...
 	| Seq [e]  			-> interpret (e, env, store)
 	| Seq e::rest		-> let (_, store1) = interpret (e, env, store) in interpret (Seq rest, env, store1)
 	...
 	| Assign(e1, e2) 	-> (match interpret(e1, env, store) with 
 							| (REF a, store') -> do_assign a (interpret(e2, env, store'))
 							| v -> complain "runtime error ..."
 							)
 	...
 	| Fst e 			-> (match interpret(e, env, store) with
 							| (PAIR (e1, _), store') -> (e1, store')
 							| (v, _) -> complain "runtime error: Expecting a 				  Pair!"
 	...
 	-- Update the environment to have x in v - then evaluate s with this in place.
 	| Lambda(x,e) 		-> (FUN (fun (v,s) -> interpret(e, update(e, (x,v)), s), store)
 	...
 	| 
```
    -  _**Lecture 8**_   Derivation of Interpreters 1 
        - **Datatypes used in SLANG ** 
            - **The basics** 
                - $N$ - set of integers 
                - $B$ - set of booleans 
            - **More interesting** 
                - $A$ - set of addresses 
                - $I$ - set of identifiers (variable names) 
                - $Expr$ - set of L3 expressions 
            - **Most interesting**
                - $E : I \rightarrow V$ - set of environments. Takes identifiers to values 
                - $S : A \rightarrow V$ - set of stores. Takes addresses to values 
            - **Values themselves:**  \
                - $$V = A \ | N  \ | B \  |\{()\} \\ | \ \  V \times V\\|  \ \ (V+V)\\| \ (V\times S) \rightarrow (V\times S)$$ 
        - Need to make sure this is well defined.
        - The M Meaning function, takes a (well typed) expression, a set of environments and a state - and returns the value the expression evaluates to and a state. $$M : (Expr \times E \times S) \rightarrow (V \times S)$$ 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QMEmU5Wlw2JhjlAYC7asW310MWu7rAbFVEH7J510SaHa0dkFrVCQJjFFyCpLeBZ4LmgwyT48IX63aOezaKrA7w7vF2AJ4GrtLBp1-xCEth_9ncPdIz5XG-OSZk_2rDJj.png) 
        - Runtime Stack
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jDmO1mKZTmgd5-AlMDIvON2gJRyi8b1ao_nRmJHiK-6MybB_p-IhaNUOI6Es9oLG79ryjtnTfnG4PEecagVgCosnc-omH7wTlfRyZKDG9Ww6n436zWdFK7eqUW4kjN9r.png) 
            - h calls g calls f. Activation record for each function invocation.
        - Tail Recursion
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jZV4LPJUhv2kiQ40zZqXTuQEEBLkZ08vUM_ky6Mj5g3EnSKgRKOMD8Eh13rjvUntbqnYQRIaVHwx-7FZBa_5MoQySWBMxKWUZJnN04mpJp2js-P2FyWuPIuFoEZnGN3y.png) 
            - **A tail recursive function can be converted to a tight loop** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bAcsOPDbszWT4O17zSzuwdyi73wor519XCrRAzD4Im8JlXbXwGCdAt7jwAQ19z81bOciYqUt1TX4jD3bGtcKDViIfrdG7TlKAGW_G69qrSiL0L1q3HMDK80m9dmCmxFN.png) 
            - **NOT tail recursive**
            - We cannot always convert tail recursive functions to iterative ones automatically, (in complex programming languages **with state involved**). 
            - But for OCaml, we'll consider all tail-recursaive OCaml functions as representing **iterative programs.** 
            - Any recursive program can be converted into a tail recursive program! 
                - We add a **Continuation argument, **containing the **rest of the computation.** This is called the continuation passing style (CPS) transofmration. We'll then defunctionalize these continuations and represent them with a stack. Finally, we obtain a tail recursive function that carries it's own stack as an extra argument. 
        - **Continuation-passing style (CPS)** 
            - A continuation is where a function continues on to. These functions we carry implement a stack. 
        - **CPS transformation of fib**
            - ```python
def fib(m):
	if m <= 1:
		return 1 
	return fib(m-1) + fib(m-2)


def fib_cont(m, cont):
	if m <= 1:
		return cont(m)
		
	# First we figure our fib(m-1), then fib(m-2)
	# finally we need to get the sum of the two
	return fib_cont(m-1, 
		lambda a : fib_cont(m-2, lambda b: cont(a + b))
	) 
```
            - Depends on order of evaluation or +. We assume the left side get's evaluated first.
            - **Note: **This makes the order of evaluations explicit!
            - Need to pass an identity function in the cnt at first.
            - Course-of-values induction needed as we call with m-1 and m-2. Course of values induction means rather than assume some statement is true for all k (and proving that implies it's true for k+1) we assume for all n < m.
            - **Proof by induction of correctness**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/d4nS4A7lMAI5nVjoC8dw_FEEMyn8Wd9UPGjsq3KDPiy8ElByRFwOAfhQUs7bgX2qa9vsBk_A2mliDSWkrEAJhKovT8ko9_JNJ10gxLp1o4vPYw8aTG10gJ87dKcCPpDk.png) 
                - First we define what we seek to prove and find the base case.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qY3cEFR8toYKQJLDs7F18MLaPGdB5j4EdR7F0OcU2AI6jxcWL_7II60h9HPMxCkwrBnTzHYEYyCfa2xRubUAf2Ee4bif7FGxO9bPe3y4qA4SO_cr5xlnujPxwKvZ6m2r.png) 
                - In the last step we apply the induction hypothesis, applying fib(m) to our continuation 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qLz4sxJsXKnXkX0qOYDcNPspIXOZ0t0qxy1nwhavwHvl3Bm1DspU6avkOAeBE42LlwaseN_33jdht5kldxm2b_lPSRN-1ZvvC1eEVYgsdqtT-7koMjETb-DhmYMDRUoh.png) 
                - Line 2 uses the induction hypothesis again. We then pull fib(m-1) into b. By inspection we notice fib( (m+1) -1 ) + fib( (m+1) -2) = fib(m+1)
        - **Defunctionalisation (DFC)**
            - Replace the functions with datatypes. We can do this because the types of functions we're introducing are really simple. 
            - ```python
# (* datatype to represent continuations *) 
type cnt = ID | CNT1 of int * cnt | CNT2 of int * cnt;

# (* apply_cnt : cnt * int -> int *)
let rec apply_cnt = function 
	| (ID, a) -> a 
	| (CNT1 (m, cnt), a) -> fib_cps_dfc(m - 2, CNT2 (a, cnt))
	| (CNT2 (a, cnt), b) -> apply_cnt (cnt, a + b)
	
# (* fib_cps_dfc : (cnt * int) -> int *) 
and fib_cps_dfc (m, cnt) =
	if m = 0 
		then apply_cnt(cnt, 1) 
	else if m = 1 
		then apply_cnt(cnt, 1) 
	else fib_cps_dfc(m-1, CNT1(m, cnt)) 

# (* fib_2 : int -> int *)
let fib_2 m = fib_cps_dfc(m, ID)  
```
            - We form 3 data types that act as tags that tell us the function to compute, namely:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WgI625yRK4dDX5bHFVOT5PuGKm3_iJf6GqCBIzHtOu3sTf-EM6THqXkuJg8HhmTQs70Xr2iNBvo21MmuVB4VHOSSsfo4DKD40iJ4m4EueJ4UQTpXMaBcYPFVyf6w03Ag.png) 
            - We can think of this:```python
type CNT = ID | CNT1 of int * cnt | CNT2 of int * cnt/
``` as a list with two types of cons!!
            - So we can replace the continuations with lists! ```python
 type tag = SUB2 of int | PLUS of int
 
 type tag_list_cnt = tag list
```
            - So our possible tags are the list containing SUB2 and PLUS - the stack becomes more obvious now! 
            - ```python
type tag = SUB2 of int | PLUS of int 

type tag_list_cnt = tag list 

#(* apply_tag_list_cnt : tag_list_cnt * int -> int *)
let rec apply_tag_list_cnt = function 
	| ([], a) -> a 
	| ((SUB2 m) :: cnt, a) -> fib_cps_dfc_tags(m - 2, (PLUS a):: cnt)
	| ((PLUS a) :: cnt, b) -> apply_tag_list_cnt (cnt, a + b)

#(* fib_cps_dfc_tags : (tag_list_cnt * int) -> int *) 
and fib_cps_dfc_tags (m, cnt) =
if m = 0 
	then apply_tag_list_cnt(cnt, 1) 
	else if m = 1 
		then apply_tag_list_cnt(cnt, 1) 
	else fib_cps_dfc_tags(m - 1, (SUB2 m) :: cnt) 

#(* fib_3 : int -> int *)
let fib_3 m = fib_cps_dfc_tags(m, [])  
```
            - **NOTE: **If we have two mutually tail-recursive functions, we can always reduce that to a single tail-recursive function - we simply introduce a datatype indicating which function we're using at the time. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qeIJGGHORRHaqVVHauTI0yTqvbV9IqIP_PpLX2uIX3jn17TOoYVue1EYE6A4X3-mDiRgZ2mFdS1ybY5XZ1P4ywJqZMNXL8C9eDHSAvsMErMEmB8RX5JimUTilcOIEFyT.png) 
            - Finally we obtain the **fibonacci machine:** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oFTKuyK0FJNfyCgKr8dqPIEuCxFT2vmFTwrWC_AcIX0ZJCikHo8Y6usJryxNMMbMUzC-DZa-vpwSrq_kSz_xQAyEMOfoGfjwmHR1cg3RV5EZhvNMsRvDmuZxuKmN1wU2.png) 
    - 
    -  _**Lecture 13?**_  Garbage collection and simple Optimization
        - **User library management** 
            - Gives garbage collection to higher level languages - but programmers can be too clever and make mistakes.
        - Garbage collection, remove any data in the heap **not reachable **from the root set.  
        - Some languages disallow cyclic datastructures - meaning reference counting can be used.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/v8xsmNF9W7C2IiwBmuu6Kiw3htgcNd93Q1nFiAAwiGYN8gY25DYn5PGiH6yxUkfdC1Lw61UjNJCxtGIjsK010W5o684KNgdMk1Zmjkg6GWu6A_7bycQqTViQRmreEGl3.png) 
        - 
    -  _**Lecture 14**_  Static links on the runtime stack
    - 
    - 
    -  _Supervision 1_ 
        1. **Describe the three stages of a typical compiler frontend (lexical analysis, parsing and semantic analysis), including their inputs and outputs.**
            -  _Lexical analysis_ : Given a character stream (written in the source language) and a set of regular expressions defining many lexical classes (in priority order) the lexer deconstructs the character stream into a set of words and outputs a set of tuples containing each word and its corresponding lexical class: $$(i_1, w_1), (i_2, w_2), ... , (i_n, w_n)$$
^^I'm actually a little confused by this - as in the lectures he describes it as above. However, in the Dragon book it says the tuples are the lexical class and a pointer into the symbol table.^^ 
            -  _Parsing_ : Given this set of tokens & lexical class tuples - the Parser forms a **Concrete **syntax tree of the tokens and outputs it. This concrete syntax tree has operations as it's inline nodes and children are arguments to that those operations.
The parser finds if the input set of tokens, is part of the language defined by the formal grammar. It will emit an error if the input set is not.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tbKxJtHiCp3CbBxRlp_EkyQAP1XqKc-OpuMSQjnwUL-rQtkYOd8jufcrGm36SvfsOUtctR4_Gov8suG6V7c0iMfP5dcJ81OUZcyISggeE9MHYqlueMkJH0ExCKUMhooT.png)
This also defines an order of operations. We work bottom up, first performing the multiplication then the + the the =. 
Errors can be detected at this stage and error messages can be produced. E.g. no whitespace between a number and the start of a variable name. 
            -  _Semantic Analysis_ : Semantic analysis takes this AST and tests it for semantic correctness. E.g. are the scoping rules upheld, does each operation have the correct **type **of operands (type-checking). Some **coercions** can also occur here, where a incorrect type is massaged into being the correct type - e.g. an integer is converted to a float when multiplied by another float. The output is a **Abstract Syntax Tree. **The abstract syntax tree has none of the extraneous elements that are not needed to generate the intermediate representation.
Semantic errors can be detected at this stage and error messages can be produced.
        2. **A student proposes doing away with the lexer and writing a parser which operates directly on characters rather than tokens. What advantages and disadvantages might this have?**
            -  _Disadvantages:_ 
                - During recursive descent parsing, we would have a **huge **number of stack frames as every character would result in jumping to a different function. 
                - We would have to have recursive descent parsing functions for each character, with cases for every character. 
            -  _Advantages:_  
                - Don't have the overhead of using or implementing a lexer
        - 
        - REST OF THE WORK IN TXT FILE 
        - 
    -  _Supervision 2_ 
        -  _**Tim Questions**_ 
            1. ```cpp
s -> •t
s -> t•
t -> •u
t -> u•
t -> u•->t
t -> u->•t
t -> u->t•
u -> •bool
u -> bool•
u -> •int
u -> int•
u -> •unit
u -> unit•
u -> •(t)
u -> (•t)
u -> (t•)
u -> (t)•
u -> •u re
fu -> u• ref
u -> u •ref
u -> u ref• 
```
            2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ekdpc2F2HR6gwzZ-Ot_X63u20rCKJU_gy7jdsMGR1Lj-Hn7g_uVkgVnCNV-u6IQryLnI_6VN7GtE6GaN--MFhW2Bb4glXbq3jCqKXHvFLXZP1O86t2qemmp2Ln73p_2M.png) 
            3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dgGvLkWfTqKT9D52nB0O2dCzuejRS8t1leh9-Y5h9iZ1wcRDXD0DxfqKCdfKrRWZ7oPvy4VbydU79JWAje6a0P38dax3_GgOwa9h-UCgaWz3Qll0kUer4aKg8tSt0InI.png) 
            4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Irv6di9gs55RekJujLdRwMp31s3XBTnk3JD8jGwn_sR-HcAiQ7iu3D9cEU1F-CGf9p_KWRw5wap1tklKED7F7vZ8kGcg2xEH8TfjHHKOyx-Ifg8dB3alXkORi7XGuSeC.png) 
            5. A reduce reduce conflict is when we could perform two different reductions from the same input character. This SLR parse table contains none of these.
A shift reduce conflict is when we could reduce immediately, but there's a possibility of a different reduction in the future if more items get shifted onto the stack. This SLR parse table contains none of these.
            6. Don't understand this at all. Neither what LR(1) does, nor how to construct a DFA with lookahead 
        - [**2012 Paper 3 Question 4**](y2012p3q4.pdf.md)** Parts (a) and (b)** 
            - A.) Define the following terms
                - i.) A non-terminal symbol - a non-terminal symbol is a symbol which can be replaced by terminals and/or non-terminals in a derivation step, as ascribed by the grammar rules.
                - ii.) An ambiguous grammar is a grammar which allows for a sentence to be via more than 1 derivation chain.
                - iii.) A production is a rule for transitioning one or more non-terminals into a string of terminals and/or non-terminals
                - iv.) A context-free grammar is a grammar which can be generated by a pushdown automata. The application of the productions requires no outside context other than the string of terminals and non-terminals on the stack currently. Every production rule produces a single non-terminal.
                - v.) A regular grammar is a grammar which can be generated by a Finite State Machine (DFA or NFA). Productions in regular grammars are of these kinds: $A = a \ | \ bB \  | \ \varepsilon$. Where A & B are non terminals and a is a terminal.
            - B.)
                - i.) "cat"+0 
                - ii.) During Semantic Analysis - We've not done that yet in the lectures
                - iii.) ```cpp
Var -> x | y
Str -> "cat" | "dog"
Num -> 0 | 1
Exp -> Str + Str | Num + Num | Var + Exp
S -> Var := Exp | S S
```
                - iv.) Because we would need to create new productions for every function that takes two operands in our language (with every correct combination of types) which would make the grammar massive and unreadable.
        - [2020 Paper 4 Question 4](y2020p4q4.pdf.md)
            - a.) ```cpp
 S → 
BAb →
BBBb →
BBeb →
BSdeb →
BAadeb →
Bcadeb →
ecadeb
```
            - b.) ```cpp
 S →
BAb →
eAb →
eBBb →
eSdBb →
eAadBb →
ecadBb →
ecadeb
```
            - c.)```cpp
S → Aa | BAb
A → BB | c
B → Sd | e


FIRST(S) = {}

We can have an A first in S, or a B - so it'll be the FIRST(A) ⋃ FIRST(B)

FIRST(A) = {c}
c ⋃ FIRST(B)

FIRST(B) = {e}
e ⋃ FIRST(S)

FIRST(S) = c + FIRST(B) + FIRST(B) = c + e + FIRST(S)
 	     = {c,e}

FIRST(A) = {c, e}
FIRST(B) = {c, e}
FIRST(S) = {c, e}


FOLLOW(A) = {}
Examining all the rules, Aa -> a can follow, BAb -> b can follow.
Next consider Sd, S cannot goto an A alone, so d cannot follow
∴ FOLLOW(A) = {a, b}

FOLLOW(B) = {}
FOLLOW(B) = FIRST(B) + FIRST(A) = {c, e}

FOLLOW(S) = {}
Sd -> d can follow. And it could be the accept so $
∴ FOLLOW(S) = {d, $}

FOLLOW(A) = {a, b}
FOLLOW(B) = {c, e}
FOLLOW(S) = {$, d}

```
            - d.) No, because the grammar is left-recursive. S -> Aa -> BBa -> SdBa
            - e.) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RJPkFSaQ1I1IdMygv68aIVqpofJ2mbcrO0cYBOiVmICWXXsfwfhs6xIccgSxyCHENYvdUDMZTnE4d7ElHrbxUR3Yv2vQQpkUrO38xI67TshlFKolycje4YRjqMZpYfYi.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UtjPh7EYwkhJUQIHcu34fj6wVSXN11A4auLD2RV7grdK-LTvOciskX2vvhDNDMrl5B6PpdhoMz89xWsrbhrbgay9iF-JGvOyE8yj3hI9obsHkoY1e1eSd6QZt-ymJQgi.png)
By inspecting the SLR table we find there are no such conflicts 
                - 
        - TEST FOR SLR CORRECT
            - No 2 reduces (reduce reduce conflict)
            - SHIFT or reduce 
        - 
    -  _Supervision 3_ 
        - **Main Questions** 
            1. Continuation passing style makes the current state and the next step of a computation items that are passed over the course of the computation, similar to tail recursion where only the state is passed. It allows us to easily analyse the stack that is being passed, and allows for defunctionalisation where the function being passed is converted to a datatype. But on its own, the possibility of pausing execution and resuming it when you wish allows for greater control over control flow - allowing for the implementation of exception handling, multithreading etc.
            2. ```haskell
let rec gcd (cont) m n = 
	if m == n then cont m
	else
		if m < n then 
			gcd (fun v -> cont (gcd (cont) m v) ) m (n-m)
		else
			gcd (fun v -> cont (gcd (cont) v n) ) (m-n) n;;
``` 
            3. ```haskell
let rec map cont (f) ls = 
	match ls with
	| [] -> cont []
 	| a :: rest -> map (fun v -> cont v @ [(f a)]) (f) rest;;
```
            4. ```haskell
let rec fib m = if m < 2 then 1 else fib (m - 1) + fib (m - 2);;

map (fun x->x) fib [0;1;2;3;4;5;6;7;8;9];;
// this works 
```
            5. Defunctionalisation replaces higher order functions with a data structure - it allows for easier serialization of the program, allowing to split up different actions (allows for splitting computations across different cores/computers) and form a interpreter.
        - 
        - [2014 Paper 3 Question 5](y2014p3q5.md)
            - a.) The tail recursion eliminates the need to generate a stack frame for each function call - as all the state required for the final computation is carried in each function call. So iteration can be used and only a single stack frame is needed - resulting in less memory being needed and the time walking through the stack frame at the end is no longer needed.
            - b.) ```haskell
 let rec fact n =
	let rec cont m a =
		let counter = ref m in
		let acc = ref a
		in
			(while (!counter > 1 )
			do acc := !counter * !acc;
				counter := !counter - 1;
			done);!acc;
	in cont n 1;;
```
            - ^^c.) Not really sure about this question  ^^
        - 
        - [2016 Paper 3 Question 3](y2016p3q3.md)
            - a.) Tail recursion is a method of recursion where only a single stack frame is used, and the entire state of the computation is always held by a single function instance. This means the recursion can be replaced by iteration, and we don't need to spend the time winding down the stack nor the memory building up the stack.
            - b.) ```haskell
 let rec foldl (f) l =
	match l with
	| x::y::[] -> f x y
	| head::tail -> f (head) (foldl (f) tail);;
```
            - c.) ```haskell
 let rec is_even n =
	if n = -1
	then false
	else not (is_odd (n - 2))

and is_odd n =
	if n = -1
	then true
	else not (is_even(n - 2))
```
        - 
        - [2017 Paper 3 Question 4](y2017p23q4.md)
            - ```haskell
let rec eval_cps (cont) e = 
	match e with 
	| Integer n -> cont (INT n)

	| Pair (e1, e2) -> eval_cps 
						(fun n1 -> 
							(eval_cps (fun n2 -> 
										cont (PAIR n1 n2)) e2)
						e1

	| Apply (f, e) -> eval_cps (fun n -> cont (eval_function (f) n)) e;;
``` 
            - 
        - 
        - 
        - [2018 Paper 4 Question 4](y2018p4q4.md)
            - a.) We will need to use stack pointers which point to the top of the stack, and frame pointers which point to the top of the current frame/computation (i.e. the current function being computed). Then when a function is called a stack  is used to which contains the address to return to and the argument to the function. 
Implementing the stack frame will be made easier as there are only first-order functions, we won't have functions as arguments and functions can only take a single integer argument.
            - b.) For a element of type t we need to allocate the number of ints contained in the datatype. This can be calculated recursively via ```haskell
 to_allocate = function
 	| int -> 1
 	| Prod a b = (to_allocate a) + (to_allocate b)
```
            - c.) The base case of the evaluation of a int is to place it on the top of the stack. For left-to-right evaluation first e1 would be evaluated, then within e1 the left most item would be evaluated (we are computing a depth first evaluation) placing ints on the stack and returning when we meet them.
((1, 2), (3,4)) ⇒ 1 2 3 4 (top of stack)
For right-to-left evaluation the opposite would be the case.
            - d.)
First we would evaluate the value as on c (depending again on left/right evaluation order). We would then shift the stack pointer down to_allocate(e2) positions for fst.
Then for snd we would need to for each item in the top to_allocate(e2) shift them down to_allocate(e1) positions and then shift the stack pointer to_allocate(e1) positions - this would have the effect of overwriting the first values.
        - 
    -  _Supervision 4_ 
        - Slightly off topic question, but I read here [Phases of translation - cppreference.com](https://en.cppreference.com/w/c/language/translation_phases) that \n in code results in lines being concatenated - when would this be present? Are they talking about a general newline character?  
        - **Code generation, ASM, linking and loading, ABI, ELF, x86**  
            1. Discuss the advantages and disadvantages of having a single compiler with many target-specific backends vs a compiler that targets a virtual machine which has been ported to the same set of targets.
One can consider a targeted virtual machine to be a separate backend compiled at runtime - this has certain benefits including:
⇒ Runtime security and memory safety checks can be performed on the bytecode, such as array bounds checking or types of garbage collection.
⇒ We don't need to distribute multiple binaries of programs, only multiple VM binaries - and as there will be far more programs than VMs this is worthwhile.
⇒ We don't need to redistribute binaries for all our programs when the backend technologies improve - only the VM need be updated. 
⇒ "It can also provide a foundation for efficiently implementing many dynamic language features." - just parroting this from stack overflow, not 100% sure why this is the case.
It also has downsides including:
⇒ Because the compilation needs to be done at runtime, certain slow and costly performance improvements cannot be performed - this means code may run slower.
⇒ We now have the additional burden of loading the compiler when we run a program, meaning programs are slower to load.  
            2. What is a linker? What are its inputs and outputs?
A linker takes object files as input, and combines them to form a single executable file as output. The object files contain certain data about the program that the linker can use, this includes the symbols to be exported and imported, (not 100% about this) the locations of addresses that must be relocated and constants used in the program (not 100% sure why constants need to be specified). 
            3. Give examples of programmer errors detectable only at link time.
If a programmer writes the wrong name for a method in another file. 
If multiple methods (in different files) have the same name, type signature and parameter types/num parameters. 
Variables defined multiple times in different files. Multiple declarations could throw an error too, depending on the language.
            4. What is a loader? What are its inputs and outputs?
The loader takes an executable program, loads it into memory then runs some preparatory code before passing control to the program code. The loader is part of the OS. 
Dynamic linkers link libraries or files to already running code at runtime, they load files into memory and can thus be thought of as loaders. They take object files.
            5. Give examples of programmer errors detectable only at load time.
If a dynamically linked library is used incorrectly, e.g. incorrect method name or type. If dynamically linked libraries contain additional definitions of methods or variables. 
        1. **Register machines, simple optimisations, OOP, exceptions**
            1.  _What are the _  _**advantages**_  _ and _  _**disadvantages**_  _ of caller-saved vs callee-saved registers?_ 
Caller-saved:
Don't have to worry about the callee messing with your values (even if accidentally). The callee doesn't have to worry about overwriting any values, can just execute their function and use whichever registers they like. Means you have to save all the registers on the stack, even if none of them would get overwritten, this takes time - additionally have to resinstate them afterwards.
Callee-saved:
Caller doesn't have to wrap and unwrap (afterwards) all the registers. 
Callee can only save the registers it would actually overwrite (could be none).
Programmer needs to remember to reinstate the right variables, could cause hard to diagnose bugs if a value gets overwritten.
            2.  _Explain a typical layout in memory of objects in a language supporting single inheritance and dynamic dispatch._   
Objects contain fields arranged in a given order in the object data, and a pointer to a vtable containing their methods to be run (the vtable is the first item in the object data). For subtypes, the fields of its parent types are the first field items followed by its own fields - its vtable contains a pointer to each method and where methods are declared and defined as they could have been overwritten (if there are no overwritten functions then this will just be a pointer to the method). Note the order of methods in the vtable is maintained from the supertype.
These features allow for a pointer to a subtype to be treated as a pointer to the parent type.
            3.  _What complications does supporting multiple inheritance pose at a language level and at an implementation level?_ 
We cannot simply treat subtype pointer as a pointer to its parent type, because the fields will not necessarily be in the same order - i.e. the first field could be from class A, the second from class B and the third (the subtype) from class C. If this object is treated as a B type pointer, the first field will be incorrectly interpreted as a B type field. 
At a language level, we could have multiple definitions of methods from supertypes and not know which one to use.
        2. **Garbage collection and bootstrapping**
            1.  _Can a garbage collected program contain unchecked runtime errors?
_ Yes, depending on if the safe-use rules for the garbage collector are followed. For example, programmers shouldn't obfuscate the pointers being used by XORing them together (or similar) as this could result in the garbage collector trying to access data outside of the allowed bounds or messing up the heap.
            2.  _It is alleged that garbage collected programs can contain no memory leaks—is this true?
_ No, for one there are some garbage collection methods that do not collect detectable leaks. For example if reference counting is used, cyclic objects could be formed which are not garbage collected - these could amass and form a large memory leak. 
Additionally, if an object in the heap is being pointed to from the root set - it is possible that the object will never be used again and is thus garbage, however the logic for this would be very complex and slow to decide and is in general undecidable. Thus, such an object will continue to sit there and if more pile up a memory leak forms.
            3.  _"It is impossible to write the first compiler for language L in language L." Discuss this claim. True or false and why?_   
This is technically False, as you could write a translator which translated the whole of L into some MBC which could be interpreted - then you could simply translate this compiler into MBC, then interpret that and compile your compiler to the base language and use that. However, in general writing such a translator for large languages is extremely difficult - and is not necessary in general. Instead we write a translator for a subset of the language, which we then use to compile L. This compiler is finally used to compiler our desired compiler in L. 
            4.  _A devious hacker wishes to write a compiler for their own language L which adds a security flaw to programs it compiles. They wish their compiler to be open source, so people will easily spot their devious hacks. Suggest a way for the hacker to include the attack, even if the user recompiles their compiler._   
The compiler could change the source code of the compiled program, so whenever it is compiled again that same security flaw exists. 
        - 
        - 1. [2004 Paper 5 Question 7](y2004p5q7.md) 
            - Consists of function definitions which have bodies containing if-then-else, while-do, assignments and (typed) declarations of variables. Only 1 statement or keyword per line
            - For each of (a)–(d), (i) summarise the main phases of work that are done before execution in each case, giving a brief explanation of the main actions of the main interpreter loop (if any) during execution, and (ii) for each of the following possible erroneous forms, explain whether the error would be found before or during execution: malformed syntax, undeclared variable, type error, division by zero.  
            - Note, by the **typical front end** I mean lexing, then parsing, the type analysis and then semantic analysis - where we come out with an AST with correct type information attached. 
            - **a.) Compiling J to machine code
**We start with the typical front end. Then we must compile this to an intermediate representation, we can then perform some optimizations on this before performing targeted changes to the code to transform it to machine code. This machine code will be machine and OS specific, and different methods of translation will be needed to glean the best performance. During execution the machine code can simply be run, no interpreter is present. Malformed syntax, Undeclared variables and type errors will be found before execution. Divisions by zero will be found during execution.
            - **b.) Compiling J to "interpreted byte code" and then interpreting this**
Again we start with the typical front end, then we compile to this byte code representation which will be interpreted at runtime. We are performing JIT compilation. The interpreter must convert the byte code to machine code on the fly and check for errors - it can also provide types of memory safety like array bounding. Malformed syntax and type errors would be found before execution. Division by zero and undeclared variables would be found during runtime.
            - **c.) Parsing J to a syntax tree, then interpreting this
**Before execution lexing, parsing, type analysis and semantic analysis would have occured - however we still need to convert this to an intermediate representation and then to machine code on the fly. The interpretor would need to walk the tree and compute this. Malformed syntax and type errors would be found before execution. Division by zero and undeclared variables would be found during runtime. 
            - **d.) Keeping J in a text file**
The interpreter would perform the front end on the fly, but only line by line - we could not find multi line syntactic or semantic errors. Then the intermediate representation would be formed before machine code would be generated for the line, the line would then be executed. All of the errors would have to be found during execution
        - 
        - [2. 2011 Paper 3 Question 4](y2011p3q4.md)
            - a.) The static link method attempts to solve the problem of nested functions, and how a nested function is within the scope of it's parent function and thus needs to be able to access it's variables. The static link points back to the most recent method that statically encloses the holder of the static link. When a function is nested within another function, the static link points to the stack frame of the enclosing function - this is stored in the frame control information. Then if free variable is encountered, we can follow these static links to find the value. This is different to calling a function from a method, as the callee does not then have access to the callers methods. 
            - b.) ?
            - c.) When we come across a handle (say e handle f) command, we first build a special handle frame - then we build up the stack frame for e, if e evaluates normally e handle f evaluates to the normal value. If we come across some raise v', we must evaluate f(v'). We then unwind the call stack and pass the value of v' to the handle frame and f(v') is evaluated.
            - d.) ?
            - 
        - 
        3. [2012 Paper 3 Question 5](y2012p3q5.md)
            - a.) i.) A variable with global scope (can be accessed anywhere in the program) who's memory is allocated at compile time. Thus it lasts for the lifetime of the program.
ii.) A temporary variable stored on the stack who's lifetime is the same as it's invoker function.
iii.) A free variable is a variable that is not bound by the function/scope which it's immediately in, and is instead bound outside of that scope beforehand.
            - b.) Local variables, as the fields value is destroyed when the object is freed from memory similar to the invoker function.
            - c.) i.) 
Statically allocated global variables are allocated at compile time.
Local variables are allocated for on the stack at runtime.
Free variables are allocated for at compile time, as they are simply normal variables but in a lower scope than they were created.
The linker must computer address relocation for statically allocated variables, as when multiple object files are compiled again the data or code addresses pointed to can have changed. The loader then loads the program into memory and passes control to the program.
            - d.) For statically allocated global variables a pointer must be stored which points to the location of the item in memory where it can be read or changed.
Local variables will be stored in registers and can be quickly accessed from those registers.
A free variable's value will not be directly accessible by the method they're in, as its value/a pointer to it will not be in a register. Some languages (like C) would require this free variable to have been in the global scope (if not in local scope) and you would then search there - other languages would have you incrementally search higher scopes (by traversing up the stack frame from callee to caller) until you find the value of the free variable but htis can be slow.
            - e.) ?
            - f.) Because in strongly typed languages you know which items are pointers and which aren't, so you need only follow the pointers to find live objects.
            - g.) Stack based allocation leads to variable length stack frames, meaning we introduce the overhead of managing **both **stack and frame pointers. The overhead of increasing and decreasing the stack pointer is tiny. Stack allocation is much faster than heap allocation, because the stack is usually in cache and can be accessed extremely quickly - however the stack is small, so should not be used for large objects with long lifespans. The heap has the advantage of being large, and is better for longer lasting objects than the stack as we don't have the same pop system as the stack. 
        - 
        - 4. [2017 Paper 3 Question 3](y2017p23q3.md) 
            - a.) Otherwise objects can build up in the heap (a memory leak forms) until the heap is full and no more objects can be stored on it - meaning objects that may be needed may be overwritten, or no new objects can be added and execution must halt. Garbage collection (mainly automated, less so explicit as errors can occur) tries to prevent this by deleting any objects on the heap that can never be used again - allowing space on the heap.
These languages may need this heap space to function.
            - b.) Garbage is data that can never be used again (in a perfect world we would remove data that **will **never be used again, but in general that is undecidable). I.e. data that has no pointers to it from the "root set", the root set being the memory accessible locally by the program - e.g. addresses stored in registers or on the stack.
Garbage can be located in memory by first marking all elements reachable from the roots set (mark) then sweeping through memory searching for objects not marked (sweep) and removing them.
            - c.) If a sensible number of bits were used to store the reference count, say 32 this would normally require 2^32 pointers to that object in order for a reference overflow to occur - currently this would be far more objects in the heap that we would generally see (except in specialist programs where 64 bits could be used). Cyclic objects would not produce this behaviour, as we only increase the reference count for each **pointer **not on a traversal of the pointer graph.  
            - d.) It depends if the language has side effects, a language like OCaml includes references which could alter the behaviour of the mapping if g is applied to all elements before f rather than f g being applied to each element in order. If x is some ref, g(v) = (!x = !x+1);v;   f(v) = !x * v;
Clearly this will have different results.
However, we can glean a performance optimization here (Inline expansion and constant propagation could be used) where the composition of the two functions need only be calculated once, then the composition of the functions can be specifically optimized as opposed to optimizing the two functions separately. C compilers often do this. This will of course increase compilation time , but could ideally improve runtime performance.

        - 
    - 
    - 
    - 
- Computer Architecture (Intro to)
    - Supervision 5
        1. Discuss an example of a problem that we can solve efficiently by using CUDA.
            - CUDA works only for Nvidia GPUs, so the problem needs to be parallelisable (problems like video decode, rendering, deep learning etc.) and preferably with enough data to take advantage of the large scale compute GPUs offer. Due to CUDAs relative succinct syntax, the solution can be developed quicker than with OpenCL and will run faster than OpenCL code **on nvidia GPUs. **I.e. while OpenCL code can be run on NVidia GPUs, CUDA exploits methods to make it's code run faster.
        2. Discuss an example of a problem that we can solve efficiently by using OpenCL.   
            - OpenCL can be used for problems where the final device the code will run on varies. Because the code is compiled at runtime, OpenCL can cater to many different device types (CPUs, GPUs, FPGAs...) as the ISA is optimized for at runtime. Thus, if you were planning on implementing your code on a microchip without space for a GPU, and on an FPGA OpenCL would be a good option. However, the hardware you're planning on running your OpenCL code on must have support from the vendors as otherwise the API will not work with the device. OpenCL can provide many of the same parallel features that CUDA does, however on some of it's application domains those features will not be applicable (For example CPUs with modest numbers of cores).
        3. How is it possible that so many different devices, with completely different internal  architecture are compatible with OpenCL and enable acceleration of execution?
            - This is possible due to two reasons
                1. OpenCL code is compiled at runtime, allowing the system to implement system specific optimizations when the physical characteristics of the device can be determined. The alternative method would be to have separate binaries for every device.   
                2. OpenCL gives the programmers set ways of abstracting away from the metal. Memory is viewed abstractly, threads and thread grouping is viewed abstractly and the platform model abstractly models the system with one host and multiple devices. 
        4. In CUDA, what’s the difference between a thread block and a warp?
            - In CUDA thread blocks contain multiple warps - while thread blocks describes a set of warps all executing the same kernel, a warp describes a set of threads all executing the same kernel. Warps within a thread block can communicate. Thread blocks are executed on a single streaming multi-processor, with individual threads being executed concurrently. 
        5. Why does OpenCL require an application to discover the available platforms and devices?   
            - Because we don't know before runtime what platforms and devices are available, OpenCL code can be run on a wide range of different platforms and devices. This also forces the programmer to consider that fact.
        6. Compare and contrast the OpenCL programming model with CUDA.   
            1. CUDA built for NVIDIA GPUs only, OpenCL heterogenous. Meaning OpenCL requires more general programming approach that will work for many devices.
            2. CUDA specifies host and device, OpenCL specifies host and devices. Both have sections run on the host CPU and the devices. OpenCL uses the kernel keyboard while CUDA uses device.
            3. OpenCL much more verbose than CUDA, more code required as less guarantees about the devices and their capabilities.
            4. OpenCL has work groups and NDRanges - while CUDA has warps, thread blocks **and grids. **NDRange comes from a use of mostly 1, 2 or 3d problems in most target applications of parallel processing, CUDA gives you more freedom to structure your solution how you'd like.
            5. Compilation at runtime with OpenCL, meaning you can't know the exact machine code your program will generate - with NVidia you have more guarantees.
        7. What types of application best suit GPUs and how can you program to take advantage of the  various forms of parallelism available? Try to describe examples.
            - The best applications are so called 'embarrassingly' parallel applications. These applications require the same operations to be applied on a wide array of data items, with (crucially) individual operations being independent. This allows all the operations to occur at once, with minimal consideration on whether another operation has completed or not. However, one must program in such a way that the parallel operations are truly done in parallel - for example in graphics the different types of the Phong light model are independent, so rather than doing them one by one in - load them all into the immensely capable GPU and let the cores work away. Another example would be machine learning, while layers depend on each other for back-propagation, we can pipe in partial results from one layer to start working on the next - partly parallelising a linear sequence. 
        8. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4ouCT39UXVo_2Bj7qJhThMxfe_vyMST5gsBkVM-nYLDRVEczCQPWTeC682qd3XYi7ev-Yxp_eS8B81hHJxaArA1PcHIuWtWGLg33HbqWjk-UfwxRh92RVUusa5o9yQEf.png) 
                - Platform Model - Describes how one host interacts with multiple devices. Using a rich API to facilitate communications to disparate devices.
                - Execution Model - Describes how the host interacts with devices, an abstract environment is prepared to manage memory objects and interact with devices.
                - Memory Model - Describes how memory is logically (not necessarily physically arranged) where work groups have their own shared memory, work units have private memories and there are device global memories - one read only and one writable.
                - Kernel execution model - Defines how concurrency is mapped. ^^This wasn't really discussed in the lectures, would be helpful to go through this.^^ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/H3ilrOTcONHsImYWvjkSJBeFEo9leITtzTe7jiTnlRn4YtakmfeQyrbb_Qkmf5FxDwUSwoP6vq3qjhEol_xbZoZRgvNVYRZVQ2Oixupxv0-lRigrvS1dtv3qu5D415Gs.png) 
                - Individual work items have their own private memory containing their stack and registers for computation, this is very fast to access with no congestion. Then work groups are given a shared memory to facilitate communication and allowing for a single fetch for all work items rather than multiple different fetches, this is slower to access but is still quick. Multiple work groups can be running the same kernel, and each of those can access a global memory, which is part constant read-only memory this is slow to access - but large chunks can be loaded to work group local memory at a time. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hIyewZoz0zMszjLOw_8Fhc9vO2cWNX9KLO1Y8Fj1AQo2SEjqXrRCp5jE8pFEUQBWnDyj57QuFpxZPgHD039DzVEJ-UqOX1K3dYrptvYfgwdv34jySrYMs-rQnMdx_Y1I.png) 
                - In CUDA calls are scheduled based on if they are blocked, the scheduler orders commands for maximum efficiency - the programmer must specify the grid size and the number of warps in each thread block. The function must be specified as running on the device, and is then launched form the host computer. 
                - In OpenCL command dependencies replace the scheduler, with guards used to ensure dependencies are not violated. Each command is given an event and a wait list, where other threads are dependent on a given threads event. NDRanges containg work groups much like warps.
        9. Why is energy efficiency the “new fundamental limiter of processor performance”, as Borkar  and Chien say?  
            - The problem is no longer the number of transistors that can be fit on the board, we now have the issue that we cannot control the heat produced when a large proportion of those transistors are switching. With the breakdown of Dennard scaling (due to transistors requiring more static power), transistors are used actively sparingly to not overheat the board. A similar effect describes why frequency cannot be easily increased as it had in the past, the heat cannot be easily dissipated and hotter transistors perform slower.  
        10. Describe Arm’s big.LITTLE system.
            - Arm's big. LITTLE system pairs a smaller more efficient CPU with a larger more powerful (and more power hungry) CPU into a single SoC, such that the system appears to be a single multicore processor to users and the OS. This allows for real-time selection of the appropriate processor for the task, depending on the required computation intensity and the power budget. The vast majority of the time, the smaller low power CPU will be in operation saving battery power - however when the user undertakes demanding tasks like gaming, video decode and certain web browsing the larger more powerful CPU steps up to take the load.
        11. When might it make sense to implement functionality in a specialised accelerator rather than  within a general-purpose core?
            - If energy efficiency and speed are a important, and the task is specific and unchanging then a specialised accelerator is a good option. Accelerators are faster and more energy efficient than a general purpose core, this is because they can make much better sue of parallelism and take advantage of the fact that not everything needs to be routed through a CPU. However, they are custom designed for a singular purpose - so if a better algorithm is found then the accelerator would need to be replaced to be upgraded, which can be expensive. 
        12. **Discuss a general multicore CPU vs ASIC vs DSP**  
            1. A general multicore CPU does implement some parallelism, but is designed to carry out any problem one can dream up to throw at it (albeit not hugely efficiently for all) - DSP and ASIC on the other hand are designed to solve specific problems efficiently and quickly. DSPs are for signal processing problems generally concerned with mathematical operations, they are SIMD and allow for lots of parallelism. ASIC are designed for a very specific operation, customized for high performance and efficient power usage. ASICs are more general than DSPs in that more problems than digital signal processing are solved with them, but only one problem is implemented at once on an ASIC. ASICs have a much higher one time cost than CPUs or DSPs as a specific solution must be painstakingly designed and implemented on silicon, while CPUs are very general and can be bought off the shelf and DSPs are cheaper to specialize to a given signal processing problem. 
        13. **Discuss Approximate Computing:**
            - Approximate computing is computing in which (generally small) errors in results are accepted, allowing for far less error checking and the use of algorithms that sacrifice correctness for speed. Approximate computing is deployed in areas where correctness is not critical such as videos, gaming, graphics, audio, etc. The thought process that a missing pixel here or there in a single frame of a > million pixel image will not go amiss.
        14. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HJi56y0nwzE0cilTtsd0vFKyRasLtGjNsw1DJmHZ2k_Z5AZbF26xUzydqNZ8R4cDZGqlx-uz2Mr-vqVET3nPtWYHUTRVkzh9IpfC04h0gM2H0H8no3diZPWaPBipsAAb.png) 
                - Computational sprinting would be perfect for workloads where the general case is simple, manageable computation - but rarely a heavy serial amount of execution needs to be undertaken, for which a speedup of clock speed will reduce the time taken to compute. In the case of serial execution, accelerators usually take advantage of parallelism to make gains in speed and energy efficiency, thus accelerators would fall behind. Additionally, if the general case the CPU can manage the load. This system would also be cheaper than a specialised accelerator and allow for on the fly patching.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IYi4VtVDDSvT6SSNeJaOQg40uKCtASXOwlFUH6X8fD715TIU5JbCDXzquNypf5adAkXxMJorq5-LTdmZf3hapXwMQqZpgvTuQcEaPVjeMhAJhLpTMtxS9URgZlW0hExL.png) 
                    - Advantages:
                        - Can speedup tasks that the CPU regularly uses, as well as reduce energy usage.
                        - Can change the function the FPGA (acting as an accelerator) computes, depending on requirements, changing of the algorithm or depending on user habits (e.g. a user that does more graphical processing could convert the FPGA to do rendering).
                    - Disadvantages: 
                        - Added cost of buying an FPGA. Additionally, FPGA need a lot of power supplier for their constituent controllers - need to have access to lots of those.
                        - Need to keep the FPGA close to the CPU, so time isn't lost transferring the data (energy will be spent during transfer).  
                        - FPGA slower than an ASIC and less energy efficient, so if we end up not upgrading the system we've lost out. Additionally, while ASICs have a high up-front cost they are cheaper per-unit - thus if a large number of these boards are to be produced use ASICS.
                        - Reprogramming the FPGA can be arduous as you need to use a hardware design language like verilog, which requires a lot of expertise and low level knowledge (far more than a language like c), and a very long compilation process (hours long) needs to be undertaken (place and route very slow). 
        15. **Discuss the Spectre bug** 
            - Spectre takes advantage of speculative execution to extract kernel information the program should not have access to. This is done using speculative execution, where commands within branches are computed under a probabilistic assumption that the branch is likely to be computed - while the CPU does roll the changes to registers back if unwanted computation was performed, it cannot roll back the changes made to the cache. The cache can then be probed by repeatedly getting the CPU to read data and timing the speed it takes, if the data is read quickly (you start this process by flushing the cache so you know you aren't reading an unrelated value) then it's in the cache and must have been what was read from the kernel. 
            - This is an interesting bug, because it was prevalent under many different CPU manufacturers and was caused by a design issue within **hardware **not software - meaning it couldn't simply be patched on the fly. This resulted in millions being spent patching the bug, CPUs having to be redesigned to address the issue. 
        16. **Create a diagram with all discussed elements of a computer system (e.g., cache, RAM). Discuss  common units of time for operations that these elements perform (e.g., time to fetch memory  from cache and RAM, time to execute an instruction).  ** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/f-uF3MGr2QyRTAJRFcKgoGMmxdh6wtTBzNR1fJGCFn25DufzT_OEp61iAggmyk0HybwuVUX0zMdRTKlP5KijPkXPlLmrsYAdEzukkCjPYvOAPdKvLCq4mWxzAKZv3Kdt.png) 
        17. 
            - Write a 1-page essay (no longer) describing how topics discussed in different lectures are related, and how in your opinion they relate to software engineering. Focus on identifying conceptual solutions discussed in different lectures and explain how these abstract concepts are applied for different concrete problems, on different abstraction levels.
            - Discussion of GPUs, FPGAs and parallelism improvements -> Moore’s law and breakdown of Dennard scaling -> Discussion of increasing complexity of computer architecture -> System Verilog and HDL -> Abstraction to and away from the metal -> Using different cache levels and relation to C programming -> relation to security with spectre and meltdown
            - Three areas that had direct relations between lectures were that of GPUs, FPGAs and concurrency in general. All of these topics move away from serial ­computation, and towards parallelism allowing multiple computations to be performed at once (with individual instructions often taking longer to compute than in a serial CPU). GPUs user a huge array of threads which are split into ‘warps’ which operate serially in lock step, FPGAs design varies and makes use of concurrency as sections of the program can be computed in parallel and then combined. Abstractly concurrency is used in both, but on the metal, they employ the technique in different ways.
            - Concurrency is something programmers are increasingly having to take account of if they wish to gain large speedups in code, this is because of (and relates to) the decline of Moore’s law and the breakdown of Dennard scaling.  Dennard scaling relates to the increasing amount of static power transistors use, resulting in power requirements not shrinking with the size of transistors – this is part of the reason for the slowdown of Moore’s law, as a large number of transistors cannot be made use of due to temperature constraints. The solution to the decline of Moore’s law is twofold, one is increased parallelism of architecture and software and another is cleverer architecture making further use of techniques like speculative execution, accelerators (which make use of concurrency) and pipelining (also uses concurrency, different stages of execution computed at once).
            - These techniques relate to the discussions of increasing complexity of computer architecture. As systems become larger, more complex and with more people working on them the design of chips has long surpassed what can be contained in the brain of a single person. Computer architecture is now developed using the cognition of hundreds of engineers over tens of thousands of man hours. While systems like System Verilog and other Hardware Design languages be a solution to reduce complexity, computer architects still need to be incredibly focused and detail oriented to make progress (the required focus is rewarded with a big fat salary). Another tool for conceptualizing massively complex systems is abstraction, allowing for thinking at the level of individual transistors up to the level of communication between different components on the board. Similarly, programmers should have some conception of these abstractions when writing performant and accurate code – for example, a thorough understanding of the working of a cache can help write more performant code using techniques like preloading, loop-blocking and struct-of-arrays.
            - However, when a large system of huge complexity is deployed, unseen problems can occur (despite extensive testing through fuzzing and other methods) as they did in the use of caches. The problems in discussion being Spectre and Meltdown, these two disparate functions of the CPU, that of speculative execution and caching, to leak kernel information to people who should not have been able to access it. These bugs cost (and is still costing) companies across the globe millions as they rushed to fix the problem, also resulting in a palpable slowdown in the computing devices of all large vendors across the glove as systems were needed to ensure the exploit isn’t employed. Similarly, software developers need to be cognisant of the security of the code they write – and ensure exploits are detected or ideally caught before they make their way into the codebase.
        18. Summarize the main message from “Lecture 15: Cuda, OpenCL” in 1-3 sentences?
            - New programming languages can help build better code in specific areas. CUDA is Nvidia's approach while OpenCL is more heterogeneous. Modern GPUs are multithreaded multiprocessors, with multithreading hiding latency from stalls.
        19. Summarize the main message from Lecture “16: Future directions. Energy efficiency.  Performance. Reliability. Security” in 1-3 sentences?  
            - Computer Architecture is changing rapidly, with the rise of multicores and accelerators. There are lots of good solutions already, with more sure to arise. We are in a new golden age for computer architecture.
        - 
        - OpenCL the same as C - .cl file. 
        - Is this method of heterogenous compute feasible? Software engineer needs to know how all these types of hardware works. Breaks the abstraction between software and hardware.
        - Embarrassingly parallel - convert problem into many very simple mathematical operations - no branch prediction
        - 
    - Supervision 4
        1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Guf1exbPhgo5Z2eHqD_6p41EcW-pvbqzLDBBZ_gOjY64bnMq11BYpEMCRjDD3_JWU3vMJWO67JNqmPSquhOyJkS2PxJKRzPY6XuzIcYWXPAbuDEVMGcvlSn9bpEIyR0F.png) 
            1. The load linked instruction ll r1 (0)r2 loads the value of the memory address in r2 from memory into r1, the store conditional sc r5 (0)r2 then checks if the value stored in r2 has been altered in-between operations (generally checking for alterations or reads by a different core), and if it hasn't it writes r5 to memory - if the write succeeds (e.g. r2 hasn't change and no hardware problem occurs with the write) then sc writes a 1 to r5 otherwise it would write a 0. 
            - This attempts to mimic an atomic operation - e.g. do the whole operation or do nothing, by only writing the result of the two operations if no changes have been made to the operands. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1rdxh0kr1BQ1jjIGbyqaSZ8W2c6wf4DwLBw-5RvlBmglt3WQDKr8tj0N7ni9qzJv8j-MwMl_epY5fYx-LhZR_yWnD56j0E2Ggjch1EbaAr2z58svi8htj_54ryx4vAPH.png) 
            - ```csharp
		membar // Ensures that loads before and after the membar cannot be reordered across the membar

label1: ll r2, 0(r1) // Store value in mem add 31 to r2
		sub r2, r2, #1 // Subtract one from the value
		sc r2, 0(r1) // Write-back the updated value
		beqz r2, label1 // Repeat this operation untill we successfully write-back without interruption
// Label 1 performs the atomic operation mem[r1] += 1

label2: load r2, 0(r1)  // Load r2 <- mem[r1]
		bneq r2, label2 // r2 is a lock which we are trying to get hold of, we keep spinning until
						// it equals zero 
```
        2.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_U4TG3oypX8dYFLZO9RObBtRyB8CiCxGwFyqdIBjeCkDFKKdS24mEW7ZeWtP7DGgM0Hau_p5zXZC2zepjdNVfT9eaglGIqaHO5f5eI7RbA-wk7uzdG1YQM5jfVVbNjb-.png) 
            - i.) The process supports branch divergence through conditional execution, mask registers associated with the warp decide which threads will execute the commands based on commands within the code (e.g if (i%2)―0) then the inverse of the command is also calculated (else) and the other threads are selected to execute - we also have the mask registers being reset by the end ifs
            - ii.) 
                - ```csharp

r1 = load X[i]              0,1,2,3,4,5,6,7    100%
r2 = load Y[i]				0,1,2,3,4,5,6,7    100%
if (i%2 == 0) 				0,1,2,3,4,5,6,7    100%    //(They all have to calculate the i%2)
	if (i%8 == 0)			0,_,2,_,4,_,6,_    50%
		r1 = r1 * 2 		0,_,_,_,_,_,_,_    12.5%
		r1 = r1 + r2 		0,_,_,_,_,_,_,_    12.5%
	endif					0,_,2,_,4,_,6,_	   50%
else						_,1,_,3,_,5,_,7    50%
	r1 = r1 - r2			_,1,_,3,_,5,_,7    50%
endif						0,1,2,3,4,5,6,7    100%
store r1, X[i]				0,1,2,3,4,5,6,7    100%


Average usage = 725 / 11 = 65% 
```
            - iii.) 
                - Multithreading - the GPU can schedule warps based on their access to resources and if they are ready to run or not, if a given warp is stalled execute a command from a different warp.
        3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TNZR6cjY7oDvebFDH8Cku4Hqg0vqxF1BSYSpUjOiqgAWrDoYi2S5cFGlDfZP5rP65SgqJKwjyUXpj1qFqbQj14QsIMksEU5uqkf_dPBy8QcvdaTEkTbCPg3n67v5RIQZ.png) 
            - Accelerators allow for better energy usage, speed and efficiency - however the specialisation necessarily denies generality - meaning they can only accomplish the one task they are designed for. This specialization could be creating a custom ALU for the instructions or adding greater parallelism (less hold and wait time). GPUs are more general, and can compute a range of tasks with data-level parallelism additionally they can be purchased off the shelf, meaning they are usually the cheaper (and faster to deploy) option than designing a task specific accelerator. So for products not likely to be deployed to a million users, they are often the better choice regardless of higher latency and power usage.
        4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jdQXJHFRblXwGUT5JyMar0f0PdVC6YoHzUuZYif0STh_qA2hDyTnHtaY0G42L0jQ4LeVMdCHILzPoe-pEmhEOIshVbehstITpHUg6150ZIOgB6qnwTvXomUgOOdrP9N2.png) 
            - The store changes the source register to instead store a 1 if the store succeeded, or a 0 if the store failed - e.g. if the value stored in the address register had been updated. This operation has two reasons for overwriting the source register:
                1. So a third operand isn't required to the command specifying the register to store the 0 / 1, as we need to know if the operation succeeded or failed.
                2. Because we don't want to keep a stale value of the operand, if the value has changed we want to compute value to store again - there is usually no need to keep the stale value, and the overwrite promotes safer programming without usage of stale values.
        5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NajlrDgoopacMKkKoVyMrpgocQeL1ZzZluRfVJ3EblO8mKTajlNTXshswBRR0RBXh1G2ZweW-oFnOJwLUMfV0kauNuNe73ov5MOOtZe-i7jzZXH_IfZGPOOzy2jbYaeD.png) 
            - ```csharp
lock:
	si r1 1  // store 1 into r1
	xchg r1 LOCK // exchange r1 and the LOCK location in memory 
	bneq r1 lock // spin if r1 != 0, e.g. if the lock was 1 before hand
				 // If the lock was zero we'll advance
``` 
        6. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6pCNKWTCJojnQ9ocytIxRRox7zAzsCnW7GLFj_qBYwN2RkQ08135G36BcSkP2eWadM_XBWCXPJaAOehbxZFTty-4odvJYJGgpZYMiMzwuMXTUkxhPpmiXPqBIhfBxCBd.png) 
            - A memory barrier ensures that load or store commands before the barrier cannot be rearranged to be after the barrier and vice versa - this ensures the memory consistency cannot be damaged by the rearranging of a CPU seeking high performance. Consider:
            - ```csharp
CORE 1:
	a = 3
	a = 100
	b = 4

CORE 2:
	if b==4 and a==100:
		print("This should be impossible")
``` We could fix the error here by doing the following:
            - ```csharp
CORE 1:
	a = 3
	a = 100
	membar
	b = 4

CORE 2:
	if b==4 and a==100:
		print("This IS impossible")
``` 
        7. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iHIusEpcvm2NLeNyL3AhyejG8cbQ69rFfzL0jRTwwzXkKlf1HfJmUFGqLfK_Yy2P3P6Wcn3XoaCaH3l7IMIWRauhgEVLChvv4IAHzqvk5YSq9tzJCOEmzQxXhk1VYNUs.png) 
            - Because placing the memory locks after the lock ENSURES the lock inside the two memory locks runs after the lock is gained, likewise the final memory bar ensures the code runs BEFORE the lock is released. If we placed the memory bars before taking and after releasing, then rearrangement could occur resulting in us performing computation before we've gained the lock and potentially after we've released it. The memory bars create a contiguous set of code that can be jumbled around (within reason) but cannot be exchanged with commands outside those bars, placing the lock and release within those bars allows those two commands to also be jumbled.
        8. 
        9. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5uy3-Ave4JWzB5if7xDjyuptcRc2P18LQVLSyqhAchb4gpelNdsRmxiuPMTs_2w3d3ec0eGZe6o9o7XbZwYQvanclbcIt8VbOG6f2CjuFg2KnV0CWrbcnHtnfRTekPnz.png) 
            - Single instruction Multiple Threads is a method of parallelism, in which multiple threads are grouped into warps who execute together in lock step. These warps all work from the same code on the same data, however they may execute different commands due to branching paths in the code - they execute those commands on **different** data items. Each thread also has its own registers and memory, and the concurrency of the threads in the warp is coupled with concurrency of the processor executing multiple warps at the same time.
        10. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ix1_1-b9Uqxg1LL281nlEESsr1Rsq0Xhfq_qPOmvSo9dIqP7XA-seCjj8CpabVZW9e5_0CL7GytshZayofYi5-Ys-jakOdh9-_dkhwn_n_kznVYpn-yS9zZF-PHHu-1I.png) 
            - The SIMT processor can choose from multiple warps (or even multiple instructions within the same warp) to execute, allowing it massive multithreading - this means if a given warp is blocked waiting on data the scheduler can choose a different warp to execute and the latency is avoided. This differs as in a CPU threads are in groups not one by one, and we don't wait for an interrupt to know that a resource has loaded instead the scheduler has that information all along - additionally multiple instructions are executed at once rather than one at a time in the usual pipeline.  
        11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GQ6bygtAaGCx0cF5VnHRJPttyMp5ex4FtV34sztbIaRH76EPEVxR8xztT-g_E9HxgIUydQBQXLoKNh1m2BNOvf2k1e0DlWIwfrNuthm4Km1QnqLFlTEQ95X5leTGFEcJ.png) 
            - The data cache must be larger to allow for a larger amount of data to be flowing through (we now have to provide data to far more threads), each thread has its own private cache and each warp has its own larger caches. However, the inherent data-level parallelism means less communication needs to occur between caches as our data is independent and changes need not be communicated. 
        12. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NAEUQVtSV9DFM_c_whatVLAJ-LlLb8T2iCQASPraqNRYadmSa9p5hsl8X1ZQB9aSq41EvabBTqfCblhKpTJUl8ZZ9Nbcx6RVBCmc2OKe8Sjuv3xfR5QLZ6OAOJaJ1G9G.png) 
            - Each thread is given its own stack, and predicates are push and popped from it - the GPU decides which thread should execute using mask registers and will allow only those that are unmasked to execute. The threads still walk through the code in lock step, but only certain threads are allowed to execute.
        13. Sum the total number of threads executing instructions, divided by the total number of threads times the number of instructions:
            - ```csharp
r1 = load X[i]              0,1,2,3,4,5,6,7    8
r2 = load Y[i]				0,1,2,3,4,5,6,7    8
if (i%2 == 0) 				SET PREDICATES    
	r1 = r1 * 2 			0,_,2,_,4,_,6,_    4
	r1 = r1 + r2 			0,_,2,_,4,_,6,_    4
endif						Restore Predicates
store r1, X[i]				0,1,2,3,4,5,6,7    8

Average usage = (8+4+4+8+8) / (8 * 5) = 32/40 = 80% efficient
``` 
        14. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xNBXDXDISRgklZb-mFVvIiDg_mQ2q5YIYCPyEerp4me7-uhdHT0f0_6uOSB1wlZcvShNWDf0kcT97Y2sdGDs25PcjqhklqseiyRE4Kaha0KE4qajcJIQvLKel2vRm5Ic.png) 
            - Warp parallelism is multiple warps executing commands at once, this is done by a GPU with multiple cores wherein a given set of warps are scheduled and executed in parallel. SIMT parallelism, is the parallelism in the individual warps where multiple threads execute the same set of instructions (subject to branch divergence) in lock step.
        15. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HTSklwp1g1oC-jOqXimSsTSqBEYpGHpEKvwn75yk1S7sooPub-mert71pd1W8ZyfLTCeNkbvKa-ZelnPnBg-k-rRme14lQaTdHNp3l9MO-4Zsp_f41BWLdSbgrD4mCos.png) 
            - Each thread has its own private local memory, this memory is very small but incredibly fast.
            - Multi-threaded processors has its own shared memory, warps executed on those processors can access that shared memory (different processors cant access each others shared memory). It is slower to access but **much **larger than that of the individual threads- this can be used for communication between threads. 
            - Global GPU memory is available for communication between processes, this memory is the slowest and largest - but is accessible by the host and can thus be programmed and changed.
            - Finally we have constant and texture memories, these are read only but are quite fast. Constraining the design to be read only can lead to performance or energy benefits.
        16. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nXULcIhJFr_O7XGmj-_A0xcqUzMr6itAeNRtJnovL9geICqxQzFpqlhqaOrGGK2Rt1Idg7pqtXfDyoTw6zWU3MGgb7LlhhZwMZ0fsPdONqgGsfdPHcsiY6ZTyyS8v7WU.png) 
            - Atomic operations can be achieved with multiple instructions. The memory consistency model describes how loads and stores to different places are seen. Memory barriers and load-linked, store-conditional important tools for synchronisation.
        17. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BAHk5Ew6Aadc2EIputQEPJ_blb8CdsP4EqgyMkmax37DCVDwd9QVOkSpqXQFqdc4ZlooNd0GgywjzgS4bEeyQd2-RisE8pzdvHTX22vuql90zZXHvM6UiKjWFbNVAimz.png) 
            - GPUs massively multithreaded processors, threads grouped for efficiency into warps - SIMT execution. Multithreading hides latency.
        18. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pP4O5zBCdjQJYUWklv6yE2IM2zLCEYTh7q-a-5drkiw8_5Np4mmtonZuB6JqoYWM8wv2q5_fipmGMOL99neXPwVVIjlwu30pqRBEGDv5nupq0gePUC4ch0pp760WtpHW.png) 
            - CUDA Is the common NVIDIA approach, while OPENCL is more broad. Programming languages are designed to help code using GPUs.
        - 
    - Supervision 3
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jf-UuofY17s1TjPGvIF8ZS9eJEGHmrfT6Dtk0fNmdAlw730xbsBUpcv3s28ChgFS2TM2cTESgdTonLNfsyKo82RUWXrUehVixXxz1GrdTSRgtEiPUrhlTh0PBrIs_iYQ.png)
            - Interrupts are caused be factors external to the programmers, and cause a context switch in which the kernel takes over and performs certain commands - this could be scheduling different operations to take place, in which case the operations stack space and registers are saved and a different operations starts work. These occur occasionally and we have no control over them, and cannot predict when they will occur.
            - Environment calls are made by the programmer, and are used when the program needs to make use of an OS feature - such as allocating more memory, changing access level (generally decrease) or make use of IO. The kernel will take over, execute the relevant command and then return control back to the user space process. We can predict when these will occur and have control over them.
            - Exceptions are also caused by factors instigated by the instruction stream, usually errors like division by zero. These cause the same sequence where we jump to some privileged piece of code & in this case we detect whether this can be recovered from or we simply have to core dump and abandon the program.
        - 2. [2008 Paper 6 Question 2](y2008p6q2.pdf.md) a, c
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rSCemIkz1ebYPPCOr7SiSWifHvnyMGhn6yrZ9to0JpDF1YhzqazpR0aBclMH_lj0DloczVqRw5a47AgXdpLRkVsQ2IYDWR1NA60tCiDN30tXtTWFlVRF_z3ZGBMGkceV.png)
                - RISC stands for Reduced Instruction set Computer while CISC stands for Complex Instruction Set Computer. In practise RISC commands are fixed length, while CISC commands are variable length (1 to 15 bytes) this means RISC commands are faster to decode as we don't have to wait for all 15 bytes to arrive - additionally, when CISC commands are decoded they are broken down into many short RISC like commands that go into the pipeline. However, given the greater length of instructions, you can often write complicated instructions faster (by hand) in CISC than RISC.
                - RISC tends towards making the common case fast (based on Amhdahl's law of diminishing returns of speedup) while CISC often pushes for specific domains of commands being made as fast as possible - e.g. adding a specific integer division command.
                - RISC has less pre-packaged instructions than CISC, but more can be emulated using subroutines that are attached to many of the Instruction types - CISC attempts to handle a wide range of instructions out of the box while RISC prefers the architecture to be built upon for specific usages.
                - CISC attempts to minimize the number of instructions per program, the logic being fetching instructions takes time - however the result is long instructions that take time to decode. RISC attempts instead to minimize the number of instructions available by default and thus the cycles per instruction (while still offering a good amount of functionality). 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WZL6Sadbb6pgxZVdsiw95Y6XfhAd9nu9lmRaLHS618gTWt-VuLb_R7g1HiKWz7yOgUknIgOPRjJLlg7Vwxiy8TUcGgV774gb4Jrk8dEUdGp5aOCrhIEphZe3_cRJUzTQ.png)
                - For an accumulator to run an instruction on two operands, it needs one to already be in it's accumulator and the other needs to be fetched from memory - so the operation is run on the value in the accumulator & the value fetched from memory, finally the result is placed on the accumulator. For stack operations we need both operations on the stack, and then the two are popped from the stack the operation is applied and the result is pushed back onto the stack. 
                - In stack based we need to fetch the two values (if they're not already on the stack) and then apply the operation (which is a dense command, causing two pops, some arithmetic and a store) while for an accumulator we would need to fetch one value, apply the operation (which is less dense just one fetch, an operation and a store). Thus the stack is narrowly more dense.
        - 3. [2006 Paper 6 Question 2](y2006p6q2.pdf.md)- part b:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ae32BTrZ-dV7nLJGOy84Vjb38Zcr5CHMvCizurI6cEumjHdLdYWRWpseLfZoW_MaM56457SlgWeI7KxpeVYNir2vq5LEvUElvflyby7X80EKYYOCUe7UrmzeTn-tZTHt.png)
                - One reason is that while transistor speed & density continues to increase, the speed of electrons in a wire cannot be increased through engineering effort - as CPU speed increases, the clock cycles taken for electrons to reach different cache levels continues to increase to our detriment (no useful work done in that time). 
                - Another reason is the problems caused due to ever increasing parallelism, an increasing number of cores that need to share data between them requires the creation of shared caches - we then have the overhead of ensuring the values stored by different caches is coherent and we also have the increased time of accessing caches further away from us than the L1 cache. 
                - We also continue to live in a world governed by the Von Neumann bottleneck where Instructions and Data flow along the same buses, and although we have separate L1 caches for Instructions and data this separation causes a slow-down when fetching from caches higher up the hierarchy. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/N2z2HfJ2xfd2fMm_8q2AY3g1spuGcmNGdYAqgGKe2nVAmUHSlooSzcnxnw8TonaSGIieAKfswunhEfudtuSIKlINozST-DoJR5sPNSWjVzu-MSWvPEqJNf2C2qgNQD2h.png)
                - Spatial locality: 
                - We adapt our caches to take advantage of Spatial locality through architecture to improve cache hit rate, we do this by reading items around our desired value into a cache line in the event of a compulsory miss. This decrease in hit rate makes memory accesses (appear to be ) faster as we can often fetch the data we need from cache. Similarly, for temporal locality in that we make the choice to evict the Least Recently Used item from the cache - even employing a victim buffer to stop pathological misses. 
                - We also employ a hierarchy of caches, where if one cache further down the hierarchy misses another is likely to hit - this decrease in misses results in faster reads. These SRAM caches are faster than DRAM, and are positioned closer to the core (L1 cache often being part of the core) resulting in FAST read speeds.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p03-uxf6e0ERGAz1XawaYCw7btJszLgaAdOl_9LioV5SIYV9M_mSybKikb1jwSu-tf5rClW2ZW2npscjSUTC6xHOmS0OB6fD3L2aYHFFG7HSDSV_X7KwBxpPJT9EcRJJ.png)
            - The TLB improves performance as it can decrease the number of RAM accesses made - TLB is close to the CPU and can typically be accessed faster than level 1 cache (because we need to determine the page to fetch very quickly, before destination register flushed), if we do get a TLB 'hit' then we don't need to consult the page table in main memory, instead the TLB serves up the address of the PTE directly which can then be fetched. 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DWS_DbhGbc1gfIswk9CSqZ45WLZrf9UPdQHZRIsWfvwQNEa4LUS-7LN3ZTONqD4l32WulBKQ6vEeh61WDP8bjVaW9FwQW7_R6km3bdSFypp-552Dfv-HHSbZvoiZpiAf.png)
            - When a program attempts to access memory outside of it's virtual address space, this will be detected as the PTE will not be in the application specific page table (or on disk) and a page fault will be thrown. Thus, an application cannot access memory managed by different applications.
            - Additionally, virtual memory provides permissions on who can read, write & execute a file - whether or not a process is allowed to access a file is checked dynamically and if the process does not have the required permissions it is denied access. This is possible because the actual address is hidden from the process, and hardware can decide whether or not to supply the real address.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TsQ1TzHmnIZh5ASUJrgWmNdalT2Zw2lQ1gChLh3aBI1DCJ2z37OJ3-onlMT0sr1ZQdr9V4wufI_vCt25EgM4-6292xa0NpHZpbPp83Gp_7CcxJF5Um7CO1zm-6IVqKap.png)  
            - Processors, memories and interconnects.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/F_LCdAJw_NvkBinFS1Gf3VgNHiTkHy8SR9hyIqFeWs7ZDgDljRLP2Yr9aHash8P-S1J4EgtjKeVXKMQdI-h1IghV1NsyUmNzs08g_0n9Cydxxupmz8HK-7obw5I7Mz0G.png)
            - If all run in parallel, the bottleneck is the slowest member - and as D is now doing 60% of the work in the time it takes to do 20% of the work, the speedup is 3x.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7iZx4ZweGdvOvzu5z_l70StyotqciorBogTQ6HIlyEXejW8oGySnXQQfZCUZhw2tU6rTH-01veBC5M7vS31eFkBzdRBLQ3ICvBuolW6SbLwQDIkIruoq87qCMzXkPvy5.png)
                - $\frac{1}{0.15 + 0.2 * 0.5 + 0.05 + 0.6 * 0.\overline{3}} = 2$ times speedup 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cY6QT7bsC9lo6AwrvC6bshytYsneI0Hw01nqLGFF74XMVHNoFR1aiMWmRvU9zDkm96sQ1QKHnzZ7l_0qY-sGa6ZgT3K9iWmc_KtliJetZvTqQNpWLw4OKchJdbPsoa7m.png)
            - Sequentially: If B & D are instant we have $\frac{1}{0.15+0.05} = 5$ times speedup
            - Parallel: If B&D are instant, the bottleneck becomes A so $1/0.15 = 6.\overline{666}$ times speedup
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KwpkuAQjVok9cAmJfeDWPSi6oD4n6EUgpULx4L_MeBp9qelxjRMHG8cqi8mnKxJhZpR7xXflxIOMJxLE9p6JdL5UdFgHo2D2rxvpU7_rh3ekNroZr1WgKZ1jJ9D46sr7.png)
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GROvBCPnzUMS58cVrT3Cj0AK5Lml2PHMrLGzq7qHqdvCFxTqpSpzlcU9qywrd8F_wkJMNTLhCzEn1T8NNIcKIouGy01kJyUJoGh3GEL2su4bnhr8puZW-1W_Dl_AQNr9.png) Drawn by hand.
            - The DRAM cell is a method of storing data in a mediumly fast, volatile and cheap manner. There are two methods of operation ↓ 
                - Reading From Dram - In which the Word line is set to high, and the Bit line is set to some 'floating' value between low & high (say 1.5v) then the capacitor either outputs to the bitline if it was holding charge (a logical one) causing a voltage of $1.5V + \delta V$  to be read at the sensor below OR if the capacitor contained no charge (a logical zero) and gets charged by the voltage causing a voltage of $1.5V - \delta V$ to be read at the sensor.
                - Writing to DRAM - In which the word line is set to high for 1 and low for zero depending on what we wish to input, if zero then the capacitor will expunge it's value to the BL - if 1 then the capacitor will either charge up or remain the same. 
            - The capacitor ambiently leaks the charge stored within it over time, thus we need to periodically (every ~64 ms) read the values held in the DRAM cells and write those same values back to them - recharging the capacitors who held 1s.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fq2nVqfEASe2rnCEpIIB2dL4wn9JaIZo1qx0FAHCetvWKlRNXoDp8gYk2ux0o77RDN4Ro3VigSt_yze77Jh-2UXANVxx-u99AV8ctH75RxR8mAR8fAQ7hfMj9-E7VnsX.png)
            - Because a bank that's just been accessed may be in the middle of refreshing the values stored in the arrays (since reading from the arrays is a destructive process), we can mitigate the time taken waiting for the refresh to complete by accessing a different bank first.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mmrjr3lJSwf2HGb3SEYjiUKgGoC_g_F0kimsPV6k_2xFRkZ0A6igeyMEd_tqeBSKrmR3DI-gBBzMiFEN-YNgHIqIGHyhLEn7QBHcYdOAJUdv3cPHOrQxvhGYKxH_Tc3Y.png)
                - If we're in a Open-Page scheme, wherein the sense amplifiers are not reset by automatically after reading a bank, we can simply read the data stored in the amplifiers without having to fetch the data again - this saves time, and thus is beneficial.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dS9yzQZbCPSxlszPvk9vMGJBUhD26m5AgQr5_qloo3ztSp3LGRDaNwWZmAu5rWuUwGxgHB6Wz2wVfmoQ_klivUNkYoj3yVhVS2ntTuQ56YwIIXr_d_NN5nYWoa2Ygde1.png)
            - The row access enables the transistor, allowing the transistor to emit or charge and the column access then allows us to read the value detected by the voltage sensor.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hFCKZctPGzZ4iaV3m296g8bI9xVITUwrowz8mkSRk3vgg9FevcflRk0umaT_oB4dNRsSCktLVAOykLSWqm8VGBeRn6WOfTASMY-cjZIW_GH3-s6e_sg6EzAJNStZnoZk.png)
            - Single Instruction Single Data: A simple single core, sequential processor who reads instructions one at a time to process data serially.
            - Multiple Instruction Single Data: used in systems designed to cater for robustness, i.e. when we have multiple CPUs voting over results from data inputs such as rockets. This voting process makes correctness more likely.
            - Single Instruction Multiple Data: Vector operations where a single operation is applied to a host of datapoints, this is efficient and low energy.
            - Multiple Instruction Multiple Data: The commonly used multi-core parallel processors of today, wherein multiple cores operate different instructions on different data at once.
            - A multicore process with a short-vector instruction set would fit within MIMD, this highlights the breakdown of Flynn's taxonomy for use today - as almost all use cases are multi-core.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bkqqQkjhlzBDEmrYDKbLncwWBjl4nfafP6NZ5sIS9AZ11TZe8Uff_d-RhB6y5uHGDwUSadY6o3Q8BnforMTm7i-C8f93mPgyHG0tr96jZocEoD4J4RuIboucDnA7H84A.png) 
            - Amdahl's laws concerns computation of fixed instruction size, evaluating the speedup as number of cores increases. Namely: $\text{speedup}(n) = \frac{1}{B+\frac{1-B}{n}}$ Where B is the serial proportion of the code, and n is the number of cores. It makes clear that for a large speedup, one requires a significant process of the code to be parallel.  As we increase the number of cores, the speedup becomes more significant.
            - Gustafson's law concerns computation of a fixed time, wherein the volume of the problem varies. For such a problem: $\text{speedup}(n)= n - (n-1)B$. This law explains that even when problem volume is scaled up, the parallel part still gains increasing speedup but the relationship becomes linear rather than sigmoidal.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PCW_aIZZjTdu7vAWNNYXs1SCIspDtj-FJfICVMl0rMpOguJqmOjQAEti0fEDQYBLgNVutmTfoEN_9h16fi3c04prxuHmgEvO2WYtsVu_GYawovf9i1GV5UnOeXZPrjF6.png)  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vvC6eIv17JNOfYPFCIjZjixAGSJU0u7t0rYbRD6Rjln0rhC2Oil3z1gmJl4Jhe0BVV6yG4UwTq14ZcXWFePWclF7RrTBlfNYZlYz7ynWsW1exuY4nJPZ2JKwbvmzQqvw.png) 
            - DRAM is organised in a hierarchical structure, Devices are combined into ranks who act together (their results are concatenated) where ranks are independent. In devices within ranks, the data is gathered from a bank (only one at a time), the bank gets its output from individual DRAM cells concatenated into arrays. In this case we have 2 devices where each of their banks has 12 arrays,  resulting in a possible 24 bits.
            - ^^I don't understand the below excerpt from a slide, if we have 512 columns why only 16 bits?^^ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ha_YYFQAifCByvjCuocyUgozmMrufyZe2HmoWyQEwRCgg7NHMoS_ALKGvZj-DJDxn1TX0BwBVqXxTaHSps4j4sMu91wuKIfxHaKz4Qls6sDc6V3l_zkfO5d2bMIAM2NV.png) 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/s5cRytkd_TEPs8P-ywDIKKBH2Wgremx2bFpd2YLXnDvfbbtZqoanRSfNgVaHxKxPnr0tTxE7gLemr26vugi0EUihzKgW1ZIFwSYsSZL6tQQGsPcLNK3bPuZbtziODcBQ.png)
            - Open Page: Results stored in the Voltage-Sensors are not flushed by default when results from a bank is read. This benefits processes which are likely to access the same locality repeatedly, as we don't need to re-fetch the values.
            - Closed Page: Stored results are flushed after reading. This benefits processes which are likely to access differing localities, as we flush the buffers before the new locality fetch is required.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QGN4oxkVDnrIU52JdgYHePNfoYhX_cMCGGZx5x4ocIjBwWGWPZczL9Hu_fx7unVcBnOZKJ2ZaVHfMWoaES-nb_R6rNO5qRRfngwCWRdkyE-hr_G3tCaw6zkzv9Y7aKXM.png)
            - Shared memory is a useful concept as it gives an easy to conceptualize method for threads to act in unison. It's disadvantage is in the effort that must be done to ensure the threads are reading the same values, in ensuring this uniformity of values we have to implement some serial sections - e.g. the MSI Protocol which forces cores to wait for each other in order to communicate updated results. If this necessary aspect of data synchronisation is not upheld we can have data overwritten, incorrect calculations (based on incorrect input) and general undefined behaviour.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bFXtw7UfA25j4KUr2DJJUcsjAxscfdX-35LYuYejGdzHRyY4kdhrOC5d503-rnVmjiQ4u-YYuIXP2PyuvFRetOJZyw3b5HXa-7V6b-dvPmqK7tbhGDfigV1Ik-pNNSgu.png)
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3JlfPD9eb-Go6IkvwXCQJQwV-gJPBgRjyHUFwSqajFROt9wz7C5lEwuI9s6PhgKxsJN2TbmSp8UmX3Q2ipWLea8CoO8j_MBJioz6Qxi5oLFuz6gVNfD3fNCw9HV1TrDA.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TS1Nt5YEigxRgtW21hBSS8kqzIL47DstMDt2jtVksbpi4U7ScTIEqG8YB900s-M9LoSntSCNOiL76knagGsjSa7g6yiDvxz6CXDHKJwVDWsiSS2aE5s8uyS26E6bBvvy.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OEtTI8My8XSioVO0Fju6T0ioO0N3yT_0PgAM0j28ogNebOiJNjON2n_zZxQ_TKlC_LeRDwFwuPpFVxvaaZcdUOLvq_kQ_i8hdoKStO-ZXyuie8nEygfTeaPu5w8JrpNQ.png)
            - Method 1 has the benefit of quick communication of values between all cores in the fast L2 cache, each core has it's own fast private cache and not a huge amount of data is repeated as only one cache holds repeated data. However, the central bus could have a lot of traffic slowing down processing and a lot of effort would have to be done to ensure consistency between caches.
            - Method 2 has the benefit of reducing traffic on individual buses by spreading it across two levels, additionally every pair of cores has a fast method of communicating. It has the downside that for the two pairs to exchange values they have to use very slow memory. Additionally this method makes bus sniffing more complex as the L2 cache would have to communicate the sniffed results to the L1 caches.
            - Method 3 has the benefit of expanded private use space for the cores, reducing the chance of having to resort to memory. Additionally, it is more straight forward for cores to communicate via bus sniffing than in method 2 as the private caches & the public cache are clearly separated. However, this results in more repeated values being stored needlessly (in L2 cache) and a lot of processing has to be done before it's decided a value is missing (search L1 cache, search L2 cache, send a message to search L3 at which point we have to wait for the other caches to run a check after sniffing the bus then finally we check L3 and at last we have to resort to memory).
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ALKU8hSSW9mdiBjiPYuDGLsx0Yl4N1tAyPEOjyemUzf0V5Qnp09h7t0pF8FsR4kWqM3fsbMiT7BPGslH8kAKeBK4w4aQG8BduX9nUZ36TEHQYmUwr466QGue4LicVYun.png)  
            - Inclusive: All values stored in smaller caches, will be stored in larger caches.
            - Exclusive: Values will only be stored in a single cache.
            - NINE: Values in smaller caches may be stored in larger caches, though there is no guarantee. 
            - By smaller caches I mean caches lower in the hierarchy & larger means the opposite.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gnGeaQmtcoNy5ZhjROBvVzAwXMfdjSG3C5kxJSC1R9dsEAKRSGo7La2Kh__bK0IqcThPgZFWL6EVgJ40BaDlG0R15A5Z3ygZm4ecv5AXzMAgqGhykj_kpllr7QCOI1-i.png)
            - Under the MSI cache coherence protocol, caches can be in 3 separate modes:
                - $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {I}}}$ mode, where the cache-line is marked as invalid - i.e. we act as if we don't have it stored (but don't actually take the action of removing it, it will be replaced). If we wish to read the data we must issue a BusWrite call, read the value from memory and upgrade to $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {S}}}.$ If we wish to read & write values we issue a readWriteX call, read the value from memory and upgrade to $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {W}}}$. 
                - $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {S}}}$ mode, where we store the value as a reader NOT as a writer. If we sniff a BusWriteX call, we must become invalid - If we decide to want to write to the value, we issue a BusWriteX call and update our value from memory before upgrading to $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {W}}}$ mode.
                - $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {W}}}$ mode, where we are the exclusive holder of the value and can read or write to it. If we detect a BusRead call, we must write our value to memory and downgrade to $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {S}}}$, because a cache in $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {W}}}$ mode must be the only holder of the value. If we detect a BusReadX call, we do the same but the down $\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {I}}}$.
            - This ensures all caches hold the same values, as only one cache can hold a value that's being written to - after which any reads to that value are synchronized from memory.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zvEuBYjnX_eiFcabqGcgI7WQeE3cwisMx6wIcGbV_ZNC8yuXiSQ_QbKt9YoH9AGmPE3nAK5Zxw984u6aeLkgmviAX7qWDeEpq_fkZf5I3060QNzC3RfrUYed19J4R8Vn.png)
            - You first write your data to memory (^^Wasn't really explained how the precedence works here, how does the other cache know to wait? And for how long?^^) then transition to S state.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FLBiBIzm4AwpDjF5bcxLv5v2J-QpDrRQiIZ3-U4ywuFOuLlp5wtq5620H_U4i83aERdqZOCaCjqbyp3O9n6rhEtsONWsDM8eFJF06RDYT_sUUjj-IBRcLj9OkqSubU13.png)
                - You do nothing. One could extend MSI to send your value along the bus as that would be faster than fetching from memory.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/esM97s0emvnAHg5JhST0ezKtEWoXS0lquJCV3hWl-OV8mfsa04RPXrXaPXm8stTTTnWe9l71sxFURzzUkrG8nCc1oFmH-FUIcBCmdgm5S33WwNah0wEdFDIEViBeOWb7.png)
                - You do nothing.
        - 21. [2018 Paper 5 Question 3](y2018p5q3.pdf.md), part b.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7bgda-H3OLiUSJ063JyXJ8hE_s3S8ODxBRThEtdRTcAvpZBsXTcvLesI5jMCnQHKsNqaZMBGHWC-sO4GO7NUTejpenn2Fduf-I0DaX3OMVlRSIlDYf-x0G3Pi95ccwxd.png)
                - Cache coherence ensures values written in one cache are seen by others, while memory consistency attempts to ensure the ordering between reads & writes doesn't cause improper behaviours.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5sIceteoEqGQoCKvfF8ey7aWgLHquJ87-RSGWsI1jBVqxzH51ZjWAVVN0bXAsIYoA_Ag7Br1dFR-YusLhlkFbHuah8oaUtQEJCJiubLqCynCqx00PrnKEH8ooq3Xj1nr.png)
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_ZQbCuIDZz0b7M3HkNsf6nTPaV3HqYI82Jpr810QCnTppzPYXgokn6juAkBg-3vUXrYgXirk_6iXKppd_Mhb9RyCETtt1mvUpix-lqgAyYxW7b7yi1XLPBs6BlwQ5ojh.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PDJPOQqzMhDtFwmkSxYgzwPaNArVL2To06Gd2Vj1BVTOFgrKjfF4Gu5z-ubiAH-T6NP3JpuUd5xvQMyEbTBpmWlK51W_u4WPtiEYpMMvuG31e8qJCvjsgykieZJspy2l.png)
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8a68vLHMj-2N5qVbfqbGSlhp4lOGjEmuoQ2L7vprEQu9SHKgVq2P3EcR6RU2WcKkQ0eLJ6EFSaQ03JFc7mEAqSXjaDufcacKCBFWAH9hQBPCX0PmB-Uwqi3unoKivYn1.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZjGTjLTqjWMKO282PNdtrnKWSu7g-SzttsWD3jlULbBncXDZd2j-ap8qG2JDUwTpU4FeoSyCizFVhpO1ex3ayr4ZgjgLSTh7c66SzzkqfzNG0UNBqRSgxTp89T4bS22J.png)  
                - Passing from the cache to other caches is faster than fetching the values from memory.
                - If we're in the M state and another thread issues a read, we transition to the O state - after which if we wish to transition back to M we no longer have to process an extra memory transaction - we know we have the most up to date version.
        - 22. Summarize the main message from Lecture 9 in 1-3 sentences?  
            - There exist lots of methods of hardware support for operating systems. Different processors have different implementations. 
        - 24. Summarize the main message from Lecture 10 in 1-3 sentences? 
            - CHERI protects from improper memory accesses by explicitly linking bounds measurements to processors. Stack based ISAs can have very compact instructions.
        - 25. Summarize the main message from Lecture 11 in 1-3 sentences? 
            - SoCs come in all shapes and sizes, designed for specific domains (whatever that may be). Lots of opportunities for customization within an SoC.
        - 26. Summarize the main message from Lecture 12 in 1-3 sentences? 
            - Multicore processors provide MIMD parallelism. Using shared memory paradigm intuitive for programmers, but propagating writes to data can be hard.
        - 
    - Supervision 2
        1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ujcL6v4TPBhwrAcC9U-DaheF_SZq6DZo4qsSSIJ_y5ZWZw2da0KoPhAc-IC7-96muSFQa3iDtOcZFGvVILKMMqKF8thbd7P8VPDM5HDH-kPnflEeHP0Iu8ue1pvtHVLD.png) 
            - An immediate is a value that does not need to be fetched from a register or memory, that is it represents a value directly rather than an address of that value. The only computation that needs to be computed is extracting the immediate, involving sign extending.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bp04bTw83jaJ9i3BiMwlJkcbV2zGungrBbTZkiONosl6IIUNJIY44FN8t0FxPPXLej7ilSAiBcFsEAvBObuzn9CT5dsZGLDwxryh2ouy-blZW25weMm4z1xKCbkLAbPx.png) 
            - ```javascript
AUIPC rd -1000; // rf[rd] = PC - 1000
BEQI x5 x4 100; // if (x5==x4) PC = PC+100;
ADDI x5, x0, -5; // This stores -5 in x5.
```
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TeoYGLDUjRa7z5q-5Sn9A1w67YUAcm-CNL2WnXCz09VzCz1Y1eAmoGrncZiSqTrcIBx5hleeoQ8KLbe3CDOo3AHBFzl_korJ4nzpcqvhA0TUp8CJZVWmEYJoi97vraU9.png) 
                - Because immediates take up space that can otherwise be devoted to funct3 & funct7 fields, which extend the opcode space and allow for thousands of more instructions. R-type instructions contain no immediate and thus have a funct3 & funct7 field, while I-type uses an immediate and thus only have a funct3 field - 6 bits less opcode control results in 2^6 times less possible instructions you can perform. The reason in general is that register-to-register instructions require only 5-bit register addresses, while immediates often need to be longer than 5 bits.
        2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TYJ8_gFTsVYCGehDl-wZLT7Wk-FpYNQne44DtqUNd_0Py1Jv5aJylbRJ4IaeaoUsJeyOuexaycxFPcKAOd--yodGGGFhyijXf2dy-_R2Ffu7kqihZ0lBTMsOzn79_bnA.png) 
            - ISA level simulations are programs that interpret machine code and run said machine code in a higher level language, they are often "bare metal" (they don't run an OS) and also ignore factors like varying clock speed & interrupts from other programs. An example would be SPIKE which is the ISA simulator for RISC-V.
        3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J7L7np4Dby_9cLgtwDrxVP_rCQvCdpja652qu3tqA_9_zf00zFxmlz5Y1Y91Q67pxNMadtl_1T3b4jNQSVQnK436sCLkhjdhDGUyd30sLe-CNjCeLVA7cAOgRoHtkRP5.png)
            - The data path is the actual flow of information (be that immediates, addresses or register values) while the control path is the signal that controls the flow of information. They tend to flow together because certain control decision can only be made once the instruction has been decoded, and the data values can be examined - for example, the values of the registers in a BEQ command control the control-flag the ALU emits. 
        4. 
            1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hUXO8mnviRXtruya41BN9kijy81S75f1t4yhCe2D_F-K5Xcfy00i2Whwvtj99jatVA46g22xuuDOv_P9KBet5IdEGrYBfqtoWorSMisBVdFzpaJ7X8lrnVRKxaSQIBiq.png) 
                - Performance can mean many things, in terms of CPU we have Clock speed, Cycles per instruction, Cache fetch speed, Number of cores, Individual core speed etc. A benchmark could be developed to measure any one of those metrics, but there is no overall metric of performance.
                - Performance varies as outside conditions vary, a benchmark could be run when the CPU or other components are already hot or when the room is abnormally cold, which can lead to incorrect predictions when the system operates outside those conditions.
                - Performance can change due to conditions inside the system. for a CPU we could have lots of OS interrupts during the benchmark or lots of other processes being used that hog resources - making the benchmark innacurate for normal operation.
                    - Performance can vary for the use-case, for example a CPU can favour high core frequency vs more parallel cores - where the higher core frequency system could do better in a non-parallel use-case the system with more cores would do better on tasks like video-decode that are suited for parallelism.
            2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DHrxwCXTlVqaXyaqr4YJu0IbL7nGyZFwnlKjLGPDeZMf46R9iyOaHoTqqmMn5aIdtOCMtTu4BuB1UhY87LdrVnJM-IsjP_GRWLZyIzpINdk3GP7_nPBvnq869JBRisYq.png)
                - Instructions per second varies wildly depending on the program used, some instructions take more cycles than others - thus, a computer running software with more lengthy instructions would inherently be considered slower by this metric.
                - Two computers using identical hardware but with different ISAs would result in different measurements for performance, consider CISC vs RISC - a given CISC instruction could encode multiple RISC instructions into 1, and even for the computations would thus compute less instructions. 
                - Again, this measurement would vary with the conditions of the two computers - a higher temperature computer would likely throttle and result in a lower clock speed, leading to less computations being computed per second.
                - Under Von-Neumann architecture, much of the time spent is data fetching & setting - and while we wait we can simply perform polling instructions. Thus, the most critical factor for performance is not captured by this metric as we can compute a load and then repeatedly poll to see if the data has arrived - this will result in a high instructions per second although nothing useful is calculated.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oJoZsvB6MsmJwvU8JTK0mCpOZwXsO74aGqk67D3Kj0BtNaS0ZZ3ub3GzMCUEzROzFokhWOllo9mU1Ht2Rdzvp0omRBRQ756XZfOpMBsc7tz53YwTOfD_naTefMAxWsxm.png)
                - Peak performance is only useful as an upper bound on performance, can't tell you anything about the common case.
                - Common case can vary wildy from the peak performance.
                - The difference between peak performance and common case performance will vary wildly from program to program.
                - A computer with much higher peak performance may complete a task slower than a computer with a higher average case performance as the peak performance cannot be continuously upheld (temperature throttling, data starvation etc.). 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jazhr05nvPg_iVt0LtIBeOZTQuMCyOcdNOviCvlVf8W-KmER0h5cIj1Gy4QVqy27RU2Mf6u2qwK0glP-aOVH4hOEofmgDjSUeOpeV9vqStLxou_cxkEC8iLi0bDwCb7X.png) 
                - Some applications are orthogonal, e.g. best performance and lowest price, meaning you can't have both. 
                - General purpose CPUs are usually slower than FPGAs computing the same algorithm, due to the allowance for greater parallelism. Thus, serving multiple purposes results in slower speeds. This similarly goes against making the common case fast.
                - The design is always a trade of between performance, energy use and area - these trade offs cannot be thrown aside, as some applications want small area & energy use with a lower requirement for performance (phones) while some require high energy & performance resulting in larger areas (compute servers). So no ideal processor can be developed for all applications. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Dpic-8nsa3ExxGcMZkvAmhuAwT4wbYgoy6GScYpcugSf2Dc3x02taF2oTvhMwuRzlhJIHprRr0jXl8fTvSyvfLNlzpcchdPBLJhtQxoF8eFn_67EheC2FgQxVtZv5h56.png) 
                - While longer pipelines can allow for higher clock speeds (less work per stage, allows for higher clock speed), there are associated trade offs. 
                - Diminishing returns from performance increases, Amdahl's law - if an operation time is barely used, adding a pipeline stage can decrease performance as time needs to be spent waiting for that stage to complete while a fast operation may be waiting.
                - Additionally, resolution of control and data hazards increases time taken (we need to fetch the correct instructions and flush state causing bubbles in the pipeline). Mis predicted paths have a greater effect on longer pipelines - ^^Got this from notes, but don't really understand why it's the case wouldn't it be the same?^^ 
        5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HrcWNFR_E2HESaJNxYOc7XrcKLX7vDuEmKx5F6q0Ap4tlz7gLbVz46xUZcZFdvFK8tcDtriByoZ1znxvUBVKmXSTWuBOSG3FdtkBC2qTP4jjZxoijgI4vGt2mfKPaIf8.png) 
            1. No, more complex pipelines can have more stages - the 5 stages is what RISC-V uses and can be modelled as an abstraction for more complex pipelines. For example, CISC pipelines can have a second decode stage where longer instructions need to be further examined but this would be put under the umbrella of DI.
        6. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3Uy5_FV4LoCFD69iUHoN_NLwWYbbpIANN4-7dl7wqsadCZTdSr4xD-zcEHF0qNv23_lY9jodR7L4rdJ2zgKOFGKC_LU5288COxmEU7NaLzdlxbKOIQJjtXzlziqGeyJz.png) 
                - From a birds eye view, data & control hazards are a necessary feature of parallelism - if we are to run sequential programs concurrently we are going to have instructions which rely on the results of a currently executing instruction. More specifically, data hazards are when an instruction needs one or more of the items that are to be "written-back" by an executing instruction as it's operand/s. This hazard is caused by operations wanting to use transformed data. Control hazards are caused when conditional branch instructions need to wait for there condition to be evaluated before we can update the program counter and fetch the next instruction. This can be mitigated by trying to predict the outcome of the branch, and rolling back if the guess was incorrect.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p7VHTCavrC_gDoAR3T0SQE-x2lZ_lO0XFya-WFeB8v6O2zvBO6s58odYJIEVdVIHLepDOIV3hatj8h8JZdGnpm9wZjd81eZD7Yeh9vuEx_fffZQ2FUQWL9_RZI45vFYL.png) 
                - ^^Can we go through this question - don't know what it's asking ^^
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fzxrPBHAxm4NkUXqKIIy3xlM1J658qmhBqCZWn75WRdHYpWMNfBPKWKdz_GVO_imF2vt0XpRlyQLUNFiCsbEkHOa2w2Cam9dfqed3WxBz8dZ6CMFjiYVFaTwaSLC4WdA.png) 
                - Pipeline A:
                    - Data hazards cannot happen in pipeline A, because once we've decoded the instruction the previous instruction has concluded and the register has been updated so when we fetch the register the results will be correct.
                - Pipeline B:
                    - We can introduce forwarding from end of the 3rd stage of the 1st instruction to the beginning of the 3rd stage of the 2nd instruction:
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/I_OZbM7nhza2JNMJh9i2jbqw_hqkjESg5n2cqMqBOB5aHntnRGYE-eWc_xiuCoxd86If-izdy5APWDfFTaUwprErMbypg7j-UDXOSqc8QYz1J78Ht_rHpij5uhmKKGSh.png) 
                    - This forwarding would overwrite the values in the registers if they were changed, for example: ```javascript
 ADD x1, x5, x6;
 SUB x2, x1, x6;
```
                    - We would have to feed the updated value of x1 from the 1st instruction to the second.
                - Pipeline C:
                    - This can be resolved using standard forwarding if this is an R-type instruction, where the result of the execution of the first instruction is fed into the operands for the second execution stage:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2X9HLoPP_olxS3qMxdKywBN3qrUQgBv4Kf1gqfUKzKNf0TriTV0CpKUE2BvwaQrnlAVIwM7SmYywV8nKXZauyItrAKNbnAdUzyMExe8igbYJHystbNYxCkDFFvGOvzwU.png) 
                    - HOWEVER, if our first instruction is a load that the second instruction relies upon we will have to have a bubble and use forwarding from Memory to execution.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1iYR9GJRtRBen6sgG7ruEOkFMcgFH1yGk9-keOL-hwq0rO_NbQwSkqMITqdFblngsP9H1TSsdhYrqlPyp7_pYQ3nO1B8moL3fvPWS0_tSq2TYDbf0Sl4P_D2up8CNA64.png) 
                - Exceptions do introduce control hazards, as they result in the pipeline being flushed. For a precise exception, the exception is recoverable and this will simply result in bubbles in the pipeline according to the number of clock cycles the exception took to resolve. However, for an imprecise exception we cannot recover and must simply exit.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rj3My9YwE1oxjg_TS7tLeqXizhP0fVSeBZvGTt2ve4bmbMWPQx7skKXtO1nEQyuIwAIIMTOB6YrXpcvSAXWF2iVxhwW8_c-mpR3DUg3SjHZGkZiofmio1q8VIZBtSeVB.png) 
                - Interrupts do not introduce a control hazard, as the entire pipeline would be pushed onto the stack in the event of an interrupt and resumed after the interrupt was handled. We never add incorrect instructions to the pipeline while the interrupt is running.
        7. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E7o0ebzVnw8np-AE1bfqtq4SmA7zbpTWTm-KLVnaK_u4T80CWJvAXgZpbBOgPh4J56uQ4qBtn1GzFJSpo6w6QmNmH-NJvJhJvQJ09P40jKqdpBMgVJjx2UR11VtZah4J.png)
                - Branch prediction is when the processor does not wait for the arithmetic operation section of a conditional branch to be executed, instead we make a prediction about what leaf of the branch we'll follow and roll back if we are found to be incorrect. This can avoid control hazards (if it predicts correctly more often than incorrectly) as we don't begin fetching items while we wait for the branch to execute, instead we instantly make our prediction and update the PC resulting in less instructions needing to be flushed.
        8. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E3_cpU7FhIMFMosx0KRu0eo_OaU7N78GMgNKn6Z4mK05y9ZFcbgrbb_xNb5vFRQhmDFCxO9uEGx9vqsbmy8p0InfYnVHSLIG032U0pjFECdo8YqrRwhM5RB2uJCC_tJB.png) 
                - This is contents of lecture 9 which has not occurred yet.
        9. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XqoBtTygBlIN6uHJnGQFh8I3qcG5IFvD87VmbkDnkztk5tUxtfQOmQ40ltDXkkhsoRbKPujZEQQmJ1r7D0-xwc8AfWKfENyGLKqnF8dNeNZPx3Hzb5rcMjgZsBNdVUPU.png) 
                - Memory latency is the amount of time it takes for memory to arrive after being fetched, while memory bandwidth is the amount of memory that can be fetched within a certain amount of time (generally a second but sometimes 1 clock cycle).
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4MbwB78Gg0rz54Ex-HTTS495wkzxAFFrId7boZPkYTW-NPvTw84Qy-53SoNYxxl69wJs1_1j2r8vQFsyMWfBPaiv3mkT0CgYqPKrqdf5aOTBKXc-hPD3KD_pC3UhqCiU.png)
                - Exceptions are caused by processes in the CPU, whether that be a division by zero error or a syscall, while interrupts are caused by an outside I/O controller like the OS. Interrupts require the registers to be put on the stack until the handler is completed, while exceptions can cause irrecoverable flushes of register files.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/64IDOmAG3--v5FSz06UBv19TM9Ten3RMit5FpFJrCZQedy_Pgck5FP-1510pdgGPPtl5qPy-9vTc09QwuPVdvnZrrzZiJBbbQO3Ao__BU6FBh4ye4wZ_zhLPMo43xFM7.png) 
                - The programming model of a flat linear address space is the most intuitive and easiest to reason with model, we assume the programmer doesn't need to know the fine details and abstract them away. The CPU is then tasked with making this intuitive process fast. A hierarchy of memories is used because the speed of light is slow (and because very fast memory is expensive) , calls to fetch data from DRAM can take hundreds of cycles so we position fast caches nearby the CPU that can be polled very quickly. Only if we miss our poll do we need to step up the hierarchy and fetch data from DRAM or potentially even HDDs. This is also a result of the Turing tax, as most of the time is spent fetching and manipulating data rather than performing computation.   
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CjzrJJe0a3jCVrKSznbuZBlZa6b775Anpio3P0U3NAmDXWuekow4eGuAqN7z0olkCfSAxcq0RR6HeaMfRf00bPhCXCBf0EgKikgvbJN88Rgdaj0FmQZeFT_L1NBYBygS.png) 
                - A direct mapped cache consists of many cache lines that contains data that was spatially-bunched on memory when it was fetched - each line is referred to by a unique hash which is usually some combination of it's index, it's tag and the word to be fetched. A set associative cache is a large collection of direct caches, where all direct caches are polled simultaneously to find data. In direct-mapped we have no choice of which cache-line is replaced, as it is built into the memory address. In Set-associative we have certain options, such as least-recently used, not last used and random. 
        10. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ayul6TLMRCoxjIc4cAeVdla03F32FFZBHs2WOkxOm2JoUTWhDDDPHb8vr82sLaKnJBgFSvWweZFPG13haPBzu_i3HkOIMibSi3Dl2xp5QEaUlmmq0CIc6xsAEWPCUWJZ.png) 
                - In control-flow machines, values need to be accessed and consumed quickly to allow for the progression of the program - as later instructions will require the results garnered from the consumption of the aforementioned value. Thus, if the memory access latency is high the program cannot proceed - this lack of progress while waiting explains the sensitivity.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6XbZtfmhU9YoHSaiiAAH83hNSuVF-1TFe30ZdN-KZp1KnKiYdasyjpow9irpDz__J0zagsIWnV0Khhi2GcNVi-DMhcImhRCB06PwBVLuNLgsTvXFz3zIms49CxjvSPPJ.png)
                - Temporal and spatial properties of data access patterns are exploited. Spatial: if a certain piece of data is accessed, it is likely that nearby data is going to be accessed soon. Thus, we cache requested data and data spatially close to it (in the linear memory) on a miss. Temporal: If a piece of data has recently been accessed, it is likely it will be accessed again soon. Thus, don't just flush data after it's been delivered to the CPU - cache it for reuse.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BubVqInmQH73h3cTr6eb56u3QrOMDUy5kFkJzxcyS4I_rHKgLZAQl5X7WiVh5fbXXb0d-BcUAOC62OoAj4WKHekVCLk6dpp5CjkD76PMcil9bcVpM3nVLQdjz19D5dBH.png)  
                - Direct-mapped caches have no choice as it is governed by the address of the item. However, set associative can use least recently used (hard to manage for large sets), not most recently used (easier to manage) or random (easy to implement and around same performance as LRU). They might also implement a victim buffer, to avoid "pathological misses" 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/x42S6Ceps_2HqEL8DCX2MNjn47hCcBIv9BnoibcAplrSNuL_RqflsWNePHiY5N5eqrUFDV2Wm8SpJfcq6qwtGCjYEhto6W3BFUAt7d3m4rdWi9Mim0FhrzSw8TvhPmWe.png)
                - Write back & Write through. Write through is where you keep a write buffer, when a data-write hits update the item in the cache and add it to the write buffer. Only stalls if the write buffer is full, in which case memory needs to be synced. Write back is where we mark updated items as dirty on data-write hits, then when we attempt to remove the item and it's dirty then we must sync memory. Both of these are methods of keeping memory and caches synchronised while keeping the CPU occupied with computation rather than memory management (as much as possible).  
        11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tSOQjmd979Wel0vDmCZMaa4dj7gHcSLmRnHZGNq-uA1Gb4DFVOomMrCrDVhBVXvV9Cxt50j0SrgvZUOg3hsJqdi3K1aOOmmrVFslMiHiQztfSseQ-kh8ZOlfQIHFQgdf.png)
            - Cache miss rate is the rate at which we poll the cache for a certain value, and it's not there - meaning we have to fetch the data from higher up in the memory hierarchy, if that's DRAM then hundreds of clock cycles can be spent waiting for memory to arrive rather than the 1 or 2 for the data to come from cache. If our cache miss rate is very high then we are constantly accessing from DRAM, resulting in huge slowdown of our code as we wait for memory to be shipped over to operate on.
        12. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/neVpREEPM9QEQh0eE3YLO6iHU2MOTJ8UiE2T7JCPv6ylofruCHwLnLNZxJUANvvPIw5kajdAq7yl4xxj7T7OJgd_Pjuc4SmLGKzDApXwbEKWsi1JFjIsiPUVq-HFBqUE.png)
            - Single sections of the pipeline can take less time than others:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QgDYiw-84BUNbSgRI6NeWKTsYHXqJqKIWtTbVWCEnfVMsvlGWNfH5W5BeOhrrU5w0y9YksdAxhGCdVecxuyuDUb4iJjyRvl6EzU7QIohyaNRMn-pQ631fgHoWeTquEbn.png)
            - Thus, if a given instruction wasn't waiting for the proceeding instruction to finish it could complete the execute stage quickly and advance to the memory stage - however in the pipeline model, every stage takes as long as the slowest stage - resulting in: 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mu_iWQF_bZD1YvTf0XGvMi35rlo8rUysvGO3fuqEI3NB9t-5Gn3tTOVaLJEIMSSn0JHGqE_6up5Rok71mWSeQJahF-fzbRXKp5m9o7AZUGIw25izDnqQ1xJ4OkzYnv1n.png) 
            - While individual stages can be slower, we can compute up to 5 stages simultaneously using the pipeline model, resulting in the overall execution being faster.
        13. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xBcTxIj0lgc1qrOs4Tz9MmVw0eVOqdOgEF_xlwQ3nmMJXJNAb2DWCYVTLvC9tinnMJxqkmtRZYWBUOLadV3iTFoi4cPNaDDMkYTXclrfMWae96U6qY0svUk7ndFljEBZ.png) 
            - Compulsory misses occur on the first access to the block and will always occur.
            - Capacity misses occur because the cache is a finite size.
            - Collision misses occur (only) in non-fully associative caches due to competition for entries in a set.  
        14. **Discuss the main message from lecture 5 in 1-3 sentences:**  
            - The ISA provides the interface between hardware and software, however that interface can be misunderstood as its often explained in English prose rather than a formal language. We desire a formal language of an ISA to allow for easy ISA simulation of a processor. We can then compare the models of the processor using tandem verification.
        15. **Discuss the main message from lecture 7 in 1-3 sentences:**  
            - ISA influences the design of the data & control paths. Multiple issue and dynamic scheduling can be used to reduce hazards and increase parallelism.
        16. **Discuss the main message from lecture 8 in 1-3 sentences:**  
            - Because physical constraints prevent the creation of a huge low-latency memory, we must rely on a memory hierarchy. Caches (widely set-associative caches) take advantage of the temporal and spatial statistical features of memory access to store data that is likely to be used close to the processor.
        - 
        - 
        17. **Discuss the main message from lecture 6 in 1-3 sentences:**  
            - Pipelining improves performance through parallelisation, each individual instruction has the same  (or higher) latency but the overall computation time is decreased. However, it is subject to hazards that must be handled with care. Instruction set design affects the complexity and feasibility of a pipeline.
    - Supervision 1
        - 
        1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2UQdpnQ1FkPkFUL4c5t1kWXX8y3CADrCFDn91MYJHDc14YPQZRJNraIwCbbIp89K4lKp_c4rP_kIcGIvHYGgzPMxlPie8s-mfFv3OwXYC4kPYjfGX5OrK1qSldMXblyW.png) 
            - Moore's law states that the density of transistors on integrated circuits, doubles (about) once every two years. This continues to apply for the time being, however we are approaching the limit in size of transistors - given that the smallest transistor we could produce lithographically would consist of a single atom in size, it stands to reason that Moore's law cannot continue forever (although we cannot predict future discoveries). However, for the time being the doubling of transistor density every two years is still being upheld. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xYXHCdBxVEZ6SpLlP-ayz2XFjwCy7rNKi_33h8Ft17-nd85USY418aMCx8u1LRpktHyZtvLU8yMgvokFrZkmRMFDkL0vk1EJmqRIId_2caDaXUokQUVpOl0smC6Vz0Ut.png) 
                - While the density of transistors continues to rise, the computing power you can leverage from said transistors is not increasing at the rate it used to. This is due to the breakdown of Dennard Scaling, Dennard scaling is the idea that the decreasing transistor size results in higher clock frequencies at the same power. However, this has broken down as transistors require more static power to run and the working voltage of the system cannot be scaled down at the rate Dennard scaling requires - this means relying more on specialised chips (accelerators) and improving processor architecture rather than continuing to miniaturize it.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Q4ZZGTuw-9knew4SIejsy_O4NY5MIENMPj9WtraKgVUfPcSKFU4XeS2GoYszaS6keQ62ydV4udorTU2XdJ9BwbPsD6FykSnC-dIDlRpqDT5no4GOWHQdqm53hiHH5EYz.png) 
                - The doubling in density of transistors every two years would result in a pattern of Dennard Scaling, namely
                    - Chip area halves every two years
                    - Frequency can be increased (by about 40%) as the length of the critical path would have decreased dramatically
                    - Voltage must be decreased to maintain the same magnetic field over the chip
                    - Power & energy decrease in sympathy with the voltage
                    - Thus, frequency has increased 40% but power draw is unchanged
                - Before 2006 this relationship of doubling transistor density resulting in increasing frequency at  the same power draw was feasible, however after 2006 this relationship broke down for a few reasons:
                    - Transistors leaked more power, static power use rose and transistors required relatively high voltage even when not switching
                    - Semiconductor technology no longer could improve at Moore's law like rate
                    - Wires don't scale with same chip area -  __Writing this from notes, but don't really understand what it means - would be helpful to go through this.__ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Fw_FBajQEF-Q1GHz6GAARODE3VXBhH3R0LRSkqdRZBXYmxqRgG7vn8gy-EfmFUvKbVD4PG8R6E4mtm2ATTTyn4E3hlZyrRlAn8ZcsIpWvWI84T60DpyNFqGCSomlzvtp.png) 
                - The breakdown in Dennard scaling requires a changing in approach in the design of high performance general purpose chips, the 1.4x frequency increase every generation can no longer be relied upon to bring hardware improvements. Alternative strategies to improving performance must be employed including:
                    - Domain specific FPGA chips known as accelerators
                    - Limiting the number of transistors active at any one time - in that vein is race-to-dark, turning of cores when not in use
                    - Improvements to chip architecture & ISA
                    - Employment of different chips for different workflows, e.g. a more powerful CPU (or a GPU) being employed when doing rendering work
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rEOnDKh22cKdx73dq-PcN_vOV8Cxn89SGxibA9BzJ7xQI8S8uQLf6rULEmAM-eaeTDB4Ug_Uer2MECtP2NkXhQ72OTzE_UTYrbJTWJwoOjKvDbK3WuAUaRsHuiK6WyxQ.png) 
                - Dark silicon is the amount of chip area in a integrated circuit that cannot be powered on while maintaining suitable working temperatures. As described above, the efficiency of transistors has not increased as Dennard scaling would have it - so if all transistors were supplied with power in increasingly dense chips, the resulting increase in temperature could damage the chip or cause a fire.  
        2. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IT2dql__fLGqf4GVNEhdRVjR6-BnrpjXNiugp6PTQvw_I9j5k69Tv1Ks--Ykd6G55c_eFnSdr0NXF0Bnfq2S51OWqpezgQTjtNyZgIA6LYsNC6ur2O8y0tNYxfYTKSUa.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p6oneUwYrLCGTrHJs9vTxCUgjN_tN_NPdlHLiLcZ2R31Mlpdau-G6wEKpokuFnXG7JYy8TBo0PPh_tqb-dvSq4DmiVNA-T1lLxeiegE0vgor63iFn6gkmX20JkzBeyQZ.png) 
                - ```c
module seven_bit_nor(
    input [6:0] a,
  
    output [0:0] b);
  
  assign b = !((a[0])||(a[1])||(a[2])||(a[3])||(a[4])||(a[5])||(a[6]));
endmodule
``` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hvLJ8_w-jNwTuRhid60ORFMQI6QKJZXkC8LH76ZnP4iZ2IE4w0g0eVxf3OW6r5RkQ5ioCwFNi-he9qQbhhPmCi0M9x7sdqXKWkrrkduxhT2DJdtzGg8MmwysRT1TuKr3.png) 
                - ```c
module four_bit_adder(
  input [3:0] d,
  input [3:0] e,
  
  output [0:0] carry,
  output [3:0] result);
  
  wire [4:0] temp = d+e;
  assign carry = temp[4];
  assign result = temp[3:0];
endmodule
``` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cIXgZzNJHK2WR6WlPb5Xa5O2WJKh45GL9qCrPopl3SFPcaCG-s-u1w9WGvjhgCbyIFpB6r2kDBj2h2Wab-OzxI5hjcdWEk1dr9jAQXL6Hcg3EMaZL8Whr8K88mR2V78B.png) 
                - ```c
module multiplexer(
	input [3:0] a,
	input [3:0] b,
	input load,
	output result);

 	assign result = (load == 1'b0) ? a : b;
endmodule


module thing(
	
	input clk,
	input load,
	input r,
	input [3:0] g,

	output h);

	reg [3:0] ff_out;
	wire [3:0] adder_out;
	wire [3:0] mux_out;
    wire who_cares;
    four_bit_adder adder(4'd1, ff_out, who_cares, adder_out);
	multiplexer mux(adder_out, g, load, mux_out);

	always_ff @(posedge clk or posedge r)
		if(r)
			ff_out <= 0;
		else
			ff_out <= mux_out;
		
	assign h = ff_out;

endmodule
``` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6K7crCiuD-NaTWO5HDkgVM6FkAe0Of2_sqJQvWVP3upsUajztlz2m-KGH70D7eVV_cRR_H2gri3BqPGzELahOpgmJNKlqGC3AkLtPehk75w1wo19H5XEy5BjYc71zyOa.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BUjnDkUsxRvCapdfbOZPBKiFsYzgeUIhACSbI38k3SkiAJHDSdGse8ICaWWLaDhY1QPEzayhsBQazHEWL8mEiPFuKe6xKYh2ACD0Ay86olZl4U2_cY3jZ_Q8vlc3HAPC.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rOhjWwznStNn4uT7WgYJKTEYQY4qRLbaELNgyfAg_NM3wpopMfnPgCTJQjnNMs_sWeE2SDwzHA8sfu83f4BRt2tp23FdJE-wgyPDlw-hZDFfbhuxHmg4VccfcEJn3ofm.png) 
                - Whenever Ain is 0 & Bin is non-zero, 
        3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/62jYcXcvp5-K-KT9jGUFLq0G8ymM7zsMMkrns5IvjLMBDOFIj_hYmDl0Uu-FPw3unnSyFYHrkKInj3tYN7P7WcJIENoO7_UWgxJx9CieJwrKeJ72aOLVsCwi4GZLAmri.png) 
            - The mystery module behaves like a stack. 'head' is the index of the head of the stack and mem is the equivalent of an array (that head points into) that stores that items in the stack. The opIn command puts the value in dataIn onto the top of the stack and opOut simply moves the head of the stack back one (allowing that value to be overwritten in the future). When the module is full, if we try and add an item error will be set to 1, meaning we will not be able to add another item. Similarly, when we are empty and we try and take an item out error will be set to true and we will be stopped from doing so. When we are empty we have the additional side effect of outputting -1 in dataOut. op decides whether we are inputting data or outputting data or neither.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hUkjVm7UBOSGw-ABIHcSOtftvD9mLbfGtF8VIgib2ETzsgFn_3vwsXGxUFPyBesxk70KJMVN-DGsja5FjlBTelQFspG3eQMSnM_LpRYyv_H9nyR77FhX4LWjKMsxofik.png) 
                - Production tests are used when the chip comes off the production line, it tests whether the correctness of the board is maintained throughout the manufacture process. Functional tests are done before production, and ensure the correctness of your HDL code.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ufaK7X_Tg3kA8QzEtneISxNOefoDhJE0V6Bwh8EMdc0lNl24lQDjdz45KY_jSQnZ3BoMOUZaiGkFQh7PHbsB_cERPZb1pGLlXTkJ7_H-wzYumQeY3U19dJK9j7kMQG_s.png)
                - The mystery module is parameterized by the width & depth variables, thus there are a huge amount of permutations of those values that would need to be tested. The opIn, opOut & opNeutral values would all need to be tested - and varying ordering of the commands would  to be tested, resulting in thousands of possible permutations. Additionally the correctness of the outputs of the stack would need to be tested according to varying inputs.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/61sohsSD65S5uRDO7M5mmOgV9Cl-ttxt3bT7agOqJCBQKBffyOlE7wriUFv-K7DgJEA2Ypjvj8YJOmEqUlqVRJrugPn9eJvIEfwbDq9tse1AiMDeUsoDqHjZyftziDRh.png) 
                - Similarly, the correctness of opIn, opOut & opNeutral and permutations thereof would have to be examined as well as the effects of varying width and depth - however less permutations need to be tested, as we have concluded the logic is correct and are now testing the physical board where any problems would appear with less nuance than a small logic error. However, this process is made more difficult as we are using a physical board - it becomes more difficult for testing in parallel, and physical factors like temperature and humidity need to be considered. So individual tests may take longer, and we must ensure the board is kept at the conditions it was designed to be used in by users.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/L9w2S79jAzPJe-B5MEgJrZ03BGSBkt6ryzB0yvzSWy6YJnEalCGKflbVuEEnCT8EnxOGZGmphXuvmJHHIgbQbo5e1g2J3nlZ3sSZhNL8s3thrK64Ai1YlI9irxlIGCQq.png) 
                - SystemVerilog is a hardware description & verification language used to build logical models of hardware that can then be simulated & tested before finally being implemented in silicon.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/s_dGIjzu1_bYbflvHG1GqIQhDr3wBoOryD0wRVWVCyiN6pAc-21l-DmB-dHReBb1K4qy7jBN09IW3LXdZ_Er7L0PsQNeynZaSeNrZK5awAt4wP1JLQnjySt3ubgF1bHM.png)
                - Meta-stability is when the output of the flip-flop takes a value with voltage between that of a high & low signal. It occurs when the input to the flip flop changes during it's setup or hold time, and the flip flop captures the value of the input as it's changing.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rljtTxKhNSKzEPi1Q5loesdd1fpx_6hXt-vg42OuntEKsxFmYR8YCUiuM_cGTjeV4PMnY7az-5OR-AB6gUor50g7dvs4gHpRrUzmsOADWhjf35daaVoLOl9YYuVEt_5U.png)
                - FPGAs comprise a sea of interconnected logic blocks & IO units. These logic blocks can contain complex features like flip flops and lookup tables, and can be programmed to implement a variety of functions. They benefit from being directly programmable by the user, that is one needn't invest in a chip negative for millions and produce your design in silicon - this means programming one is much cheaper than the alternative. Because of the vast array of logic blocks, FPGAs can take advantage of massive parallelism resulting in quick computations. However, FPGAs are much slower per gate so this parallelism is necessary to reap a performance benefit.  
        4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9JfvfQNG88PPatL-LGthmAf1ekA6VqJBTBChY92IumRxKw24x0ntjkLvUzM3ZV_UObXKGqhdW8oZCKDv9HvetY8ptV4R6SvHMBd1ReiQGfLE3VqcKcrEsKWXtP0KCHIi.png) 
            - In C's case first pre-processing is done where the plaintext elements of the code is changed. Then the compiler compiles the C code to assembly code, this is ISA dependent as different instructions will be deployed in different architectures. The compiler will employ tricks to improve performance while keeping the semantics of the code the same. The assembler then converts this assembly code to object code and finally the linker combines various .obj files into a single executable file containing machine code.
        5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Sdh8cPzeyLI-XzDa6wMfkiZYUB6H_Zki2pKhO_YN3Ns3c_Cd1JHwxAtAhDZ1pu1Ami8Tl67xRH55V6FFll45UCaBIp_jWUQ7AO4j4wtkLEoRCqk4knF7CI_GcEe-lMhw.png)
            - Clock Speed - The number of times per second the CPU clock flips, equal to: $f \leq \frac{1}{\text{Time taken to traverse critical path}}$ . Operations can be segmented based on the number of clock cycles they take to complete, and all are sped up by increasing the clock speed.
            - Number of cores - more cores allows for greater parallelism and thus a potential speedup, this does require software to be written to take advantage of parallelism.
            - Cache size - as fetching from memory is such a slow task, having a cache large enough to minimize those expensive calls is very important when trying to improve CPU performance.
        6. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/g0pdH_L0Ima0pUXs9OKScuB2D6KMgpQBOK8bRQXVNuGGd4YUOCHTjIuTOuDn4mbe9YjsJu96F3uCt8T5d5g8-3koJVb3dsY5T-P1_ZtOeXm0cm2F_khcU2PV50yInyY_.png)
            - An ISA is the set of primitive instructions the CPU can perform, ISA matters for a number of reasons:
                - Ease of programming - One can design ISA instructions that couple multiple commonly combined instructions together to make the life of assembly programmers easier. In RISC such instructions could be left as subroutines.
                - Making the general case fast - Including certain operations into the ISA can result in speed ups in specific operations that will rarely be used (e.g. supporting integer operations) due to pipelining. Thus choosing which instructions to leave out, or how to use non-special-purpose components for a given instruction requires careful thought.
                - Some parts of the modern software stack is ISA dependent, meaning porting those sections to modern systems would be incredibly expensive. 
        7. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hSiQu5PlT8ACwIkSvrP7QR59BevxaMb9YVZOVrd72gcmD7ONRE87Qq0XY_iUHb-sZke0qV9Mo3060_YtFMjL3kjOJu2x8zQoyUG6we5DDRM8kYSGECzgwqA61IXsyqee.png)
                - Moore's law makes predictions about the density of transistors on the CMOS chip (namely that it will double once every ~2 years) while Dennard scaling makes the prediction that clock frequency will increase by 40% every 2 years while keeping power the same. While Dennard scaling is based on the assumption that Moore's law is true, it goes further and assumes increasing transistor efficiency. Dennard scaling broke down in 2006 as transistors required too much energy even when not switching, however Moore's law still holds today.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UY0yfJpN6phy-eB9hvgQ8zb-XyGz1uy9gljT2bTMYvVfdOY_EehHgKuHVUtdm-aK4iLXdRS_gJN8kk9kNvtfh5QBu_Ks21NuUw_QuEqCXalCgUT-Su4MqvY2lq6OPKZp.png) 
                - The critical path is the longest path that data can travel in the circuit - an exhaustive search could be carried out by testing every input for every state & measuring the time taken to finish computation. Alternatively, we could model the circuit as a type of graph and compute a breadth first search - recording the largest number of steps in the search. The critical path directly impacts the maximum clock frequency, in that the clock frequency is:
                - $$f \leq \frac{1}{\text{Time taken to traverse critical path}}$$
                - Thus, decreasing the length of the critical path would allow you to increase the clock frequency.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sZU5STJY-guUdE3BQKXz05R38ufvi96_JuO8__Gyvy-s_Q1IZ9jQ2FMe83wU57ZB1AyOmj6Q6vhwYopP9mIrqF_gwdK52wpZVyQFbII2GpcxT6E7JRL7sJiwee9hg3wq.png) 
                - A calling convention is a low level scheme for how functions receive parameters from their caller and where they do with results, for example MV r0 r1 moves the value stored in r0 into r1. It can impact the design in a big way, calling conventions imply certain big decisions such as:
                    - Max instruction length, decides the total number of instructions possible
                    - Max number of immediate parameters to a function, e.g. parameters that don't need to be fetched
                    - Where return addresses are saved
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BlFcoIXChRxj-7sJ7kp-w1qtgRgmJVcwHgNY9niWjD3TvdTtUvetXCboQ-cPtmM99T17rV38pCr_s6_zcGGjV1gQjSxxBDzzPhZrcLgC062aMOSSTZ4l6eEFqpLRvye4.png) 
                    - Section A: This section checks if we need to do another round of the function or if we're finished. If a1 ≠ 0 then jump to .L7 otherwise jump to ra (this will either be to the initial function caller or to another instance of gcd)
                    - Section B: This section allocates space in the stack, and saves registers so we can make our way back up the stack frame to the initial caller. Allocate 4 spaces on the stack, store the current return address in the first segment of the stack.
                    - Section C: This section computes the modulus and recalls the function with these new values. Set temp = n2, n2 = n1 % temp and finally n1 = temp. Then jump and link to gcd (storing the current instruction location into ra).
                    - Section D: We'll reach here if we've previously completed section C and section A finds $a1 = 0$. Here we retrieve a previously store return address from the stack, free up the stack and jump to the return address. This starts the process of unravelling the stack frame.
        8. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sBPoSMEcGwfeclHCQG5umDhvhCzuEURc3ZFKjKlKxZWrAqVUb05SDX2eaWMJOC8QpkfIjBRGoNxhcRdC4XDdaIiJtDvfcRC-5S02rkInpNg2NzzkCnvWZBbX9yoCyJl0.png) 
            - Von Neumann style processors are not the be all and end all of general purpose processing, the incurred Turing tax results in slowdown & massive power use. As the golden age of silicon is over, we need to consider accelerators & other methods of improving performance that our outside the Von Neumann box. 
        9. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xzHKmOBmsp5VTUoRYJqnaeoGLIMjg6wfYAlFayAT7WDYyE3UH1rDsBABqCNr8M6_ZfUR7SyD0-tUrPiXdfiXuO3t1uuT3vqOiMDug6FC-Z0X_z9Z_q2JxwWc_W0nGfvb.png)
            - Clocked digital designs are used everywhere, propagating the clock signal is very hard and requires careful thought & design. Designers need to ensure that their system meets timing requirements and handles asynchronous inputs safely.
        10. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KnuI9ow0ir_IgodEqmPCY7IHvLAA5uGz_W4OqIwyGOIrbGVgtUaub1gRxD2OMrQg2JLYTmNUH5OKJLuUMoJLFzyHknqz358TnMcq-rMQVSx21tmKPfKUcYzwonBnDHlT.png)
            - There are many possible elements to optimize in processor design, and while one optimization could help a given workflow it may hinder another - thus there's no perfect CPU architecture only compromises. The Von Neumann model doesn't help with improvements, most transistors are used moving & storing data rather than performing computation. 
        11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/M6Mcdr232g4ok7gXv5Jnt0aBIXo-zv-LY1wfcfH3O-o8qTWJ_IbgZSIJJN-ma2PeMKIeiC8JlpD4XwHqS3srsVvlCk8lnU8OBJjeMph6pjP8HqEP4LLLL_GZ1rw1InkS.png)
            - RISC processors are often simpler and lower power, but CISC still dominates the PC industry (ostensibly due to backwards compatibility issues). RISC is used in the phone & microprocessor space and also in the research & teaching space as it is open-source and (relatively) easy to understand. 
    - 
    -  _**Lecture 1:**_   Technology Trends  
        - Different Processors are created to fulfill certain requirements, what are the 3 main requirements?―Power, Area and speed
        - Give two factors that constrain the production of CPUs with higher speed―Instruction-level parallelism and Power
        - What is the main benefit of devices having general purpose CPUs when a preprogrammed gate array would work?―General purpose CPUs allow for firmware upgrades in the field
        - **Von Neumann Architecture**
            - Almost all processors use this architecture 
            - What are the two main features of Von Neumann architecture ↓ 
                - A linear memory storing data and commands
                - Control flow processors that execute sequentially 
            - ![](https://www.cs.mcgill.ca/~cs573/fall2002/notes/lec273/lecture8/vnb.jpg) 
        - **Memory Hierarchy**
            - Various different memory storage types with increasing size and decreasing speed. 
            - Processor Core, L1 Cache, L2 Cache, DRAM
            - What feature of processors poses a problem for fast memory fetching―Sequential execution, means the processor cannot asynchronously fetch data
        - **Manufacturing cost**
            - What is the most crucial factor for determining a chip production profit margin, and what is that item proportional to?―Yield, which is proportional to Chip size
            - One of chip production cost is going up, and semiconductor fabrication foundries are getting  more expensive exponentially
        - **Wire Scaling**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1T9JycMAAFENrnfZUO0ti3ABwW9gPPx7tlIvpaxhOCk1D53dJNi65eBCRM6mtfzcDtHO6cPcfvmz_juAgfvUAO6oZ3_swOANtSJ3F89qkLy0QdS604_CmJIUBd_MtVwp.png) 
            - $$R \propto \frac{L}{W+H}$$
            - $$C \propto w \cdot L$$
            - $$T \propto RC \propto \frac{L^2}{H}$$ 
            - Where T is the "charge time", e.g. the time between applying a voltage at one end of a wire and reading it at the other. So performance doesn't increase with the same chip area
            - Halving L makes the wire go 4 times faster, so can add buffers
        - **Dennard Scaling** ↓ 
            - Sequence of Dennard Scaling ↓ 
                - Transistor dimensions reduce by 70% each year
                - Area decreases by 50%
                - Frequency can be increases due to more densely packed chip (shorter critical path)
                - Voltage must be decreased to keep electric field the same
                - Voltage decreases 70% reducing energy by 65% and power by 50% So **the transistor area has double, and power stays the same.** 
                - So every generation, **transistor density doubles, frequency gets 40% faster and power density stays the same. **The idea that transistors get smaller, while power density stays the same is Dennard Scaling  
            - Causes of the 2006+ Breakdown of Dennard Scaling ↓ 
                - Cannot further decrease supply voltage as transistors leak too much, static power demand increases vs dynamic power (when transistors actually switching)
                - Improvement of semiconductor technology slows - no longer delivers on Moore's law like performance
                - Wires don't scale for the same chip area - E.G. If I double the number of transistors BUT KEEP AREA THE SAME. THE WIRES ARE STILL THE SAME LENGTH AND TAKE THE SAME AMOUNT OF TIME TO CHARGE!!!
            - Is Moore's law dead?―Moore's law is still (just about) delivering on the doubling of transistor density every 2 years, however due to this leakage and static power issue we need to constrain the number of transistors active at a time. Move to accelerators.
        - **Age of Dark Silicon**
            - What are three methods to improve processor power efficiency in the age of dark silicon? ↓ 
                - Use domain specific processors (accelerators) which are more efficient and often faster
                - Race to dark - Keep transistors depowered when not needed
                - Use a range of processors for different work loads
        - **Voltage and frequency trade-off**
            - $$Active Power = C \cdot V^2 \cdot f \cdot A$$ 
            - Where A is the proportion of transistors actively switching (Activity Factor)
            - For a limited range of V, f is proportional to V - so why not just crank V?―Heat could pose a fire hazard, and CMOS circuits get slower as they heat up
            - What is Dynamic Voltage Frequency Switching?―adjust voltage with frequency to trade off performance and power use. Similar to overclocking
        - **Low power at idle**
            - Would like power use to be proportional to load, however the i7 uses 258W at 100% and 121W at 10%
            - Static power makes this difficult, and having a lower static power results in slower transistors
        - **Moore's law for storage**
            - Moore's law for density applies to DRAM and flash memory, because they are made of transistors
            - What is Kryder's law?―Kryder's law is the equivelant of Moore's law of increasing density for magnetic HD. However, the size of HD increased much faster than Moore's law
        - **Design and verification gaps**
            - As computers get larger and more complex we get problems with managing designing them
            - Solutions to the design and verification gaps caused by large and complex systems ↓ 
                - Hierarchical Decomposition
                - Replication of parts
                - Libraries
                - Abstract interfaces
                - Higher level hardware description languages
        - **General Purpose Chips**
            - Not power efficient and slower than the equivalent FPGA which have 15x slower gates - this is due to parallelism being exploited. 
    -  _**Lecture 2:**_   Digital Systems Design  
        - **Setup & Hold Times**
            - Setup time is―the time an input is stable before a clock edge 
            - Hold time is―the time input stable after a clock edge. It is typically negative - e.g. the input can change just before a clock edge and the right value will still be measured.
        - **Clock trees**
            - Clock trees are a method of distributing the clock around the board. Distributing the clock takes **30% of the power.** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RNWvNUP8E-F1Z3BSv0mWWJJT24TTB1ecMszjTAPsmjXzwE1YNxg6N57BULPNDoVedNlxRWWWdmHUkEF05vrioBLBVG4o-fOtXUlAHcxZ9_1puIyceF2vQ2kFi9_z-VqR.png) 
        - **From HDL to implementation
**  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mzaVgamHApPBW1cFzJkRSZR4GyKnbc2ZjRhgDkdo0qN1aPDd0JAf8-w_V8ri2KvrsOlEiGoN1_oYQrj2eXG-_mSutGOZmKJBMI4ozWiafquWcXTB0AZh4SISPQiBCXBW.png) 
            - What is synthesis and what optimizations can it provide?―Synthesis is the compilation from a System Verilog program to a lower level representation, typically a Directed graph e.g. Netlist. It provides Boolean function opt, Optimal state assignment, retiming of timing closure e.g. parallelization: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/N-I0g_1_6868oJ_oBQ2btiiLKAmJjVvCFyVtNpAbiz-KxBTaaJ6xDTw0UEfbcE4MvmeUotl2deP0FvgF48jP3ajn46FLQznvmFXFKAUSUg6et_J0qI1nIYDKulLKI9De.png) 
            - **Place & Route**
                - What is **Place & Route** given to use?―A directed graph of components linked by wires. A Netlist!
                - What happens during **Place & Route?**―Components are placed on an FPGA route, wires are routed between them and items are moved around in an attempt to find the optimal placement.
                - What are the **constraints, limitations and benefits** of **Place & Route**?―Area, location of pins, set performance/timing constraints. 
The automated approach is **SLOW**, but can often find a better solution than a human.
Automated system **STOPS **once constraints are met!
            - **Timing Analysis**
                - What does **Timing analysis find** and what needs to be **input**?―given the **physical netlist** and a **detailed physical model** - it gets the** longest combinational path**. 
This determines the **max safe frequency**. Place & Route is critical!
This process ensures the digital time abstractions are valid.
Timing Analysis is PASS OR FAIL!!!
                - What is the **main limitation of the Timing Analysis**?―It tells you if the **max clock speed **$f_{max}$ is safe and finds the $f_max$ based on the critical path, it **doesn't **tell you what the maximum possible clock speed for the circuit is. If it finds the speed to be safe - you **can then rerun place and route** with a higher clock speed.
                - What is the **main critical path**?―The longest path in the circuit.
            - **Simulation**
                - **Model inherently parallel circuits**
                - What is **discrete event simulation**?―A method to **improve simulation speed** using the fact that only a small proportion of gates are active at a time active - so independent events are simulated separately.
                - What are the benefits and downsides of a **high-level simulation of Verilog** to simulate your system before implementation?  ↓ 
                    - **Benefits **- no place & route or Synthesis required so can be **done quickly** during programming. 
                    - **Downsides **- no timing delay from gates or wires so inaccurate -  _Semantic understanding of sim may vary from the synthesis tool!_  
                - Give a **benefit** of **Gate-level simulation**. Why don't we just use get-level simulation and do away with other testing?―Post synthesis and place & route so **accurate **- if a **bug is found, we have to redo everything** so using only this would be too slow.
            - **Structure of a FPGA**
                - What are FPGAs made up of―Many reconfigurable components with wires going between components in a grid pattern. The components could be Look up tables, SRAM, ALUs, Digital Signal Processing blocks ETC.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/X1s98mFwX2cqCgx77_C9QzPyQotGBgdwML3Z38_6WbPlXJYVFENn4GRyaX0BjT5uu0BJ16A-113f73PVjajpIm9QYdZUKF3VDlOYbMfqp9drn3yAoUjVJiedcskUmmgI.png) 
            - **Structure of an ASIC**
                - What is an ASIC―And ASIC is an application specific Integrated Circuit. It is specifically designed for it's purpose and thus is very expensive.
                - Why would you use ASIC over FPGA and vice versa―ASICs have the potential to be much faster. But ASICs have a much higher one-off-cost, which can only be recouped after selling thousands of boards - FPGA if selling only a few.
        - **Synchronisation and Metastability**
            - What's the **problem **with **external input** for simulations?―They break digital abstractions, input can occur in-between clock edges - violates setup and hold times. 
Makes simulation much harder.
Can cause **metastability**! 
            - What is **metastability and how does it occur**?―When the voltage stored in a flip flop is between the threshhold of a 0 or a 1.
It occurs when the input to the flip flop changes during it's setup or hold time, and the flip flop captures the value of the input as it's changing.
        - 
    -  _**Lecture 3:**_   7 great ideas
        - **Designing for Moore's law**
            - Describe Microsoft's **Tick Tock model**―A** new design** would be **created on the current silicon **node (**Performance through architecture**), then after design would be ported to the newest silicon technology node (Perf through better silicon)
            - How has design shifted―Nowadays focus is on parallel design, using more transistors rather than assuming performance will increase hugely. 
        - **Levels of Abstraction**
            - High-level > Assembly > hardware representation
            - Give two benefits of High-level languages―Closer to problem design. Productivity and Portability!
        - **Defining Performance**
            - Give three metrics for rating CPUs―Clock Speed, chip area, power use.
            - **Measuring Execution Time** 
                - What does Elapsed time include during testing?―Processing, I/O, OS overhead, idle time.
                - CPU time only counts one thing, what is that thing?―Time spent **processing a job**. So no I/O time is included. Different programs are affected differently by this.
                - The equation for CPU time is―$$\text{CPU TIME} = \text{clock cycles} \times \text{clock cycle time} = \frac{ \text{clock cycles}}{ \text{clock freq}}$$ 
                - What are the two main factors affecting the speed of a CPU command―Clock cycles vs clock frequency. TRADEOFF !
                - What is CPI, and how can it be used to find CPU time?―Clocks Per Instruction, clock cycles per instruction bro. $$\text{CPU TIME} = \frac{ \text{CPI} \times \text{Instruction Count}}{ \text{clock freq}}$$ 
                - What decides the instruction count and what decides the average cycles per instruction?―Instruction count decided by Compiler, ISA and the program. The average cycles per instruction decided by CPU hardware. 
                - Computer A: Cycle Time = 250ps (4 GHz), CPI = 2.0 
Computer B: Cycle Time = 500ps (2 GHz), CPI = 1.2  
Which faster and by how much? 4/2 = 2 - 
2/1.2 = 1.66
The first is faster - 1.2 times faster
        - **Make the Common case fast**
            - What is Amdahl's law?―the law acts on **sequential programs** and is ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pS5PMlfDvIWly9ASCfp-wvg0l1aGEp9dCVaDSvnGv5jP3-YS4CX9jR9Z--1FH2r7v7Y45S55jLSbs2hqKEOlDi0DokzNn4bMQDloEFB0GTS2zhgSMWW2M1yOUn01iPM4.png) or in another way:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4fE0uNtkoLgGTJ2F7PzA05nPdm7XV_eCCZUZCsoopuyxkhk2t4F0lnF6ExfOieefF-57npbbE7HvqwnBzVYr9ia4aw4f5pMGt3CLWlnWqDHU3TnoMXB67zP0qW0yaf9U.png) 
            - What does Amdahl's law imply?―If a command is used very rarely, it's not as important to optimize that as optimizing a more commonly used feature. E.g. if integer division is used 1% of the time and we make it 9 times faster - the overall speedup is ~0.9%
Make the common case fast!
        - **Parallelism**  
            - Instruction level parallelism is―parallelism achieved by executing multiple instructions in the same clock cycle.
            - Thread level parallelism is―having sequential threads on multiple cores.
            - Data level parallelism is―Vector processing. Instructions act on >1 data item. Think numpy Bratan
        - **Pipelining**
            - What is Pipelining?―A production line for executing instructions, where at each cycle multiple instructions are having a specific operation computed. While on instr being executed another is being decoded
            - What are the main five sections of pipelining? ↓ 
                - Fetch
                - Decode & Fetch registers
                - Execute Instruction (alu)
                - Memory Access
                - Writeback result to register file
                1. Decode & Fetch registers
            - 
            - 
        - **Prediction**
            - What is prediction & what is it used for―Predicting what might happen next to make the pipeline and control flow more efficient
            - What is Control flow prediction―Predicting what instruction will be executed next, including predicting the result of conditional branches
            - What is Data-value prediction―predicting that a value will not change or that 2 pointers don't alias to the same address.
            - What is Data-access pattern prediction―Ensure data needed is close for low-latency access. Predict stride of array access. Takes advantage of spatial and temporal statistical properties of data access.
        - **Memory Hierarchy** 
            - What are memory hierarchies and why do we need them?―A hierarchies of caches, so if data isn't in one it's likely in another fast access cache. Needed because DRAM takes >300 cycles. 
        - **Dependability via Redundancy**
            - Give some examples of dependability via redundancy―RAID: Redundant array of inexpensive disks. Bit error detection & correction. Larger transistors used in ALU than memory, less likely to fail!
        - 
    -  _**Lecture 4:**_   RISC
        - What is an ISA?―An Instruction Set Architecture, it comprises the primitive operations of the CPU.
        - **RISC Philosophy**
            - How does RISC make the common case fast? How is compilation relevant to this?―Smaller, highly optimized instruction set. As opposed to x86 which gives a rich tapestry of commands for an assembly programmer to use - RISC leans towards compiled languages where this is less relevant.
            - What is Orthogonal Instruction set design―An instruction set where instructions have the same format and all registers and addressing modes can be used interchangeably - the choices of op code, register, and addressing mode are mutually independent (loosely speaking, the choices are "orthogonal"). This contrasts with some early Intel microprocessors where only certain registers could be used by certain instructions.  
            - How does RISC have an orthogonal Instruction Set Design?―All registers are general purpose. 
And for example, all arithmetic instructions use the same operands  
            - How does RISC have "Simple Instruction Decode"―All instructions are fixed length 32 bits (with an option for compressed 16 bits). As opposed to intel with instructions being possibly multiple data lines - resulting in more time spent decoding.
        - Why are ISA's important?  ↓ 
            - Large cost to port code to a different ISA
            - Even a large cost to recompile supposedly ISA independent parts of stack
            - Might not have the code, if using closed source - can lose the code if corruption occurs??
            - Most of the cost of developing a new chip (with a new ISA), is in developing the software for it! 
        - Why aren't ISA's important ↓ 
            - Most of the cost of developing a new ISA is software dev cost
            - Most of the speed of a system is independent of the ISA - Algo, code, compiler etc. more important
        - **RISC OpCode details**  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ewaZ8u8KVX8O3PE6jke-UOqLxj5YC0Pq72stOigK-avZZUg1XlEoSCfWn-jDmp2SDv2WdYHTkbS5j5b3jr2r0Z5B8-FI02SlOHBCSEjOheajUvQU0ZiRuIpIMMxHhsgH.png) 
            - What do the registers x0-x32 hold?―x0 holds zero - x1-x32 are integer registers
            - What is sign extension?―Increasing the length of a binary value by adding bits. Note that negative values will have to have 1's added to the most significant side while positive values will have zeroes.
            - What are rs1, rs2 and rd?―rs1 & rs2 store the register addresses (source registers) of the arguments to the operation, while rd is the destination register.
            - What would the assembly code for x3=x2+x1 be?―add x3, x2, x1. Result first, operands next.
            - What is the syntax of a JAL and JALR call?  ↓ 
                - JAL rd immediate - e.g. JAL x1 +100 - The immediate means, add 100 to the address of this instruction and jump there (This is about where we're **jumping to!**). x1 says store the next instruction number PC+4 in x1 (This is about where we'll have **jumped from!**)
Note that rd can be any register, but the convention is to **use x1 **which is called **ra.** 
                - JALR zero rd 0 - e.g. zero is the return address (we don't care about it) rd is where we're jumping to (set previously to some PC+4) and 0 is what we're adding to PC+4.
            - What does JAL do?―The jump and link command takes a register destination and an immediate - it stores the PC+4 in the register destination (rd) (where to return to after completion) and then jumps to the part of the code specified in the immediate. 
            - How do you return from a JAL call?―JALR (jump and link register) saves the return address to a register, and takes an **indirect address **(from a register) to jump back to. It also takes an offset to add to that indirect address. So: JALR zero, ar, 0 - we use zero because we dont care about the return address, ar is the address we set in the JAL and 0 is the offset.
        - **RISC-V Calling Conventions**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dlHtv1a4j_El6lpUtfcsD0aspQ5hCJsdmI4N_4ImNVRycespgIBKGq7Xo284Qx9v1IJN54Oy1z1izp2soicQ5Xm007OClnTIckuqzbeGz4_KAetsYphI9M97c5s3kAI9.png) 
    -  _**Lecture 5:**_   RISC commands in more detail
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tc63rQlPnsgzhr7HGAUaXHOBCK-_v5DG9Z9STTjCB01EaJPE7HJCqtIMl94zBKnv_m-l4X-DfZidOEzUe89SMiNLMowGCKP2lRVMCVlzWW91PRtdoLdAOEkCfKIVFLgh.png) 
        - Instruction function encoded in the {{opcode, funct3 and funct7}} fields (where  present). So there can be a large number of R-type instructions but few U-type, etc. Source (rs1, rs2) and destination (rd) registers are always in {{the same place}}. Immediates formed in {{various ways}} 
        - **Decoding immediates**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BmG5FfWL4T38FbaDw7mA_ZWjINDNHV5fm2P-FjhMYKGey6YUcSP2Bk92o4zQMxpFzKSd8Rv8VzR2jnoFPNBqHWOAfW3NCDJVXJJrkWHNDNQ0aobKwuIX0oknkdxd4Brs.png) 
            - inst[31] means we take the first bit and copy it through sign extension
        - **Different types of instructions**
            - R-Type instructions are for―register to register arithmetic instructions
            - I-Type instructions are for―arithmetic instructions where one operand is an immediate
            - S-Type instructions are for―Store instructions. They store values from registers to memory. 
            - B-Type instructions are for―Branch instructions
            - U-Type instructions are for―commands with large immediates
            - J-Type instructions are for―jumping to functions
            - What is the difference between a J-type instruction and a B-type instruction?―Jump instructions have no conditions attached and thus you have more bits to specify the address you're jumping to. B-type branch instructions have conditions, so smaller range you can jump to. 
        - **R-Type instructions**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bAx5CPGovBiurdeVjtQdaiBLhbVr9GNP-lVrlXHyQQTypMdCoM3Cz1D-Nt9WOtZ-ttm8cgA2-TM_Sffo47k1W1WL91pRve3GK5ChYl0e5QxXtzYBg3_jQzf530EOfg0Y.png) 
            - R-type instructions have many operations under the same {{opcode}}, with funct3 and funct7 specifying the {{function}} 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SjqaajqS06UDROmY7ESbUP-YmmPaPwcIln1Rhqxw5qCT-8mnaZ81A_NSQ408mgM3stCEvgfBRl9g3XIjmIi-4iIT96KeA-476uLB8FSAOsP8h2wib89Mn5ZtLeVxLoRx.png) 
        - **I-type instructions**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PPCj3xbCKcXdLnl58yGqP-MMZTzZwcb5iplYXCuLa5fOFhLFhEOL_W_EDCUg654SC_xC7oI_fgMgRRlXf8Y2JNd6AQwM3k6DubQnUiswZW_EKke-o3VQAg3MYIjobrDb.png) 
            - I-type instructions can perform two types of commands, {{arithmetic and loads}}, note there is no {{func7 }} in I-type instructions so far fewer {{functions}} can exist than in the R-type instruction. The immediate for I-type instructions get's {{sign-extended}} from 12 bits. Can perform LW, LB and LH which do the following respectively: {{load a word, byte or half-word into a register}}.
            - How would I store 1 into register x1 using assembly?―addi x1, x0, 1
        - **S-type instructions** ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TE1aJoMV427ggNZe-uViZSjoqyIUXwbQ5jIpr5tmQNisJ9u59yV-8CD_Zs8AIZCaYQcv9Tc5Z0s1kgf3pqbZ5xdIed-lSEXaH7xxx1FEIPrEhjkytLFZDmqSWp-SPZdy.png) 
            - What would the assembly command be for storing a word (E.G. store the value of x1 in memory address 100) IN MEMORY and what does it logically compute?―SW x1, 100 (x0) - this logically compute memory: $\text{memory[rf[x0] + imm] = rf[x1]}$  
            - Why do store instructions have their immediates separated? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_HSqr1Ba3T2KirPQGDeu3vMs52C-j_MmI5n0Q0dsBqHA6vYI-qDrgMoswNqqxfV0m1G1HiCuJfccC3oyPi9fFt9ikm6H7WwX3UGT2pn5hc0UrTaSgGYNLrbcHzuPVxjc.png)―because in RISC, func7, rs1 and rs2 are always in the same place. And as S-type instructions have no func7 - so an immediate can be placed there. The two immediates are combined by hardware to form a single immediate/.
        - **B-type instructions** ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VTcfLxAEYEyBbo8son0fr_tOGMla-i_bidBSNuAHX3ykCNhUytnIyihpQgtOI_OqO-raXVXgKkZBGffWpgdI1p2879yyK3_bPTTjJCXE3idaBtk6EPyoaXpA1pe154NI.png) 
            - How would I branch 10 instructions forward?―BEQ x0, x0, 40
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i_avbOSjziwNqd4dXHR884uyp3a3tJU6AZO2AclBvk49UzBQ_KpLCucp7gAB0Wg1-VGXNxKISW-vrXA50PJ_8Cqkq95JRbmkX5M3hDOlonJvCbHVdcxT8bELqsU3qWSr.png) 
        - **J-type and I-type jump instructions** 
            - What is ra?―ra is commonly known as x1 under the calling conventions. It's where you store the address to return to in a JAL
        - **U-type instructions**  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RkOVYxsgJP8HBaZ7fuOCh6668EAuEBzUfm2z2ZJn_VFjuQ26tbEoINJQqa3zk-h0MFTsHJDuTtVfsKQQxtoEg1EeqhYlxWjrUAkVC_539nCzUFYLjSuTx3VIjHLYm5b0.png) 
            - What do LUI and AUIPC compute?―LUI stores the 20 bit sign extended immediate to a register and AUIPC adds the upper immediate to the pc - e.g. performs a jump.
        - **Pseudo Assembler instructions**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xoEKZ0lWldIRDt_AVMJM3jIYdPfLPKBu-azEObXEGdnLfhheN9M76im53a6Ey-bKgbNlT69u5za0MIsrshzOKqkoC8aSn6PzCdCIOWJk1X0dgBMqV4qzJlsQYH64lADA.png) 
            - What are Pseudo-Assembler instructions, how do they work and finally name 2.―Human readable assembler instructions. The risk 5 assembler converts them to correct commands. CALL (goes to JAL ra, +4) and RET (goes to JALR zero, ra, 0).
        - **Decoding Instructions**
            - What three things need to be done to **decode** an instruction?―First we determine the class of instruction via the opcode. 
Then we fetch rs1 and rs2 (we always do this and discard them if we don't need them. 
Finally, we extract the immediates.
        - **Execute** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yGn0mss-e6x51YxjAzHg5K1NeS0DOUKOesIQIik-q-mfMW7mIxNbVf1GodDTctHE9TYy3v4ifY8kEmUbNk7n5Ct8QlXjZ3OJf5f2RfaVjTdIkDA6d7TQlRm-6vc7ZImC.png) 
Describe the steps of executing using the ALU―The Operands are fed into the ALU. The function code (or ALU opcode) is also supplied. 
Then the result together with a status is outputted. The status is things like overflow, negative result, zero etc.
        - **Branch** 
            - Branches often {{occur in parallel }}with decode and execute stages.
        - **ISA-Level Simulator**
            - What is an ISA-level simulator, and what are they useful for?―ISA-level simulators simulate assembly commands. They have a method for bringing code into memory and then they simulate the fetch, decode, execute etc stages. They are useful for **building up software while hardware is being developed.** 
        - **Formal model of ISA** 
            - What is a formal model of an ISA and why is it useful―A formal model is a unambiguous description of the ISA not written in plain English. They can be executable and used to generate a simulator.
        - **Tandem Verification**
            - What is RVFI?―RiscV Formal Interface. A standardised method to report completed commands
            - What is tandem verification and why do you need it?―Tandem verification uses a golden formal model and a simulation, runs the same code on them and compares the RVFI streams - if they are the same the simulator is correct. The simulator could diverge due to Interrupts or different I/O behaviour - this checks for that.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hZWUFJ-Wq0kuutWiqA5tJjvgPVXwUzB52sW4ozeCLFxNGpYhaayWsjriNQIcEZMVD2KFd6WHPrP4Ou28tpqlMTJzCwQFWDVyPJFqJdy9XxXQNHpKH9QxXU2uqywgmGtu.png) 
        - 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J3MzKK3pDFYrWpq6o3zr0fd5Eo-EfdYy1Pk6kckThQAJNd7BvdlOv_g3EHFz-8bDSfwdVMNNCGWWNRHOMD83chjNK3Yk3hOIfxLc0UFUeUAun-nlGzxoLMeEafrc1VTL.png) 
    -  _**Lecture 6:**_   Processor Pipelines
        - **CPU overview focusing on Data Path**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/m0bCdoTVaC8poTqwCHEPoT4ARZPFC98hoo--bRIRgtV8C0skvgvC0GiGnS4EUfVS1Mi7DnJgLA0qtt7eAaK8O6YBTUOarKPA9ddJw2JgHD-zX0L2dG6VVIYGjPe6o0Mx.png) 
        - **Control logic**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Z7On8YIWAkJLhGon-BLEe_UNN--ulADC9rXUEHqbvlSyJ80BIpGYA95kEy9U3u-8I4s-9FkvGiVqvMAWixczzkCb35r58vaa0ZrEt-cNSTB7J4YvB1syXbfT2TV3PYCR.png) 
        - **Instruction Fetch**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TBlFF1M7OqoZdVYjWpmgR8l_WA5NzkUOK_nlqFjtrCUlHBLnLDxl99w6SGitCwffMTOVrTi-6BnkiGHygVu1Ic4NafK6mQmwK3IaWj4R1cbPIDTkKTk25yOyM3xbHnCA.png) 
            - What 4 numbers are (2 fed into each multiplexer) inputted to the branch unit, 2 of which are added together after multiplexers are used (hint 2 are obvious)―The first multiplexer is fed the current PC AND rf[ra] for a JALR instruction. The second multiplexer gets a constant 4 (progress to the next word since 4 byte instr) AND an immediate for branch instructions. 
            - What decides the output of the multiplexers in the branch unit?―the decoded branch type and the ALU flags (sign,zero consider BEQ x2, x3). 
        - **R-type instruction**
            - What 3 steps are performed in an R-type instruction? ↓ 
                - Read the two register operands rf[rs1] & rf[rs2]
                - Compute arithmetic or logical command
                - Writeback to register file
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9J2wlztwAIMGv7KSwHlM9Nw0HqYgA8zhBVbQlcrxGaguX7MKFUiKVtbXNg2AMvXXg7ymWWEfNH6v7n6cbhPYhGCEkkCdrwswiw3wpxsnjgCGHK8Azf4sdd9TcmhfYR1_.png) 
        - **I-type instructions**
            - What 3 steps are performed in an I-type instruction? ↓ 
                - Read the two register operands rf[rs1] & rf[rs2] even though rs2 isn't present
                - Decode the immediate 
                - Compute arithmetic or logical command
                - Writeback to register file
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zpv5W9yPhFOUAvwivFdGmThG_xsEa4tQa3zDBQyjnLXiLcKOI5P149xZLhJj78Vt4CZs9v6S0BJdJ7Gjl4wX9p3fSnGMRCI0IeuuRZU-h6kqpJbG7MFq55zS5fIsdoJp.png)  
        - **Load/Store instructions**
            - What 3 steps are performed in an I-type instruction Load and for Store? Note Load and store are slightly different ↓ 
                - Read the two register operands rf[rs1] & rf[rs2] (even though we throw away rs2)
                - Decode the immediate and calculate rf[rs1] + immediate
                - Store: Store the value rf[rs2] in (rf[rs1] + immediate) in memory
                - Load: Load the value operand2+immediate into rd in the register file
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oXu9xazpFnLrzldxhKKqNe3_-55dVug7ha9P4ijAEo0RCXeXspWyFsrpekI2Q1V3ROoWfTXqUUCXG8FgNsLeweKp6qfapDnaVZTe6gwDfagKKzhM-9WTnXCCvhW1u2CB.png)  
        - **Branch Instructions**
            - What are the steps in completing a branch instruction ↓ 
                - Decode the two operands
                - Then get the ALU subtraction flags - zero/sign
                - Then decode the immediate (and sign extend it) and shift it left one place. The immediate has already been shifted right to **save space**, as the PC is a multiple of 4 we can never have odd access! Also the **smallest instruction is compressed 16 bits, so we only need 2-byte access.**  
                - Finally add the result to the PC
        - **All elements together**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YcIYtf0I1Ws1t55sZYKl7ibRLRavvi47e6cTFBzq8yDA_uc3nhCLReoGnzG0JUbZN1HMx1FXjXFpNA3oXjP9isCqQsqvYfEqGNGLC_CUrW33C68aexLMLMAPPnM54qPv.png) 
        - **Control signals for R-type instructions**  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iwmCEdAGMK7RzhbW_eAr5PKDPNXhBxH0oGUAH0W9mXOyVc7QG51ZIvEtzXdChxRoa2uV1NnT6fjmXADdRSC0K35eYJkZAOk2-d_VXvf83RIfYVLjxGyGD_hLYTCCQ4Gt.png) 
            - What 6 things does the decode unit supply for R-type instructions?(good luck) ↓ 
                - The branch type to the branch unit
                - rs1,rs2 and rd to the register file 
                - write-enable to the register file
                - Selects operand 2 to be used in the ALU
                - The ALU opcode
                - And the result source from the ALU not data memory
        - **Control signals for I-type instructions**  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iwmCEdAGMK7RzhbW_eAr5PKDPNXhBxH0oGUAH0W9mXOyVc7QG51ZIvEtzXdChxRoa2uV1NnT6fjmXADdRSC0K35eYJkZAOk2-d_VXvf83RIfYVLjxGyGD_hLYTCCQ4Gt.png)  
            - What does the decode unit supply for arithmetic I-type instructions?(good luck)―Same as R-Type but the immediate is selected to be input to the ALU
            - What does the decode unit supply for LOAD I-type instructions? ↓ 
                - Same as R-type but the immediate is selected to be fed into the ALU
                - The data memory is set to read mode
                - The result source is set to come from the data memory
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2u35Z0wCP6DTmyNp1BlsZVQlhEiYLjs6ure8e9CQr3K6TibSQkwAl_aZ7K2TrVrecXcmGmpuHFoCWxCo7O3keJ1IUzUz1IN2rkLp-7RM2BvI4d7yoauxw1p3eJsouv0e.png) 
        - **Control signals for S-type instructions** 
            - What does the decode unit supply for S-type STORE instructions? ↓ 
                - Same as I-type LOAD instructions but the memory is set to store not load.
                - And the register file is set to **not **write-back data. This means we don't care about the writeback result source
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WZ7k2oKk5w9UjNKILYeCLuXTte8QBMh28Xp30s3kImIpgvc6BA00fhOiTN_G6OybVMvgiRwaORN0EqPDalOHRXFzfquDWtm5YduDAJxmKVI7eWcziGrot7z6yZR7fhcL.png) 
        - **Control signals for B-type instructions** 
            - What does the decode unit supply for B-type instructions? ↓ 
                - The branch unit is set to a conditional branch 
                - Write-Enable on the register file is set to false 
                - The operand 2 is selected to input to the ALU
                - The ALU opcode is set
                - The ALU zero/sign is fed into the branch unit
                - We don't care about the rest
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/txL8jW5jxdFtRhaQ7DT8mvS76ZHCOZ7-qiIInEE5duJwGwWIZfPBiMuUHKayp5jEGIT65WS_LcsShbpbUAJlStWOIsQxsVaMRRjAcE2vDIfrhw6iWxgW7CELY1dzVdU2.png) 
        - What type of instruction is the critical path?―The Load instruction - the instruction memory ⇒ register file ⇒ ALU ⇒ data memory ⇒ register file. This means the common case is slow ); - performance can be improved via pipelining
        - **Pipeline performance**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-SLiRpHjwKfayFDlfQLPPPk4pKIyfh8gRRqe6wSuQlxCPDzhh--q2EKELoTHBuRg7cKATxlLFlqfzRW8BCpNiJwEn9UmyzQRndxw330W5jjIBDMG6QC9nJQAZeh6r2_Q.png) 
        - **RISC-V 5 stage pipeline**
            - Describe the 5 stages of the RISC-V pipeline ↓ 
                - IF: Instruction Fetch from memory 
                - ID: Instruction decode and register fetch
                - EX: Execute command or calculate address
                - MEM: fetch data from memory
                - WB: Writeback to the register file
        - **In what 3 ways is RISC-V designed for pipelining?** ↓ 
            - All instructions 32 bits, so you can fetch them in 1 cycle
            - Few and regular instruction formats. Means we can decode instructions and fetch operands in the same step 
            - Load/Store addressing (Only Load/Store commands can access memory and because the memory calculations are so simple) means we can calculate the address in step 3 and access memory in step 4
        - **Hazards**
            - What are **Hazards** and describe the three main types ↓ 
                - **Hazards **are **situations **that **prevent starting the next instruction in the next cycle** 
                - **Structural Hazard**: A required resource is busy
                - **Control Hazard**: An instruction decision depends on the result of the previous instruction
                - **Data Hazard**: Need to wait for previous instruction to complete memory read/write
            - Why do **pipelined data paths** require **separate instruction/data memories**?―Because otherwise we would have a structural hazard whenever memory was accessed - Instruction fetch would stall for a cycle and we'd have a **pipeline bubble**  
            - **Give an example Data hazard, provide the solution and a situation where the solution fails**   ↓ 
                - An example is ADD x1, x1, x2. MULT x1, x1, x1. 
                - The solution is **Forwarding, **where we use the result from the ALU right after it's computed and don't wait for memory writeback! 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ujv6s6fkOdGv8O0HH9hBI6c2nyLuNxY9BzAkoWU7YIPq5IHy-PygYiVuA4M3wdj8HuK_P3efuoTFkoxFAFRzpA7W_4hT1H25xxZTWFGvfj13EG0c4Br91PNlT7imuXQb.png) 
                - This requires a connection between the ALU output and the ALU input.
                - **HOWEVER, this fails in a Load-use data hazard.** I.e. if we're loading the value from memory, we cant just grab from the ALU will have at least 1 bubble - we fetch from memory before writeback.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bYbPy4_rUFIC50N_CLivRiyE1ui0AQcIUAMU-lC0R3XzgYQ0OBPH6ZgFjob1XG7_gFfdMquAsa1-N45_FWqQFr3Fh_yq3eP7JFRSmp5TCxmkhMyeencKK0me1bqy-RcA.png) 
            - How can the **programmer reduce stalls due to data hazards and what is the technique called**?―Place loads more than 1 instruction before they're used, can group all loads at the beginning of the program
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zv_5EtCmyOCjFPCfkMbIM-yIIPfKgrHcp9PINQHqEfDb-KidvTxS8FAKPA5uQVishZ_X6p_lI2IJz-0tywUXm59k1srFJ-Yt5abyWwifpe_M194O5mROFMGU-zzvxvfJ.png) 
This is called **Load hoisting. **Often compilers will do it automagically 
            - What **two types of branches** cause **control hazards** and **which is worse**?―**Unconditional branches** and **conditional branches**. Conditional branches are worse because you **only know which instruction to fetch after the execute phase**. 
Although, **unconditional branches will still cause 1 bubble** as they must be decoded.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Yd-CxNKvoeb470jvIjb_jHIHJ-XbG0UJIppFBMiy8zYi1zSjpgbVlijV_DDVPr6lFMUFK0AiONDRgNp4rS77DMYElSY0RnsdwnYpll7bSE862I2ARQzAPDGaK0-qO2qK.png) 
        - **Branch Prediction**
            - Why is branch prediction necessary―In larger pipelines, can't quickly determine the branch to fetch (ALU might be far down to check) - stall time becomes unmanageable, so we need to guess.
            - Describe the 3 (possible) stages of branch prediction ↓ 
                - Predict a branch
                - Stall if prediction wrong
                - If prediction wrong, we need to clean up state and reverse our changes to preserve the sequential execution model.
            - What are Static and Dynamic branch prediction? ↓ 
                - Static branch prediction is based on common branch behaviour. For loop / if-statement branching, always take the backwards branch not the forwards one (in a loop from 1 to 100, only 1 time in the 100 do you branch forwards).
                - Dynamic branch prediction hardware stores branch history and assumes that the trend will continue.  
        - 
    -  _**Lecture 7:**_   More Processor Pipelines
        - **Pipeline Latches:**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RrfZllD94G3n1d2zwt8iTAL2FFD6mLiN4zd7quhZJySfWgiTQ1r0WJHNU8nyDvYe3ZjFujTJPGHQstQyhSQAHH0mii0TJRepAVodkN6KHWMruK_kMi3myRKgta-sJkBU.png)
Why do we need these flip-flops?―We need to store the result of one layer before we can pass it as input to the next - we want to do this every clock cycle to thus the clock pulse pushes out the value from the flip-flops.
            - The black bars are arrays of D-type flip flops
        - What problem does Pipelining cause for write-back and what's the solution?―The rd input to the register file will likely have changed since the command was executed: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BUZ_SkG_i6YcfxoNZuq7_Pd3vaPscCHpP2XnEjClyqk4z_sYCiVj3rYDlnr_nIVEm3YuC8lqjcuRYNGlKGs2RunPheVkYJvlq7nDcN2ncIfgPCLwKHWscOY9xXmvj5Zv.png) 
We have to propagate the control information from the original instruction, along the data path. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZV27jhdv4eojFzXT7zUt3m4wznjbHSHINQU_IejitACgad8fW0JKFImlB2Hfqvy1zV0TM4Wjg9wUvRcMghvFCkUqmhTIzO9iJjJH6HKyEr9IXYs-H110dWum562rFXLJ.png) 
        - **Forwarding **
            - How do we forward results from a load?―Forward the writeback directly to execute. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PFX-8fd8jFUhQVKjtqCg5Qe_4lFthMnkiAfqB1XnO0gJlwIr0dl-1St-GPpq1oCeQc8tcueJI2icOmrOY1EPrSzfD0_qIqmK4BgsZF1I-U3zkDz9ymEINeHAg9C-TZPr.png) 
            - **ALU forwarding**  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-CKrzKVRg6UgyhYJeXhCdY16wNBmtjByW3wktzEYcbA2Nel2cyyjcZ0QjH49vpP6waV71wrxlqVEU729dtiHHaiW8HdkxpPcYZlbK0qbcxXQGA7smPWJzuHs57YHCydS.png) 
            - What if we have instructions S, A and O - and both A and O need the ALU result from S? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0tAQ2Y7ukTGvAaDDxSRvo37lEOePkRCIgsVgAfx42O_Z05LJh9ZelL98i7gkkSDixx8xKoW22cqKBommKzeDA710pIROY6inEp36XEBsWYRZnxd7Qk7mhkT4vOpB3TXx.png)  Remember, memory access is before write-back.―While B can get the result by ALU Forwarding, we need to establish a second forwarding line for C. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pdDUbfEJgusSq8hjqBEHz2Md6Lt0iFWM9wBoweAaIuA9dJApPEC6c8StLUUUMY21R5nFqpaWnSqyRiV7g7nSxSThTVsZkDNWgqwzEGmDRZes1m09fuXudXYLsS0gkJFq.png)
For arithmetic operations, 2 forwarding paths remove **all data hazards** in the pipeline. 
        - In a large pipeline, many** **erroneous instructions may be fetched in error, and **th****ey may affect the sequential execution model**. **What are 2 solutions** to this?―We must not allow erroneous instructions to complete their computation. 
We can either flush the instructions from the pipeline (mark them as invalid) 
Or we can add a epoch number (colour) to the pipeline, and when we find the instructions to be invalid increase the epoch number - the instructions will then be ignored.
        - What is a **branch prediction buffer** or **branch history table **and how do you use it? ↓ 
            - This stores whether or not branches were taken indexed by the location of the command
            - To use it you first check your current branch command in the table, and assume the same branch will be taken
            - If not, flush the pipeline and flip the prediction
        - What is the **branch target buffer?**―This is a map of addresses branches have branched to indexed by the Program Counter - this means you don't have to wait for the ID & EX stages to do prediction. We just read the PC and jump right there.
        - **Handling Exceptions**  
            - What are the 3 basic steps to handling exceptions ↓ 
                - Save PC of offending instruction 
                - Save cause of exception - 32 bit. Indicates what type of exception it was
                - Jump to handler at predefined location stored in a specialised register
            - What's the difference between Precise/restartable exceptions and Imprecise exceptions? ↓ 
                - Precise/restartable exceptions are hard to implement. They entail flushing the pipeline and the instruction then jumping to the handler, then after the handler finishes return to the offending instructions.
                - Imprecise exceptions simply flush pipeline without recovering it - Illegal instructions **need this** 
        - **Instruction-level-Parallelism**
            - Give 1 benefit & 1 drawback of a deeper pipeline ↓ 
                - Benefit: More stages means less work per stage, which means a higher clock speed can be reached 
                - Downside: This also means more hazards and bubbles
            - What is Multiple issue Pipelining, why is it not more prevalent?―Having more than one pipelines and all of them operate in tandem. But instruction dependencies make this very difficult in practise
        - **Multiple Issue**
            - What is Static multiple issue and how is it made possible?―Compiler groups instructions to be issued together. The compiler detects and avoids hazards
            - What is dynamic multiple issue and how is it made possible―The CPU examines the instructions stream and chooses which to execute - compiler can help but mostly the CPU detects and avoids hazards at runtime
    -  _**Lecture 8:**_   Memory Hierarchy
        - **Simplified Hierarchy** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KMlCQdiT80SX9-YDPVhi43hFkqREInuvawwt35m0RWISHmhoBvx-GN05A8P6YbHWOiu3EG5SJs2zL__r3QpUNFrs0dTlsI5b0UDUjooKhA07DSVlEXB0W8afVN16hh4k.png) 
        - What are temporal and spatial locality? How does our hardware benefit from these?  ↓ 
            - Temporal locality means that locations accessed recently are likely to be accessed again. Cache benefits, likely to be used soon before stored value is evicted.
            - Spatial locality means that if we access a location, it's likely that we'll access a location nearby it next. Plays well with DRAM bursts - fetch data requested and neighbours.
        - Describe a directly mapped cache  ↓ 
            - In a direct mapped cache, the upper address bits are used to validate the returned cache address, the middle bits are used as a key and the index bits are used to select which word of the cache-line we'd like to select.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mf7QfJYNhkwJXN6iaz9wpe06aNkpy8RMXfRAbWHOvi8-HLNRCXi-7IQFBkDCCKCLs8iJ6SxyBr0AEhT6MP2YVe8aprZD5Wm3upZDXsSlKJaVi9vO6n6t8ukFBsMV1to8.png) 
        - In a fixed size cache, what are 2 drawbacks of larger cache lines? What's a drawback of larger cache lines in general ↓ 
            - Pollution - more data in there we'll never read.
            - In a fixed size cache - larger lines means fewer of them, so more competition which could increase miss rate as lines are evacuated faster.
            - Larger cache lines means we have to fetch more data on a miss, meaning a larger miss penalty is incurred.
        - What happens to the CPU pipeline on a cache miss, for both types of cache miss ↓ 
            - First we stall the pipeline and fetch block from the next level in the memory hierarchy 
            - Once the data is retrieved:
                - If it was an instruction miss, restart the instruction fetch phase and continue the pipeline
            - If it was a data miss, complete the data access.
        - Describe write-through―When we want to write a value to RAM, we don't want to stall the pipeline for the ~100 cycles for the memory to be sent BUT we don't want to just update the cache and make the memory inconsistent. 
Instead we write updates to a write buffer, and only stall if the write buffer is full. The write buffer ships memory to the RAM over time. Note that when we read from RAM, we first check the write buffer for an overwritten value that hasn't reached RAM yet.
        - Describe write-back―On a write, update the cache-line and mark it as dirty. If the dirty line get's evicted then update RAM. Can push the evicted line onto the write buffer to allow replacements to still be read.
        - What happens on a write miss? (e.g. writing to something **not **in the cache)  ↓ 
            - For write-through we can:
                - Allocate on miss, e.g. fetch the cache line and then operate on it. 
                - Write around - write the data straight to the next level of the cache hierarchy
            - For write-back we must fetch the cache-line and update it in place. Allocate on miss.
        - What is a fully-associative cache?  ↓ 
            - Instead of checking a specific line indicated by the upper bits of the address, and then validating that with the middle bits. Check all the lines in parallel, with more of the upper bits now serving as the tag. The lower bits are then used to select a word from the line. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NL2Sl-O1fy8KYYBAsiS3MJ0N-CWlT4BT5EKxsTGI5rBWRwtSuCfCv_5EC71bCTlXduSV3eGKflNylTpONeG7PUg0kal_IhMq-euchWpxPSMPQMfDg6IGi-E_7RtoLMpw.png) 
        - Give a benefit and a drawback of direct-mapped cache vs a fully-associative cache ↓ 
            - Direct-mapped caches are smaller. The amount differs on FPGA and ASIC 
            - Fully-associative caches tend to have a lower miss rate for the same size.
        - What is a set-associative cache?  ↓ 
            - Combine multiple directly-mapped caches and query them all in parallel. Gives the space-efficiency of a directly mapped cache, while getting the higher efficiency of a fully-associative cache. N-way associative = N direct caches.
        - Describe the cache-replacement policies for different caches ↓ 
            - For a directly-mapped cache we have no goddamn choice 
            - For a **set-associative **and a fully-associative cache:
                - Prefer to place in a non-valid cache line (without data in)
                - Alternatively, write to Least recently used
                - Not last used 
                - Random - approx the same as LRU
        - Describe the victim buffer. What kind of pathological misses does it prevent?  ↓ 
            - The victim buffer is a 'second chance' for an evicted cache line **in a directly mapped cache**. It's a small fully-associative cache that stores evicted lines. When it's read from, swap it back into the cache (according to wikipedia).
            - Consider reading two arrays and trying to sum them, we read the first value and evict it when we read the second (in a direct-mapped cache). This breaks spacial locality. Not as effective as set-associative.
        - 
    -  _**Lecture 9:**_   OS Support
        - **Virtual Memory**
            - Describe what virtual memory is, and give three benefits of it ↓ 
                - Virtual memory is the OS & the CPU giving processes the illusion they have their own address space and storage. This is done using pages (4 KiB) or superpages (4MiB)
                - Aids memory allocation
                - Improves memory security (can check that a process can write-to/read-from a section of memory during translation)
                - Allows lesser used pages to be moved to HDD - giving the illusion of having more storage that reality. 
            - What error results from trying to access a piece of memory not in your page?―A page fault!
            - **Address Translation**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mll1jb30EmTDbe4jOm2FimwPS13y5-P0bJEOKlTXzXJgp16eRKfQUSwnG_gLsocTI8OFx323HyUXKJB2v7QYdg6N_Gae6GzRlQRoze4phFyCOmcr_zSPEFI2EK8KetR8.png) 
                - What changes in a 64 bit address after translation―First note that in 64 bit addresses (as it currently stands) only the first 48 bits are currently used - the rest is sign-extension. So in translation the first 12 bits is the page offset that stays constant - the next 28 bits are the translated physical page number:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/StpnR4tGLibsuNTvjL5iyWlZ5f7L8tAPG-1XZisUixnPB4gUUN-T6QMUDL9qTjdla3ig9GBcCEGFELaabQyvbhgHMRKBIF-tnIa37hmk8cXORs-MOupIHPBvJPWC2HkU.png) 
 _**NOTE: THIS IS IN 64 BIT - MOST OF THE COURSE USES RISC V 32 bit**_  
            - **Page Tables**
                - What is a page table, and what happens if I query it (and how would I even know how to find it in memory)? ↓ 
                    - The page table stores the physical addresses of pages, indexed by virtual page numbers.
                    - The address of the page table in memory is stored in the page table register in the CPU.
                    - If you query with and the page is present, the physical page number will be returned - it also stores certain metadata like referenced or dirty...
                    - If the page is not present, it may have the location on disk - whether it does or doesn't, the **Page fault handler** will be invoked. 
                - What steps must the Page Fault Handler take to get a Page Table on Disk? ↓ 
                    - First choose a page table to remove, if it's dirty we have to write it to disk before removing 
                    - Then load the desire page from disk and into memory - and update the page table!
                    - Then restart from the offending instruction
                - Describe what it means for the page table to be **fully associative**, and give the replacement policy in use ↓ 
                    - Fully associative means any physical address can go into any virtual address spot, so we can fill the page table up before we evict - this is possible because we're using a map **not** calculating the virtual address from the physical.
This means we will never have conflicts for a single spot in the page table. 
                    - The policy is Least Recently Used. 
            - **Translation Look-Aside Buffer (TLB)**
                - What is the TLB―The TLB is a cache of page table entries stored in the CPU, this is used because translating normally is high latency - as me first have to access the page table, then get the specific page table entry (on DRAM, slow )<: ) 
                - Why are TLBs effective―Page tables have good locality!
                - What happens on a TLB miss and how soon must the miss be detected? ↓ 
                    - If the page table is in memory, fetch the page table entry and retry. This can be handled in hardware (complex for large page table hierarchies) or in software (by raising some special exception)
                    - If a page is not in memory, normal page fault.
                    - The miss **must be** detected before the destination address is overwritten 
            - **Hardware page table walker  **
                - What does the hardware page table walker do?―Searches for a PTE on TLB miss, if it finds it the entry gets put in the TLB - otherwise exception baby.
            - **Page table structure**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3qaWcOMCeWbIG6jLM6Zpq4B9MEQRl9_z0qynqCpwjcK6I85TumTyCxrfArQfMs9Zhox0seP2L8UGtsnQIWr9HIT3wqvKePlsJgFcEzUyb7h6hYkAnEb8jmOLbiyYTcX5.png) 
                - Describe the structure of a RISC V virtual address―32 bits, last 20 are the two sections of the VPN, the first 12 is the page offset
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zholROCQwqqhQ7U5VrZqu3G6B2gID6nb1NOjFI4zptI2xEJtiFtLdkXK-gBe3K0h5DnySO-pYC5e0CWvoNAhJxgWr3etgVvbHEGLVxxQzJ3o2PI7IflOC2_8eyrkEpNh.png) 
                - What are multilevel page tables, and why do we need them?―Multilevel page tables means we have a page that points to multiple page table entries. This means we don't have to have all of the PTE's in memory at the same time!
                - For a 32 bit computer, how many 4KiB pages can we store?―4KiB is $2^{12}$ bytes, so every page table is 2^12 bytes in size. Since we can point to a possible $2^{32}$ addresses and each page takes a $2^{12}$ sized chunk - we can point to $2^{20}$ distinct page tables.
$$\frac{2^{32}}{2^{12}} = 2^{20}$$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kHKwdQflonEfPVFBKCqN0ToChwiQkPQEs9evvKvOsQiGiWtWGAtLNvb3_uxC-SvSrgMUojdF-HnuNW1xxQo_AjLaC9PIignuKhh1trDJxisTiC6qKBV2iEwjIv4_O1dL.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oFOLMuQEgadHrGrocXsAAxxnCXf5uGuXeSFgh7DGwZENwaXSrEgX190GwfHUnPHZBUnKMl18sQVUsgclmyjertP2Wnrv67Kb1uhU_DY3TCWGEqu3z2z35sVKbK5XpAwh.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dJKmVJuCkkMRfiplPQ-p06APVKN5s_00iz2yE0KHkxDQpl2mzLoW1QdfMQa8r4qqcIity5pEtl9vMzJk5JaE1uVVq33eqgpn7mpUDRcmqpDnFS6yXnGJDOb_fOMio8wK.png) 
        - Assorted:
        - How do we change which address space we're using when accessing different applications ↓ 
            - The satp in the CPU changes to point to the new page table **in a context switch**, including the 9 bit ASID (Application Space ID)
            - The TLB often stores the ASID for virtual addresses, so we can quickly check privilege and the TLB can hold translations for different address spaces
        - Describe the different Hardware support for page tables the OS ↓ 
            - Privileged or Kernel mode, Page tables only accessible in kernel mode 
            - Privileged instructions
            - Kernel interrupt (ecall) which invokes the kernel. 
        - What are the 3 operating modes in RISC and what do they control?  ↓ 
            - User (00), supervisor (01) and kernel (11).
            - They control how much of the physical memory a process can access (e.g. peripherals), if the process can issue privileged instructions. 
        - Describe environment calls (ECALLS), also describe how the kernel returns from them. How does the kernel know the cause of an interrupt? ↓ 
            - ECALLS (also called software interrupts) are how the kernel escalates permissions from User mode to kernel mode. When an ECALL is made, the PC of the ECALL is stored in the EPC (Exception Program counter) and the kernel takes over. (The EPC is hidden in User mode).
We write what we want the kernel to do in one register, and the parameters in others (a7, a0-a6 respectively).
            - SRET is used to return from a software interrupt (aka a **trap**) and the PC is set to the value in the EPC.
            - The cause is stored in the **cause **register, 0 means user software interrupt. 
        - What's the difference between interrupts and exceptions?―Interrupts and exceptions both cause traps (jump to some privileged kernel level handler) but interrupts are caused by external events (timer runs out, keyboard input etc.) while exceptions are caused by the instruction stream (divide by zero etc.). 
Note that **software exceptions **are purposeful "springing" of traps, e.g. ECALL. 
        - 
        - 
        - 
    - 
    -  _**Lecture 11**_ : SOCs
        - Describe Amdahl's law―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LwLqkNINYk7IGwLZsPj6_f9A0bE5-MNlFKJ2_MemQjLwqUuh_kF7MEq-9onSBCoHRPRC_WiWdA6tWtfS4Z5rfAANyeHxMnybmztVSrBoOGI88X6ehCNNGBgShmO7OYtO.png)
Speedup of a parallel program is limited by the sequential parts. Need to write large parallel programs to see the benefit.
Maximum is limited by the fraction being improved  
Amdahl’s law assumes a fixed problem size
        - Describe Gustafson's law―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bva-fxwhknd-_pn3WzKZNG4Q0e19G1tKYy5KgzAbnGBTrs00XQC5OGhw197zO9ypVDfPGfmFprEIkll8qnMM4cPEqXEgeP11eoGiuHIZAF-d4I3pl2IvvmLyqOrKHWTi.png)
$$Speedup(n) = B+n(1-B)$$
So the parallel part scales linearly with the number of cores, sequential part remains constant.
When given more compute, assumed we'll build bigger problems.
Gustafson’s law assumes a fixed execution time, and the problem size is scaled.
        - Describe a DRAM cell―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IvKMhFEuj0EWP4V8BNDMhaEAOZyRDa0VO5flZMTiyycEZ8rvuknauqUXulySDYFBpyklY2YYWcjYjUs8MdJ3tdON09Nv3X42aF1w4NeAku84lug_HPrIns9rY1DKeF0S.png) 
One transistor and one capacitor, wordline selects the bit and the bitline contains data read out or data written in. Capacitor needs to be refreshed due to leakage.
        - How do you select from a DRAM rank?―A rank will contain devices which contain banks, those banks will contain arrays which will contain rows and columns. Each array provides one bit, we select one bank from each device and all of the arrays from that bank. 
So bits accessed = num devices * num arrays in bank
        - DRAM commands:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/s32XbfOvsdUKXDDzJngj2ENVeqKGbpKccBkMNVu7tiH0slEUsZ5NLXqCzo7HOcaYNDF3yiMtctyE_bDDpCul55pFoEV2MDGOletMRwy_irwJVrWfw3UjS9WQ02ullXQQ.png) 
        - Describe open-page vs closed-page in RAM―Sense amps act as buffers. We can choose to reset them every time they're used (closed-page), or reset them when we explicitly say to (open-page). 
Closed-page is best for cases of low spacial locality when we're accessing different columns.
Open-page is good for high spacial locality when we're repeatedly accessing the same row (maybe a different column to before). We need to explicitly reset when selecting a new column.
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/agSiMdOctYzBxP9ftltUjsAHJXiZmGBA6umt028_62mBlBd-VurGS5z8pdwG-AxspC_Wjyn7pmmKQ7_oucFYley3f1nv19vPnymAJLR52Lq0hZv6DxI-pja5t3VE4qwN.png) 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/h9XCmbrAbDy0mUL2nIi_LT1brpX0SESMf8lAaCiEUFdNGK9a8ZAW1pEL9PQZsEtfYMG6ZbuYSrzdpyNDR8X9tkzEPRw0UJb3sH_yFp1-Hznz0oPTzBjG1BY0KongjvrV.png) 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4L7RFXmqPL3Z5Zt1xTbjdLdE2XjyIPrZM-6LsIYLn9NzPxhxaX9oFZGrTGi2sEgNnwPOueMW532hzz8_va6HQN9YF5EvpUYvxRqY4V5IET4wDpVU1aA8I_9G4HRqrrVk.png) 
        - 
    -  _**Lecture 12**_ : Cache Coherency
        - Why is shared memory a useful concept?―Different cores can use memory to communicate, they all see the same address space. 
One core writes the value that the other reads. 
This is the view programmers have so shared memory is easy to program.
Shared memory systems are common and are the basis for desktop, server, mobile system  
        - Describe the benefit of shared vs private caches  ↓ 
            - Private caches may be faster, but can be lower capacity. Can store the values the cache needs to work.
            - Shared caches might be slower, but can be larger. Allow for message passing and sharing data faster than memory.
            - Choice depends on application, multithreaded or sharing data?
        - Why should/shouldn't data be duplicated at different cache levels?―Miss might not have to go all the way to main memory - but the tradeoff is that data will be duplicated in different caches which is wasteful.
        - Describe the 3 methods of cache inclusivity ↓ 
            - Inclusive - everything at a lower level cache is also in a higher level cache. Might mimic evictions as well.  
            - Exclusive - cache behaves like a victim. If a value is read from the L2 cache into the L1, it's evicted from L2 into L1. If L1 evicts a value, it goes into the L2.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fKyTvz1hQomKWvHOsC1AlvMZKebUFHiV0Ylbnly7wCuMnUHoOfPST79nMAZ2NHwnwqV_wHBuF_BV0aUj7Fv2q_7oOTLHfOiqNAoBqKYt4GFhU1QhEQJmoiFfQY0JJM44.png) 
            - NINE - store memory fetched in both, but when evicted from L1 - don't change L2
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/s217eSlmMmOHwNL_IOP3gHs_JLVpLZg5n7fmOfrVVRHk2xeMmq_-a3m-dpr4_vSxjM_n7ia7ECLQXMq5imnvvawisC4K1sdM86TWM2lgQYbbTbVYQD27X-4B2Z6aNQit.png) 
        - Do Write-through caches solve cache coherency?―Write-through caches are one partial answer but these create a large amount of traffic as we still need to propagate values to other cores. Write-back caches are preferred and ideally only propagate values when actually necessary (i.e. on reads by another core)  
        - How do we know a given cache-line is the most up to date value?―Associate a status bit with each cache line - that tells you if a line is up to date etc. Will tell us what action to take.
        - What are the 3 statuses in the MSI protocol? ↓ 
            - Modified - means we have the most up to date value and the higher level cache value is stale.
            - Shared - means our copy matches that in memory/upper level cache. **May be present in other caches.** 
            - Invalid - we don't have a copy of this data
        - Describe the possible transitions on a local read of a value  ↓ 
            - M - we have the value and it's up to date, simply return it to the core. M⇒M
            - S - we have the value and it's up to date, return it to the core. S⇒S
            - I - we don't have the value and must initiate a memory read. I⇒S
                - If another cache has that value in M state, they snoop the bus and flush the data back to memory. Then we get the value from memory and they transition to S state.
Even if other caches have the value in S or I state - we get the value from memory. They snoop the bus but do nothing.
        - Describe the possible transitions on a local write of a value ↓ 
            - M - we've already updated the value, we're gonna update it again - M⇒M.
            - S - we've got a read only copy, which we're going to now update - S ⇒ M
                - We send an upgrade request and any S copies snoop the bus and invalidate their copy. We now have sole access of the value and can write to it. Write hit.
            - I - we don't have a copy so this is a write miss. I⇒M
                - Initiate a bus read, so any M copies snoop the bus and flush their value to memory and invalidate their copy. We get the data from memory and keep an M-state copy.
S copies snoop the bus and invalidate their value.
        - Describe an MSI extension―Instead of going to memory, allow cache to cache sharing. I.e. if in I mode and want to read, then another cache in S mode can send the up to date value.
        - What's the problem with the MSI protocol?―Sends a lot of invalidates for thread private data. E.g. for data only one cache should ever have, we still send bus messages telling other caches to drop values. 
Solution is to add an extra Exclusive state.
Snoopy protocols don't scale well.
        - 
    - 
    -  _**Lecture 15:**_   CUDA and OpenGL
        - GPU Memory:
            - Different hierarchies of memory, various levels of sharing. Isolation vs sharing for individual threads and warps composed of threads.
            - Why do Modern GPUs also use caches, even though multithreading hides DRAM latency?―Caches reduce DRAM bandwidth requirements (Would need larger buses).
            - What are the GPU Memory Types ↓ 
                - Threads allocated private local memory. Stack Frame, spilling registers.
                - Shared Memory on each multithreaded processor (streaming multiprocessors):
                    - Not shared between processors 
                    - Dynamically allocated to thread blocks on creation
                    - Can be used for communication between threads
                - Global GPU memory available across GPU, also available to the host/system processor. **This is GDDR VRAM if the GPU has it, else** **external RAM.**
                - Also constant and texture memories 
            - GPU Memory Locations:
                - Local memory - in external DRAM; Can be large
                - Shared Memory - within each multithreaded processor; high bandwidth
                - Global memory - In external DRAM; can be cached
                - Constant and texture memories - In external DRAM; cached in specialised caches.
                - **How are thread accesses of values different in a GPU to a CPU **―** Accesses by one thread is broadcasted to all other - don't need 32 accesses for a single value.**
            - Example - Kepler Memory:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XuzblUh_rrlMLk8o-CPXl4Rw7Hjsp0HIfwgeOevS6YsNjBev9u3lAXwXPQ77Cg8sIS57ijCwg3fcPgtWE5wzKHu-ltUTmoxfomsFz8W1B26CPtf6i4BOuhcvjPl8DIq_.png) 
                - Configurable, can set up a split between amount of shared memory and cache. E.g. 16/48kb split.
                - ECC (Error correction Codes) on registers, caches and DRAM, protect from errors from things like particle strikes.
        - Programming with CUDA:
            - Why use a GPU programming language?―We can use High-Level languages, make things **portable across GPUS. **To **abstract away from GPU internals.**
            - CUDA widely used and mature.
            - Compute Unified Device Architecture overview: 
                - Its a C like language but allows C++ constructs too. 
                - What does the programmer need to specify about CUDA code?―Programmer identifies the code to run on the CPU and that for the GPU.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dbmGAZxgLYhjIY9qKOOKtFehp2duKks1M9KvhVIZ8qGP3rH_8j3ZFrfwKvIgEaCBq2jOImcvNFHRsExCVfjqAsUD1uCtrSUpFx1kq6Y0vy2xxCRBsFo7TQ3LxrLETxKf.png) 
            - In CUDA what is the **kernel? **―A Program or function, designed to be executed in parallel.
            - In CUDA, what is a **thread? **―A single stream of instructions from a computation kernel
            - In CUDA, what is a **Warp? **―A group of threads that are executed together
            - In CUDA, what is a **Thread Block? **―A set of threads (usually a set of warps) that execute the same kernel and can cooperate
            - In CUDA, what is a **Grid? **―A set of **thread blocks** that execute the same kernel
            - The 128 forms the **THREAD BLOCKS **within the **GRID. **Contained within the Thread blocks are **WARPS**. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IOpN_f2w7U97udVrPrApTVX3kF50t4vhMTdOHOIfpfFaCbTbe3SpkPBmt4vq47OWje2XY4Uee77ULJh7FJSLx-sIvb4GYv3lSqzlQkdXiGXKo602PG-3Yq9gjV1bNum_.png) 
            - ```csharp
__device__ or __global__ mean on the GPU.
__host__ means on the CPU
``` Must call GPU functions with code dimensions:
            - What does this specify in cuda: ```csharp
func<<<128, 8>>>(params)
```―These specify the number of blocks within a grid, AND the number of threads within a block. In this case, 8 blocks with 128 threads for each block. Note in CUDA this will result in 128/32 = 4 warps for each block.
            - ```csharp
func<<<dimGrid, dimBlock>>>(params)
In the above case:
func<<<128, 8>>>(params)
``` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IV-BieGOCBrUPR1f1WfLxLAxTszfR145eY_YKGy6PUT58Cez6N2otQQygd5YmlzTzqVo6sdf9kkTILbMntewX-mi3FT19NTryACLaUcemLRyXt3Q6gJk81Jk6trgQf3t.png) This is replaced with: 
            - Explain this ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mge8HfaS1Wte6Kp2rLWLoeKXEMlPkYyTEXjOskuf7-lRgHMPpunbIMoP_g09Dp2D3RyvUfD1ulqyB1crfvIveWJYrFJmm3Fl1Mg6lk0g2yC5mlsHeDOYPVCQUjhG2I_Z.png)― __Each thread is one iteration of the for loop!__   i<n is used **because we could call it with more threads than needed, as there are 32 threads in a warp.**
            - Called using:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fEpPAxd5Adxm1gbu5o48waHRg8Yxt0gtDGWLkfS9yGG8Jv0zZoC4LWtuGndgcOhm9EcJTaqJhJ_hZ7TkS2UpMKYBig7Qu_MvpVUdkKiW8ugEl_TJRrqNhxm61IH2LTMN.png) 
        - **Programming with OpenCL**:
            - What types of systems is OpenCL designed for?―Many types, including CPUs, GPUs, DSPs, FPGAs, etc
            - **Based around 4 models of Computation** ↓ 
                1. Platform model - Specifies one host and multiple devices
                2. Execution model - Defines how the host interacts with devices
                3. Kernel programming model - Defines how concurrency is mapped
                4. Memory Model - Defines the abstract memory that kernels use
            - **OpenCL Platform Model**:
                - **Give a high level overview of the OpenCL Platform model**―Host & 1+Devices where devices are divided into compute units and then divided into processing elements: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/foy6M1jue01yXLC_9O94FlbNKw1Rz3fHxllaYgi_isUxkQyhHD8T45bMRrfdRiCzZBKBQDkHLITYvoRTRFvdVravQx_dgMKWFf6lLrUAqLVHBVOgQq2J8hTfO3AHKzFF.png)
                - **On your PC, what would the high level parts of the OpenCL Platform model?**―The Host would be main CPU for your computer, the GPU would be one device containing streaming multiprocessors (Compute unit) and each thread would be a Processing element.
                - How does OpenCL handle multiple platforms on a single system (e.g. Intel and AMD devices)―Apps use **a rich API to determine devices and platforms and create and run computation.**
                - How does  ```csharp
clGetPlatformIDs(entries, *platforms, *num)
```work?―Need to call twice, the first call gets the number of platformIds then allocate the memory for the platform array (now you can with the number) and call again to populate the array.
                - Do the same with ```csharp
 clGetDeviceIDs(platform, device_type, ...)
```
            - **OpenCL Execution Model**: 
                - This describes how execution is actually set up.
                - For which we need a context. What is contained within the OpenCL Execution model context? ↓ 
                    - An abstract environment for the execution
                    - Manages memory objects
                    - Keeps track of programs and kernels on each device
                    - Manages interaction between the host and devices
                - What are Command queues in OpenCL? ↓ 
                    - Command queues allow the host to communicate with the devices within the OpenCL Execution model
                    - For example data transfer or running a kernel
                    - One queue per device, host sends the commands
                - **What type of queues are used for OpenCL command queues**―Queues can be in-order or out-of-order, in order = FIFO Queue. Out-of-order, commands can be rearranged for efficiency.
                - **How do we synchronise OpenCL command queues?**―Barriers used to synchronise queues.
                - Describe Command Dependencies in the OpenCL execution model ↓ 
                    1. A given command depends on others. Event objects specify these command dependencies.
                    2. Each command has a wait list.
                    3. Each command has its own event, to link dependent commands with this
                    4. Events contain the state of the command: Queued, running, submitted, ended, ready, complete.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/g5IxZIxS7kbLZkh4q50OMN6J0KveTEEgfwzVD_yBNJfcMjSDnH5CEJgWa8M4KMFeOlATwdk4J67xdlsd_bLA_53GlGQGpP9J8Pb3z-zz9Ft5R0mIlv-ggcPKyCJbahrV.png) 
                - Kernels is the **code that actually runs on the device.** 
                    - Syntactically like a C function, each kernel contains the **body **of a loop. 
                    - Kernels express parallelism at a fine granularity - allows efficient mapping to a wide range of hardware.
                - What are work items in OpenCL?―Work items are the **basic unit of concurrency, **each work item executes one iteration of a loop. Corresponds to a CUDA thread.
                - What is an NDRange? ↓ 
                    - Work items are given a index depending on the NDRange, for a 1d problem consider vector addition work item X computes the addition at index X. For a 2d problem, consider matrix multiplication where work-item (x,y) computes a multiplication (x,y). Work group space would also be the same number of dimensions.
                    - Usually corresponds to input/output data 
                    - Either 1 2 or 3 dims, called an index space.
                - Describe work groups ↓ 
                    - Work items within an NDRange are grouped into smaller units called work-groups
                    - Share a memory address space AND can synchronise with barriers.
                    - **So**  _NDRange like multiprocessor, and work group like warps._ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YIcQUGPH3R_-VjyAdj7kTkf8DIabxxt09KamvGHs6zTC4mm1qgG_bR7FaodXWBWygh_LmlhTO6ZLlzLk7TcU74n8x182ThQtHUsOZoQBo6gSPZiTRmFFdY5dSKRl2cgx.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ByZZ8HnD4pWOMhL-gIvdDRe5GmBzERU4KHrrgdtesq-HdvOkuhp6Tll6ruD-BIxUuuGrq9vmfm7ig5BGEXQUwAITQSF9GUTpPxN7AQZ34pHceFFNr_koWHUL3qmflvOZ.png) 
                - Describe the benefits of compiling the kernel at runtime―Allows for optimisation for a specific device - **otherwise would have to provide binaries for new devices. ** Allows easy development and execution on different systems. **This adds an overhead in startup time.** We start with kernel code as a char array in memory.
            - **OpenCL Memory Model**:
                - **What is the benefit of the OpenCL memory model?**―Abstracts away differences between different devices, need to be able to map to something physical as vendors map their hardware to this model.
                - Defines what happens to each memory operation, i.e. what values to read and in what order the operations should occur.
                - **What are the 3 Memory objects in Open CL** ↓ 
                    - Buffers - equiv to C arrays
                    - Images - abstract storage that cannot be directly referenced, rather pixels can be selected. Just stores images mate, innit
                    - Pipes - ordered sequences of data as a FIFO
                - Memory is either host or device memory, host memory is **not worried about by openCL. **Device memory is accessible to kernels. 
                - **Describe how memory is structured in the OpenCL memory model?** ↓ 
                    - Global memory visible to all work-items.
                    - Constant memory visible to all for simultaneous access.
                    - Local memory shared between work-items within a work group
                    - Private memory only visible to each work-item
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DyxW5z8yzG_0ws52kJDEee5y0NAr4d8jYSmzFcS94aip5zBnrvJCXtc1SldJS8_PcHcWFkcHnIXFN6E-16fB-ISxGATxacbBHZkXLftjvkdQa2nDWRT2-aOmmh8dhhAX.png) 
                - Running OpenCL code:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5w9hDVmdSIRGs7TDGAtayWCd-e7D4CWxIJ84aSMi1Wo_lFYQUkTL_VltlCzoRG9MuDh0_GjWFi-XqsqOxlKycy2ICDXGGpezzUn8h3M6eqoYPtaMVodyqTzHDEVc4Zb4.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rA3v0z1Eq08duWs10CRgOManH37EqCKMBY-BtWX7cAPLjleoKygO7meQgBbN98k8Q-IJZJkR5dX7VRAeFqH2sIZqOvA3HheT5dDzSaJN8N_2Knaifnp2Zz5ZHsz_5tWr.png) 
                - **Why do people sometimes choose CUDA over OpenCL** ↓ 
                    - OpenCL **much more verbose **than CUDA
                    - OpenCL gives start-up slowdown as kernel compiled
                    - CUDA faster on Nvidia devices, better optimizations
                    - Never know the exact commands that will be run with OpenCL, decided at runtime 
                - Platform discovery **and compilation** performed at runtime. **SO you can't actually know what's going to be executed, in terms of machine code.** Allows code to be changed at will depending on the generation of the gpu.
                - **CUDA **only targets NVIDIA's GPUs, so one platform and static compilation to PTX ISA. OpenCL targets much more than that.
                - Intel and ARM can't "retire" commands from their ISA as they require backwards compatibility, however NVIDIA can change by adding or removing instructions. For OpenCL **the ISA is only known at runtime.** 
            - 
        - 
    -  _**Lecture 16:**_  Future directions in Computer Architecture
        - Industry Opinions
            - Industry quite conservative, only looking 5 years ahead max. 
            - Energy efficiency is the new fundamental limiter of processor performance, far beyond the number of processors. Miniaturization helping with energy efficiency. Compute very inexpensive.
            - Moore's law slowing, getting down to 7nm. Even if you don't make the transistors smaller over a period, you can improve your process of working with that node. Smaller transistors more expensive, used to be a complete win of smaller and cheaper. 
        - Challenges:
            - Energy efficiency - moral obligation to keep power down.
            - Reliability - keep things working correctly.
            - Performance - how to make things go as fast as required.
            - Security - How to make things go as fast as required
            - Often these things are intertwined
            - Could get to a point where there's a backlash against computer systems, need to get roll out right.
        - Energy-Efficiency Challenge:
            - What change comes with multicore systems―Moving from complex single cores, to multiple simple cores.
            - Dial down clock frequency to save power. 
            - Problem: Neither CPU like or GPU like multicore designs are sufficient to meet speedup and efficiency wanted.
            - Simply adding cores not solution. 
            - Need to fundamentally alter the cores themselves. 500x more energy efficient on ASIC than on general processor.
            - One option to specialise our multicore chips. Heterogenous cores. Problem, locks in to using a specific algorithm. 
            - Often optimizing around software designed for specific hardware. 
            - Google's TPU uses custom ASIC for neural network training - locks yourself into a particular style of machine learning. Could be better solutions designed in the future. 
            - Use reconfigurable FPGAs that can be changed. But can't get clock speed up very high.
        - Performance Challenge:
            - Performance **must **come from parallelism, can we beat Amdahl's law? Research and change in culture takes a long time! Only mid 2000s multicores became mainstream. 
            - Speeding Sequential Code:
                - Temporarily exceed power budget (sprinting) allow some cores to run faster and hotter based on dynamic voltage/frequency scaling. 
            - Processing-In-Memory: Data movement uses energy, some computations can be done in memory such as **Zeroing blocks of memory** don't need CPU to be involved. Lot's of different systems try and zero memory as don't trust other things to do it.  
            - New Memory Technologies:
                - Phase change memory is **non-volatile **but with slower writes than DRAM. 
                - 3D XPoint - SSD caches could be alongside DRAM within the year. Latency of 10s of nanoseconds, slower than DRAM but **far faster than flash.** 
        - Reliability Challenge:
            - Reliability is also becoming a significant issue.
            - Process variation is a concern, doping has some random elements. Meaning some transistors operate slower than others.
            - How to get less variability with transistors?―Use bigger transistors.
            - Why do failures occur over a processors lifetime?―Transistors wear out quickly and Permanent faults develop that must be addressed.
            - Dual-Core lockstep:
                - Two seperate processors running the same code, for safety critical application. Logic ensures results are the same, mandated by standards for some sectors. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4fQL9HpquKHetGG8iCV-SW96EfhFJPWdBMSLSWkS2cd416xjxAEgeWtBflEsVDK_-B_iEqPnwBkjXOO4XrPmeycG7zLIIzZB_y1q2MP9oDy6fr8aSFIiYSq7rOb3bSc1.png) 
            - Can Embrace the poor reliability: 
                - Many applications don't require 100% accuracy. Such as graphics, video, audio, sensor analysis, games, etc.
        - Security Challenges:
            - Why do systems increasingly need to be secure ↓ 
                - May be running on unstrusted servers (cloud).
                - May be computing with sensitive data
            - Programming languages can help, but lots of legacy code out there!
            - Spectre: 
                - An attack that relies on speculative execution, tricking victims into loading secret data by **training the branch predictor**. Cache side channels to leak information via timing - see if the load hit in the cache or not. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JX1bFVt_kKvC56tPoPSUzeAdbKGPd8Ffb-GrW-TeSnFavGYQ7emHM4a8RD4_m0po810-ISomhkeXccel9A4bFeLmapustEXEQscVl6ZCy_cu5sJtNP4K3gYZzYgF3jZC.png) 
                - While the execution is rolled back, the cache is still perturbed.
                - Mitigation:
                    - Filter Cache preventing things in speculation affecting the cache
            - Generally want to prevent leakage of secret information, ensure no unaurthosised modification either.
            - Must protect against existing attacks, we can protect against whole classes of attacks (CHERRI). We can also make systems resilient to future attacks, allow for patching in the field.
        - 
        - 
        - 
    - 
    - **Assorted Flashcards** 
        - How long would this function take to complete in a simulation on input n=8?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/giNQGy5L5xtQtgOurkjdpo6ItJQqtSuXUNnL6pGM615tqp9saauvuOVHXeu2PEPy95a5-kYDbj5DzwuAsqFbM5fOm0UgpEUJWcrBJLSuubWAOCOmRNnqvtiYCjZtrjzN.png)―This would take 1 cycle - while this recursive fib would take fucking ages, in simulation time steps this would be a single step. 
        - How long would this function take in a simulation to complete on input n=8?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eu-M05bqCEITpIMjZfvMMVJg_Ck-PVswzMqo-OUmYKfNSVqtDk8ZLR_ia8Rg5lu0i0m3pectgrEsO9APD2yytTvrMaC7SmJ7WbNZRJYFic-ATEKNvgO7UVbnkziwhHOF.png)―Initially setting the values takes 1 cycle, updating the values takes one clock cycle and returning the values takes one clock cycles. So 8+2 = 10. 
        - How many clock cycles would this code take in a simulation?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ccigabnq7EdeXyXMtSA-YEMGHU803ksRfint6aUNqSZ2EHKl0c9IK_YUUPcceMLwSiuO2IWzTkIsEaOnBtXrC_TSUXvfli0HWrCaQV6foIFxQSL3PvvrVDWhwSlnFfqk.png)―This would take 1 simulation cycle.
    - 
    - 
- Computation Theory
    -  _**Lecture 1**_   Intro
        - **Hilbert's Entscheidungsproblem**
            - Is there an **algorithm** which when fed **any statement** in the formal language of first-order arithmetic, determines **in a finite number of steps**  _**whether the statement is provable**_  from Peano’s axioms for arithmetic, using the usual rules of first-order logic?  
            - Describe the problem, and is it provable?―can we use an algorithm to **decide whether a statement** (written in formal language) is **provable ** _**in a finite number of steps**_ . It is **not **solvable. 
            - A **decision problem** is―Given a **set S **whose **elements are finite data structures **(simply means some data to read, could be formulas of 1st order arithmetic), and **a property P of S**. The decision problem is **find an algorithm that terminates with 0 or 1 **-  _**only yields 1 when fed s with property p**_ **.** 
        - **What is an algorithm**
            - Common features  ↓ 
                - **Finite **description of the procedure, in terms of elementary operations
                - **Deterministic** 
                - We can recognize when it **does terminate** 
            - Turing ⇒ Turing Machines. Church ⇒ Lambda calc. Allows for regarding algorithms as data, on which algos can act
        - **The Halting Problem**
            - Is the **decision problem **with―Set S of **all pairs (A,D) **- **A **is an **algorithm **and** D **is a **datapoint **that A works on. **Property P holds if A eventually halts**. $A(D)\downarrow$  - means A halts on D.
            - Church and Turing found, no algorithm H such that H(A,D) solves the problem. 
            - Describe the **Informal proof, **by contra ↓ 
                - If there were an algorithm H(A,D) that solved the halting problem.
                - let C be: "input A; compute H(A,A); if H(A,A)=0 then return 1, else loop forever."
                - So we know **within C **- if A(A) runs forever C halts, and A(A) halts C runs forever. But what if we apply C to itself? ⇒ If C(C) runs forever C(C) halts, and C(C) halts C(C) run forever
                - This is a contradiction.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/siFmc-hoYXZI03PTHj1UFNUEdQ78lNvCIy_Lq-2rLG89Dm5egQBa19h0-bBEX6537hlsOchorTSYTvpREK_mMfO9G7wYXdk5et3HPJbSB58zkSZEIXsHM7pK8GpCq6ns.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/run013sEKw6k5TVw9nteiquELNVaqM5bDeYaVbYE1_S7taZeJaLzd4NxVPaGJmBn_fjjJdso-ORkObK8Pm4ChpUFNbzwwjGY0_OkTQhLmcSlTCcc0QHNJd-u2vnMZzDE.png) 
            - The dubious sections of this argument are ↓ 
                - Can we make C out of H?  
                - Is H(A,A) allowed? 
        - **From HP to that German one**
            - Rephrased the question to - If a statement in arithmetic is **provable **then A(D) halts. 
            - They encoded an instance of the halting problem as arithmetic statements $\Phi$, such that if you could decide if $\Phi$ was provable, it decides if the program halts. But as solving the halting problem is impossible, so too is the **Entscheidungsproblem.** 
        - **Hilbert's 10th Problem**
            - A **Diophantine equation** is―an **equation with polynomials** with a **fixed number of unknowns**, with a fixed number of **natural number** coefficients ( __implies whole number coefficients)__ . Where the **only solutions of interest are the integer values**. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qxLC7QDSPKmIEmN0o7zNfIiL7OfeoGT_jHowoaRR1nzL5UOXpWThiBK9ZPofEn-nENcVeaaDMfGMlnCnn1DtFl2nkWVM1rw24jTsI5tOrgNSIiPKJfia7ZfO9s2IojQy.png) 
            - Give an algorithm which, when started with any **Diophantine** equation, determines in a finite number of operations **whether or not there are natural numbers satisfying the equation**.   
            - It is **undecidable - **found by **reduction from the halting problem.** 
            - 
        - 
    -  _**Lecture 2**_   Register Machines
        - **Register Machines, informally** 
            - Operate on natural numbers (can be any size), stored in idealized registers using the following elementary Operations: 
                - Add 1 to a register
                - Test if a register holds 0
                - Subtract 1 from a register if non-zero
                - Jumps
                - Conditionals
        - **Register Machines more formally**
            - **Register machines consist of** ↓ 
                - Finitely many registers, R_0, ..., R_n.
                - A program consisting of a finite list of instructions of the form label : body, where labels go from 0 to k.
            - **What are the three types of instructions ** ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fxk8AwYFUA0rhP95tR13a2my0eD4RWCqi73G-xqu4UtDOyEnUYxFkwFhhbalvTu7S1d3qCjpXfFHPjnlR-CdYU_KVQPP3Vn94S9Cr7Iol-yycHl4N52bfTzLVZAdXnz1.png) 
        - **Register machine computation**
            - At any time we can store all the data about the register machine by taking: $$c = (l, r_0, ..., r_n)$$
Where c stands for configuration 
            - A computation of a RM is a sequence of configurations. $c_0, c_1, c_2,...$ each configuration can be computed from it's previous configuration (other than  c_0).
        - **Halting**
            - What are the **two **ways of halting a register machine?―HALT command, or jump to a non-existent label. Called an erroneous halt. Can consider infinite HALT commands after finite number of non-HALT commands.
            - The last configuration must be a HALT configuration for a finite computation
        - **Graphical Representation**
            - Easier for representing control flow
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ATSzCaqRa1E99W-Awl8pdLZtB4qVrZ3YH7iQ6nD_aOmS1E2zknssVF09D8hsasqG4E46OpzUL_-VvJB9amrXfRLCPPxPI5q0UQAu9MRZnq5LmzCF63A2kMNBBg71oBSp.png) 
            - Program for summing two numbers:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p2AtCKLNZDVUBQtBVCl1dzFcagI6NjN8WxjAsbae6T8Lflgad-ue_oyEG8wOahd3qqN8YiBalu9xXhPZ37FBf5LNSOnEWu76bTHX7hbs-unLcZ-0mwrQPieOLeg_Di2B.png) 
        - **Partial functions**
            - Register machine computation is deterministic, relation between initial and final register contents defined by a register machine program is a **partial function:** 
$$( (x,y) \in f) \ \land \ ((x,y') \in f) \implies (y=y')$$ 
        - **Notation**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1zv_EQfE_VTdHhjE0s1Tx3oMCaCbfXD4eE185wSJMdwyf19HQQbKmf-kPeIGk5SjWzUr92BYNkv-zD_zApMHrHu1ik_hVUgWlefjYjr53Ghf7xZmkS4I6U2hvg-vE5hv.png) 
            - So the up/down arrows say f(x) is defined.
            - A **total function **from set X to set Y satisfies―$f(x)\downarrow$ for all $x \in X$.
        - **Computable Functions**
            - A function with n arguments is computable by a register machines (with at least n+1 registers, n_1-n_n holds arguments), such that for all argument and output pairs of the function - the machine halts with R_0 = y with the arguments set in R_1 - R_n 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cuvOKu96585HgTMZDaKltXxfp_Re5kTBmR3Cbne1PxTMhRLYpbzDFMNFO0-lk2qf_afGnYCeum7diREAPOZBA3_bZmSTVgdqOYQglJpMaYHmI9Sl2y267g44sDXwhNeQ.png) 
            - Note, there can be many different M that compute the same partial function f.
            - Note our previous register machine witnesses that, ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OUusJqbA04doG099vl9ymQrnDKks4l3kpaJ5aNRkwLxg6ZJFjEi19EVi321d5xDAX-eZZ4AE8Z82l-fsgCnMPKA7R_b0SOGrgy86WnzEaWtDmbFKyfCPz7fDLLfXOSX5.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CG-JvWoVYIBLtGajm2nPwpKxErPdhCb3Hg7l3XE3DW0oriC_taKwgAksEkO-hIxXbJ83Gyg2zoGV7Ihg9Osf7pFuqwjMcqMI0daQIfqCTuYQp2lisfE4fmJTvI-9uKlw.png) 
BREAK DOWN INTO SECTIONS AND SHOW IT WORKS 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/m_pOxTAUP6F2kliOu-96STivxWsFgXXHhLs4327ErKEtWK9rtjZiEygt0UihD6DbyTEGZZh0romr0x3ln3Sa37hRdbiP0udzLkNnsdCO5ZjRpLvbTRgDEVhsJcUUzjB8.png) 
        - 
    -  _**Lecture 3**_   Coding Programs as Numbers  
        - $Prog, [x_1, x_2, ...] \rightarrow y$. (y in R0) 
        - **Numerical Coding of pairs**
            - Triangle equals means by definition.
            - A bijection (one to one correspondence) between pairs:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wxblGNzAQoXmEAp1VRPuG8zD2QjQzoqsd9Do2crsF5jy6P1MUXsP7fgMPSVnJelLevodmZauZsuYFMBBaa_l3Iy0e5p7etaHf53VTxOBNdkLIqpFErN8nxMqMkqMwKZU.png) 
            - Every natural number (not including zero in the first case) appears uniquely in this encoding.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lUV40eWVwJCvak73kaQmwm58az0YmKiIwx66doA-RJ10vPomyVyG-nAAK3VV-wQ4gGsq-Uyn1uyXo-Aldsom7hrC0VRgVnENbHjo2YPbnWfLLX58XNgnB1xKDJOnI5Jq.png) 
            - First version is x 0's, then a 1 and then the binary value of y. Second version is x 1's then a 0 then the binary value of y.
        - **Numerical Coding of a list**
            - We recursively apply this pair encoding, stepping through the list with the empty list set to 0.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Igt53IFPBELGvpNnjMA9xgk2Gm82407Ur22Tp9jTzev0JMDr-LjpupXj4ILEoHqnWTcpElMjUsFrvZx0MJnkkdXv4j7hUmW-PxSouuIqWxTV7XK6auD4PSql6hf-Ybly.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AWzKSIpKAfvQe29H4D6RVFaK1tjEm84cjuMNfxG_7K3S52QUytj-7pHJbe_ZUvjgA8GspdGnnK7YJrtMU5MEYlYMDE4onjlrpVTGew4YJMgzeKV8YFyYg5NGkZU_i9ZR.png) 
            - You can find the elements in the list within the encoded binary - the number of zeroes in-between 1's form the values.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gF4nk51h36_RDmyecs-pvBmIAZY5Xqp61M20y1NZ0NxIk9-qBHxWkXvZLkLJpXuEONsGoU8lFEX2-y8B-mEwxpJdb_37j63X9F8poBRjZDAbIKyCw_nsdrxQ7yz_4-mc.png)
E.eg [2, 1, 3] becomes 0b100010100 - 3 0's, 1 0, 2 0's.
        - **Numerical coding of programs**
            - For a program:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U1BttrJOAPjiiqmrMllzDYSWuXz9xBQhdtEdmHqixxepjyvzqtlL_a8D66lIlqdjabQfzE4PDTVCSyyu7ftudE_H60YKmk-WiJkPYAB1lgrPei5UK-7fZNxiRDXou0jS.png) 
            - It's numerical code is: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PThJM8ADv9sbWOYMw_R-pieWc6lVNzbJ__WilD-0_B2JZmuyp5jWFY4cQquuSuVFH-G_aejoli-1oNqLryOSGGjyqCkTINr6l0j7c2uhlTw8ayufLhzH7aGkJqPTzCW2.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vt8ogfpFQJ6T0FK4O-VHShYpqbmfvNcwZBpWM1gNumR4UhY9qhmHiGjVozwSBZI8hElL7m4_HAZ7GPN6mCQPBO9-ctsQGu0jwhSeWMIA-Qi9WJBnIOmD5mLtgSiGVdRg.png) 
            - Note, we distinguish between the 1st and 2nd instructions by testing for odd or even.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1czSVods4EE1kb8fspAYGUkEpCVrVXTGFqi8V3hC5RNp5CG8hWuRuevudjrU5iS-0HYulMXFAGrRpSDjiG9Ve1StKpVOAGsxMKBjnzpWdHntCojXqydae784DW50hK6g.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ypq4lD8J0YnIEGC4AdknfgxCmwXVDoNmI93OknzSl0pvydl-ndwO4b4s9BU8R_1mmuX1p_criJ6pcVM2Jq2tu58SbHrv3bkjiltdWpfcec6KjCDAk_IvrSGnL0QsdPec.png) 
        - **High-level specification**
            - Universal RM $U$, does the following: 
                - Starts with $R_0 = 0$ 
                - $R_1 = e,$ where e is the **code of a program** 
                - $R_2 = a,$ where a is the **code of a list of arguments** 
                - And all other registers are zeroed 
                - We then want the machine to 
                    - decode e as an RM program P
                    - decode a as a list of register values $a_1, ..., a_n$ 
                    - Carry out the computation of P, with $R_0=0, R_1=a_1, ..., R_n = a_n$ 
        - **Overall structure of U's Program**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6SEXwKGB81mN2HEZW19IO9h7mJ6C34SKBSXv57rMEPEC7TTRziDVsgHZeo55wNx3pvnM-LJrVL62OjqL6k2XNmTLT5rIRAcZHCMSNE30Rdf8DqRruHT_B03nHTIB30Il.png)
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dMZd0ekDYPufF-mXVg293IHLWpuG3Y22rbiUG7hvc5zBgXciqzkDbKk8cnw_HBORXmQ9vDhvO19AvNmJeah5qwG_KuwJTUImuyOiKUhDtyu9eWcOvLghCx1ot9LIlCid.png) 
            - 2: If a halting instruction, we want to save the output of the simulated machine.
            - 
    -  _**Lecture 4**_   Universal Register machine
        - **High-level spec** 
            - Starts with $R_0 = 0, R_1 = e, R_2 = a$ where a is the coded list of arguments.  
            - Then needs to decode the program, decode the arguments and carry out the computation on the decoded arguments. With other registers set to 0
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/K3tc3n2xp2-oDMQ9lBS2ARpLBaCnkKOiTtbqG2aRafKXrhm5fL58aGWv6U47hvt3WF5lALwh6wrek0Pt2xPAg3_VSzEaugaN9Ixwa2k20VFocKUrfOrdHQ6hZvOWSzKe.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2iuOrCYQMNQN-u-HURqJva7bVu7reuk68WIoRuE2PP_FnKCGO3CD_HO7tkLyf9AWCvvsq-oCUITvki3E1bNj--lv4jhX8kmAYAhhbMlBQcLsXcZg6B9_B7XspvJ6HA8s.png) 
        - **First, non-destructive assignment computing S**―**=R** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SK-SvNlFgy25MKJkyiTFCqzC5gj0RKLvSOOWint7sKY_n6iHTplVXWXbpA4XiyVT4KjwTPFZ60ad_LSSaM5l2P61a8QIuDUcm4dfQKKz3e0dtgxRag-3EgIk83rdXVj1.png) 
            1. First zero out S 
            2. Then put R into Z & S (R now zero)
            3. Then transfer the contents of Z into R
            - Note - requires Z=0 at the start of the program.
        - **Second, need a method of adding a value to a list (X,L) **―**= (0, X::L)** 
            - Need $2^x (2L + 1)$ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vjClI-VL7U0maj4KS2xSUGBr_aSOIf-rCDHY3phA0lhItZMfg7I3HyNE0xlcT9dvKf8IkZysQWcK3CmS5vtWYFLp_Z0flM7rNDh4wwec_CUM-8aFu-2qmbgxQwv1ermI.png) 
            1. Z becomes 2*L + 1  in the first 3 transitions
            2. Then Adds Z and L becomes 2*L + 1+ Z 
            3. We then repeat this whole process X times 
        - **Third, need a method of popping an item off a list (0,X**―**L) ::= (X, L)** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-DZ91vSCkov50xS6muMjEA0s3_ycVD_KFfQuROmKzi4VlWUM1AscJRVEUFk_-C3sGBw0N_6swd10mQV_FcC2rtKfvnfHUfqj7GoAJ9bHJvrcgFGc8TdQmayhJK2bs4gH.png) 
            1. X gets set to zero 
            2. If L is zero then exit
            3. Otherwise, Z = Z+ L and L=0
            4. L=(Z+L)/2 and Z=0 
                - If Z+L even then we compute $(Z,L) ::= (0, \frac{1}{2} (Z+L) )$ and continue. 
                - Otherwise, $(Z,L) ::= (0, \frac{1}{2} (Z+L-1) )$ - then we halt. 
            5. X = X+1 then repeat  
            - We've started with $2^x (2L + 1)$ and found $x$! 
        - **The program for the universal register machine**  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fKWdWvWXlf7MRzV4_VUa0zMBKi56VdF7hzbTxpI-z5e7PPS6vEq8F94ZLbqNI4e8BGj8qydq4ZTCFblCC0pbGVJwqu6zXRlaVRXyN4j7r_ilR9IqR8yxtBEQ2OMxNdMh.png) 
            1. First we make sure that the simulated machine has register 0 set to 0 
            2. Copy the program into T, then **continually **pop off elements of the list until we have the **PC'th **one. So at first we get the 0'th item. 
                - If N is 0, then we wanna halt okay!
            3. The we pop N into C (If zero, that's a halt instruction and we need to finish)
            4. Then pop get A (the arguments) into R, we can decide what type of instruction C is by **finding if it's even or odd.** 
                - We need to get the ith register contents in S, as that will tell us what instruction to run
            5. If **C is even** 
                - We know we've got an increment and a jump to Z. First we set the PC to N, that being the instruction we're going to jump to.
                - We've incremented the ith item of the list, so we need to push R back onto A. 
                - That pop S into R (it will be reset anyway)
            6. If **C is odd** 
                - Adding 1 converts thick angle brackets to thick angle brackets, then peels the thin angle brackets to get N In the PC.
                - If R is zero, we want to jump to N
                - If R is non-zero, then we need to loop again
                    - 
    -  _**Lecture 5**_   The Halting Problem
        - A Register machine **solves the halting problem **if when a program is loaded with arguments, the machine halts with R_0 = 1 if the input program halts or 1 if it loops forever. 
        - **Proof of the theorem**
            - Assume we have such an RM H
            - Let H' be obtained by doing Z = R_1 ⇒push Z to R_2   
Does our diagonalization, sets the input to the program.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/icZsNlwGEfEkQqLBRu1q8NNJBMMfiTKhpP5M2KhQBZbkVFRNClDwBJSZ6dwKq6nuPcQ4_jqKPvIX9GBaX9RVVgMz3JDGcK2HNARXTtv8bXn1gF7tgtQ4BWXqTwCGXDY0.png) 
This just does the - if halt run forever, if run forever halt.
            - Let $c\in \N$ be the index of C's program. 
            - If we stick C into C we have:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iGWofZILXpfLkMnIaJZNeB60ngWlEj4BUbA8if9mWwVa5Ppo4NNG1pKkYfwCZyll6sIah8RX8p3gL-VlpUkduAt0RnTGmvbEfc7f71QR9Jst34FlPSkfA8TYB70mxbp2.png) 
        - **Computable functions**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qtXDQx_vG86XX80_EpdlnKN1XaLC_rrhwNLRkhCYvezlZhrO3F4NGgkSci9yF-5452D4rJSjINpNSUz2qrX268EFX7Jf1Di8sVhUTjyhtjUHvmULDt_kMysyYP-10qrs.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PJDSlq6_zsO1hMQEJh_YmSyNTWZz-PcohWH_N6aKBMOULAPs00r-NEHnRwEilqhDDDV3dTWRo4LliS3oiC3ujjrpbZg9AiFEqEwVc0WSF9Svz_I-PgKi6Jk9YVDcNMkf.png) 
            - Basically apply a register machine to an input. 
            - Thus $e \mapsto \phi_e$, defines an onto function from N to computable partial functions. But this is countable, So $N \mapsto N$ (uncountable by Cantor) contains uncomputable functions 
        - **An uncomputable function**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GW93ZmARcIoHylVkuLE0j9kZJsYB6xqdpOGxGI4GwMw3bGmvyFOTLntufpSPQANUAanUh7Lqk-76TCfsREFYgAU75RpSyflkm3Yn9P2tZ8uoXW2f4YtGHW_WvpQpAyD4.png) 
            - 
        - **Undecidable sets of numbers**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Js2OV9u9HtSzMHQcGQBjgNAUW5bGyhbcPkM8C0Wu-FYL0-JSnBSMbC5-GpfT4gvMMYdHt9E29M7gkwALPZXq-rMzsv_IEpYPZ4rrexeSHE-vUofyUPK0RG7NTsISM3_4.png) 
            - The set S is **decidable**, if there exists a register machine that can always figure out if an x is in S.
            - Basic strategy to prove undecidability:
                - Try to show that decidability of S would imply decidability of the Halting Problem
            - Let the set S0 be the set of register machines that halt when given 0. 
            - 
            - 
    -  _**Lecture 6**_   Turing machines
        - Turing Machines 
            - **Informally:**
                - Machine in a finite set of states, with a finite alphabet and a finite number of cells with values in. **Goes infinitely to the right. **Distinct symbol for blank. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IeWbubffbBSIDQKZVJ_g3W4KCmTU3p_nFXWjKYjlvRU1CGXi7lSZPvLoH8Ccao4bFOJNJS_9YuwHwF30RR4n6DuxYh9xnaZOJLR9Gug_2ur6XjFAFJ5p940EGsbaV5S4.png) 
            - **Formally:** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pktd1rD7w9TC4G1z99F-iXcjFAy7rbDQDZ1odh4_cFnTqt7ckziMmUy9XRWWbtjPOJsdVGoVTOVcucb0-51ssyP8jY-RRAsCmwYzlXFj26EhoDnNCtL0_OUvnE89z3lx.png) 
            - **Turing machine configuration** 
                - $(q, w, u)$ ⇔ (current state (could be acc or rej), w = non-empty string of tape symbols under and to the left, u = string of tape symbols to the right (up to some point of all blanks))
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GNEnc6-kN6WhUIS0cCv0yCj99CH0LcTEXjWPnQFIeydDxF5EYbLpCHJhUH5qmjejmIjv_CRYcm_mASIg64K6UseUmISrsApQ79m_Bf5gzlnAAUFmqp7HySuB6Pvt_OrY.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J263e2cNBbeSp3D-RuUqBHJdX8IKtvTY80GjgYzFP0C5HaSQEq2HcGw56WNbxw_sfEFIXa2qV_osSSlq77W3vUnzpKw_XkX_pGu7zLHdbX0q0LkWC0NWgQ1hPsif3JRo.png) 
                - Initial configurations = (s, ▷ , u) 
            - **Turing machine computation**
                - A (finite or infinite) sequence of configuration, where the changes in configurations are deterministic. Note, the delta function can only be applied on elements not including acc or rej - so there will be no transition function and the machine will halt.
            - **Register machines can simulate Turing machines** 
                - First we encode symbols numerically 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vpEKLauN7JsrHWEGnLOjQJEkZ1tzQMgOpEfgBAe3R6r6NDbYNf7Mt59_Xxc3PZg8GutEewYyH9_vP2Xy6ULiVu9Y0pMXOlijeW5o6xdgOtpn0q2z2YLOiQoiwABCnD4s.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4Eh3baDkdoHrSZ7KTEg3eENS3JxBOMhUO32AvGdA8PABCZw0HjEK1bWQLhrCgGEuDdu_lJkvf9ccy9JZnVooxtF6b9__t6c3ecKtU1ex09Ixaviud3XmhAENOCwGJVJr.png) 
                - Encode a configuration into a list! Note the list behind you is from end to start - we want to be able to pop off what we're looking at straight away.
                - Next we implement the transition function of the machine 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_zM-rF0Y9txffqJFsLKfkrgGZ5yrYv91rzwvyGZ_7h2NMXxTe0dWtU7jbquaXA-FA5BFkxTjd6V5_ZOafvnG2v8q-NBMxJkNIPZ1SyFurnFiWRYitZWYnjrvQxzBIuRu.png) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WJ_UEBqJWz57fRSpQq1DjcWPgQGU_NzarWbajTuIb5AaQtURZ49_R9AgiRx_57ZFmOfwT6XLeJ8wacrCrQNMwR9gwoPOOo-YhotyO8LvsCKTSS3jOxCelf9OTVKCSrxJ.png) 
                    - Basically saying, given that there's finitely many such transitions - we can do it. 
                - Finally implement a register machine to repeatedly carry out the instructions
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wRVf--kZPTRz0fhsW_6vCm43oOaWciw4cojNrL0YqDGmtYuolyZu5zHAh4OelC0VO2uTALjwjq4QjW_Ob9BxFJ-uNhS_nizJEREW5XyA5DJkx5Zcn6HdtrpFtvhVOAxn.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LoecY4TA6VFG92E0P071sbOcC0C7BvTk-A0XVUgUg5U47SykAbd-KUuTMoUpKTS2UuwZSlK7uSqV981uyxqYRNGQQuLFcKMLwGrLo3O1M8LXcmX3WpWJvuhzsvXL74Fv.png) 
                - If Q<2 we need to accept or reject
                - Otherwise get the instruction we're currently looking at and stick it in A.
                - We can then get Q,A,D - if we move left we need to shift a value to the right of us OTHERWISE we either pop something and push it to the right **or **remain stationary. 
                - 
    -  _**Lecture 7**_   TODO
    - 
    - Supervision 2
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kFP0VuaP_47A6RwFgm_NaRNz2zTTYQpfmW5005k0aI1IHSIF7cC0Z948wk6YZXRXidmYEHdFLFpTyIXTvD75Trwbg9eLkKdGLS2mhRz2mxKo-NBgw3uC7WXpNof2WBxa.png) 
        - DONT REALLY GET THIS
        - 
        - 
        - **Exercise 4** 
            - Exercise 4. Show that there is a register machine computable partial function f : N ⇒ N such that both {x ∈ N | f(x)↓} and {y ∈ N | (∃x ∈ N) f(x) = y} are register machine undecidable.  
            - 1 - does f halt, given natural numbers as input.
            - 2 - we can find all the defined outputs of f. 
            - Consider the register machine M that takes an input e, and simulates the program e encodes:
            - Proof by Contradiction.
Assume {x ∈ N | f(x)↓} for f = $\varphi_e$ we can decide if M halts given natural numbers as input.
As this is decidable and as our programs are coded over the natural numbers, we can decide if a arbitrary program halts. But this is a contradiction, as the halting problem is undecidable so our assumption must be false.  
            - Proof by Contradiction.
{y ∈ N | (∃x ∈ N) f(x) = y}. Consider, if all the outputs for our simulated function is decidable - we can find all the inputs for which the program halts and thus we know it does not halt for all inputs, solving the halting problem. As this is impossible, this set must be register machine undecidable.
        - **Exercise 5**
            - Assume S2 is register machine decidable - that is assume there exists a register machine M, such that M with input a halts and outputs 1 if a is in S2 and halts and outputs 0 otherwise. 

So to test if an element x is in S1, we simply compute f(x) (which we can do as f(x) is register machine computable) and then execute M on f(x) - if f(x) is in S2 then we know x is in S1, if not then x is not in S1. 
So using M, S1 becomes register machine decidable.  
Therefore if S2 is decidable, S1 is too.
        - 
        - **Exercise 6**
            - Proof by contradiction:
Assume we have a machine M that decides if two codes are equivalent. We can then create a machine that takes the code for a program e and compares it to the program```haskell
 L0: R1+ -> L0
``` which loops forever (using M).
This overall program then decides if a program is equivalent to a program that never halts, (i.e. if it isn't the input program doesn't halt) and we have solved the halting problem.
But, this is a contradiction as the halting problem is undecidable - so we cannot have such a machine M. 
        - 
        - **Exercise 5.1** - Show that decidable sets are closed under union, intersection, and complementation. Do all of these closure properties hold for undecidable languages?   
            - **Union** 
                - If I have a set A & B that are both register machine decidable by machines $M_A$ and $M_B$, we can form a machine that detects the union of the two sets by doing the following: ```haskell
 RUN M_A
 LN : R0- -> LK+1 LN+1
 LN+1: RUN M_B
 LK: R0- -> LK+1 LK+2 
 LK+1: R0+ -> LK+1
 LK+2: HALT
``` I.e. run M_A, then if the output in R0 is nonzero halt (after increasing R0 again) - if R0 is not nonzero then run M_B and check if thats nonzero.
            - **Intersection**
                - If I have a set A & B that are both register machine decidable by machines $M_A$ and $M_B$, we can form a machine that detects the intersection of the two sets by doing the following: ```haskell
 RUN M_A
 LN : R0- ->  LN+1 LK
 LN+1: RUN M_B
 LK: HALT
``` I.e. run M_A, then if the output in R0 is nonzero reduce it to zero and proceed to run M_B - if R0 is not nonzero then halt.
            - **Complementation**
                - If I have a set A that is register machine decidable by a machine  $M_A$, we can form a machine that detects the complementation of A by doing the following: ```haskell
 RUN M_A
 LN: R0- -> LN+2 LN+1
 LN+1: R0+ -> LN+2
 LN+2: HALT
``` I.e. if M_A outputs 0 then switch that to 1, and vice versa.
            - **Do these hold for undecidable languages?** 
                - Clearly this is true for complementation (i.e. that undecidable sets are closed under complementation), as if there were a machine that could decide the complement of an undecidable set - we could just use a register machine to find the complement of that complement and retrieve the original set.
                - Proof by contradiction. Assume undecidable sets are not closed under the union. 
Consider two sets A & B, where A and B are undecidable but the set $A \ \cup\ B$ is decidable by a machine M. Consider if we have another set C that contains no elements of A (and B is a subset of $A \ \cup \ C$ ), and the set $B \ \cup \ C$ is decidable by a machine N. 
However, this makes A,B and C decidable,  as we can simply compute M & N and if only M is 1 then we have A, if both are 1 we have B and if only N is 1 we have C. But as A,B and C are undecidable we must have that undecidable sets are closed under union.
                - Consider two sets A & B, where A and B are undecidable but the set $A \ \cap \ B$ is decidable by a machine M. 
Proof by contradiction. Assume undecidable sets are not closed under the intersect. 
Let A, B and C be three undecidable sets.
We know that $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$ by the distributive property of unions. 
As the right hand side is decidable (under our assumptions) the left hand must be too - this implies that the union of an undecidable set with a decidable set is decidable. 
This is trivially false, as if we took the union of the set of programs that halt and the set {1}, we could decide the halting problem. Thus the union of an undecidable set with a decidable set is decidable which is a contradiction, so our initial assumption must be false.
        - 
- Computer Networking
    - 
    - **Lecture 1**
        - The abstract definition of a network is―a system of "links" that inteconnect "nodes" in order to move information between nodes 
        - **Defining Characteristics of the Internet**
            - A federated system―is a system of many networks, **coupled together by a single common interface. **
In terms of the internet, all tied together by IP, a single common interface between users and the network **and between networks.** 
            - Single common interface good for interoperability, but tricky for business. Why?―Consider should Netflix pay IPSs for giving users the opportunity to buy a subscription - or should the ISPs pay Netflix as users may buy the ISP simply to use Netflix. 
I.e. interoperability allows for using the ISP to use another service, where does the money go?
This business problem is important, because business incentives drive a lot of network advances.
            - Enormous diversity and dynamic range - varying communication latency, bandwidth, packet loss, technology (optical wireless etc.). Varying **Applications, **varying **users. etc.**
            - **Constant evolution.**
            - **Asynchronous operation**
                - **Speed of light slow**, server receives my operation after my CPU has gone through millions of instructions. So, **Communication feedback is always dated.** 
            - Why is the internet **Prone to failure? ** ↓ 
                - All components along a path must work flawlessly, including error prone humans. 
                - Large scale ⇒ Lots of components. 
                - Asynchrony ⇒ Long time to detect problems. 
                - Federation ⇒ Hard to assign blame.
            - The internet is an engineered system, and thus is constrained by what technology is practical - **Cost. Cost is important, lower cost ⇒ more people ⇒ more useful network.** 
        - Channels = Links. Peer entities = Nodes. 
        - Bandwidth, latency and BDP are  ↓ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/68cshaTQsHYS7T08GVb4HL1DsAaPweAVF0lTy6EqYOHNrxcPyYFhms_6d18JimR4zox1lc3pfggbpcMI26hlHg0juxUYqg97NaOOB-JHHxr18BSQuDfkfNwehLux0VwX.png) 
            - **Bandwidth - **number of bits per unit time 
            - **Latency - **Propagation time for data to travel along links
            - **BDP -** Bandwidth-delay product, the amount of data that can be "in flight" at any time. 
        - **Packet Delay**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iwVYDBNZeqP2raNkJpBPysGimipgCK6SonUfviFO-ej1ad2J86qvvNNnyN8NH1zRC_M9xO9Gn1rkK6B8UwV5TCFRPX-bpjEZwOOqbECBe8Qj5K-qsP1gAAd0Crnnb0Fm.png) 
            - Includes time it takes to "load" the bit into the pipe. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tQ-o34-sieQG09HZLZRPCImnstnJdY5IHi2bw4gpy247wZrXaRR25--WveOEdZuUljQ8kQbx8f4FyI1CWm_nXt11Qk-yAHxI5fbfwTSiDYUuvn9GprmuD_glu9aebyeg.png) 
            - Different term dominates.
            - Can have networks with same BDP, but very different characteristics.
        - 
        - 
    - **Lecture 2**
        - What problem do **Switched Networks solve?**―Switched networks are an alternative to having data lines between each node. They solve the **scaling problem **of such a solution. 
        - **Switched network** 
            - What are **switched networks**―A method of **scaling interconnecting nodes**, where network links are a **shared resource. **The problem is ensuring sharing is done safely, might not want interleaving/interference between messages.**
**![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/B3FXY8lP2qYLEuS5lOsmdEFie0uFkzIVtxLVOHiNGqvTPiQWdTPWxGZ7BM6-QiyTzmVqSGruqeMOZfymQihBxutymlp4tXHWlnJ9cAifP1RxLAn_YtBtfe40XCnsyPgu.png) 
            - **The two forms of switched networks are** ↓ 
                - Circuit switching - used in the POTS (plain old telephone system) - with switches controlled by people or mechanically. Physically connecting wires. 
                - Packet Switching 
            - **Circuit Switching**
                - Source reserves network capacity along a path, repeating that establishes a connection. Only then can A start sending data. After message end, you send a ""teardown circuit message
                - The **4** steps of** circuit switching **are ↓ 
                    - A node sends a reservation request - desiring to communicate with another node 
                    - Interior switches establish a connection, i.e. a circuit 
                    - The node sends the data
                    - The node sends a "teardown circuit" message 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2hk3X2advrBVh0hfQHDmLgoKDaCO0sNeDaQMcfN4A4UCMiZ4tn72g3oNtM54K3BiQyUS5Kcdtwv3hdOxZlmqeoH4JjEFPU1u2AFIRc_UuI_KqfEx_iMPrtokeZ58CCm_.png) 
                - What are the main 4 problems of Circuit switching? ↓ 
                    - **Set up time is slow** - may need to reserve dozens of connections. Get worse the fewer the connection lines. 
                    - **Failure prone, **could be dozens of machines you're relying on to work.
                    - **Slow recovery from failure, **as they don't route around failure.
                    - **Waste bandwidth if traffic is bursty **(intermittent),** **as no other switches can use the line during that period.  
                - What are the **pro's **of **circuit switching**?―Garuanteed performance & fast circuit after establishment 
                - **Circuit switching Pros and Cons**   ↓ 
                    - Pros: 
        Garuanteed performance & fast circuit after establishment
                    - Cons: 
           Waste bandwidth if traffic is bursty. **Connection establishment is overhead.** For each connection we **rely upon many machines being reliable! **Recovery from failure **is slow - **Generally circuit switching doesn't "route around failure". 
            - **Multiplexing**
                - What is the foundational idea behind multiplexing?―**Sharing **makes things **more efficient** and **cost less**. Having **many telephone wires** along the same route is more efficient and the cost is less than having individual poles for each line. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Y6Y848Wq2KCORgadL4hP7heIUbFkx8LhtlKUcGSnCyGyTl1ybB5ztuQcKZ-R6djOClrZZxwg109FqfpMAh51P1bVKT4ZrkancHbzoZBgzRphVxaWZ0oPugwAg8FpTe7W.png) 
                - Sharing makes things more efficient and cost less, 
                - Old time multiplexing, many wires along the same route, pole/wire is being multiplexed. No other way to give people a wire per telephone.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Y6Y848Wq2KCORgadL4hP7heIUbFkx8LhtlKUcGSnCyGyTl1ybB5ztuQcKZ-R6djOClrZZxwg109FqfpMAh51P1bVKT4ZrkancHbzoZBgzRphVxaWZ0oPugwAg8FpTe7W.png) 
            - **Circuit switching: FDM and TDM**  x
                - **Frequency division multiplexing**. Consider tv stations broadcasting to different frequency bands. People are given pieces of the available channel - decreases the maximum amount of data sent, but data can be sent simultaneously.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UKj4XaR01npEZh8o4zx_jybJ2x5BWoxiscC3R0VPFgJJoraeHyek-eL9XI4I4KstK-AG8aTW2-HfbbBFdQSm2smNFvPCSZu5V6LWHo4oqSzkW5A9FYCaSUEJVeLhnJ7m.png) 
                - **Time division Multiplexing. **People can take up the whole capacity, but for a certain timeslot (consider a lecture theatre). Radio used to be News⇒Sports⇒Weather⇒Local⇒News⇒...
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Cowjx_Xu9MV8BraHdFpcfbf9tfZ3z5-N-E5BV_uvalnEw103LUWplG2zDPFHCB170m-xQr3ga73FRPNK0QL2UszFpZx4PYtuNps8jEJJIkJJv3uM8Y0Tc9bbEDiCLBIr.png) 
                - **How is time division Multiplexing achieved**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QYstAMPLEKh6uKL2EJKgfd0DvlDCrn96VlcMwx9iU0Itp5792CFlrBg3XKZ0fpZGgUoHuXP_ebXzLl7fxOa9obssTkKyfBtzlZVWfpXLwceNkpi0VEetx7-KRVTlUEPW.png) 
                    - Six simultaneouos slots, where frams are loaded onto (Think how crosstalk could occur if data wasn't lined up right). **NOT FRAMES LIKE YOUR THINKING** 
                    - Relative slot position inside a fram determines which conversation each bit of data goes to. Slots are reserved during circuit setup and teardown occurs afterwards. Capacity will be taken up even if no data sent.
                - **Timing in circuit switching**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6kEPJfPobG6ODpKponTQCDZ76L62k-AYmizKiSAIkOHuOLKAZ5rpB-g8Bf8d1qDoq4WtDUwM5lBXJ5QNWECzdOLvzsXFWl1eQWrDPFQLvpHbozaf9VeT_lZssx9pCDhn.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b5PoGvWPGCw1PF5HNmnpU_rEVBPLoGz-lC1AFMeIg8E6jYXOa1Xnbe3XMhPUumTA_y_ldpuI4GkC6fommFUnkmec4TkGFJe3oTgQXgRMSYphgsxEYBKGItOI2zkHJQqU.png) 
                - If I have a **640,000 **bit file, sent over a circuit switched network. Where **links are 1.536 Mbps, **Each link uses **TDM with 24 slots/sec. **And it takes **500 msec to establish an end-to-end circuit.**―$$0.5 + \frac{0.64 \cdot 24}{1.536} = 10.5$$  
            - **Packet switching**
                - Data sent as chunks of formatted bits (Packets). 
                - Packets consist of a {{**header **}}and a {{**payload**}}. Headers as an API describing things like {{destination address}}, {{length of packet}} etc.etc.etc.
                - Switches forward the packet to other switches or to the destination. Need a forwarding table to know where to send it. **Each switch operates independently.**
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yGX72IaZwju2Ai-Odsn2TA499Zk1sas8UMBv_PIM1kz96Obi7rkD7UC1wG5NUpYiXNMJAUupWBin0Y7TJlVC5tcBC8oJpJOaThPJ-Xsk7O36vpZf3BzIeyMKvTZG1ZKb.png) 
                - Each packet travels independently, **no concept of a circuit.** 
                - No link resources are reserved in advance. This Packet switching leverages statistical multiplexing, and the result is we can have repeated/reordered messages. 
                - **Timing in Packet switching**
                    - This method of waiting for the entire packet before delivering is called "Store and forward"
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7SD0WybrxjxXWruZ201la_zA3f4u6RrSKG2OSjHuFtWbmGjLMbmQIoa21cWRVG2_ldYBubPVQ6PJIHSfK6AtNfOdvUelI9kcx3mSEVdZ6BGYwNhMCuq_3IUzH_d0ePob.png) 
                    - We can even start transmitting as soon as we've processed the header - using a cut-through switch:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jUdN2RNWsMfZLz1Ah_lHLpTXGzsb68Zje_mkmLhs97N3KHV3khQrAzMe_tEai8WDkTwk7NFD0lNviQfhDTsjPp8sDvT9s__tlxwUWun-FlF9es5iLmYRULyo7lULa9NL.png) 
                - **Flows sharing total capacity**
                    - Statistical multiplexing relies on―the assumption that not all flows burst at the same time. Very similar to insurance (literal insurance, if an earthquake occurs everyone who had earthquake insurance needs to be paid), and has the same failure case..
                    - Get diagrams form ppt 
                - **Statistical multiplexing: pipe view**
                    - **Queue does not increase capacity - adds time!**
                    - Works fine if messages aren't simultaneous. However in the case of transient overload we must do the following:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dKFgFY-J1msyqWUJv456QmQUEAHUPPS-5zO4JcuRCbS76Y_Yn4Y8mmNis3xMRLKOLbFzoVaE4W9CRPMg5m_tz-MBqqpnbtWzfrHgrk6DVdbI6ZF23JrOaBe28yx9WAHI.png)
Queue will cause some delay.  
                    - However, if there is more input than our output capacity we'll eventually drop packets:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2BhAKrrdOo6JdBTvh5AotbXXN0uloZjqShw6W6z-kSSb_fqM0sCw9BIpMbyUQM0eEwtL_4JaRT1tIcWXUQZb4feH9-Xyp3cEkb5Govt092vsFYqGm8geQVLj1r6_UKIG.png) 
                    - **Queuing Delay**
                        - packet delay = transmission delay + propagation delay + **queuing delay** 
                        - Caused by packet interference
                        - Made worse at high load - no idle time where the queue would have drained out. Traffic jams at rush hour.
    - **Lecture 3** 
        - **Multiplexing** **Disadvantages** 
            - Might have to **wait** 
            - Might **not know how long** you have to wait 
            - Might **never get served** 
        - Multiplexing is the action of sharing of common resources. 
        - **Queuing Delay Extremes**
            - $$\text{Traffic Intensity} = \frac{\text{Average Packets} \times \text{packet length}}{\text{Link Bandwidth}}$$ 
            - Describe the three cases of traffic intensity and their effect on the queue and the delay ↓ 
                - Traffic Intensity $\approx$ 0. Queue is empty and the average delay is low
                - Traffic Intensity $\approx$ 1. Queue contains some items and the delay becomes large 
                - Traffic Intensity > 1. Queue is always full, average delay infinite - or data is dropped.
            - We need idle times for the queue to drain. Queue supposed to be during panic times.
            - A large reason for delay when sending a message is not because the line isn't straight, or because fibre optics travel at ~2/3 the speed of light. It's because all routers inbetween have queues that add delay
        - **Internet structure: Network of networks** 
            - Packet passing through many networks!
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/P_BPuCNYkMCi_mR4m9fZqqUstd6x9GdmhavxKZ21TzbC951rorQ0J_uUnldimaX_WjrAoJI9EbKj4CmB56GCM6xXJQlpPGvn4CsmKIRVK78YRr4MxChVJAw-PaBqIvPo.png) 
            - Tier 1 ISPs:
                - Have a complete knowledge of where everything is, if they don't know how to get somewhere you don't get there.
                - They exchange traffic with each other via Peering links.
                - Most extensive operations team, most expensive routing kit. 
            - Tier 2 ISPs:
                - Pay for the privilege to access tier 1 ISPs
                - Can have peering links to other Tier 2 ISPs
            - Tier 3 ISPs:
                - Similar - pay for privilege to access tier 2 ISPs
            - Local ISPs - last stage
            - **Internet exchange points** **(****IXPs)** 
                - Allow everyone to connect to everyone else 
                - Companies that aren't tier 1 ISPs like this - means they don't have to pay tier 1 ISPs to access their service.
            - What happens if an ISP tells Netflix to pay them, otherwise they won't route their service to you? Netflix will pay 
            - **POP - **point of presence is a connection point of a network. That could be between ISP and users, ISPs and other ISPs, users and other users etc. Particularly large ones are from ISPs to other ISPs.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9zJ4OJK892aZif6rH7L_gtrdKaU8Jx4jpD7mX_oNhrDrsJPSFvYN84mI6E0Xi7m8IC52nuoyzETfH-Gg0Zq25o37l3cOWX2P7tP56GIFJapNGsbr_gsQsdSeqq4BvpbY.png) 
        - **Packet switching vs circuit switching**
            - Packet switching may (does!) allow more users to use network
            - If we have a 1Mb/s link and each user uses 100kb/s when active, **and they're active 10% of the time. ** 
                - With circuit switching, we can have 10 users 
                - With packet switching and 35 users, the probability that >10 are active at the same time is less than 0.0004$$1- \sum_{n=0}^{10}{{n \choose {35}} (0.1^n)(0.9)^{35-n}}$$ 
                - However, under the binomial assumptions - these assumptions may not be valid. 
        - **Packet switching Pros and cons**
            - Cons:
                - No garuanteed performance 
                - Header overhead per packet
                - Queues and queueing delays
            - Pros
                - Efficient use of bandwidth (stat mux)
                - No connection setup overhead
                - Resilient (can route around trouble) 
        - 
        - 
    - **Lecture 4**  
        - **Abstraction concept**  
            - Breaking down a problem.
            - What not how - 
                - Specification vs implementation
                - Modules in programs
            - Vertical vs Horizontal
                - "Vertical" what happens in a box - "how does it attach to the network". Vertical monopolies: Consider Texas Instruments DSP processing chips.
                - "Horizontal" the communications paths running through the system. 
            - Partition systems into modules & abstractions
                - Well defined interfaces give flexibility! **Hides implementation. Extend functionality of system by adding new modules.** 
                - E.g. libraries encapsulating set of functionality
                - E.g. programming language + compiler abstracts away how particular CPU works 
            - Well-defined interfaces hide information
                - Isolate assumptions??? What this mean!
                - Present high-level abstractions
                - However not showing your code - **can impair performance. **Missing knowledge etc. 
                - Ease of implementation vs worse  performance  
            - Implementation is distributed across many machines (routers and hosts)
            - You must decide:
                - Layering : How to break systems into modules 
                - End-to-End Principle : Where modules are implemented 
                - Fate-sharing : Where state is stored (connection oriented network, if a node fails inbetween we lose our connection).
        - **Layering Concept**
            - System functions divided into layers built upon each other.
        - **Layers and Communication**
            - Interaction **only between adjacent layers** 
            - layer n uses services from layer n-1, and provides services to n+1
            - Botto mlayer is physical media.
            - **Top layer is application.**
        - **Entities and Peers**
            - Entity is a thing...
            - Entities interact with the layers above and below.
            - Entities communicate with peer
            - 
            - Entities usually do something useful:
                - Encryption - Error Correction - reliable delivery
                - Can do nothing at all
            - Not 
        - **Layering and Embedding**
            - Higher layer information embedded within lower layer info - consider repeatedly wrapping/boxing up :![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XP9YQ0M5kcFGCxEtez0evlz8d1-jW_B_IUjtAWl5v9CLLP_-Y_jKwXRON-3cww6kd_uuKJpa0iliSytt_zfDOpgXNC_WFKqiKwPW7crFRTQStVttlNLWMx9Yron_NC5x.png) 
            - **Embedding is not the only form of layering** 
            - Encapsulation 
        - **IP stack vs OSI stack**  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HrftcK6my4vZZPgZkHTAItcbef7Q_nfPeEJ-qez1xJ0uxhC9K-H0rqR6o58WtZYkmsYXEWyfszQUjpELMG0fgkPDbNv801uaWIdY7i0zIcaUwl3WySaFIO_l6yzUR9aJ.png) 
            - OSI had extra layers that were left to software - next slide 
            - Can have repeated layers
        - **So many Standards Problem** 
            - Many different packet switching networks with **their own protocols **(system for organizing communication - e.g. English language protocol) only nodes on the **same network can communicate.** 
            - The solution is adding **Gateways **between networks:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tZGlX-KY2tNvLPa653K5c78LYl_GtphzGCBikJSaVcWq6fGIyWKG7tpqAe8Y9BPgfo5KDcAAwaPuGXyyjPuiJ_8dkRH8ImFawwYdRAMcY0K0TjSpPJR4pPtyYJxaZvcp.png) 
        - **Internet Design Goals - **retrospective, made after internet was going
            - Connect existing networks 
            - Robust in face of failures
            - Support multiple types of delivery services
            - Accommodate a variety of networks
            - Allow distributed management (I'll look after my stuff - you look after yours)
            - Easy host attachment (Want to make it easy for people to join a network)
            - Cost effective
            - Allow resource accountability (contradicts distributed management - also do we deserve resource accountability? We aren't paying the people who's switches we're using)
        - **Multitude of Apps Problem**
            - We don't want to write code for our app, for every different communication medium - e.g. Coaxial Fiber optic etc. 
            - Solution: Add an intermediate layer that we write the code to talk to. The intermediate layer then speaks to everything else.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oyuNaGmMChbuko44ZmoOxF1LFVqQrFFwNXdbAEHEvCxL50sIijqYA0KwzRZgxzXL7IBO1D0EfTtsRVtaGenQ5wJFJ63Bxip1n2CClJgbp_nIlaM4iNzuWyST_WZzFUw8.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Kq6eyK7F-WPoCFxckOGexwl295R2fuowNMZDKxpkglLTeeP4BI08Nw9nA9q4Q5OyceqC5MUiZxzVEhYm5hitPgknoC9AjNX9MfUrspKc29zIDBJe2IHHjIfniWIiW-WO.png) 
        - 
    - **Lecture 5**
        - **Why use vertical stacks?**
            - Make it very efficient
            - Own internet property
            - Own the system
        - **Layering crucial to Internets success**
            - Layering is―the separation of a task into many separate functional components that communicate in a hierarchical manner.  
            - **Layering allows **for  ↓ 
                - **Reuse **of code - whatever application is being run, the code to communicate to ethernet doesn't need to change
                - Hiding **unnecessarily details** 
                - **Innovations **at each level can **proceed in parallel** and be pursued by **different communities.** 
            - What are the **drawbacks of layering? ** ↓ 
                - Can have **duplication of functionality** - e.g. error recovery to retransmit lost data
                - **Information hiding** can **hurt performance, **- e.g. we don't know if we have packet loss due to corruption vs congestion (info not stored in IP)
                - **Headers start to get really big** - e.g. TCP+IP+Ethernet is ~54 bytes
                - Layer violations still occur when the gains too great to resist - e.g. wireless peering into data they shouldn't see **or **when the network doesn't trust ends - e.g. firewalls examine packets 
                - Layer violations when network doesn't trust ends - e.g. firewalls, need to examine the packet
                - Layer N may duplicate lower layer functionality - e.g. error recovery to retansmit lost data
            - Persued by different communities 
        - **End-to-End Principle** 
            - Some application requirements can only be correctly implemented end-to-end - no other elements should access the data. - reliability, security...
                - Implementing these in the network is hard - every component must be fail proof 
            - Hosts
                - Cant rely on networks help, so must be able to satisfy requirements
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Pm4jhvVZqAgYWYdTvep-otuqAdgLnKtRJA5GfTLIJYU068rsmWWIho_0zaVxUMM5fNOoXCaciWNZ9ksSTNWNu_NCvyxcZ13VycOq2A_HRqMwxhm7zTuFltOT11SgXqGC.png) 
            - Solution 2: end-to-end **check if the sending worked, **and retry if it didn't 
            - Solution 1 is incomplete
                - What if any network element fails? You need to do the check anyway!
            - Solution 2 is ... 
            - • Implementing functionality (e.g., reliability) in the network  – Doesn’t reduce host implementation complexity  – Does increase network complexity  – Probably increases delay and overhead on all applications even  if they don’t need the functionality (e.g. VoIP) • However, implementing in the network can improve  performance in some cases  – e.g., consider a very lossy link  
            - Only if Sufficient Interpretation
                - Dont implement a function at the lower levels, unless it can be completely implemented at this level
                - Unless you can relive the burden from hosts, don't bother -
            - Only if Necessary Interpretation
                - Dont implement anything in the network, that can be implemented correctly by the hosts
                - Make network layer albolutely minimal
                    - improves performance
                    - lower layers more flexibl
            - Only if Useful interpretation
                - If hosts can implement functionality  correctly, implement it in a lower layer only as a performance enhancement • 
                - But do so only if it does not impose burden on applications that do not require that  functionality  
            - Distributing Layers across network
                - 
            - What gets implemented on a host 
            - 
            - What gets implemented on a host
                - Physical layer  - 
                - Datalink layer 
                - Network layer
                - Transport layer NOT SUPPORTED
            - What gets implemented on a switch:
                - Same, but no Network layer - just local delivery. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vjr4ZaxAgWVNqv2GfEGdv49-r23QR5WyeZhUMwEZqsmi-bLF_EIZPvrvdPlQBZr8Bchhu-YRRVNeN_uRfcJqA35cfdBYLWuFZK3Qx7mDtYBt_7BxraRO3I7B4TQ2oM4a.png) 
            - IPV4 and IPV6 not directly compatible
        - **Alternative to Standardization?**
            - Have one implementation used by everyone
            - Open source projects -
            - Or sole-sourced implementation, only their code will work with their own
        - 
        - Skype, FaceTime, Signal ETC OK ETC EtC CETC ETC etc C!!ETC 
        - **The physical layer**
            - The copper glass or wifi - Comes with the fundamental limits, that of light. Coaxial cables and twisted pair cables are bidirectional - as opposed to fiber optics.
            - Capacity, delay, fidelity (signal to noise ratio) all limits provided by physical layer
            - Bandwidth is BETWEEN to things, e.g. 1.0 and 1.1 MHz = Bandwidth of 100 KHz
            - Some frequencies area **supported **by media better than others, for example the atmosphere doesn't support the transmission of infrared light well - it get's absorbed.
            - **Radio physical media**: 
                - Bidirectional and multiple access.
                - Propagation environment effects like reflection, interference and obstruction by objects.
            - Fidelity is the **signal to noise ratio.** 
            - **Analog meets Digita****l** 
                - Need to make transform between analogue and digital world. As the **world is analogue.** 
                - Infinity of frequencies to form a square wave. 
    - **Lecture 6**
        - **Analog meet Digital**  
            - Square waves have high frequency components, resulting in random super peaks as below: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Df2mRJBJKr-Esgexa-4bOE-JzqC9WnT9t8wFHJCV_AFoEuMuusiHFNJIBy2uh6YFiyG1Qzo5clVKADknt0nxwk2Kje9NURYrFyGHd4IVZGsoVHFWa5vFaT7jNu6a9vUi.png) 
            - $$\text{Received Signal} \approx \text{transmitted signal + noise}$$ 
            - Noise can be systematic or random - e.g. systematic noise from equipment or random noise from thermal vibration. 
            - Noise increases in distance, so larger systems can be less reliable.
        - Bandwidth vs Signal to Noise 
            - What's better: High bandwidth or low signal to noise ratio?
            - Information capacity is measured in bits per second, of a channel. $\frac{S}{N}$ is the signal to noise ratio.
            - $$C = B \log_2(1+\frac{S}{N})$$ 
            - Channels with no noise have infinite information capacity. Channels with a Signal to Noise ratio of 1 have information capacity in bits per second, equal to the bandwidth in hertz.
        - **Digital channels**
            - **Symbols **are the voltage levels on the wire, 5V 0V may map to bits. 
            - Baud rate is―the rate that symbols can be transmitted. I.e. the number of times we can change between different voltage levels in a second.  
I.e. The number of indivisible units of information sent per second.
            - Why are bit rate and baud rate different?―Our bit rate can be higher than our baud rate if we have multiple voltage levels to represent more than 1 bit. E.g. if we have:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j38PlNezW40gwwE00P_6yI5Ci6OgGUXH2l-o-wcSF01RKLjilt-2J-_9Z46sFEHl3ecnjhlhR07XyQProaa0_ing3an2T6XOVW4tKvN-dJzfctCvisgQ0pD_KIoFzhEk.png) 
The bit rate has doubled as we can now send 2 bits per second, but the baud rate remains the same.
        - **Modulation**
            - What is modulation?―Transforming an information signal into one more appropriate for transmission on a physical channel. Could be converting data to light in a fibre-optic cable.
            - Can have conversion errors in both directions, noise leads to incorrect digitization and insufficinect digitization leads to information loss.
        - **Bit boundaries** 
            - Where and when are the bits? Need to know what the boundaries are
            - **Synchronous**
                - Shared clock - bit transitions inform clock?
                - Transmission is continuous
                - Receiver continually adjusts its frequency 
            - **Asynchronous** 
                - Transmission sporadic, divided into frames
                - Receiver and transmitter have oscillators who are close in frequency - producing tx clock and rx clock (transmittor and receiver).
                - Receiver first synchronises its clock by examining 1+ bit transitions
                - Receiver clock drifts, but only a fraction of the time over the course of the frame 
                - Transmission time limited by accuracy of oscillators
        - **Coding**
            - Changing the representation of data so it can be sent on the physical layer 
            - Might have system where 1 = transition and 0 = no transition. Or if we flip the output whenever we write a 1 ⇒ 011001001 becomes 010001110
            - **Manchester encoding**
                - If our clock is greater than our data rate, we can align our data on the clock pulses. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/H-luNVF1rwYTgUgTZCwfjXFlVx9UwUCTmy45Bas1mPByf-hCB3lPgEA9o92ym2jQas0PFuKMAaE65vYZQSsNr-kGUEt2RZcOm4k8cganpIN1w4mERO173Mtyy5bqDklc.png) 
                - Change our representation of 0 to the transition from 5v to 0v, and vice versa. Means we don't need the clock as we can just examine the transitions. Removes long periods of 1 or 0s
            - **Quad level code**
                - Have 4 discrete levels (0v, 1v, 2v,3v) to represent sets of binary numbers We can pack more data in but the sender and receiver have to be more sophisticated
            - **Line coding**
                - If the clock rate is greater than the data rate (5 to 4 in this case) have strings of 5 bits that decode to strings of 4 bits. Has an overhead, but is easy to decode with a lookup table.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KFX4U0jK6toNq9vRLBPfnwvxxGpZuj9GYiPzb0cydJFHeyX6MQk8nLvEcq0o0HrRZweHCJayQSuwlHyYHUJ795OtS4_WicckWFMZfNDaaA0rvlceNnqvY-06IIWvUzUu.png) 
            - **Line coding scrambling**
                - Generate a random sequence and distribute it securely to the receiving end - then take your message XOR the sequence and send it on the wire, doing the same on the other end will result in the original message.
                - Assure you a lot of transitions.
                - No overheads
                - **Self synchronizing** 
                    - Takes the previous n digits and uses them as the scrambling pad.
                    - Downside - startup cost need to wait for the first n bits.
                - **Hybrid coder**
                    - Adds 01s as our scrambler could result in long strings of 0s /1s probablistically.
                    - Mark start of frames using a "01" string, know it occurs every 6.4ns so know to look for it. Means we can always extract the frame reliably
            - **Multiple Access Mechanisms**
                - Many people can use a shared channel, so needs to be divided - Freq Division Mult or Time Division Mult and code division multiplexing -** note these can all be combined and used at once** 
                - **Code division multiplexing** (CDMA)
                    - Apply different codes to a signal and get different outputs. Unique code assigned to each user
                    - All users share the channel, but user has own sequence (chipping sequence) to encode data
                    - Encoded signal = (original data) XOR (chipping sequence)
                    - decoding - apply xor again
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WCEyWZ0iogtJbVTjsRoZzK10jiQka6ALN05NF8ENmOIB7AwwGuftUtEWfBg2E9s--Qv2TVjwGsJIPnU3W1ZZtKwQ_t-gL230j58JrDxNrXcYTAXkYnOwvNI9qFx5lT1b.png) 
            - **Error detection and correction**
                - Problems of transmission: 
                    - Attenuation: loss of energy
                    - Distortion: signal changes shape/form - caused in composite signals
                    - Noise - thermal noise, induced noise, cross talk, impulse noise
                - **Basic idea**
                    - Add additional redundant information to a message, so we can detect the error
                - Error detection code: **Parity** 
                    - Add one bit so that **there are an even number of 1s** 
                    - Cannot detect even number of errors
                - **Error detection code** 
                    - Generate a "checkbit" and send with data, other end can also generate and checks if theyre equivalent
        - 
    - **Lecture 7**
        - **Error Detection Code : CRC (Cyclic redundancy check)**
            - Sequence of redundant bits added to the end of data.
            - CRC = data MOD divisor
            - Check if the data mod divisor equals this set of redundant bits. Easy to build in hardware!
            - More powerful than parity, can detect various kinds of errors - including 2 bit errors
            - Choosing a good divisor is crucial
            - He says you can add the rem on the end and the entier mod will be 0
        - **Forward Error Correction (FEC)**
            - What if errors occur in the same way each time
            - Replace erroneous data by its "closest" error-free data - E.G. Send copies and majority vote
        - **Detection vs Correction** 
            - Detection uses less check bits - but need to resend
            - Correction uses more check bits - dont need to resend
            - Both can be used together
        - 
        - Data Link Layer 
            - Data-link layer has responsibility for sending data from one node to another over a link.
            - **Channel services** 
                - Encapsulate datagram into frame, adding header and trailer - MAC addresses used to frame headers
                - **Reliable delivery between adjacent nodes** 
            - **Where is the Link layer implemented?**
                - In every host - implemented in the network interface card. Attaches into host systems buses - combination of hardware, software and firmware
            - **Multiple access links and protocols**
                - Point-to-point vs Broadcast. 
                - Need to handle interference in broadcast - collisions can occur if a node receives two or more signals at the same time.
                - **Multiple access protocols **determine when nodes can transmit over a shared channel. Communication about channel sharing must use the channel!
            - **Multiple access control (MAC) protocols**
                - Three main types:
                    - Take turns - nodes take turns, but nodes with more to send get longer turns
                    - Random access
                    - Channel partitioning
                - **Taking Turns**
                    - Polling 
                        - Primary nodes invites other nodes to transmit in turns
                        - Need to decide on primary 
                        - Concerns: Polling overhead, latency, **single point of failure** 
                    - Token Passing
                        - Control token passed around sequentially
                        - Can only send when you have the token
                    - ATM (asynchronous transfer mode)
                        - Sender transmits labeled cells whenever necessary
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DOymKJFTYZNPgN8UnU-i0ABVrZ_NNrdWBTFIPD0ULvHfejeipIRDWnTmlgQeRfhkwbjqcGu_adFtAZqxh_Siugi3xVdDJpZfC5ewS2NyQfgdmM8FVaRS9XXZH2Oq-fCk.png) 
                - **Random access**
                    - No communication needed
                    - Collisions and data loss can occur
                    - Specifies how to detect and recover from collisions 
                    - **Carrier Sense** 
                        - Listen before speaking and dont interrupt
                        - Check if other nodes are using the channel
                    - **Collision detection**
                        - If someone starts talking at the same time, stop
                        - Detect by seeing the data on the wire is garbled
                    - **Randomness**
                        - Don't start talking again right away - Wait a random amount of time
            - **CSMA (Carrier Sense Multiple Access)**
                - Listen before transmitting - if idle transmit entire frame, otherwise defer transmission
                - Doesn't eliminate all collisions due to propagation delay.
        - 
        - 
    - 
    - **Supervision 1** 
        - Revision: How does a network distributed system compare to one running solely on one cpu?
Network distributed systems are more complicated to design around as you can make less assumptions. For example, it's far rarer for a CPU core to fail, than for a single server in a massive server farm to go offline.
Thus you must consider such failure states and build to "route-around-failure", through redundancy or protocols allowing continued communications despite losing nodes.
Additionally, network distributed systems face far greater latency between nodes than CPUs do with memory and with a lower bandwidth.
Furthermore, you cannot guarantee that nodes will not disobey the protocol defined for communication (or act in a byzantine manner) while we can generally assume the RAM will not be trying to trick the CPU.
        - **Define The following:**
            - Node - A node is a single actor in the network, who is connected to other such nodes through links. Nodes can communicate with other nodes using links, but can crash (permanently or temporarily).
            - Link - A connection between nodes in a network. Considered only partially reliable, can fail.
            - Router―Routers are devices that send and receive data on a computer network, they do this by examining the packets they receive (specifically the Physical , Datalink and network layers are required for examination) and sending the packet to either another router or to the destination computer (routing tables are used to decide where to send each packet).
            - Bandwidth - bandwidth is the maximum amount of data that can be sent across a link (by a given node) in a second. This could be due to a limitation of the link (e.g. copper wires have a lower bandwidth than fibre optics) or the node (i.e. one node can have a faster network card than another). ^^Can also refer to the frequency bandwidth^^ 
            - Bursty-ness - Periods of very high network activity, means network is bursty. ^^Kettles at half time^^ 
            - Latency - latency is the time between the sending of a signal and it's arrival. ^^The time taken to do something.^^ 
            - Jitter―Jitter is the variation in latency. A network with high jitter may have some messages that are sent in milliseconds and some that take up to a second. This is usually due to high network traffic resulting in congestion as buffers are populated. 
            - Buffer - A buffer is a list like structure where incoming messages can be stored while waiting for the network to be free enough such that the buffer can be drained and the messages sent. It is usually only used in times of great signal load.
            - Protocol - A protocol is a set of rules governing communication over a network. For example, the English language protocol has grammatical and syntactical rules about how the English language can be used for communication via sound, text, etc.
            - Multiplexing―multiplexing is the action of sharing a certain resource between multiple users. Wherein different users are granted access to a resource at different time.
            - Federated system―a federated system is formed when a group of distinct compute or network providers decide on a united set of rules and guidelines to follow. For example ISPs agree on a set of guidelines for internet data. ^^Allows you to get more users - bad if you want to change the protocol, need to get everyone to change. Protects against bad actors.^^ 
            - Horizontal abstraction - considers the breadth of the problem, i.e. the communications paths running between many complex individual systems. ^^Not 100% sure on this^^ 
            - Vertical abstraction - Considers a single piece of the system with high complexity. E.g. how exactly a component attaches to the network. ^^Not 100% sure on this^^ 
            - Layering in protocol design - layering protocols means multiple protocols are in effect at once, allowing the use of multiple different mediums at the cost of increased space taken up by headers.
            - Bursty-ness - A system is bursty if it has lots of periods of very high activity/network traffic, contrasted with periods of lower activity. ^^During half time lots of kettles get turned on^^ 
        - **What is multiplexing? Define and give a non-networking (non-lecture) example of:**
            - Multiplexing is the practise of sharing a connection for increased efficiency. Rather than having thousands of telephone wires from every persons home to all their friends, we form a network which everyone uses for discrete slices to time.
            - Time division multiplexing - time division multiplexing is a system in which users gets a set amount of time (a slot within a frame) in which to use a given resource. For example in a network, we might arrange packets from specific users as slots into frames. The receiving end of this data-stream must know the order of slots within the frame to route the correct messages to the correct destinations. An example of time division multiplexing is when as a child you are told you are only allowed to use a toy for given (miserly) number of hours, after which time you must turn over the toy to your sibling. Even if that sibling fails to appreciate that toy during their allotted time.
            - Frequency division multiplexing (hint: use something analogous to frequency) - frequency division multiplexing is where a resource is divided into frequencies, which individual users are given access to. Thus dividing up the resource and allowing for shared usage. An example would be in a jazz band, if a guitar player is soloing over a bass backing track they are encouraged to inhabit the higher frequencies (notes) - as any lower frequency playing will be inaudible over the sound of the bass.
            - Statistical multiplexing―statistical multiplexing is where users can use a resource at any time, under the assumption that the probability of many users (more than the system is capable of handling ) accessing the resource at the same time is so low that it will not cause a problem in the average case. For example, gym booking slots in a University assume that because there are many hours throughout the day for users to book - the gym won't be overrun at a specific hour (neglecting to consider the two main camps are morning and night users). ^^Not good when you have coordination. Good because you don't need complex organization. Demand for internet spread out in time and space.^^ 
        - Outline how to implement time division multiplexing?―One way is to divide time into frames and assert a certain number of frames per second, then those frames are divided into slots. Users are then given slots in which they have sole ownership of the resource (this can be a permanent time slot, or the time slots may be temporarily allocated to users with a Queue storing waiting requests for timeslots.). The code of which slot corresponding to which user (and how the frames are organised) must be understood by all parties (including parties receiving a message using time division multiplexing) in order for the system to work. 
        - Why can't we just connect every computer to every other?
Because the result would be that every computer would have $n-1$ connections (where n is the total number of computers) and there would be $\frac{n}{2} (n+1)$ total connections on this network (~$1.35\times10^{31}$ according to estimates on internet connected computers). This would mean we would have to have a system allowing billions of connections to (even though a given computer only communicates with a tiny minority of these)  which would be impossible (too expensive to do for all billions of computers and likely there are not enough raw resources on Earth to accomplish the task) - even if each connection had a bandwidth of 1 bit. Additionally, monitoring all of these connections for waiting for a signal would take a huge amount of time.
            - How do we bypass this problem (big O estimation would be a good idea here :) )
We bypass this problem by using packet-switching, instead of connecting all computers - groups of computers connect to switches, which then connect to routers to share the internet network. The total number of connections decreases from $\frac{n}{2} (n+1)$, to the order of $n$ - each computer need only have a connection to a router which will communicate with the wider network. This system only works because computers only communicate with a small subset of the total computers in the network and not all the time, meaning the router doesn't work to capacity at all times and the wider network is not required to always work at full capacity.
        - What are the two types of described switching networks and what is the main unit of transfer in each?
Packet switched networks and Circuit switched networks.
Packet switched networks use statistical multiplexing and send discrete packets of data on the network that are routed by routers and resent if lost. The main Unit of transfer is packet.
Circuit switched networks first establish a complete connection through a network before transmitting data, then tear down that connection when communication is completed. The main unit of transfer is an entire message.
            - Give a use case where each is optimal 
Circuit switched networks are ideal when a connection needs to be very stable, but the time to establish the connection is not as important. For example a surgeons connection to their remote surgery robot.
Packet switched networks are ideal when you have many users communicating intermittently, with a few network bridges which cannot be locked up - for example if using a messaging platform, you don't want your message to have to wait for other people to stop sending messages before your message can be sent.
            - Give a use case where each is highly suboptimal 
Circuit switching is suboptimal when you have nodes likely to fail, as your teardown message cannot be sent and recovery from failure can take a long time.
Packet switching is suboptimal when a secure connection with guaranteed low jitter is required - as packets can be lost/ routed different ways/ delayed by queueing.
        - Why would a p2p file sharing protocol like bittorrent not work well in a circuit switching network? (Hint think about the costs involved in each network flow and how long each flow exists for)
Bittorrent works by sending small packets of data between "seeders" depending on the data the "leeches" require - this means leeches receive small pieces of data from many different seeders. In a circuit switched system, the overhead of creating a connection to each of these seeders (only to send a small amount of data) would be too high for the system to be viable.
        - Discuss the Internet networking stack
            - What is it - The internet networking stack is a way of dividing up the stages of internet networking to provide abstractions. This means that not every app need implement the code to communicate over different types of mediums, instead the code is written to interface to the application layer and the message filters down through the layers.
            - Why does this make it simpler to build each part of the system?
Unnecessary details unrelated to the target domain is hidden. Also systems implemented elsewhere can be reused. Also innovation at each level can proceed in parallel, meaning interfacing with these other improved levels becomes easier.
        - Why when transporting a box of diy electronic parts from China to the UK is it likely that it makes most of the journey inside a ISO container?
ISO containers are a form of multiplexing, where many different packages share space to reduce the cost of transporting items on a tanker - this way the cost of operating the tanker is shared. The bulk of the journey from China to the UK is the shipping over water, meaning most of the time is spent in an ISO.
            - Does a similar reason apply to why IP is used as a common transport layer in networking?
You could draw the parallel that packets spend most of their time in transit in WAN's rather than LAN's, as there is much less distance to travel in a LAN than in a WAN. Thus the IP transport layer (which transports over WANs, i.e. using the network layer) is the most common transport layer.
            - Can you imagine a scenario where IP would not be a good fit? 
If most of your data was being sent locally (perhaps internet communication with between virtual machines) where the added headers would not be necessary.
        - Outline the internet :)
The internet is a large amount of LAN's, connected by routers. The connections are possible (and routed) due to ISPs, these ISPs contain the way to contact every computer (that you can reach) in routing tables. 
            - What kinds of organisations does a packet traverse travelling from Cambridge University to MIT?
Travels first through Cambridge's switch, to a router and then through an ISP to a MIT server within the UK. If it did connect with MIT it would likely travel through an undersea network connection.
            - Discuss the how traffic may differ within these organisations and if it may be possible to exploit that. 
MIT may expect more traffic than Cambridge, meaning Cambridge could be vulnerable to a DDOS attack if very large traffic was inflicted on it's servers.
        - What is the bandwidth delay product and why is it a useful measure for system design? 
The bandwidth delay product is the product of the bandwidth and the latency of a system. It tells you the amount of data in the "pipe" at any given time, and thus the maximum amount of data that can be sent without receiving an acknowledgement. This is useful as it helps describes the use cases for a given connection. ^^Not 100% sure^^ 
        - 
        - 
        - 
    - **Supervision 2**
        - 
        - Protocols 
            - Come from RFCs, they get comments and send it to the IETF after changes. The protocol is then formalised
            - How do they get standardized? When a good protocol starts being used, there is a desire from customers to be able to use the facilities of this new protocol and to be able to communicate with people using this protocol - this drives the generation of new technologies using this protocol (the protocol can even be hardwired into the board) and the usage becomes so widespread that switching protocol becomes almost impossible (especially for small performance boosts) as the web of people using such a new standard would be so small it would be useless.  
            - Layering
                - Downside of layering:―Headers start to get large as different layers add their own.
Information hiding results in some useful information being lost that we might want, e.g. we can't know if a packet was lost due to corruption or congestion. Performance overhead at each layer - results in performance drop.
Higher layers might replicate functionality of lower levels, i.e. error recovery.
The layering philosophy often gets violated anyway as certain layers might peek at data their not supposed to if the performance gain is large enough, or if the packet poses a security risk (firewalls)
                - What is a cross layer violation―This is when a layer accesses data it's not supposed to, this can be for a speedup or for greater security. For example in header compression the link layer accesses header data of a different layer to it, but the speedup gain is large enough that this goes unpunished.
            - What are end to end guarantees
End to end guarantees are guarantees about certain features of your communication over a network, e.g. max latency, privacy, reliability etc. These can be implemented multiple ways, we can have the network implement these guarantees - meaning every connection would have to ensure packets are reliably sent. Or we can push this responsibility to the user program, make them ensure reliability by checking if the message got through or sending multiple messages.
                - Why might multiple interpretations of this principle be negative?
It makes the term almost meaningless, as different people use it in almost opposite ways. Additionally it means people can back up their arguments using end-to-end guarantees as a term even if their definition is different to yours. 
        - 
        - Physical Layer
            - What is it?―The lowest layer, along which the data is physically sent (potentially) long distances over copper wires, fiber optic cables, radio waves and more!
            - What is analogue and digital
Digital signals are signals that alternate between a few discrete values - e.g. binary signals alternate between 0 and 1 (often represented by <0.8V and 0.8V < x < 2V).
Analogue signals do not have discrete options for values, and can be a continuous range of values over the real numbers.
                - How can we convert from one to the other? (don't go too deep on this)
We could convert from analogue to digital by taking samples (at a set frequency) and putting the value of the signal at that time as the closest digital value (e.g. 7.43 might be rounded to 7).
We could convert from digital to analogue using Fourier analysis, if we carry the data required (the combination of waves) in the digital signal.  
            - Define bandwidth in the context of analogue signals 
We could define bandwidth to be the highest frequency signal we can send across our link. As the higher the frequency the more information we can encode (while wavelength could simply be scaled up and down so higher wavelength doesn't necessarily imply more information being transferred).
NYQUIST LIMIT
            - What is noise in analogue signals, and where does it come from?―Noise is when an unwanted signal is superimposed on top of our desired signal, it can result in information in the original signal being masked and thus lost. It can come from interference along the wire (e.g. copper wires might face electrical interference from magnets or similar, radio waves might combine with other signals on the same frequency) or at either end.
            - ^^Dont really understand self scrambling signal - can we go through?^^  
$$y_n = x_n \oplus y_{n-3}$$
xor incoming signal (x_n) with a delayed 
            - What is a self clocking signal?―A self clocking signal is a signal that can be decoded without some other means of synchronizing the sender and the receiver (by sending the clock on another wire for example).
            - Define manchester coding―Manchester coding replaces the coding of low and high voltage for 0s and 1s with a transition. 1 is now represented as a transition from a low signal to a high signal, and vice versa for 0.  
^^NEED PREAMBLE - If we just get 010101... can't know clock period^^ 
                - Why is it useful?―This transition can always be detected, even if a stream of 0s or 1s is being sent - meaning we can always detect where the clock pulses are and where new signals are being sent. This is an example of a self-clocking signal.
            - What does interference look like for example on the signal: [1,-1,1,1,-1,-1,-1] and [-1,1,1,-1,1,-1,-1]:
[0.7,-1.2,1.1,0.3,-0.2,-0.1,-1.2] and [-1.4,0.1,1.6,-0.1,0.45,-1.41,-0.41]
            - How do we use Code Division Multiple Access to allow multiple signals to be transmitted on the same wire/airwaves―Each user is given a chipping sequence to apply to the data, when they apply their sequence they either get the original data or some garbled mess - depending on if the data was intended for them - if it was they can decode the signal using their chipping sequence, if not then decoding would require a different chipping sequence to access the coded data.
^^Think of this as taking the dot product of the combined signal with the two chipping sequences -  so you get the component along your chipping sequence "vector".^^ 
            - What is error detection
Error detection is a method testing for certain types of errors in a signal, upon detection the message can be resent.
                - Outline parity checks―Check if the message has an even number of 1s, if not then append a 1 otherwise append a zero. The receiver can then check if the entire message (including the appended value) has an even number of 1s - if not we have an error.
                - Outline CRC codes―We take the modulus of our data to be sent (modulo some number p) and append this remainder to the data. Then at the other end, we take the modulus again of the **data portion** (using the same p) and check if the computed remainder is the same as the appended value.
                - ^^I have some confusion about CRC where he says you can simply append the remainder and the entire remainder should then be zero - but wouldn't you have to add the value to get this result? Because you're multiplying the data by 2^(size of modulus) which could change the remainder.^^  This works apparently, dunno how ask Yash.
            - What is forward error correction?―A method of replacing erroneous data with the closest error free data, i.e. **guessing the minimum number of bit flips** that would make the data correct with your error detection protocol. This could be majority voting where each bit is sent 3 (an odd number in general) times and the majority bit is selected as the value. E.g. 011 ⇒ 111.
Can send 7 bits for every 3 and that's resilient to any 2 bits change. Then you should only have 8 possible incoming signals - check which signal it's closes to and take that.
            - AM vs FM - amplitude hard to change quickly, so FM encode data in frequencies. High frequency 1, low frequency = 0. **Noise doesn't affect the frequency, only the amplitude**. AM varies amplitude not frequency 
        - 
        - Data Link Layer
            - What is it?―The data link layer is in charge of reliably transmitting datagrams between two nodes over a link.
            - Define Broadcast links 
Broadcast links are links where multiple nodes receive the message and possibly rebroadcast or deliver the message to the application layer. You always send your message to all connected nodes. Single shared broadcast channel
            - Define Point to Point links
Point to point links are between two nodes, no other node accesses the data and you don't rely on rebroadcasting by other nodes.
            - What is a collision?
A collision is when the data from two nodes is received at the same time - interference can have occured.
            - Channel Partitioning
                - Discuss TDMA, FDMA―TDMA is done by partitioning the channel into frames, within which each node has a slot they can put their data into. This provides an upper bound on the capacity of the channel and helps eliminate collisions (if nodes obey the TDMA protocol in action)
FDMA is done by partitioning the channel into frequency bands, nodes are then given a frequency band that they can communicate on - as waves of different frequency have little to no interference this helps reduce garbled signals.
FDMA and TDMA can be used in tandem.
            - Taking turns
                - Discuss: Polling, Token rings―Polling is a method of reducing interference. A single node is elected the primary node, and that node invites other nodes (in order) to speak on the channel - other nodes wait until they're asked to speak before speaking. If the primary node fails, we need a method of detecting this and electing another leader otherwise no node can communicate.
Token rings work by having a token which is passed between nodes, nodes can only communicate on the channel when they have this token and nodes pass the token on once they've finished talking. This also has the problem of a single failure point.
            - Random Access
                - Discuss: CSMA, CSMA/CD―CSMA is a method of reducing interference. Before a node transmits data on a channel, it checks if another node is talking, If another node is talking then it waits a random amount of time before checking again - if the channel was quiet the node transmits its whole frame. Interference can still occur because there is a slight propagation delay.
CSMA/CD adds collision detection to the CSMA stack - we detect garbled communication due to collisions and stop transmitting to stop blocking others from using the channel. 
If you're receiving a garbled signal - then send a jamming signal to get them to randomly back off.
                - Discuss Random exponential backoff―Random exponential backoff defines the amount of time to wait after a collision, before trying to transmit your message again. After our mth collision we **randomly** choose k s.t : $$k \in \{2^0, 2^1, ..., 2^{m-1} \}$$
we then wait for the k * 512th packet to be sent before attempting to send our message again. If a node is broadcasting when we're set to send, wait for that broadcast to end before transmitting.
We need different seeds for pseudo random number generators to ensure our k is not the same every time between nodes!
            - Outline Ethernet―Ethernet uses a CSMA/CD protocol with exponential random backoff when a collision is detected. Collisions are easier to detect over ethernet than wireless signals (as wireless can't listen and broadcast at the same time) meaning less time is wasted during collisions.
Ethernet is easy to maintain, fast and inexpensive - it has also evolved and improved over time. 
            - Outline 802.11 AKA WiFi―Designed for limited area, Access Points are set to specific channel. Broadcast beacon messages with SSID (Service Set Identifier) and MAC Address periodically. Hosts scan all the channels to discover the AP’ s – Host associates with a AP
            - What is the problem with:
                - hidden terminals?―If two nodes can't detect each other, carrier sensing doesn't work and they will communicate at the same time - meaning any node that can detect both of them will have collisions and the messages will be garbled.
                - exposed terminals―Exposed terminals are terminals who wait for a given node to stop transmitting when they don't need to, this can occur if the node they think they would collide with is out of their range while their intended recipient is in range.
            - What is rts and cts?―RTS is a request to send, CTS is a clear to send message. 
A node sends an RTS request (containing the length of the transmission), and waits for a CTS message from the receiver before transmitting. If one is not received there is assumed to have been a collision. 
After a transmission has been sent an ACK (acknowledgement) message is sent.
            - What is a MAC address?
A MAC address is a unique code given to every computer, it allows for identifying which machine is sending a given message.
            - What is a self learning switch?―A self learning switch learns which nodes can be reached through which interfaces – when a frame is received, the switch “learns” location of sender – records sender/location pair in  switch table.
            - What is flooding (and what is the problem?)―Flooding is the process of making sure that all the nodes participating in the routing protocol get a copy of the link-state information from all the other nodes. Each node sends its link-state information out on all of its directly connected links, each node that receives this information then forwards it out on all of its links. This process continues until the information has reached all the nodes in the network.  
Flooding can lead to loops where nodes are sending flooding data to each other forever.
                - How do we fix this?―Ensure the network topology has no cycles. We build a spanning tree (a graph without cycles) and edges **not **in the spanning tree do not forward results. 
    - **Supervision 3**
        - 
        -  _**Network Layer**_ 
        -  _What is the purpose of this layer_ ?―The network layer manages communication over IP and handles routing around a network. I.e. the physical path a packet will take
        -  _Define simplex and duplex_ :―A simplex connection is when nodes can only send or receive data along a line, the can't do both. A duplex connection is when nodes can send and receive data simultaneously along a line.
        -  _What is the difference between the data plane and the control plane: _ ― _
_ The data plane simply pipes incoming data to a port, where it is then shipped along a connection - it does this using the routing table supplied by the control plane. The control plane handles this routing table and makes decisions at a larger time scale. Handling the routing means updating shortest paths using various algorithms.
        -  _Why is this separation also useful in other contexts (for example distributed databases)? _ For distributed databases, this separates concerns between simply storing data and also synchronising and maintaining databases - for example synchronising fragmented databases.
        -  _What is the line rate of a switch?_ ―The line rate is the number of bits per second that can be sent from a port, e.g. the speed of each port.
        -  _What is a border or edge router?  _ ―A border or edge router is a router between two Autonomous systems, e.g. clouds.
        -  _**Routing table**_ 
            - What is this:―A routing table is a grouped table of networks, for each network we have a next hop ip address to send the packet to, a "cost" associated with that route and the interface to send it along - e.g. port.
            - Why does this allow the router to make fast forwarding decisions?―The router can make a quick lookup in the routing table based on longest prefix matching of the IP, then we can quickly manage the header and transmit the packet.
            - Why is address fragmentation problematic for this table?―^^Address fragmentation is when one company get 1000 ips, they grow and need more - but the next set has been bought. But the next contiguous chunk is gone - then will have to get another section.^^ 
            - How does IPv6 address this? 
        -  _What is an autonomous System_ ―An autonomous system is a system in which a routing algorithm is run on the switches within that system, calculating the fastest routes within the system. Usually owned by a single entity, think clouds.
        -  _What famous general problem is calculating routes equivalent to?_  There are similarities to be found between calculating routes and the Byzantine generals problem - wherein unless all generals synchronize, the task fails. Similarly, if routers have differing routing information loops and slowdown can occur.
        -  _Outline and compare Distance Vector and Link State routing_  ↓ 
            - Distance vector routing: 
First each node communicates to all it's **neighbouring nodes** the shortest "cost" of travelling from it to all other routers along it's provisional shortest paths. Then each node examines the distances, and improves upon it's own list of shortest paths. Every node does this, and over time a optimum solution is reached. Need additive metric, otherwise could have an infinite loop as an equally good shortest path.
            - Link state routing:
Each node communicates it's local link state (list of directly attached links and their costs) table to it's neighbours - and they flood the table to all of their neighbours etc. Until every node in the network has received it, then every node can build a graph of the entire network and subsequently run Dijkstra's algorithm to calculate the distance from it to every other node. Then build a forwarding table, which link to use when sending a message somewhere.
            - Distance vector routing sends less messages on the network.
Distance vector routing has a lower complexity for it's underlying algorithm.
Distance vector routing iteratively arrives at the correct solution, while Link state routing get's the correct solution as soon as the processing of Dijkstra's algorithm completes for all the routers.
        -  _Under what condition is Link State routing better?_ ―Link state routing is better at recovering from loops caused by incorrect link costs.
        -  _Why does the Distance Vector routing break down_ ?―If a router malfunctions and advertises incorrect routing data, that error get's propagated to every other router and they all end up having incorrect routing data.
LOOPS - (consider triangle loop) if someone in a loop crashes, one node might just send to A how sends back to B etc.
        -  _Find an example of BGP route advertisement resulting in a large proportion of internet traffic being routed via a single AS_  - Couldn't find BGP route advertisement in the lecture notes
        -  _Describe a packets traversal through a router_ :―First the packet arrives in the port (the router then looks up the outgoing port on the routing table), it then has it's header updated (TTL decremented and checksum updated accordingly), finally it is sent to the output port where it is buffered, finally it is sent out the corresponding outgoing link. __
Just to check my understanding, the Control unit doesn't communicate with the ports sending them the routing table? It only updates the routing table the ports use periodically.__  
        -  _What is longest prefix matching and why does that result in 'optimal' delivery_ :―Longest prefix match matches a given destination IP with the destination IP in the routing table with the longest subnet mask. Longest prefix matching works on the fact that we may send many packets to a given network (to different hosts on that network) - so even if we don't know the exact route to a given computer, longest prefix match will find the address of the network (or less specifically, route it to the country/region or simply a default address) that computer is on and route it to there. 
 __Don't really understand the grouping of entries in the routing table - seems to say that ports get assigned by IP no by actual routing: __ ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QC4iKPENrlqT9O170cdiicsa4T9KuLvRbdkbZI5srFJfw2r9qhmvjY2hU3Q0kuAnR7zrh9hwXE5rdrZ7Lu80Htv5IjLD6YDmg0ZUZumcCMUUmfMQ8XTSE9IcQUuZ2116.png) 
        -  _Describe each part of an IPv4 packet:  
_ Version Number - the IP version number, 4 in this case.
Header Length - the length of the header in 32 bit words.
TOS - Allows packets to be handled differently depending on use, e.g. low delay for audio.
Total length - the total length of the packet including the payload in bytes
Identification - Number associated with a set of fragments to recompile them into a single packet.
Flags - Indicates fragmentation possibilities, do not fragment or more fragments on the way.
Fragment Offset - Offset of the fragment from the start of the datagram in bytes.
TTL - Number of hops left before the packet is dropped, useful for preventing loops.
Protocol - information about the type of connection e.g. UDP or TCP
Header Checksum - a unique number that can be calculated from the header binary, used to detect corruption of the packet. 
Source IP - IP of the original source computer
Destination IP - IP of the destination computer
Options - Number of optional header settings, for tracing or testing.
        -  _Why is the protocol specified within the packet header_ ?―Different protocols have different underlying headers below the IP header, knowing the type of header to examine allows for quick and easy demultiplexing.
        -  _Why is ip fragmentation required?_ ―Because not all links have the same capacity, if a router needs to send a 1500 byte packet along a link with a capacity of 1000 bytes - fragmentation is necessary.
        -  _Outline how to fragment a packet_ : ↓ 
            - The packet is split into multiple fragments that will all meet the MTU requirements for the link (the less fragments the better, as less chance of packet loss).
            - These are all given the same identification number (if a packet is already a fragment, the id number is unchanged) and are given an offset from the first datagram (only the payload counted, first packet has 0 offset). 
            - Finally, all packets except the last have their MF (More fragments) set to 1 and all the packets are sent.
        - What addresses are in the following subnet: 192.168.16.0/23
192.168.16.0 - 192.168.17.255
        -  _**DHCP**_ 
            - What is it meant to do? Meant to provide a method of dynamically giving hosts unique IP addresses and renew the lease on said IP address.
            - Outline the protocol -―Host pings DHCP server requesting an IP
DHCP responds with an IP
Host responds with that same IP
DHCP sends an ACK
Host then adopts this IP.

 __Bit confused about the src and dest ip's in the diagram - are these reserved so the DHCP server knows what to respond to? Also does my hub at home have a DHCP server or would it contact ISP?__ 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dyAIgnOJEZa5z3RtotRC9v-8j1ocoFTeUKByRZdBOXCcoqqwPyaJ7nvAiiTsrNMaTVvy9XQhQ3r7CmilYDSaultTwtwq-7Kdm6UhJLCqqQAUTVkUbj31n4qSdfNA1Inn.png) 
            - What is a NAT:―A Network address translation takes a private IP address and port, and maps it to a public IP address and port - then when a packet with the same public IP and port comes in, route it to the correct private IP and port.

This means multiple computers on a network can seem to share the same IP to the outside world - then when a response comes to a specific port, the router knows which computer to send the response to. 
^^NEED TO UNDERSTAND NAT PUNCHTHROUGH^^ 
            - Why are NATs required for legacy IPv4 networks?―Because there are more computers needing IP addresses than available IP addresses, this means 2^16 computers can share the same IP on a network.
            - Why might some say that it improves the security of the system?―Because a webserver cannot tell which computer within a network sent a given request.
            - Why does it pose difficulty with for example self hosted services (like game servers, or email servers)
Is it because for such a service, a given port has a specific purpose - and all data needs to be routed through this port. But here we have repurposed ports for computer identification?
            - What are ICMP messages?―ICMP messages are messages sent after receipt of a packet (sent back to the originating address) in the event of a failure or problem with the transmission of that packet. That could be that the TTL was exceeded, the packet is larger than the MTU etc. 
            - What is IPv4 ARP, what happens if an IP can't be found―IPv4 ARP is a method of determining the MAC address of a host, given it's IP address. This is useful for layer 2 communication which is done using MAC addresses and physical wires.
In ARP, hosts keep track of a table of IP and MAC address pairs. If a host wants to know the MAC address for an IP, the host broadcasts that they have an IP x and they want to know the corresponding MAC address - the host with that IP address will then respond with it's MAC Address.
            - Why does soft state result in robustness?
IPv4 being prepared for hosts to lost their IP or change their IP builds robustness against hosts  hogging an IP address without using it or changing IP in an attempt to spoof the system.
        -  _**IPv6**_ 
            - Outline an IPv6 header
Version - Same as IPv4, will be 6 for IPv6
Traffic Class - Contains the differentiated service field which classifies the type of packet (e.g. low latency sound packets) and two bits for ECN, which can indicate congestion is coming in packets (as opposed to just dropping packets).
Flow label - Groups a sequence of packets into a flow, signalling to routers they need special handling (Like sending all the packets along the same path, useful if packets are fragmented and we want them to arrive at the same time). Flow label can be any number, but all packets in the flow must have the same number.
Payload length - Same as IPv4
Next Header - Indicates where the next header is where we can add the equivalent of the options in IPv4
Hop limit - Same as TTL
Source and destination - address equivalent to IPv4 (in terms of usage)
            - Outline IPv6 packet fragmentation―- IPv6 packets can only be fragmented at the host sending the packet, intervening routers cannot fragment them.
            - Outline an IPv6 address structure:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9ocBmzW-Gq8oO09K_H5c5CQZamlwWRWvanVvjjViWmDrwFYZ5Y3qPmD8n_u6etqqInjkyS_1iBo9zuw1etAATcUOyRJQ7mDRtpCLBcavKtsZJRiAYB4cl4irI24Ki66M.png) 
 __This is the only slide, don't really know what it's on about - can we go through?__  
            - Why does this make routing easier? 
More space - very hierarchical
            - What do the following addresses mean:
Note that **Your computer will have multiple addresses, 1 for global unicast, 1 for site local.** 
                - fe80`::`/10 - ranges from fc00`::` - ffff:ffff:ffff:ffff. Used for link-local connections
                - : : 1 - all zeroes and then 1, like localhost in IPv4. 
                - fc00`::` /7 - ranges from e000`::` to ffff:ffff:ffff:ffff. Site local connections. Not globally routable, would have one for the computer lab.
                - 2000`::`/3 - ranges from 2000`::` to 3fff:ffff:ffff:ffff. Used for global unicast - If Yash wanted to send to me and Marc, he'd register a global unicast address - then me and Marc would subscribe and receive the messages broadcast from there.
                - ff00`::` / 8 - ranges from f000`::` to ffff:ffff:ffff:ffff. Used for multicast - send to the router first, which forwards to everyone else that's subscribed to listen.
            - What is IPv6 neighbour discovery - It's a method for IPv6 hosts to discover other hosts and routers on the network using ICMPv6 packets.
            - Outline SLAAC―SLAAC is a method of generating and testing IP addresses automatically, without the need of a DHCP server. First the host generates an IP address (generally using it's MAC address, although this has privacy concerns), it then pings the network with packets testing if that IP is in use, if no other hosts reply then that IP is assumed to be unique and is assigned to the interface.
Note that it only generates the last 64 bits (otherwise we wouldn't get the hierarchy of IPs) the first 64 bits are eight fe80 for link local addresses, or wait for a router advertisement.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yt6C0pLDaTVm4ClKEY5IupCYi6ZSEWIqD8-xWIZuhPT_OeNBoyvO3wfxP5FXpuwgzC-MRemF5-K5rm_xvzIAMdNpZ0dlVWdJjvgolth2smYdDuQaD3mrunbLKDH-T8hR.png) 
            - What is its purpose
SLAAC is a method of generating and testing IP addresses automatically, without the need of a DHCP server. 
            - What are router advertisements?―This is where a router occasionally advertises it's presence on the network in the form of a special packet supplying it's IP and other information. It tells the host where to derive it's network state using two flags R and O - R says to use a DHCPv6 server and ignore O. O says other configurations are available over DHCPv6 such as DNS.
            - Discuss 6to4 tunnels -―6 to 4 tunnels operate like an IPv6 VPN service, wherein a host using IPv6 can communicate with a different server - which will forward all it's packets using IPv4 (after translating the IPv6 packets). The server will then send the responses back to you in IPv6 format
    - **Supervision 4**
        -  _**Transport layer**_ 
        -  _What is the transport layer? _ ― _
_ The transport layer is the interface between applications and a stream of IP packets. We need to decide which packets go to which applications. It can also provide reliable connections over best-effort IP (using TCP) or faster (but less reliable) connections like UDP, where implementation of these details in every application would be tedious. 
        -  _What are ports at the transport layer?_   
These are the transport layer identifiers, using a mapping from ports to sockets (stored by the OS) we can decide which port maps to which application (each application must open a socket).  
        -  _Why does this make running duplicate services from the same ip address difficult?_  
Need to ensure we don't have port conflicts, where multiple services are trying to use the same port. 
        -  _Why does the transport layer need to mux/demultiplex IP streams?_ ―Because multiple processes can be sending IP streams from different **ports**, and we need to examine the header **below **the IP header to find out which port the packets need to go to. The ports are the method of multiplexing, sharing the network resources between different applications.
        -  _**UDP**_ 
        -  _Outline UDP _ ― _
_ UDP is a lightweight delivery system, simply providing de-mux and anti-corruption capabilities. Packets are simply created and then send, without waiting for an ACK at the sender. 
Headers contain the source and destination port (for demultiplexing), a length and a checksum - followed by the data. 
        -  _What guarantees does this provide?_   
The checksum provides some guarantees for testing for corruption, and the source and destination ports allow for demultiplexing - however this is not a reliable connection. Packets can be lost or reordered as no packet sequence is provided.
        -  _Outline some C/pseudocode (but valid POSIX commands) code for a basic echo server_   ```c
#define BUFSIZE 512

int main(int argc, char *argv[]) {
    int sockfd;
    struct sockaddr_in servaddr;

    if (argc != 2) {
        puts("Usage: client <port>");
        return 1;
    }

    if ((sockfd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)) < 0) {
        perror("Cannot create socket");
        return 2;
    }
    // Set server to all zeroes
    memset(&servaddr, 0, sizeof(servaddr));
    servaddr.sin_family = AF_INET;
    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);
    servaddr.sin_port = htons(atoi(argv[1]));

    listen(sockfd, 100);
    {
        int n;
        char bytes[BUFSIZE - 1];
        while ((n = read(sockfd, bytes, BUFSIZE)) > 0) {
            // Output the results to stdout
            fwrite(bytes, n, sizeof(char), stdout);
        }
    }

    return 1;
}
```
        -  _**TCP**_ 
        -  _What is the purpose of TCP _ ― _
_ TCP is designed to provide a reliable, correctly ordered and uncorrupted delivery of ^^a stream of ^^packets over an unreliable connection.
        -  _How does it provide reliable delivery?_ ―Via retransmission and acknowledgements, as well as an initial three way handshake to establish a connection.
        -  _Outline sequence numbers for reliable delivery_ ―Sequence numbers are used to order the sequence of packets in a sequence. A packets sequence number is equal to it's offset as a TCP segment from the start of the entire TCP flow.
        - In TCP what are the sequence and ACK numbers?  ↓ 
            - The sequence numbers are the byte position of the 1st byte in the segment. E.g. ISN + k:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xtdqBigCdYYHvUABNnffIo3SkGA0jM1MkzijlgGeack7W5RvxoV69_33jAT26SF0KBBztYvPwfPrc-hicC4y2TVFRl14iUW2JEfWU3z1fij_jos_7i42f_MubfXCp_ya.png) 
            - The ACK numbers are the byte position of the next expected segment.
        -  _Outline cumulative and selective acknowledgements_  **IN TCP**  ↓ 
            -  _Cumulative Acknowledgements:_ 
Packets are not dropped when received out of order, they are buffered. Every time a packet is received (packets out of order are buffered), an ACK is sent with the SN indicating the bit position of the next packet to be received. If the received packet was the next expected packet, the SN would be the bit position of the end of the last in order buffered packet. If the SN received was not for the next expected packet, the receiver sends the SN of the next expected packet + 1.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2alRg9cxu3jFsEulJf3TG8aRlb1pKdz-qMAr0gMMXx4K_sexOr1ZHmJOHXeERsChscJ7Oj_Vdkv4ekmLHlri_K4sDGQXY3NGtHh4v3RvC1wuL8iAd1NT9oFcET7eO-u8.png)
The sender only resends a packet if 3 consecutive ACKs with the same SN are received (indicating isolated loss) or no ACKs are sent after a certain amount of time - in which case the sender retransmits the relevant packet.
            -  _Selective Acknowledgements- TCP DOESNT ACTUALLY DO THIS_ 
Similar to cumulative acknowledgements, except an indication of which packets are being buffered is sent in ACKs - meaning during repeated ACKs the sender can choose to retransmit multiple packets at once.
        -  _Outline CWND, advertised and Sender side sliding windows_ ―**CWND **- how many bits can we send without overloading routers along our route.
**Advertised window** - how many bits can we send without overflowing our receivers input speed. With **Flow control **this window will vary as the buffer of the receiver fills, and the amount of space left will be signalled in ACKs. Additionally, the window size at the sender will grow as ACKs are received, as speed is gradually ramped up.
The **Sender side window** is then the minimum of CWND and the Advertised window.
        - What does TCP do if it doesn't receive any ACK's? How does it measure RTT? ↓ 
            - Retransmits after a certain timeout - we don't want the timeout to be too long (inefficient) or too short (duplicate ACKS). So we seek to make the timeout proportional to the RTT.
            - Can use exponential averaging to measure RTT:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6Hb-4bX3Nq-srt6nvRJ9avrctNSTXXh6Q5s6APtmKdX1lzEGuDcRhg8eJsNS7XumsmZ3HV4fVzJqAkNk2mwmSUOQtqVrp6rA_P11b91Wfi7x1HGQlpTH0u0JN7si_-4w.png) 
But can't measure RTT if we can't tell between ACK of original packet and ACK of retransmitted packet. Thus don't include retransmitted ACKs into RTT calculation. Set the timeout to $2 \times \text{EstimatedRTT}$. 
            - When we timeout, double the timeout. Collapse back to $2 \times \text{EstimatedRTT}$ when we receive a new ACK. 
            - Can model better by measuring the deviation:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2FKFwuJl2lOmfwNjZGez6axk0zdRuTEqiA_Xb1ab3veJ07MsUox0E93jpfvePpCYa_Oa2JGfC-_LBQ8L9RoQoIn6uxVsIIws0xzxP6vKhe7X3a5tnTon4U1t9WRwTYwA.png) 
        -  _Outline TCP :)_ ―First a three way handshake is initiated to synchronize an initial sequence number, this sequence number cannot be zero for security and reliability concerns - if we always start at 0, we could have cases where packet with sequence number 100 was lost before and now gets replaced with a completely unrelated packet as the receiver thinks a resend has occurred.
In the three way handshake, Host A sends a message flagged SYN (Synchronize sequence number) containing a proposed sequence number. Host B then replies with that same sequence number + 1, a proposed sequence number for B and an ACK. Host A then responds with their sequence number, B's sequence number + 1 and an ACK and the connection can be started.

Both the sender and receiver maintain a sliding window, where receivers send cumulative acknowledgements. Packets are not dropped when received out of order, they are buffered. Every time a packet is received (packets out of order are buffered), an ACK is sent with the SN indicating the bit position of the next packet to be received. If the received packet was the next expected packet, the SN would be the bit position of the end of the last in order buffered packet. If the SN received was not for the next expected packet, the receiver sends the SN of the next expected packet.
The sender only resends a packet if 3 consecutive ACKs with the same SN are received (indicating isolated loss) or no ACKs are sent after a certain amount of time - in which case the sender retransmits the first packet in the window.
The aforementioned packet window must be carefully managed to keep congestion low, and not exceed the maximum window size - this window size being whichever is smaller, the advertised window size of the receiver or a congestion window set to help prevent router overflow.

When tearing down the connection, host A sends a packet flagged FIN to B - then B must send an ACK to A, followed by a FIN packet from B. This ensures that both hosts have the opportunity to receive all packets in flight, and potentially request retransmission.
In the case of abrupt termination (for example due to a process crashing) the terminating host sends a packet flagged RST.   
        -  _Discuss the abstraction_   
Don't really understand what this question means.
The abstraction of TCP is that applications can now directly interface with a reliable connection, even though in reality all the messaging is done over a best effort connection.
        -  _Discuss segmentation - Why is it required - How does it work_  
Segmentation is how bits are loaded into IP packets from a stream of input data (TCP is a stream of bytes service) , before being sent over the network, a given segment either fills up before sending or times out and is sent without being completely full.
The IP packets contain an IP header, followed by a TCP header followed by the data - the entire packet must not exceed the MTU (maximum transfer unit) while the part below the IP header must not exceed the MSS (maximum segment size).
These segments are useful for two reasons, 1 they can be used to provide an ordering mechanism for packets i.e. the sequence number, 2 they allow for flow control as you can vary the MSS.
        -  _What are TCP sequence numbers?_   
Described above. Outline TCP quite a general question, didn't know what I should/shouldn't include.
        -  _Outline what happens when packets are lost inTCP_    ↓ 
            - If a data packet is lost: 
Consider a packet with sequence number X is lost. The receiving host A will continually send an ACK containing X whenever it receives a new packet - then when sending host B receives a certain number of repeated ACKs it will employ **fast retransmit **and resend the missing packet before resuming normal sending (with a reduced sending window).
            - If an ACK packet is lost: 
If an ACK packet isn't received in a certain amount of time, the receiver times out and resends the first packet in the window. If one ACK packet is lost but a later ACK arrives then we know the first packet must have been acknowledged and can keep sending as normal.
        -  _How does TCP choose a retransmission timeout?_   
The retransmission timeout is a multiple of the RTT (round trip time) between hosts, this is because the RTT is the minimum amount of time necessary for communication between the hosts . Many times the RTT is a waste of time.
The RTT is then calculated via the following two formulae:
$$\text{Measured RTT} = ACK_t \ - \ SEND_t$$ 
$$\text{Estimated RTT} = (1-\alpha) \text{(Measured RTT)} + \alpha( \text{Estimated RTT})$$
This averaging formulae allows for adaption of the estimated RTT to network changes (the estimated RTT would change accordingly) while not changing the estimated RTT suddenly in the event of temporary network speedup/slowdown (jiggle).
        -  _How a connection is established_ ―First a three way handshake is initiated to synchronize an initial sequence number, this sequence number cannot be zero for security and reliability concerns - if we always start at 0, we could have cases where packet with sequence number 100 was lost before and now gets replaced with a completely unrelated packet as the receiver thinks a resend has occurred.
In the three way handshake, Host A sends a message flagged SYN (Synchronize sequence number) containing a proposed sequence number. Host B then replies with that same sequence number + 1, a proposed sequence number for B and an ACK. Host A then responds with their sequence number, B's sequence number + 1 and an ACK and the connection can be started.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2dwl7uUhBdSRe8KzoROzqZ1xuVl3HIJNkS7gO9_LX1EI-AhI4FWUjW7qTvibd6KKh8vNRqhO-jjusseI1TnjAW_x11Lmq_8P2YaXXQqrswyhkKG-qDDGfAt75N5-xL6h.jpeg) 
        - How a connection is torn down under normal circumstances, describe both one at a time and both together ↓ 
            - **One at a a time**: When tearing down the connection, host A sends a packet flagged FIN to B - then B must send an ACK to A, followed by a FIN packet from B and finally an ACK from A. This ensures that both hosts have the opportunity to receive all packets in flight, and potentially request retransmission.
            - **Both together**: Host A sends FIN, B sends FIN + ACK (fin in ACK of A's FIN), C sends ACK
            - In the case of abrupt termination (for example due to a process crashing) the terminating host sends a packet flagged RST ^^once they've received a packet they don't recognise^^.
        -  _What is the purpose of RST_ ―RST is sent if an application crashes or otherwise closes suddenly, it is to signal that the host can no longer engage in the communication and typically signals an error- a RST will then be sent by the OS in the case of a packets sent to a closed socket OR during resource clean-up if the process didn't close the socket properly.
        -  _Flow control - Why is this needed for the receiver_ ―Necessary as we don't want to overwhelm a slow receiver, this could be due to high network load, CPU reception thread slowdown, buffers filling up etc.
^^Also consider that the receiver might want to keep data in it's buffer for a bit while it processes is - so need to communicate current amount of space in the buffer.^^^^```^^ 
        -  _Congestion control - Why is this needed? - At a high level how does it achieve this (in terms of what is it estimating, and what additional considerations apply) - Discuss approaches and why all of them are terrible :)_   

Congestion control is a way of managing global internet resources, to ensure the best connection for all hosts. As the internet works under statistical multiplexing, if many users are blasting the network routers will need to buffer packets and congestion will occur. If no congestion control were in place, no one would be able to use internet resources.
At a high level, congestion control works by adjusting resources in response to high congestion - whether that be host bandwidth or the number of packets the router drops. Congestion can be estimated by the end hosts measuring packet loss, or the routers themselves advertising their congestion levels. 
            -  _Don't care_   
In this approach we simply don't think about congestion control, while this does reduce some processing and packet size overhead this will result in many packet losses as the internet is a jittery network.
            -  _Explicit reservation
_ Explicit reservation first requires users to negotiate with routers along their route and arrange the maximum bandwidth they can use - this converts a packet-switching network into a proxy circuit-switched network and comes with all the problems a circuit-switched network has, including high start-up overhead (need to talk to every router on your path), slow recovery from failure and possible hogging of network resources.
However, it does provide a solid maximum bandwidth and a reliable connection (if no routers drop out or need to change your bandwidth allocation).
            -  _Pricing_   
Routers drop packets of lower tier customers, and buffer higher tier customers packets in times of congestion. This requires a payment model, carries ethical considerations and faces the problem of what happens if a large proportion of people become higher tier customers (back to square 1).
            - Describe Slow Start―Initially CWND is set to one, and we double the CWND for every complete RTT without any loss. This can be accomplished by increasing the CWND by one at every ACK. $$\text{CWND += 1}$$ 
            - Describe AIMD ↓ 
                - Grow the window by 1 for every complete RTT without loss, this can be implemented incrementing CWND by 1/CWND at every ACK$$\text{CWND += } \frac{1}{\text{CWND}}$$ 
                - One losing a packet, set CWND = CWND / 2 $$\text{CWND} = \frac{\text{CWND}}{2}$$ 
            - When does a sender stop slow start?―Set a slow start threshold ssthresh set to some large value. On timeout ssthresh = cwnd / 2 - when CWND = ssthresh then start AIMD.  
            - Describe fast recovery ↓ 
                - Method of dealing with isolated loss by taking duplicated to be ACKs real ACKs.
                - After 3 duplicate ACK's, ssthresh = CWND/2 
CWND = ssthresh+3
E.g. we're accounting for the 3 duplicated ACK's
                - While in fast recorver, CWND = CWND+1 for each duplicate ACK
                - After we receive a new ACK, CWND = ssthresh = CWND_old/2
                - Note that CWND_OLD / 2 is chosen as a good mid point, we don't want to go back to the old value as that resulted in loss - and starting at 1 is inefficient.
            -  _Dynamic adjustments - Why does dynamic adjustment require cooperation (and why might a company like google cause a tragedy of the commons by 'optimising' their TCP congestion control) - What signal is used to backoff? - Where does the sawtooth come from? - What phases are there to the standard algorithm - What is Fast Recovery_   

Under dynamic adjustments, hosts probe the network (routers respond with a congestion level or hosts detect dropped packets), hosts then adjust their sending window accordingly. 
In TCP we begin with a slow start up to some threshold to poll the network speed, that is a small Congestion window (often 1 TCP packet) is chosen and you add one on every ack ( Means doubling by the time the whole window is sent). 
Next we move to AIMD after reaching an ssthresh (slow start threshold) - if an ACK is not received and a packet is assumed to be lost, halve the congestion window otherwise increase the window by some constant amount. This introduces a sawtooth pattern as the network usage linearly increases, the exponentially decreases in the case of network congestion.
Fast recovery deals with the problem of TCP being too sensitive to reordering/isolated loss, the first repeated ACK message received is still counted as credit for a correctly sent packet (but ssthresh is set to half the cwnd) (e.g. the congestion window is incremented as normal). Then after a set number of repeated ACKs, if a new ACK is received set the CWND to ssthresh. 
When you halve the next time wait a bit.
        -  _What are TCP's flavors_   
TCP-Tahoe - cwnd = 1 on triple duplicate ACK. Set ssthresh back to the $\frac{\text{cwnd}}{2}$.
TCP-Reno - cwnd = 1 on time-out & $\text{cwnd} = \frac{\text{cwnd}}{2}$ on triple duplicate ACK. SSthresh also halved.
TCP-newReno - TCP-Reno and improved fast recovery (default). ":) by Yash"
TCP-SACK - incorporates selective acknowledgements
        -  _How can routers help TCP congestion problems?_   
Routers could inform endpoints if they were congested, they could tell endpoints what rate to send at and they could enforce fairness. 
            -  _Outline Max-Min Fairness_ ―Given a set of bandwidth demands $r_i$ and a max bandwidth C, max-min finds **the **unique value f such that $\sum_i \min(r_i, f) = C.$ This means that for small enough bandwidth demands, no limit would be placed on the bandwidth allocation to such a flow. For larger flows they would be curtailed to the max value f. 
This method strikes a balance between accommodating high bandwidth flows, while not letting them take over the network at the detriment to smaller flows.
            -  _Outline fair queuing _ ―
Routers try and estimate when the last bit of a packet departed a router, and packets queue where the first sent from the host are first sent from the router (the idea being they've been waiting longest). 
^^In the slides he says:
^^![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PSqP_aPoVLNSzNY9PzAIjg71nWHz6F4TFs1H3v-FcQhxJr6itBqtanTpWNiU5FkJx0wUYPfKaqFVsHNxp9AP-bTXSIYZSUWm0AQP8McvEV550zI4GJvvyodbJ0Zk8H1v.png)^^ 
What does "deadlines" refer to?^^ 
            -  _Outline some general 'fairness' qualities and discuss under what circumstances each might be optimal_   
FIFO - first to arrive should be sent first, works in situations where the time taken to reach the router is approximately equal for differing hosts.
Small packets first - works when very large packets are common, and thus won't be permanently buffered while small packets are dealt with.
Critical packets first - packets marked important should be sent first. Works while hosts don't game the system by marking all packets critical
        - 
    - **Supervision 5** 
        - Discuss DNS―The Domain Name System is a system which provides an IP given a domain name. This is required as associated IP addresses to servers can change, we may want to contact a different fragment of the server at the same domain name but a different IP. Additionally, no one host can have a complete lists of domain IP pairs - so we would like to fragment and spread that data around the web. 
            - Outline its structure
The top layer is the root DNS, this is replicated around the world by any-cast. The next level is top level domain servers, this includes country domains (.uk .ca .cn etc.) and generic domains (.com .gov etc.) these are maintained professionally. Then authoritative DNS servers can be maintained locally or by service providers (.cam .ucl etc.) which will provide the actual IP address of the host.
For example if I enter www.cl.cam.ac.uk/teaching/2122/part1b.html,
The chain would go ROOT ⇒ country specific (.uk) ⇒ Authoritative name server (,.ac)
^^Does my host machine strip the page locating part of the URL when I make a DNS query? 
Also what is the name for the servers between the TLD and the authoritative name server. As in Between .uk and .cl - or would the TLD pass straight to an authoritative which would resolve the rest. Slides seem to say there can be servers between, but googling seems to say if the first ANS fails there will be an error thrown.^^ 
            - Outline iterated queries―First you query your local DSP resolver located at your ISP, the address could come bundled with your OS or you could get it via a DHCP server (^^can we still contact DHCP servers on ipv6?^^). That DNS resolver then progresses up the hierarchy, querying first the root server for the IP which responds with an IP of the next DNS server to contact - this continues until the DSP resolver contacts a authoritative DNS server which responds with the IP. That IP is then sent back to you.
            - Outline recursive queries―In a recursive query, each DNS server is given responsibility for handling the request and a "call stack" of DNS servers is built up. E.g. your DNS resolver contacts the root DNS server who contacts the TLD etc. Finally when an authoritative server which knows the IP receives the query it responds with the IP, and the IP flows back down all the servers that queried before finally ending up back with you. This can be detrimental during heavy loads (either at heavily used servers like root, or smaller, lower level servers less used to the load).
            - Why might it being organised by an American company be negative for the world?
They could throttle/block domain name requests to competitors.
They could require payment for improved DNS request speeds.
They could strongarm businesses/countries into using their product/associated products by doing the above.
More attention might be payed to American infrastructure than elsewhere.
            - Given that DNS queries take > 500ms in most cases and each outgoing connection will requires one, how do we improve the speed of this? ↓ 
                - We can fragment DNS data across multiple locations, meaning a DNS server might be closer and faster to contact.
                - We can have caching at the server level and at the host level, so servers aren't wasting time re-fetching data and users can skip DNS requests if they already have the data.
                - Can implement negative caching, store common misspellings of domains that we know to be false so not to waste bandwidth.
                - With both types of caching, data needs to have a TTL - as the IP could change or a supposedly incorrect domain could be registered.
                - We can use UDP connections and compress headers for smaller packets sizes.
            - How can we ensure that failed queries fail fast?
Negative caching. As explained above.
            - How can DNS servers be use for an amplified DDoS
Because there's no way to verify the results of a standard DNS query, man in the middle/spoofing attacks can be used. A widespread attack could be used which provides an incorrect IP for a domain (could be done over a common shared network, like eduroam for example) meaning the website could not be reached/an incorrect website would be reached.
            - Outline the format of URLs
protocol / hostname [:port] / directory path / resource
Where the protocol is http/https/ftp etc. I.e. the request-response protocol.
The hostname is the DNS or the IP.
The port is optional.
The directory path is the path to the directory containing the resource.
The resource identifies the desired resource, e.g. image.jpg.
        - HTTP
            - Outline how connections are setup―First the client must initiate a TCP connection, this requires the usual 3 way handshake used in TCP.
            - What are the three most common types of HTTP request?
GET - requests a specified resource.
PUT - replaces the current resource with a specified resource. 
POST - submits an entity to the specifies resource.
            - Why is the statelessness of HTTP difficult to work with and how do servers fix this? 
The statelessness means every connection TCP connection and request is unique and lasts for the length of the request. That means that you cannot get data about the user to serve specific data over a series of requests (i.e. username, password etc.). To solve this issue, users store a small amount of server side data on the client side (in cookies) which they send with the HTTP request. These cookies must be encrypted properly to ensure privacy. 
            - How do modern web browsers improve the performance of loading a web page?―Through caching. Much of a websites content (stylesheets, pages, javascript scripts etc.) will be cached so they can be quickly retrieved without having to retrieve the whole content from the server - instead the server will simply inform the browser if the content has changed since it has been cached (if it has then the new site must be sent).  
        - Discuss content delivery networks
A content delivery network refers to a geographically distributed group of servers which work together to provide fast delivery of Internet content (they also makes DDOS attacks harder). This is done by distributing load, and pairint hosts with their closest server which can serve them data.
        - What is a reverse proxy―A reverse proxy is a cache of documents stored close to the server, this reduces server load so common documents aren't repeatedly causing server usage. Instead servers can be used to generate dynamic changing content. Reverse proxys work best for static content.
Also load balancing and firewalls
        - What is a forward proxy―Forward proxies are caches of documents (stored by your ISP), meaning the server doesn't need to waste bandwidth supplying the data and the data is close and can be retrieved quickly.  Again they work best for static content. 
        - How do we host multiple sites within a single machine? (consolidation)
Need multiple server processes mapped to different ports on the machine (through sockets). Then the HTTP request must include the site name in the header (the host address) which is required in HTTP/1.1.
        - Can we use the same approach to host multiple services (for example games servers) behind a NAT?
Yes, as long as the NAT stored the corresponding (IP, port) to (NAT IP, new port) pair so that the incoming request could be routed to the correct machine and the correct port in the machine. This would only be the case if that machine had made a request from that port previously.
        - How do we host a single site over multiple machines? (scalability and reliability)
Need to direct clients to particular replicas of a website to pair them to nearby replicas or balance load across multiple servers. This can be done by:
**Single location, Multiple machines**: Have one IP address and run a load balancer at that location with multiple servers available. 
**Several Locations**: Configure DNS servers to reply with the closest IP to the requesting host. 
        - Discuss QUIC
            - What is it?―QUIC stands for Quick UDP Internet Connection, it is a protocol that seeks to offer the speed of UDP with some of the reliability of TCP. 
It offers reliable transport, FEC, security through cryptography (a connection is started with a 3 way handshake to establish identities), better multiplexing and restartable connections. It's downside is that there is no absolute guarantee on ordering of packets.
            - Why is it implemented over UDP―Because TCP is so deeply ingrained that it is near impossible to change it, thus it's much easier to implement a new protocol on top of UDP. Additionally, no real change needs to be made to UDP - features just need to be built on top of it.
            - Who uses it?
The majority of Google's web traffic is in QUIC - aditionally over 75% of Facebooks web traffic is over QUIC. Many large companies that can afford to migrate all their services to QUIC and can benefit from the speed increase.
        - Discuss Bittorrent―Bittorrent is a peer to peer network. Peer to peer networks have no central server, instead a variety of hosts store parts of the database and share that with other hosts on request. These hosts can be distributed around the world, are intermittently connected and change IP frequently
            - Why is it useful for replicating 'linux ISOs'
Because bittorrent can facilitate higher download speeds than via a central server.
            - How does it function
BitTorrent functions by having many users send 256kb "chunks" of data to each other periodically. 
When a new user first joins a torrent, they must ping a tracker server storing a list of peers. They then contact a subset (their neighbours) to join the torrent.
When a user is sending chunks, they pick the top 4 hosts sending them data and send them back chunks. There is also the procedure of "optimistically unblocking", where every 30 seconds a host not in the top 4 is sent chunks in an attempt to make them part of your top 4. This is how new hosts start sharing chunks on the network.
When a user is receiving chunks, they periodically poll other hosts and request the rarest chunks first. When a user downloads their entire file, they can altruistically stay and continue sharing chunks or they can leave.
                - Outline the operation of a distributed hash table
A distributed hash table is effectively a distributed peer-to-peer database. 
Each peer is given an identifier represented by n bits. These are hashes to ensure all keys are in the same range. We assign a key to a peer which has the closest ID to the key.
Each peer is only aware of it's immediate successor/predecessor (and second successor to handle peer churn), thus queries take O(n) time.
When a peer wants to find who holds a certain key, they forward the request to their successor who checks their table and forwards it on if the value's not in their table. Once the peer with the value is found they respond straight to the original requesting peer.
^^Still not sure what the key/values actually represent - also in the bittorrent slides apparently a new peer contacts it's neighbours and requests what chunks they have, does bittorrent not use DHT's then?^^ 
    - 
    - **Assorted Flashcards**
        - What is the difference between a domain name and a URL?―A domain name will simply be the name of the website (e.g. www.google.com) while the URL will also specify a page within that website (e.g. www.google.com/images).
        - What is an application attack?―Send requests to a DNS server (having changed the source IP to your victims IP) requesting all subdomains (anything that sends loads of messages).
    - 
- Complexity Theory
    - **Lecture 1 **(Lower bound on sorting)
        - Algorithms and Problems 
            - What does it mean to say Insertion sort runs in time $O(n^2)$?―It means that if we run insertion sort on an input list of size n and count the number of discrete steps taken. The largest possible number of steps on that same input size will eventually be bounded by a constant multiple of $n^2$. 
This is because $O$ is worst case.
            - What does it mean to ask, what is the complexity of the **sorting problem?**―It means the lower bound on the number of steps taken. What is the best possible time complexity?
        - Asymptotic complexity review 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Szdo2lS8WmKQvH8jFN5OcSz90VZKYqSEm9710ZxBk8YFZTgwCxNlvEErkyJg4ggMzXyva26ctY0e4UToGnj2pmydPeWv-t5ciDT173XwRTReXMFi2lc-Fe3aye2_a7mC.png) 
            - Explain the difference between $f = O(g), f = \Omega(g), f = \theta(g)$  ↓ 
                - $f= O(g)$ is saying, f is no worse than g by some constant factor. So O is an upper bound.
                - $f= \Omega(g)$ is saying f  is as least as bad as g. So omega is a lower bound. 
                - $f= \theta(g)$ if $f=O(g) \ \land \ f=\Omega(g)$ . I.e. f is exactly the complexity of g.
            - If we can find the lower and upper bound, we've found the exact complexity of the algorithm.
        - Lower bound on sorting 
            - Describe the argument for forming a lower bound on sorting―Consider a binary tree containing all the decision points for an algorithm.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gIqeI92NlQcsGyPy4Pg1r-Pck7gfDY2T-GB3R33f8HmoMSZSPsyl8QGFZcznE4BQEX6AGBcSjPDuhnvDTxalGuj47fKZEvLfPc1eNE1OYZubkdE8m4hY2-WaE6qBhb3n.png) 
The algorithm must have these decision points, as otherwise it would behave the same on multiple inputs and we could craft an input that would defeat it.
To work for every permutation of an input list $a_1,...,a_n$ it **needs to have **$n!$ **leaves. **Therefore the height must be at least $$h \le \log_2(n!) \le (n\log n )$$
So the height is at least $n\log n$, giving us a lower bound. We know the upper bound is $n \log n$ from merge sort.$$\therefore \theta (n \log n)$$
Or you could do this to get a lower bound:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OqoZ_xD-eTLtoIutr9JSneuil2kjIQbm1VVSMVck2n4Z1k7ZfAlLTB1L1vt_Hqx1HXUQ9Ydzv2kFS9ijBgQ5BLmHkBIiTbFzvanJwUTqG5pKynGTvbWkWyCONMGodDZA.png)
 
            - How can sorting be nlogn when radix and bucket sort are linear?―Because those algorithms cannot sort an arbitrary list of numbers. **If you don't limit the radix, iterating through the **$\log n$** digits n times is just nlogn.** 
        - Travelling Salesman 
            - Given a set of nodes and a cost matrix of travelling from one node to another. 
Find an ordering of the nodes, such that the total cost of going from one to the next and finally back to the start is the smallest possible.
            - We can find a lower bound by performing exactly the same analysis as the sorting problem. We find a lower bound: $$\Omega(n\log n)$$ 
        - 
    - **Lecture 2** (Running time, Turing machines)
        - Formalising Algorithms 
            - To prove a lower bound on the complexity of a problem, we cannot use a specific algorithm - we instead need to proof a statement about **all algorithms**. 
            - To do this we need a mathematically precise definition of an algorithm, for this we will use a **Turing Machine. **These are well suited for proofs about all algorithms. 
        - Turing Machines 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6KTR1WbjpY8b-uhImigsS8NA4NRY5GnsOHKOKHeP8Yag5nM1RWUZHYy80cYWR2enR9P63w0SC-m2YWGlSTz7HgI8m8WE5cmN4JktY5eKuM2pOLoYXcG4OGshtCFW2rxJ.png) 
            - The transition function takes the current state and symbol, and outputs (the next state, the symbol to write, how to move).
            - What is the configuration of a Turing machine? hint: qwu  ↓ 
                - The configuration is a snapshot of all the information about the machines current progress.$$(q, w, u)$$ 
                - $w$ : The string of all symbols up to and including the  position the head is. 
                - $u$ : The string after the head up to a point, where after that point all cells are blank.
                - $q$ : The current state of the machine 
            - What happens when we read a left hand marker?―The machine is guaranteed to leave the left hand marker and move right.
            - Describes how the configuration changes:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9pEIPssJLuTmMNKn5-6bGJKOuP4tFNWG0QnuCWL5kd53er9yaPgjOTD5o-KcV9Sw93mRX93dleTsNf7AahVZhyWeEq1OvANSADGtJs7Ckc475GjUYFOFkB4I5k-t4koI.png) 
            - A sequence of configurations c1,...,cn where for each i $$c_i \rightarrow_M c_{i+1}$$
. Each transition is called a computation.
            - Starting in a specific configuration, there is a unique series of computations to reach another configuration. $\rightarrow_M^*$ means a non-zero sequence of computations. 
            - The language accepted by the machine is the set of strings, such that a configuration is reached with the acc state after some number of computations.
            - A language is **recursively enumerable **if {{it is L(M) for some M.}} A language is decidable, if it {{is L(M) for some machine M which halts on every input.}}  
A language is semi-decidable, if it is recursively enumerable. A function is computable if you can start at the configuration $(s, \rhd, x)$ and ends in $$(acc, \rhd f(x), \varepsilon)$$ 
        - Running Time 
            - For any Turing machine M, we associate a function $r: \N \rightarrow \N$ called the  _running time_  of M.  
            - r(n) is the length of the longest  __accepting __ computation of M, on an input of length n. The time taken for M to compute it's most tricky input - think a reversed list for bubble sort.
            - r(n) = 0 iff M does not accept any inputs of length n. 
        - Complexity 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NALCngAO-xDYhVKG6r9C_XrAY6Du5HJz8XD91nyoVkHs0QtxqXb-rWQQXnSCCV5USQqfoJVje0yiFrRORmMGJW6y5Sj6cAjrlYPbanOcmBkB3WsvQ9o3X66CLFQnzbNq.png) 
            - So for $f : \N \rightarrow \N$ the machine takes linear time. For a machine $f : \N \rightarrow \N^2$ the machine would take quadratic time etc. 
        - Decidability and Complexity 
            - For every decidable language L, there is a computable function $f$ such that $$L \in \text{TIME}(f)$$ 
            - We can know the running time is computable, because for the accepting machine M (which halts on all inputs by definition of decidability) simply enumerate all possible inputs of length n and count the running time of all of them - we then take the running time to be the largest value found.
            - If L(M) is not decidable, prove there is no r which computes the running time of
    - **Lecture 3 **(Complexity classes, polynomial problems)
        - Decision Problems 
            - We'll always be interested in decision problems - of the form "is this string in a language L(M)"
For more complex optimization problems, if we find a related decision problem is NP hard - then so is the decision problem.
        - Complexity Classes 
            - What is a complexity class?―A complexity class is a **set of languages** determined by three things: A **model of computation **(Turing machine, register machine etc.), a **resource** and a **set of bounds** (functions that bound the amount of resources we can use).
            - The complexity class P is defined for a {{Turing machine}}, {{time as a resource}} and the {{polynomial functions}}.
        - Polynomial Time 
            - While being of polynomial time is a property of a {{language}}, members within that class like quadratic or linear are sensitive to the {{model of computation}}. For example a two-tape machine might be linear for a problem while a Turing machine might be quadratic. 
            - $$P = \bigcup_{k=1}^{\infin} \text{TIME}(n^k)$$ 
            - Polynomial serves as our formal model for what is feasibly computable.
        - Reachability 
            - Given a directed graph $G=(V,E)$ and two nodes $a,b \in V$ - we want to find out if there is a path from a to b. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qmW30wtygqYDgBGiYMxuhLRNWlfQAwwKD00nmMg3cgDVMnNNbi6m5ipiMgyoMf4hsg8CKv3PT5jSZS_zdqC09w5HU1IH_vDIPBa14-LwZ4Yq-YobK26-sVcl--vMgCz_.png)
To formally define reachability we would need to―Translate (E,C,a,b) into a string, and formalize it as the set of strings accepted by a Turing machine with Polynomial running time. 
            - This algorithm requires O(n^2) time, as it depends on the number of edges in the worst case. It's also O(n) space.
Therefore $\text{Reachability} \in P$ 
        - Euclid's Algorithm 
            - Consider the following decision problem:
$$\{(x,y)\  |\  \gcd(x,y)=1\}$$ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zJVL0hNMSfuhdAuqtzBXUfjA6I68MgXmdPxIZr31kvny33vaLLlPSVij6ZWZdoPwEQkw8SGAMnx1ef8WGPNN1e32W-AktHtgsUcLSKE4iR-9ZIO_yNlUy0vBgtIl_akO.png) 
            - Why does Euclids Algorithm terminate?―Every iteration y becomes x mod y - and by the definition of y this is always decreasing (if x < y, then when we swap them the opposite will be true).
            - Give a patchwork proof that Euclid's algorithm is logarithmic―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0cl-TEBJ7Of4hLhb1NluXHBLtslCJ-KdekJw5aBEw7Ca7i3sYxap156fg3mhgzYCHsljLFRCXeqrBv4yUzqdL8o7AtlaUpV5qI-4CKKaR5FkIZEefTMRhKo1uGHsmFXs.png) 
            - Why would Euclid's algorithm not be Polynomial if it took $\theta(x)$ steps to terminate?―Because the **length **of the input is $\log(x) + \log(y)$ - that would be **exponential** in the length of the input. 
        - Primality 
            - Consider the decision problem:
$$\{x \ | \ x \ \ \text{is prime} \}$$ 
            - An obvious algorithm would be, for all y with $1 \lt y \le \sqrt{x}$ check where $y|x$. This requires $\Omega(\sqrt{x})$ steps - is therefore **not **polynomial in the length of the input ( $\log_{10}(x)$ ).
        - Boolean Expressions 
            - Boolean expressions are built up from an infinite set of variables:
$$X = \{x_1, x_2,... \}$$
**AND **the two constants  __true __ and  __false__ . 
            - An expression with variables can be evaluated **given **a truth assignment to it's variables.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eM9dNHgitrq0-CXl_BGwATJjWsoXH2T56t2hg-VLNJPvIpYqEmVCEYzE0I2kfguWduOEsO7GAktmY6_84TiKWrekHxlJgmQGrsV_OBqchZ1IunvBzPmaV0cRKdfv2lgl.png) 
Expression 3 is unsatisfiable.
Expression 1 and 4 are valid.
Expression 2 is satisfiable. $x_1 \land x_2$ 
        - Boolean Evaluation 
            - There is a Turing machine which given an expression of length n (**without variables**) will determine in $O(n^2)$ time whether the expression evals to true. 
            - We do Boolean evaluation with the following rules:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FMcIth4Zo7uM3kzs3e-Yd2LWsXwRbcBfxczKRois3_eIy6hUQRsTtnIYnrqspZeRSSDYEn9ogh1ncB-OGCnG2_eXtv2Cu3uGT9MCNH2JybZb8gWBIFfHs7QSiUdnXx-9.png) 
Why is boolean evaluation $O(n^2)$?―Because every boolean formula will have at least one applicable rule from this list - then every O(n) scan reduces the formula by at least one symbol. 
So we require O(n) scans to finish, and each scan takes O(n) time - thus the complexity is $O(n^2)$. 
        - Satisfiability 
            - Is ther an assignment of truth values which would make the formula evaluate to true? 
Is a formula in SAT (the set of satisfiable functions).
            - The satisfiability of a boolean expression can be decided in time $O(n^2 2^n)$, why?―We've already found that evaluating a boolean expression is $O(n^2)$, and there are $2^n$ truth assignments. So we need to evaluate the boolean expression at most $2^n$ times! 
            - The question is $\text{SAT} \in P$ is a million dollar question. And is equivalent to proving is $P = NP$ 
        - Composites 
            - Consider the decision problem defined by $$\{ x \ | \ x \ \ \text{is not prime} \}$$ 
            - This is the **complement** of the language Prime. Composite is in P iff Prime is in P. 
        - Hamiltonian Graphs 
            - A path on a graph starting and ending at the same node, such that every node appears in the cycle exactly once. 
            - A graph is called **Hamiltonian **if it contains a Hamiltonian cycle. Encodes the language HAM. 
            - An example solution is to simply examine all $n!$ arrangements. We don't know if a polynomial problem is possible. 
        - Graph Isomorphism 
            - If you're given two graphs, are they really identical?
Is $\text{Graph Isomorphism} \in P$? 
            - There are $n!$ bijections we could test - e.g. reorder the vertices in n! ways.
            - An algorithm to compute this in: $$2^{({\log n})^c}$$ 
Exists.
        - Polynomial Verification 
            - Note that the search space of the previous problems is **exponential**. However, given a potential solution - deciding whether or not that is a solution is  __**easy**__ . 
    - **Lecture 4** (Verifiers, completeness)
        - Verifiers 
            - What is a verifier?―A verifier for a language L has the following property given strings x & c: $$L = \{x \ | \ (x,c) \ \text{is accepted by V for some c} \}$$ 
I.e. A verification method for composite numbers would be check if $c\ |\ x \ \text{for some c}$. c stands for certificate.
If V runs in polynomial time **in the length of x **(not in the length of the whole input), then L is polynomially verifiable.
V is to demonstrate the whole idea of hard to generate but easy to test problems in NP. 
        - Nondeterminism 
            - If we relax the condition on $\delta$ being a function, and instead allow an arbitrary relation - we obtain a nondeterministic Turing machine.  
            - How do deterministic and non-deterministic Turing machines differ?―For nondeterministic machines, we relax the condition on $\delta$ being a function, and instead allow an arbitrary relation. E.g. There can be multiple options from a configuration:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9xbcGkwyRVnDmvCRFjHIZgznpfHnMt0n5zqRNkVHquJcf4dlSvDV3xS1ZrUW6HSCg3-3DC86YUpuQTVgkaPX-XH2EhK8avpfpxoriFnwYZjLJvVBzSYSpkvqWKLU9h4w.png) 
Note that the number of branches does **not **depend on the input x. 
            - For nondeterministic languages, a string is accepted if there is **some **computation path such that there is an accepting state.
        - Nondeterministic Complexity Classes
            - NTIME(f) is defined as the class of languages L accepted by nondeterministic Turing machine M, such that there is an accepting computation for every string in the language that completes in running time $O(f(n))$ - where n is the length of the input.
            - $$\text{NP} = \bigcup_{k=1}^\infin \text{NTIME}(n^k)$$ 
            - What is the NP class?―The collection of Languages who are accepted by nondeterministic Turing machines in polynomial time.
        - Nondeterminism 
            - If we bound the tree at f(n) for an input of length n - we lose nothing. Strings that are accepted do so, and strings that aren't clearly still wont be in the cutoff time
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wpdXN11Xl1V1M41ECP23tL8OR3Hfr5gAmSaf2bGYoNnQ3wpsGQomlG8ehvjFQ6I_g_DbrT1_4Ihou9rn3dW6zPg0DrdxKhdqalaA0j_dIZVw2i-RYLeBoWUt3DkzqZOU.png) 
        - NP 
            - A language is polynomially verifiable **iff **it is in NP. 
Give a run through of the proof for this claim. ↓ 
                - ⇒ Assume L is polynomially verifiable. RTP that it is in NP.
For the language {0, 1}, consider a NTM that takes the input, and appends a 0 or a 1, then another 0 or a 1 and continues for p(n) steps: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cOPDRwhcmI_pCoIdkjdWxcLLRslraHinHB4DgMSXvTDONGA8MC2k3nRDkEyRpF5XmtIJzIOpv2J5nij1ISBSQ-6Zarp2ro2FZvyOXuPK_BTDO1z60KdAQhrvOtGTgPuL.png) 
If an accepting state, this NTM will have a branch where it accepts it - otherwise it will reject. All in $\text{NTIME(p(n))}$.
Therefore, this Turing machine is NP. 
                - ⇐ Assume the non-deterministic machine M that accepts a language L is in NP. That is, it can accept/reject a string in polynomial time. 
RTP that L is polynomially verifiable.
Take V to simulate M. Take C to be a string which **deterministically, **tells you which branch of M to follow at each step - this will either accept or reject in polynomial time.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BoMSLUJEPCeSwvPIJiCovJXO1u6gKp9KS9MAp005aHdnmEgESS83cEq2XvwxZBJwrd78J8yLHmkS9Tv0OqvsOqa3uh6KwFDesmUxZVnHkeZ37rXisoaxR2fk3GGHqxOh.png) 
        - Generate and Test
            - We can think of nondeterministic algorithms in the generate-and-test paradigm:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/atPmJfzPf3yIKyIFSYrUxIzvffIuXZmN9bzuwgBGit39IE7RFof3_1cWJc-W3WT8BmurQ6qqOrqYJzR9cfrQC9eWIWY1JdbZoQL1eEQkrBZT0cwUH9__i4LNCfV04zqv.png)
Where the generate is {{nondeterministic }}and the verify phase is {{deterministic }} .
        - Reductions 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BkLVLu07OTSyXnGGNKapmGr5u4feGU8TOoHgEhajJgoEzzwGT_-rHNErz1biQgtt1hOYnKGJxL9WthU06ySQsPO8z8wTAoq5gFEBpBqXcAm0XWeCC1DltQIg86ItScOv.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aBJIkrhqtR918iYAQCfHC5o0AsB1iCj6oh5PxXiTEKjRfFEQ-gt3drk91PtipEacV658y1rUZNqR9GNt95zSZJ772I9s2ac1RoC9aNQcMofjcSJPHMMA4emBCZ0VEaDG.png) 
            - What is a reduction?―A function (call it $f$), which given two languages L1 and L2 has the following property: If $x$ is in L1, then $f(x)$ is in L2.
I.e. a method of mapping from strings in one language to strings in another.
            - Given there exists a reduction of L1 and L2. Give a quick proof that if L2 is decidable, so is L1―For input x from L1, compute y = f(x) - then decide if y is in L2. 
We know ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hMHi0ixunUKSHGYrWBnjQnD4VfEFUgv8au7zhNWNjv7ptUCzN17N11Ad-64FD9eoW32CAMUfiHq0BCsT4rvmK7AfZOwqMQwO7rnZojfaqMdBAMH2vQWYmFiMZnVvUzip.png), therefore $x \in L_1$. 
            - This also tells us, if $L_1$ is undecidable **then so is **$L_1$ and vice versa. This follows from the IFF. 
        - Resource bounded reductions 
            - If f is computable by a polynomial time algorithm, we say L1 is polynomial time reducible to L2. 
We write:
$$L_1 \le_p L_2$$ 
            - We can then say if $L_1 \le_p L_2$ and $L_2 \in P$ then $L_1 \in P$ - because computing f is polynomial, and verifying a given f(x) is also polynomial. So the whole thing must be polynomial.
            - In words what does $$L_1 \le_p L_2$$
actually mean?―In computability terms, L2 is at least as hard as L1. E.g. if L1 is not polynomial then neither is L1.  If L2 is polynomial so is L1.
Think about the fact that this is saying we can go from an element of L1 to L2 in polynomial time.
        - Completeness 
            - These reductions is that they allow us to establish the relative complexity of problems, even when we cannot prove absolute lower bounds.
            - What is NP hard?―A language L is NP hard, if for every language A in NP $$A \le_p L$$
So if we find a P time algorithm for L, we have one for all other languages. Since we can map between them.
            - What is NP complete―A language is NP complete, if it is NP hard and it is in NP.
            - 
    - **Lecture 5** (SAT is np complete, compose reductions)
        - SAT is NP-complete 
            - SAT in NP proof
                - To establish this we need to show that for every language L in NP, there is a polynomial time reduction from L to SAT.
What do we need to do to show this?―We would need to show, that there exists a polynomial time function which maps a string $x$ to a formula $\varphi$ ($x \mapsto \varphi$) such that $$x \in L \implies \varphi \ \text{is satisfiable}$$
and $$x \not\in L \implies \varphi \ \text{is not satisfiable}$$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SE5lg3WQaWSP1820iBXXY-yQjYNkW2egRKyqPPwEqd0PkKUOHH7ibI-vM5pKIzAgwWJ7vB1UN4GzXbB3tqSfuSLmYgJlYVwmC0r8qoXSjuzn2HUEdELZnK3MaFn8mVQf.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Jj0_NKJYXpmz9U5Eac4ko7gafr4nX-CSVGsqkSSGDcnbuSBztUzIWPbcPmNmzidwowKkLVLfQ2gWa2fg46xkKHoxepx8zqdVOgHc2kUJWlGXCeuHkJsaXc1kS-ncmXMz.png) 
                - The total number of boolean variables is $$(|\Sigma| + 1) . n^{2k} +  |Q|. n^k$$
Which is clearly a polynomial in n. 
                - What does this mean: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oMz3Z7vpTBvltpGkEnn3rOWgEnd87_ika3qjXCcTX9VANBkN_Hb8VkaJIIl7_TNjqUM64MzIvUiHgAn8dsixpn7YtWAIfnztXMiHHkCeaLgQJ_WOVNx7jDmI3b7SJROI.png)―The head is never in two places at once.
                - What does this mean: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nOiMh8k_jUGWi6ccpGMQ0duLiDNEe-TwUSp_i38mmc5aIUxi5LRdExMf8T9y84-TwMLzW2k0etmDqvKDT7NpMCY9yxtE-iRkGBJywzpfQ3RWPEOCTJr83-OMqBPzFaga.png)―The machine can never be in two states at the same time
                - What does this mean: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3yo-MOJTElHwnpRST7LsISwLNZBU9rXJryCjmB-2LUtF3HUSJM974pBOqmVBlhvlekj8mNdgDbi1XW7Fos5vwbHZpf2I83zgzXjabv1bEH1Ya_KcjUOkUghBMHnN_66Z.png)―You can never have two different symbols at the same place on the tape. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nGSJl-BmbB7ii7aUgve4Nq3eOX5jDsavplpS8LrRyB7yXURx_dIC1t7H2FtN2Mxb-Y-jhORVfw5_jq_9d9Lzjj8leY6txGSNbSGTUMiUhNzVxUIbgYOCkd0gpsyQucVO.png) 
                - Explain this, you bloody idiot hahaaha:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rytWPekMhwhV460rP7u3NOcKq0ZWwYFpI1qbDDpDQngWzD0Y9o-UY5CjIQHjl9Ek1q0SHmRW5cSwZKDFnMLwQQ0jhrb5BpnbreHDZ2R_OOjrGjKGATlA4zSVOri7wjWP.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZaejmvmYP0etW1X_A7uS1E1gpU7_89MKBA2bviiPW-2NRlp0dI5flibG0N0aqbQRZcuAJNECmRZ2TKeGdSKg9-LxEoeAYIQwEZBhweiCjk4AlJcAb2h0xONPZOiIO-8t.png)―This means all changes are done according to delta. We iterate over all the possible transitions and ensure that the new result is in there. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2V7AwZupanlbDAgN1eiL2tCju4Mz1VF3gW7NhzefjzZZdncdwto8C37PxT_xH-PZtWqKD0g-ntlGD-DWI70qOOnA8sk9o0N0ovDGFFbnDKGRefsNA8fYos2hxFzQKVKw.png) 
                - Describe the basic idea of the proof that SAT is in NP―We're going to come up with a function that maps every string to a formula that represents the **accepting computation **of that string. We do this by mapping variables to actions on the turing machine - i.e. by ensuring all the transitions of the delta function are represented, ensuring the accepting state is reached etc. ~
So then if such an accepting computation exists on the string x, then the language is in L and the corresponding boolean formula is satisfiable!
            - CNF 
                - Conjunction of a set of clauses, each clause a disjunction of variables or negation of variables.
                - Conversion a boolean expression to CNF can result in exponential blow-up.
                - But we can convert our SAT solution above to use CNF, this means―That the more restricted problem CNF-SAT, is also in NP.
            - 3SAT 
                - A boolean expression is in **3CNF **if it is in CNF and each clause contains at most 3 literals. Note that not every boolean expression can be represented in 3CNF.
                - While we can't represent all boolean expressions in 3CF - there is a way to represent a boolean expression in 3CNF such that if the original formula is satisfiable, so is the resulting one. How is this done?―Hook them together like so:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bmhpbw8d5VOzfiBXKXbxZo7MBhnXxOYwdTxc1nuzQDtm9ZJ5Sxi4RsdEdjpN8SRQ2QsK7DFS2jLQrTU7n_ODh9sNpJ3SsDSbhVOZgbH9ayqPa530joCZhDoS5AGmZiVT.png) 
                - This hooking translation can be done in polynomial time, so we have $$\text{CNF-SAT} \le_p \text{3SAT}$$ 
            - Composing Reductions 
                - Note that polynomial time reductions are closed under composition: $$(L_1 \le_p L_2) \ \land \ (L_2 \le_p L_3) \implies L_1 \le_p L_3$$ 
                - If we show for some problem A in NP that $$\text{SAT} \le_p A \ \ \lor \ \ \text{3SAT} \le_p A$$
it follows that―A is also NP complete. Because we've shown a way of going from any language in NP to SAT. And we've shown that 3SAT is at least as hard as SAT via:
$$\text{SAT} \le_p \text{CNF-SAT} \le_p \text{3SAT}$$ 
        - Independent Set 
            - What is the independent set of a graph?―A subset of vertices with no adjoining edges. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0AoJJ5-lPqopyLcgCzlRc-I4rYjACov3pWGQEJH2waAQJ30EmhKt6Rm29TUq-Gy8vgozaW8sGA61pQ4D57rfZrITzQi_y3c2e0dR3GpUiLW7BjzTlDucfKUKbHWVDamO.png)
Why can we turn this optimization problem into the decision problem―The decision problem is at least as hard, because if we have a polynomial optimisation solution - we clearly can modify that to solve the decision problem.  
            - How can we clearly tell that deciding if a graph contains independent sets with K or more vertices is in NP?―Because a polynomial verifier is easy to generate. Given a list of K or more vertices as the certificate, testing those will be polynomial.
            - How can we reduce 3SAT to IND? I.e. find a polynomial time mapping between 3SAT and IND  ↓ 
                - A boolean expression in 3CNF with $m$ clauses, will map to the IND string $(G, m)$.  
                - We obtain the graph via this:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p2lDZSP9SvHu3vhXcDDhE8m6xGDz44fFBt9Knm4Ai_pPx9C8Q5IYZNcFIQKsH98VSZmAK0VtawYlAam2ujEaqXCfahGmk7SfjfVgIuaTlj5zqSmJYD-mwFLmXNw33fvn.png)
Like this:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0beB5zQkOMzevz52qH-He7IPRIuB0kw_e_uw8iZGbwCb3xypF1XuS48-m1ZpjRHUC0o8hd5TCZEzjeCAsDyDOhS0poFzd-Rz5SwFECoOZgXUitBBVlRFMqqgAxoDEuuH.png) 
                - So, we need that if $\phi$ is satisfiable then G has an independent set with m vertices. 
Consider that this is satisfiable, iff no two connected nodes are true at the same time. E.g. we can pick one node from each triangle.
            - 
        - 
    - **Lecture 6 **(k-colourability, clique)
        - 
        - Clique 
            - Given a graph $G = (V,E)$, a subset $X \subseteq V$  of the vertices is called a clique - if every node is connected to every other node in $X$.
            - We can massage that into the decision problem, where we test if G has a clique with K or more vertices. 
            - How can we quickly determine that the language $\text{CLIQUE}$ is in $NP$?―Given X as a certificate, it seems obvious that we can polynomially verify if X is a clique in G with K vertices. So, because such a verifier exists it's in NP.
            - What is the complexity of finding a clique of size 3?―It's $nC3$, but $O(n^3)$ 
            - Describe the reduction that tells us $$\text{IND} \le_p \text{CLIQUE}$$ ↓ 
                - We need a way of mapping from IND to CLIQUE polynomially. 
                - First note that the complement is the graph $\overline{G}$, is where you delete any edges and convert any non-edges to edges.
                - Then note that any independent set in $G$ is a clique in $\overline{G}$. I.e. if we inverse an independent set - they'll all be connected.
So we can go from IND to CLIQUE.
            - We now have the reductions:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vbSu0SSq1TlnsX1e9Fl83FAU8WghHWa13rW6qaYtPoFY22GyGr2iF9QK4EYRhgRr18_2hf8e4uXDvcOh8Wy9Sw49fXbLk9Bnf35IAELudYfKkxQfBkLsGuB8FwOiXRTR.png) 
        - k-Colourability 
            - A graph is k-colourable if―every vertex with an edge between them has a different one of the k colours.
            - The decision problem then becomes, find me the minimum number of colours required to colour a graph.
            - Describe an algorithm for finding if a graph is 2-colourable―First choose a colour for a node, e.g. blue. Then choose the other colour for it's neighbours say blue. Continue this, colouring all neighbours of each node the opposite colour. If ever you get stuck, the graph is not 2 colourable.
If the graph is separated, pick a different uncoloured vertex and start again in each separated part. No backtracking.
        - 3-Colourability 
            - To show NP-completeness, we can construct a reduction from 3SAT to 3-Colourability.
            - Describe the reduction from 3SAT to 3-Colourability ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HNa9ccf6lJSvlXIeE2snbPA1aJ8Y3tlqYsW8OOL82dvtycR68p4aboQMDLgY8sUWkR7-576w0hjDXLFjLX_XXnnBJQdEj-VQ3dKb3rIsWdykNLlJ8UnZtBGAP0hhw9Gh.jpeg) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eBEbq1shFIyOo85CAPO2FwXUL0wjYBlirP91juFASm0820PE50MXzq71Y0Km8gSv6JAXYeaN0zk5ZTr5O8X0GWNBh8rc7XLglbj-oePtl1kxZO8wkBSJAD4rYxna-Fvx.jpeg) 
        - Current reductions 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FK5PdD4f0x-XAY29McLuL6PdvIAQn0l81y4-DeFbyS9jA5pAXPvs54krCryrxZu3UP8u6tC4k6P1ucjCmDaS3e_C0qit8YaDEWR8fCSU9BHPEcTgSq-24eCr5FkumADs.png) 
        - Hamiltonian Graphs
            - A note on proofs using 3SAT 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LtzPVYLKQNIGwY9NPfDHylPQOwXpu7XqiYbueuUY5BuMHpfg9rflMzMCCo2ohs3oIm-wO-i-8d6ly1c5E7_HEKP1URX1megTfZHrMp2YevvBWeAqx75aicbPjJDMttix.png) 
                - When reducing from 3SAT to other problems, we have two pieces. We have the {{variable gadgets}} and we have {{constraints}}.
e.g. We have the pieces of the graph that encode a variable {{being True or False (some connection between }}$X${{ and }}$\overline{X}${{).}} And we have the sections that {{constrain the graph to behave as we'd like}}.
E.g: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BHAJh8QvrIRVLg39-RD0qk48MSvrRjDKuER22IO3kc6l3dTlYLSbBA6k9hgO_lhtDnyh67qIdlt-dNlz7iLeR9kRzpY-CBYaRdhhPa94R9XW6bntWhWwFybxX28JC9ON.png) 
        - Travelling Salesman 
            - Decision problem version, does there exist a path which returns back on itself and has an explicit target cost $t$. So we pass: $$(V, c:V \times V \rightarrow \N, t)$$ 
            - Clearly the problem is in NP, we can verify it using a certificate. Total cost less than or equal to t.
            - Describe the reduction from **HAM **to **TSP**: ↓ 
                - We're mapping $(V,E)$ to the triple $(V, c:V \times V \rightarrow \N, n)$. 
                - We can do this by making the cost function:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_KT34ohpyQmGXJSK0yszyqwbLVQMf73I2BfsVu9mm0qc75UgYwmu5QWspt2CodhRCUE4NVIdQQHXmHPet1zClJkHfajt1_gc7mv7Gu170sqScdt3fFBaU6_O3lOuhxLj.png)
This will mean the shortest path will always be the Hamiltonian cycle! 
                - So if a Hamiltonian cycle exists, then there exists a shortest path of length n (Where n is the number of vertices). 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/czqnrM54kQYkDEnPmdKz2MscJUy61K1PWvqEj4mhH0h1ALgH8o7VIL02mDBwdeWUuw2mcUkza2CB1za_Ze99-0xQ4fDUxomfWpIaN0MXtmFdIuECBgsEXcAwiy45hnXp.png) 
        - 
    - **Lecture 7** (3D-Matching,Knapsack)
        - Bipartite Matching 
            - Problem where you want to match a set X to a set Y optimally - e.g. match all X to a compatible Y. Consider X to be your organ donors and Y to be organ recipients.
            - This is solvable in polynomial time.
        - 3D matching 
            - 3 sets x,y,z and you want to form optimal triples (x,y,z). The decision problem is―Is there a set of triples M', such that each element X Y and Z appears in exactly **one **triple in M'. 
            - We can show this is NP-complete by a reduction from 3SAT.
            - Reduction proof 
                - Take $\varphi$ to be a **3-CNF **formula with n variables and m clauses. We will then form X, Y and Z.
                - We create $x_{v_i}$ and $y_{v_i}$, one for each variable v and clause i. 
We also add $z_{v_i}$ and $\overline{z}_{v_i}$.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gMWXggiC7HhudRejVygtQCQuC-fLLpGywJA-apFLJbZwusp_3ENHbaMKDdZguVoIapXZZMVBlCO9Xq4q5Yz-3-Ot0jBCuHBf0fH5oxOjn-fhcbc5DNxuxVEepCYTFayO.png) 
                - We form the triples $(x_{v_i}, y_{v_i}, z_{v_i})$, $(x_{v_i}, y_{v_{i+1}}, \overline{z}_{v_i})$ for every i. Resulting in:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NfPLS6_g7dVcFos3DLjqhk9Iwf9b1UxQdozZqvhIULLaCieik65EjwRxl69SxJUz-KIkXOg7798DxBMe_h3jiUbjzOxtq_JVHxeDbUKvACEIz4Q1lE4WJ4OJ2dsGmZVp.png) 
                - So every element of x appears in two triples, every element of y appears in exactly two triples and every element of z appears in exactly one triple.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MCJADSq8PzoobScy8wBLh9Xf01275a6lXJ9IFQgdeE-Gfugf0W8YrOJQ20J5hZghoa_OWnAAXqSpnVN2WgwmgLR2RCbftSJsxGruU0BgxBdzmOh_ONbBbk3UBgxVY_06.png) 
                - Note that when we take one triple, our next actions are forced. Meaning either all the $z$'s or all the $\overline{z}$'s are free for other triples.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WEO6MzLl2AzrZkc89xLelPDoAFlpMoYMMGf01Qztu5BSIayXG8vD7pPDdpNKpSmdcSmcz6B_MC4aQV33SR5ItewU6eAgfKGHuiuDUMsFt-Up-YWC2w5NKA7kiq2tHQZ1.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ctC51e6cRZfjm6hYajJbIucd24TTMAAucRewT9zIEbWvaMpW7KiUpJMneKAjlnPybd227rWj-cJfZeFy5m85qFAvuDe82aDnv5UOD-sizoLfpsBPcYA9HmpvayBDs_4n.png) 
        - Set Covering 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jh6OLvU9FDLa7qRff2SPYxHdeFQxNk8HhLc-9yJP4_gkesW87w4PTtPoMt1bT_4lvMPG5smZpHH8nLJbzESeTyk-v9HOrbdeROS9Cie90Go9-Kgg3S7fJ56n_Qv0Ms5F.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j4NJd193NEkbSI23VblHsFNVeQPUUsXqGFCf-AHr1cPECex4BsmWOcwR4DWoHJnHFZY8CZ3fnYQzAhlcNVc0-O1-tZwuq-mxAxOpOBV5fuxX_RHGI26rW1_CP0yYeisp.png) 
        - Knapsack 
            - We are given n items, we want to maximize value while minimizing weight. Can we select a subset of items who's weight is at most W and value is at least V. 
            - Reduction proof 
                - We will reduce from the Exact Cover by 3-Sets.  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CAhhuQTyCBDYgPCuvzTg5sbsCWKu91uoKwiAzhEX1s8MDRdQXqbSujqep5ghWheRhsusECYpXaKUgZfb4LBjy-zT44i3n1hvdpjzaQbyquUUAKL8IBb67DkDMQf38pT2.png) 
                - 
                - Consider a table containing each subset S and the items 1-3n. Then we can form a binary number encoding which items each subset contains. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gvm4Rr3y6WmNuK0NIj81TnEbqf5XpZdGSQ3kRgiyvl8Tziag0LZtkMgi8iiOtzMenIZqTBXhPGgB5Tzniq6FBcENSC2RiJSsasLmeYGzO5UNOFB4_B6DS-6k0Zf2L9_I.png) 
                - The question then becomes, is there some sum of subsets such that the result is all ones (11111...1111) - however this can result in a carry in binary. So we view these as numbers in base (m+1). So we can never get carries.

                - So for every S we get: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZVMlKa6HgWVyChtu4AP5LbLfDnmxcwAwspUoAUg9AuGrnf6WbCGECr2UZrqoShyVpNV0yHvaOugqsN7KSb6BGDVsxqSWHJ3I_P4hS8xnwyp6QGFp2vwAy_vVQhFVo6Kv.png) 
                - The the target weight and value of all ones is: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7qJxiY7KGxuxcLXsbt-G5oPS09F-zIiQbJhbjH8KXRtME2yOlTQL7CBk1TShgpTt--l2o4wQHNmS8Wyv4Nf1KtwSBGYP3W8fW7eo7MOVnaJZq8BOihz8BeuSBnRBITS2.png) 
                - So if I can get all ones in the 3 cover problem, I can reach target weight and value in the knapsack problem.
        - Scheduling: 
            - Timetable design 
                - Given a set of work periods, a set of workers who can only work during certain periods and a set of tasks and assignments for workers so all tasks are completed?
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AXo-n5HTNxG1dK8oCYoVdMyfP92aM-1MqaKwAcwhj8S6atIphVcxhgl5x0IBh7pSu-FyxokHjd-LowbIeEb1Z9KQqPkS77MvVRbqJo0v31IsOapbfRYMzNNBGCYGSV8P.png) 
    - **Lecture 8** (Co-NP) 
        - Responses to NP-Completeness 
            - Does asymptotic complexity matter in your case?
            - What's the critical size (n goes from feasible to infeasible)? Is scalability important?
            - Are there guaranteed restrictions on the input? E.g. can we stray away from the worst case, e.g. is there a special purpose polynomial algorithm.
            - Will an approximate solution suffice? E.g. no more than double as bad as the best path
            - Are there useful heuristics to constrain the search? E.g. ways of ordering your choices that reduce backtracking
            - Can you use a SAT-solver? These are engineered to be **highly **efficient. 
        - Validity 
            - We define VAL as the set of valid Boolean expressions - e.g. those that are always true. Given that the inverse of a valid expression must not be satisfiable. We can reduce to SAT, by taking the not and finding if that's satisfiable.
            - We don't know if VAL is in NP, because the certificate would take exponential time to test.
        - Complementation 
            - If we exchange accepting states in a DTM, we get a machine that accepts $\overline{L}$. So if $L$ is in P then $\overline{L}$ is in P. 
Why does this argument not work for NP?―For NP we say a string is accepted if there exists a **path **to an accept string for that state. There can still be a reject state in the tree. So if you flip the acc and rej steps, there can still be an acc in there:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pmQ25jUdBrAZ46IZehmcUWtPm16ubkc7ECQdz6du91FzjoaW889XBGH5CroXOFPkfnQxo-MptoEg4TtCWxls0SgzpeMvVZAXmKx45SW7LFqDjpJ2zVLj4iYAuB9Hxk5M.png) 
        - Succinct Certificates 
            - NP problems can be characterized as $$L = \{ x \  | \exists y \ R(x, y)   \}$$, describe the conditions R must satisfy.  ↓ 
                - R must be decidable in polynomial time, where y is the certificate for x. 
                - R must be polynomially balanced. I.e. y must be succinct. E.g. there must be some polynomial $p$ s.t. if x is n characters long then the length of y is at most p(n).
        - Co-NP 
            - The languages whose complements are in NP. We can thus take the complement of L and find: $$L' = \{ x \  | \forall y \ \lnot R(x, y)   \}$$
E.g. x is in Co-NP if for every string, all certificates deny it's membership in polynomial time. Written with the bounds on y we get:
$$L' = \{ x \  | \ \forall y \   (\ |y| < p(|x|) \implies \lnot R(x, y)\  )  \}$$ 
            - How do NP and co-NPs certificates differ?―NP is the language with succinct certificates of membership. Co-NP is the language with succinct certificates of disqualification.  
            - Most theorists think: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sKsbjpuKbuxQWxeoW2CB4dbBxcu4Ayi4yQ9eHS1AgbES6jXZrU1MoZxJZsj3JmXQRe6ACREDlUCKPlllMFBqR9LjW4y_qwqGbZ1nsFmol-8TGK2oqx0S0l4HwsZKBkGk.png)
E.g. all different. 
        - co-NP-Complete 
            - L is co NP-complete if L is in Co-NP and for every language A in co-LP $L \le_p L$. 
            - Why does $A \le_p B \implies \overline{A} \le_p \overline{B}$?―If I have a reduction that takes an element of A to an element of B - it must also take strings that are **not **in A to strings that are **not **in B. $$\text{x in A} \iff \text{f(x) in B}$$
Implies if x is not in A, f(x) must not be in B. 
        - Prime Numbers
            - PRIME is clearly in co-NP, as it is the complement of COMPOSITE which we know to be in NP (certificate exists). 
            - Is PRIME in P?―No! Because it's $\sqrt{n}$ in the **length of the input n** which is $\log(n)$!!! 
            - Testing if a number is prime is in NP:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E7cxkG7-47-7eTj-g5jLPHLxaF-bGj69wL7gYT2qn8QVYGG-fpvukedMO6QhT1CW2fmQcCopV6fKEWTcCZQyTQL1VeZiqaLBTZKMu8iX61o71rVZu9BAZrUwHc8TVSMC.png)
We take a number r and all the prime divisors of your prime number p-1 as the certificate. However, you need to check that all the prime divisors are really prime - so you do this recursively and the result is still polynomial.
            - Testing if a number if prime is **in P!**
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U1GC2X45o57hBKma1oEGTH68kSxb98cE2tyVupquXsl0054ECi8OFaOQDpL_EcUtkb_XEtTBNJNh6TYiHotEUfBu7lDu5-XFdaRS1zoB25gyamadL0qOTCjUywxGxeq-.png) 
        - Factors 
            - Given a number x and a number k, we ask if x has a factor s.t. $\text{1 < factor < k}$.
Show that FACTOR is in NP and Co-NP ↓ 
                - Clearly it's in NP, the certificate would just be the factor. 
                - We can also easily provide a certificate of disqualification, the prime factorisation of x - we could note that all values are above k and then multiply them all together to show they factor x. 
        - Graph Isomorphism 
            - Given two graphs, are they the same?
            - Shown to be quasi-polynomial time : $$\text{TIME}(n^{(\log n)^k})$$ 
        - Give an argument that $P \subseteq \text{Co-NP}$  ↓ 
            - We know for any language $L$ in $P$, $\overline{L}$ is also in $P$ as we can just invert the states of the Turing machine.  
            - We also know Co-NP is the set of all languages, which $L'$ such that $\overline{L'}$ is in NP. 
            - From 1 all languages $L$ in P are in NP, and from 2 $\overline{L}$ must be in Co-NP. Finally we know $\overline{L}$ is polynomially computable and thus in P.
Therefore, $P \subseteq \text{Co-NP}$  
        - 
    - **Lecture 9 **(Cryptography and one-way functions)  
        - Factors 
            - We know that $\text{Factor} \in NP \ \cap \ \text{co-NP}$ 
        - Cryptography  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/urgOB-faxvwY8VPdBKAxLLPMiyvlf4DIVWiTI1Fs6tg-JO1jggu_bsB02XS3oYlXv6vWYN38V6uwpEivOcB0LL_7Gb_it8S_d2nRMR4QSHuQBrOWqsCx6X1AyNfukger.png) 
            - In a **private key system**, we have the encryption key $e$ and the decryption key $d$ and we have two functions such that: $$D(E(x,e),d)=x$$ And $e$ AND $d$ are secret! 
        - One time pad 
            - The only way eve can decode a message, is by knowing the key.
If the original message $x$ and the encrypted message $y$ are known, we can get the pad.
$$e = x \oplus y$$ 
        - Public key cryptography 
            - Encryption key $e$ is public, decryption key $d$ is private! 
            - How does this set K relate to public key cryptography? $$K = \{ (y,z) \ | \ \text{for some }x\ \  x \le_{len} z , \ E(x,e) = y  \}$$―If this set is in P, then we can use it as a black box and find x with a binary search. E.g. exhaustively search all the possible strings. We also assume $|x| \le |y|^k$.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NGw00WuMszeIgx4HAeBAoeGKkji5ORsInC0ObTWbSQdaSbIjVjyliOi02jBP0btIh9qCY5q2FoZPLxm0Ji1Qm1GCEc4Bem_ddgv7OIBfWG6tt1Hz6sbbhc_r878mZAyM.png) 
        - One way functions 
            - One way functions must be:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VeRv1DR0puQ0rCzvK8DLlmQ4aS1Jxr7TMn38pj-INhIR_nynFl0rNGr6q5Q4a9uUziN7rMQEnz4FNqlEYxI3wB2T1HKdwpMwCi2Dxlkhrxa444pbvMTMdjT7H_pc9-25.png) 
            - We can't prove the existence of one way functions **without at the same time proving P ≠ NP.** 
            - We would like to build our function such that the inverse is definitely in P, rather than something like FACTOR which we don't know if it's in NP or not.
        - UP 
            - A nondeterministic machine is unambiguous if―For any input x, there is at most one accepting state of the machine.
            - UP is the class of languages accepted by an **unambiguous NTM, **in polynomial time.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GvHjU4A9gJtxjr8UtE1m79CV0nN-VZJvqzRgApurflBXz-7GD9id8YGrb-MkWdPhrGBHvM-sYoyDr3fMkGDoqRlaQmMkVTMmaHE5UsJB9KRLCBYHq6cRjh-Kgx1APiRI.png) 
e.g. **There's only one certificate!** 
            - Why is $P \subseteq UP$?―A **deterministic **Turing machine is like a unambiguous NTM - Theres only one computation path for each string! (and it either accepts or rejects). 
            - Why don't we think there are NP complete problems in UP?―?? TODO TODO 
            - One way functions exists **iff **$P \ne UP$. 
        - Proving one way functions iff P≠UP 
        - One-Way functions $\implies P \ne UP$ 
            - Suppose f is a one-way function, we will define the language $L_f$ by: $$L_f = \{(x,y) | \exist z. (z\le x \ \land \ f(z) = y )  \}$$
We will then show that $L_f$ is in UP but not in P. 
                - How do we know $L_f$ is in UP?―Because there is only a single z that can be used as a certificate because f is one-to-one. E.g. A non-deterministic Turing machine generating all the possible z's would only have **one **accept state.
                - How do we know $L_f$ is **not **in P?―If $L_f$ was in P, then $f^{-1}$ would be computable in polynomial time. However, this is a contradiction with our definition of f.
Because we could use our $L_f$ decider as a black box, and do the binary search.
        - $P \ne UP \implies$One-way functions exist 
            - Suppose L is a language in UP but not in P. Let $U$ be an unambiguous machine which accepts L. Then form the function $f_u$ which does the following:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8Eh-ifXYSDGqBcuCqd8J9IeO9ELC_AtQ0fMDqpUInLGoSyVS6zOaQKnh1m7HVNUs3-xazBNiM7X42-NTeoCJuKollWKoiVOY-3NMD7P7WdQE6yGDoyEIbDvcl3JS7qNK.png)

                - Why is f one-to-one?―Clearly, for an input 0x there can only have been one input - x.
For 1y, x must be an accepting computation of y - and because U is unambiguous, there can only be one such computation.
                - Why is $|x|^{1/k} \le |f(x)| \le |x|^k$? ↓ 
                    - Clearly $|f(x)| \le |x|^k$, as the length of f(x) is $|x|+1$ OR $|y|+1$ but y is in the first configuration described in $|x|$.
                    - RTP $|x| \le |f(x)|^{k}$ . If $f(x)$begins with a zero, then $x$ is strictly less than $f(x)$. 
If $f(x)$ begins with a one, because U runs in polynomial time - the length of input y is less  
                - f is clearly computable in polynomial time.
                - Why does $f^{-1}$  being computable in polynomial time imply $L(u)\in P$ ?―Given a string z we simply add a one to the front and apply $f^{-1}$. If the computation this results in is valid then we accept, otherwise we reject. 
            - So we rely on $UP \ne P$ for one-way-functions to be correct. 
    - **Lecture 10 **(Space complexity)
        - Space Complexity 
            - We define SPACE(f) as the languages accepted by a machine which uses $O(f(n))$ tape cells on inputs of length n. Counting only work space. 
            - NSPACE(f) is the class of languages accepted by nondeterministic Turing machines in O(f(n)) space.
            - Some definitions:
L, NL, PSPACE, NPSPACE, co-NL, co-NPSPACE
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PumdKfa1TGUy-C0AHhPFzS1cmQfwTrg9dAsC4Va_dTUxU6SS5QC6GwOGSNRHsIYU8RYkbDfEPDHalKiHtDIrdfLgHP9d8dwc0v9AfLzbpJmJsZbXTnM8SgiJVYD2zZ0R.png) 
            - What are the languages **L, NL, PSPACE, NPSPACE**? ↓ 
                - L is SPACE(logn) - Deterministic Turing machines which use logn space. 
                - NL is NSPACE(logn) - NON-Deterministic Turing machines which use logn space.
                - PSPACE is the languages decidable by a Deterministic Turing machine in polynomial space 
                - NPSPACE is the languages decidable by a Non-Deterministic Turing machine in polynomial space
        - Constructible functions 
            - We want to prove $NP \subseteq PSPACE$ - and we will find the more general result $NTIME(f) \subseteq SPACE(f)$. It then follows immediately that $NP \subseteq PSPACE$ for **well behaved functions.** 
            - A function is constructible if  ↓ 
                - It is non-decreasing $\forall n. \  f(n+1) \ge f(n)$. 
                - There is a deterministic machine M which on any input of length n replaces the input with the string $0^{f(n)}$ and M runs in time $O(n+f(n))$ and uses $O(f(n))$ work space. 
Kind of saying if we can compute f, and we can only do that within the bounds of f.
            - If $f \ \& \ g$ are constructible then so are $f+g, f * g, 2^f$ and $f(g) \text{This last one provided f(n) > n}$ 
            - Describe how this :
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/twsCLVoV3hUrfQluCkHCAxYtD_4UQ1F-5tzJAMZ3EOWlMnCaWMV93OrpGlOjZcJZkyXJ__G6Ewb2n2XMOXQ-14h2-m_Oqp2WZhVnb0r6lShMXh0IMdy2E67dOOg6ecjD.png)
and this
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dvqgObyZ04TMBjRtRnMqfg-EYSX5q5fS10NSKEwcwrOAjatCwBq0dmag26Juj02Uj21SJ_QkcV70sFaaLYcYJcO9WrKACrugSQk9s35Rx5Ao3lW4SCWt1mwcIkUkpRHp.png)
are related to this feature of constructible functions:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9-MeDGxRFI6U-aXEW-iEw2lX8s31D6HUF4gNYP6_kFK77Hhqcs9ZjRPooLqFhSizdTwBlZRacRQ-Z_sMI577S20ntT2syhiD-WzsdGjen2lV77MxSVu6Wfywt7LlTzXP.png)
 ↓ 
                - The difference between statement 1 and statement 2 is that statement 1 doesn't contain the "there is at least 1 accepting computation of length at most $O(f(n))$".  
                - The machine in which **all **computations can be completed in length $O(f(n))$ is just the machine from 1 but cut off at f(n) steps. This accepts the same language.
                - This is why we need 3. because we need the overhead of computing f(n) to not impact the time complexity.
        - Establishing Inclusions 
            - We will establish:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BxKCNjbrkDAJ8OtfDrnaXNF9t3a1Rr8LG19TrMGTLibhZYXvbRYp3bX2DEu7aB0izpkcL6MXyAW2ZFIxUIeQiypHvuWUEsN9xRacYXzwIj0KM-MwGTqixMRSi4ob9ehE.png) 
        - Proving $\text{NTIME(f(n))} \subseteq \text{SPACE(f(n))}$ 
            - Consider a non-det machine:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/alqunfr2-dOJvrG7na2KbLNERaX5CQxsImMuBjopuH-vCLigXpIS1xdnVdy_7lAevjQuu4jrLZPbKyB9SlQrLbLPic1Lu7ZqMP4Ry-qu7tiv2Gr2Q1eghqEGkO5k66QN.png)
The branching factor is determined by the machine, and the **height **of the tree is determined by $f(n)$ (as long as it's constructible) 
            - Breadth first search by a det machine would have it's queue grow exponentially in the height of the tree. $b^{f(n)} \cdot f(n)$ 
            - Depth first search by a det machine, stack grows to at max $f(n) \cdot f(n)$ because we assume the size of each configuration is no bigger than $f(n)$ and the height of the tree is $f(n)$.  
This already implies $\text{NP}\subseteq \text{PSPACE}$, why?―Because NP is the non-deterministic machine whose time bound f(n) is polynomial. And any polynomial squared is still a polynomial. 
            - How do we improve on $f(n)^2$ time for our depth-first search?―Keep a stack of records of which branch you went down, this will be size $\log b \cdot f(n)$. Then when you reach a leaf go back to the start. You also have the current configuration which is $O(f(n))$. $$O(f(n)\cdot k + f(n) ) = O(f(n))$$ 
        - Proving $\text{NSPACE(f(n))} \subseteq \text{TIME(}k^{\log n + f(n)})$ 
            - Consider a non det machine in NSPACE(f(n))
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Iyd5yF4Bd_sTcvdMqSt5uB4WCIUNNFJCVecccU_srlXp4_uRVVWU0UvbvDszXldu7KILCUh2uWupUlyvvoXUAu1qOsPg0X4pKDI9uwyfokF4iEB3wiEPOLYHCo0pkIVt.png) 
We know only it's space bound, and thus if it exceeds f(n) cells used we can stop the computation.
            - The number of different possible strings on the tape is: $$|\Sigma| ^{f(n)}$$ 
So if you follow a computation branch, and it's longer than that - then the computation is in a cycle and will run forever.
So we have a time bound, exponential in $f(n)$ 
So we can simulate in $$b^{|\Sigma|^{f(n)}} \text{time}$$ 
            - Reachability 
                - Given a directed graph, determine if there is a path from two nodes a and b in the graph.
We can solve this with a simple algorithm in $O(n^2)$ 
                - We can simplify that to $$c^{f(n)} \cdot n$$ 
We keep n, as f(n) could be logarithmic or smaller, in which case n would be larger.
                - 
            - How many possible **configurations **are there for a non-det turing machine with input tape length x and working space bounded by $f(n)$? 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ncw714pwX6BWm7y4xgM1kPwfjrkmIffjok6MSJGgjfwtxJHnX1_XOMgdjdZGxMdFEH4VYD2HgrGxB-59Vx6KoM2GhVLVl24x8q8KZ7zLVcIfVSARWZuJILzg3iymTr-M.png)―$$|Q| \cdot c^{f(n)} \cdot f(n) \cdot n$$
Current state we could be in TIMES
number of symbols that could be on the tape (before and after) TIMES
number of places the head could be TIMES
number of possible places on the input tape the read head could be. 
            - Configuration graph 
                - Define the configuration graph to contain all the configurations, with edges between them if the machine can transition from one to the other in one step.
                - We then want to know, if the accepting configuration is reachable from the starting configuration.
                - Using the $O(V^2)$ algorithm for reachability, and a graph with $O(nc^{f(n)})$ configurations we get:
$$c' \cdot (n c^{f(n)})^2 \sim c' \cdot (c^n \cdot c^{f(n)})$$
We can bound n under $c^ {\log n}$. Then: $$c' \cdot (c^{\log n} \cdot c^{f(n)}) \sim  c' \cdot (c^{2(f(n) + \log n}))$$
Finally:
$$\sim k^{f(n) + \log n}$$ 
        - NL Reachability 
            - Describe the NL Reachability algorithm  ↓ 
                - Each node can be represented in $\log n$ bits. Write the index of your starting node. 
                - The repeatedly, if the current index i = b - then accept.
Otherwise, guess another index j and write it next to the first. If $i\rightarrow j$ is an edge, then replace i by j and continue else reject. 
                - This will guess all the paths in log(n) time and find the right one.
            - Savitch's Theorem 
                - We can show that reachability can be solved deterministically in $O((\log n)^2)$ space. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aFAoAyIaolViowwg0w0j-R5coIUeobiF3e1TyiCjAxWzL27hJnux7wZcLJFg6KyOFSh1WVw3fwrO0EXBcscXSlFsmNTOYVmYOE3WDZNrkaZ8rfDg9U2iBjwzC39n47yT.png)
Finds the midpoint on our path - and connects the two halves. 
Depth of recursion is logn because we halve i each time. 
                - We can use this to show $$\text{NSPACE(f)} \subseteq \text{SPACE(f}^2)$$
As we can use the Savitch reachability algorithm to simulate the machine on the configurations:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HQIKleY1xv69iNluTd9gq_L-L_amHYiGEp6mzxb3NJdcSGJZzF6gG7mjfh0FbjSbunrbseS4XvMh44iRYiQ3arxbVos-XkdkO7-k0N_xOSeZKpSpWpbG70PXhVYAA-R8.png) 
                - Note that we don't store the entire configuration graph on the working tape. We only need the graph to check if a pair of nodes are connected - we'll simply check if a given transition on a machine is valid.
                - By this:
$$\text{PSPACE = NPSPACE = co-NPSPACE}$$
As the square of a polynomial is a polynomial. 
            - We also have that $\text{NL=co-NL}$ by a proof we don't cover in the course.  
        - 
    - **Lecture 11 **(Time Hierarchy, Logarithmic space reductions) 
        - Complexity 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jYOcpmRQcdutGXqGpWiq642-o4kqL_VvG0wiU9z8DDQjkwl9M4j7Lx2HUc7WLfcoPKg-5ECa0Rw2M626bPCqQQ-KkVthOE4mDs0I2sx-ZBhkwLpXbGjae_i2dRA4c_kt.png) 
        - Logarithmic space reduction 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0AUN9U4pdTU3aSbgqcXeW-pUveMv2cK5TH_tMYEcfmQMChPkwGvyH1vqxXzyTF0KuBRZPKQphtitiprC1AZktn3f84hzl-JHE4nPV9TdmvlQGTDXN4drGrWES6gZZl5W.png) 
            - We form a machine with three tapes, an input tape (read-only), a working tape (limited to $O(\log n)$ tape cells), an output of size $f(x)$ (write only).
This is what computable in logarithmic space means.
            - $$A \le_L B \ \text{means} \ \\ x\in A \iff f(x) \in B$$ 
            - Why can a logarithmic space machine by simulated by a polynomial time machine?―Because the number of configurations is bounded by some polynomial, and we can do the reachability algo to simulate.
        - Can we compose logarithmic space functions 
            - To compose the machines, we can't afford to write out f(x) on our second machine - so we need to do something else.
            - ^^Didn't really understand this part^^
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ik3U068KM75Y4WIGGaDovYi-eqkkhlVe0hOt4WVDfVa6CsY8SznKzFo1MnDR9SzayRphDOR3n0tJrOXMJEII8eS1z6VijVqgPUaiQYLnhRWtabVpDfwQzl7iQgJbluAP.png) 
        - NP-complete Problems 
            - All the NP complete problems are complete under polynomial time AND logarithmic space reductions.
            - Clearly any logarithmic space reduction is equivalent to a polynomial time reduction - as they are equivalent.
            - Don't think you really have to understand, in the polynomial reductions the space used is very small.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/D_us1qbSGGCuZmb_rZlBKxhqUhcukTimV7vPdMOEpis7VRgvbsYKgaNwT55jstafJMUqA6_slDaeNDxvxd52daYNnoYiJnaMA4lMkDyZBwLEaDSqqS4ZQOiCFqU93-UT.png) 
        - Circuits 
            - Compact way of representing boolean formulae:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FkYv3dc_pbOJ4mOoMfiXc80CaoDJ8STqTiHgEi6zX2yBDpdsOb7gtudAY8X3SQ5d35TSdmg0jSptGodB2nPRTdLx3OSy_G7VtBRNy1fHZf4-B9Uq69mLRx8_QNNkF6pg.png)
Where subexpressions don't need to be repeated.
These can be so compact, that translating them to boolean algebra results in an exponential blowup. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JW9zBwqZ2Vh1JiJ4DG0zOttsI2p5ndK4jU5aAaY2TrIOOf7ZMrxZHYLopJv2Xol5j90WEb8BCEp2n-oYibM8vf1f0Yh0T0ScYid4bRRZ1p3p_XmoZqgJ7vG3-wuK2qkQ.png)
edge (i,j) then i<j just ensures an acyclic graph.
Every node V has indegree at most 2, just means each node has 0, 1 or 2 incoming edges. 
            - At each point $\lnot, \land, \lor$  you evaluate the result - until the final node when you have evaluated the whole circuit.
            - What is the circuit value problem?―Given a circuit, determine the value of the result node n.
This is solvable in polynomial time.
        - Reachability 
            - Note reachability is NL complete.
        - Provable Intractability 
            - We want to prove that some algorithms **cannot **be solved in polynomial time. We can prove $$P \ne EXP; L \ne PSPACE; NL \ne PSPACE; \\ NP \ne NEXP$$ 
        - Time Hierarchy Theorem 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JgVEygqFs-5LrQfwa9wABjqiaco32-4yVFyUACoA4KZFR87pZzW2nIUuRhSa421SVYnz9tRENwUXNVeIR6SN7xHHTdkr9HtxSfsSkeObWHK5JeiHnwk6R7GiMO5t4aE0.png) 
            - The f-bounded halting language is the language of encodings of Turing machines and inputs s.t. the encoded Turing machine accepts x in $f(|x|)$ steps:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YFvad_rknv_6y70xG74DduAmBxjFRKbimxIQp6qySs__JYTkR31Z_3fHnkd5TQup-qf3JzFAJVria3aAyBae0QxyQ4kV_kB_PeZkXCLB6cNfs_lPqsbm6jtZ-jMLQt4T.png) 
            - Then it can be shown that $H_f \in \text{TIME(}f(n)^2)$ - 
            - We do this by first putting [M] and x on the tape, THEN put a marker inbetween and calculate $f(|x|)$ to use as a counter. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ro015jaiCXaMC9_nKBuNklpFZk0UGBHVW2WyNEMbn07_iRCkXWkx62bjQK245FPSpybhSHaX2mX7q8RAMxh3L--DktOH4ukbLfzNJEwWa-4hHvMSttsBgxV2iITszCtn.png)
Then we simulate the machine to the right of $f(|x|)$ - and at every step we check of one step in $f(|x|)$. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_s6IGCBTQC4w4fHYpf0OYn00tHyBLHHG9tcUSIARljSp0bOBlT8EDtl6-Eofxq3Z8sJR8Rs4e5mjp-3uVnK9FiehYOVdi7JDDxKhsgN_ll35g9J2yUqKAkqzCx7CJtbI.png)
If we get to the end we reject, if we accept inbetween then we accept.
What is the running time of this?―We first write $f(|x|)$ which takes $f(|x|)$  time - and then at each step walking backwards and simulating takes roughly $f(|x|)$ steps. Therefore the running time is:
$$O(f(|x|)^2)$$ 
            - We can also show $$$$ - we do this by proving it's undecidable using the halting problem diagonalization argument
            - Suppose $H_f \in \text{TIME(}f(\lfloor{n/2 \rfloor}))$ - 
Define a new machine N does the following:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Spq1O7MzZi1XPNFYdshhxhtUNg57tqsM2Ba3Rq6rSVV3D-JCo8tixoVTPiBpYOWtR5haoWfX3ruJ8WRTmC4RdGcNCEfaDEze8r4nHNHLOOnuvoaj9ZVdR73Gy5h7zLSu.png)
Then note that the size of the input is $2|[M]| + 1$, THEREFORE this takes time $f(|[M]|)$ by our assumption.
THEN feed N input [N]:
N accepts [N] $\iff$ [N][N] NOT in $H_f$
                        $\iff$N does not accept [N] in
                                 $f(|M|)$ steps (by definition of 
                                  $H_f$.
                        $\iff$N does not accept [N]
 This is a contradiction, so our assumption must be false.
            - So we have generated a language which is in $\text{TIME(}f(n)^2)$ but not in $\text{TIME(}f(\lfloor{n/2 \rfloor}))$. And as $(2\cdot \lfloor n/2 \rfloor +1) = n$  we have the time hierarchy theory.  
        - Consequences of time hierarchy 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TBM-fT4fxWy-aCL3EmGFoe-lEYMpkrIviKya8asVXw2zsCAcGKhikH0u9b-bZMNbOWk8uPeMuFVDitJT5cZZlL_mgvUZmb70lFQuB8-5jOB8VERx_RZIDGIUppQQdLaS.png)
So there's no power where we can calculate all polynomial languages with just that time complexity. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/c_Vs12d06oGEoNSBaIYJYrHwV2_OK1Bd6A1wK-C0fydCLkQkd5QJ3IWBt8X5oDvAlJcbIisDd_wmz69ukboiIfeMj30URNbc4ZpuQxxdpYIoADROumo3ie3hZUMH946c.png)
There are languages in higher classes of EXP, that cannot be decided by a lower class of EXP - Therefore there are languages in EXP that are not in P, as P is a subset of the lower class.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OA2kHhW7WxyGLKqjDeqQVSTWCoEeye9lfkRmS6w6x7T4a2gqskkYG_qyKEtCOn5vgfb070pnBtm6yRB5i7XUt3zdDYvrpJrSvm8VbIhbKK6H2Uyo-3e7f9sFWOU5Ffye.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qomP6ROLkmRHFMlJbQ8W5cCmmOdrVkMVSg5GXKmk1F9kW14-0zhCOxaAWZ0n52pgvt8bWE7TcjoNVS58BT8lksd5uGNsXLqNBSHlCvcsbCVGuoBMlSaj7G3K0i2hDtGS.png)
By the first one, theres no one power in P such that it can solve all problems - so there is no such linear reduction. 
        - 
    - 
    - 
    - **Supervision 1**  
        - Question 1 
            - Consider first that the salesman must travel to every node on the graph, of which there are $|V|$. Then consider the decision points of the algorithm, it must have a way of deciding between every possible route somewhere in the decision tree - otherwise we could craft an input to fool the algorithm. As there are $|V|!$ possible permutations of the $|V|$ nodes thus the length of one path along the decision tree is $\log( |V|!)$ (i.e. the number of comparisons to complete the algorithm) which we know is less than or equal to $|V| \log |V|$. So the lower bound on complexity is $|V|\log|V|$.

We can improve the lower bound by reasoning that there must be more than $|V|!$ nodes in the decision tree. For that we can consider paths where nodes can be visited more than once (which the above solution does not account for). For example consider a situation like this:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lXDN3jkO7leNKz8Qi1Q7eKre3KtgzuIeAVo-71M906flc3aXWXcw4EcMMyn1rLXjmmdQe1GYKqO1l8Bjx8OmViezYXTVQWRksAutc-mAXC4LzMErJpEBz-Rj_fTadS_e.png) 
Where travelling back to a node is necessary.
Consider, if there is no possible way of repeating a node we would just have a one way line of nodes. Where the best path can be found in O(n) time.
^^CONTINUE^^ 
        - Question 2 
            - ```python
def TSP(start_node, nodes):
    visited[start_node] = True
    Cost = MAX_INT
    if len(nodes) == 2:
        return dist.get((list(nodes)[0], list(nodes)[1]), 
                        dist.get((list(nodes)[1], list(nodes)[0])))
    else:
        for i in nodes:
            for j in nodes:
                if i == j or i == start_node or visited.get(j, False) or not dist.__contains__((i,j)):
                    continue
                Cost[(i, nodes)] = min(TSP(j, nodes - {j}) + dist[(i,j)], Cost.get( (i,nodes), 0))
                Cost = min(Cost, Cost[(i, nodes)])
                visited[i] = True
    return Cost

``` 
            - There are a maximum of 2^n * n  subproblems, and each one is solvable in linear time. Therefore the problem is $O(n^2 2^n)$. 
        - Question 3 
            - Consider the finite automata M, which does the following:
First it counts the number of a's in the input. To do this, the machine will start with it's head over an a - it will then write an x and move all the way to the end of the string (moving right at every a) until it meets a 0 or a 1 - it will then add one to the little endian binary number stored there, before moving backwards before it meets an x. This process will be quadratic in the size of n.
Then having counted the n number of a's, it first find $\gcd(n,2)$ and if the answer is not one then terminate, do the same up to $\gcd(n,n-1)$.  
If all of the gcd's were 1, then the machine will accept the string - as n is prime.
Finding the GCD using Euclid's algorithm is polynomial,  (we can ensure this by setting the size of the binary strings as the minimum required to represent n), and we do this n times so the entire process is polynomial in n. 
Therefore the complexity is the sum of two polynomials, and is thus polynomial.
        - Question 4 
            - Assume Unary-S is in P, so there is some machine M which can verify if a string of a's is in Unary-S in polynomial time. 
Then consider a second machine M', which will convert a string in Unary-S into a string of a's beginning after Unary-S and then run M on that string of A's in polynomial time. 
The machine will function as follows:
1. When the machine encounters a 1 - if its at the first position on the tape it proceeds to the first empty space on the tape and writes an "a" - then it moves back to the first non-zero item on the tape. 
If it's not in the first position it writes a 0, walks backwards along the type writing ones until it reaches the first position and writes a 2.
2. When the machine encounters a 2, it writes a 1 and does the same as above - transitioning to the end of the string and writing an "a" - before retreating back to the first non-zero item.
3. When the machine iterates through the whole binary string only encountering 0's, it runs machine M on the string of a's.
            - An example execution is as follows
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ER6WMtwtKbwYzHKcDLdVbhaHeEomxgan3vRzQXevl5MCeM98idoGMAEJfgLpuc_hvd9JlRp5XMVYiqdodj1hl0n-6CZNDvzw6DMPHKwcJdiZJ4RLdLICjt8kb75wqqwi.jpeg) 
            - For a given binary digit, this reduces that digit to the sum of the previous digits + 1, which gives the same value - $2^n = 2^0 + 2^1 + ...+2^{n-1} + 1$, we can prove this from the geometric sum formula.  
            - The translation from binary to a string of a's has exponential running time, we can prove this as for a worst case input (a string of ones) we have to move n spots and then 2^i spots, where i is the number of a's we've written. We do this $2^n$ times (we know this as every 1 in 2^n eventually reaches the first spot) so the running time is: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eA1SD9Vjul9YY7QWuYH3YsZz3NfY2akEXi7Vl7TjMBh39hCuE6T5uGD89e-vBNgpi8AAX1mwMwntRSt6mcg0hBPYXq62s-ER-c_K_wZCJBs7xsbcGksfI7BPYnl8FyHH.jpeg) 
            - The second part of the computation would be polynomial, so the exponential would continue to dominate. Resulting in a total running time of $2^{cn}$. 
        - Question 5 
            - a.) Assuming $q$ and $\lnot q$ are not distinct variables there are $n/2$ max possible vertices.
We can have $m$ max possible edges. 
            - b.) 
RTP( path $\implies \phi$ unsatisfiable  )
Assume paths from $x$ to $\lnot x$ and vice versa exist.
If a path exists from $x$ to $\lnot x$ , that implies that for a path P: $x, a_1, a_2,...,a_n, \lnot x$
Then we that our CNF statement contains the following: $$(x \implies a_1) \land (a_1 \implies a_2)\land...\land (a_n \implies \lnot x) \land R$$
Where R is the rest of the CNF formula. Consider that if x is true, then a1 must be false for the CNF to remain satisfiable. This continues with a2 needing to be true etc. Up to $\lnot x$ needing to be true. But this is impossible, so $a_n \implies \lnot x$ is false and the entire statement is unsatisfiable. Therefore, in order to ensure satisfiability $x$ must be false.

We can do the same with the path from $\lnot x$ to $x$, giving  $$(\lnot x \implies b_1) \land (b_1 \implies b_2)\land...\land (b_n \implies x) \land R'$$ 
By the same argument we find that $\lnot x$ must be false,  but that is a contradiction. We can't have both x and not x being false, so we will always arrive in one of the two states that result in unsatisfiability. Therefore the statement is unsatisfiable.

RTP ( $\phi$ unsatisfiable $\implies$ path)
Assume $\phi$ is unsatisfiable and no such path exists.
Then we have some implication chain in our CNF resulting in: $$T \implies ... \implies F$$
However, in a system where all we have is implication chains and variables. The only way of establishing falsehood is if we have $p \implies \lnot p \implies p$. So we must have chains $p \implies \lnot p$ and $\lnot p \implies p$. 
There fore ( $\phi$ unsatisfiable $\implies$ path).
 
            - c.) We can employ a method similar to finding cycles in a graph.
For every $p$, $\lnot p$ pair in the graph, compute a DFS from both of them - and if both searches reach the opposite node (e.g. not p reaches p) then report unsatisfiability.
DFS is $O(V)=O(n)$ and we can do it a maximum of n/2 times - resulting a time complexity of $O(n^2)$.  
            - d.) 
From b.) if a given formula is unsatisfiable, it must have a path $\phi$ in it which we can search for using c.). So, the algorithm from c.) can be used to find inconsistent CNF formulas in $O(n^2$) time.
Furthermore, converting from 2CNF to the form needed for graphing can be done in linear time - as there are only 4 combinations of variables.
Finally, converting from that form to a graph is linear in the number of vertices + edges. 
Since all of these operations are polynomial, the entire process is polynomial. 
            - e.) Because you cannot form the same implication chains with 3 distinct variables in each clause. 
        - Question 6 
            - Spent a good amount of time on a and couldn't make progress.
        - Question 7 
            - Assume $L_1 \le_p L_2$ , then there is some polynomial time algorithm for going from a member of L1 to a member of L2. So, if the result of that algorithm is in L2 then the argument to that function must have been in L1.
Assume $L_2 \in \text{Quasi-P}$ (This implies a machine M that accepts string in L2 in Quasi-P time exists), then an algorithm for testing if a string x is in L1 is as follows. 
First apply the aforementioned algorithm and get a resulting string $f(x)$ - then apply M to $f(x)$, if f(x) is in L2 then x is in L1 otherwise x is not in L1. 
This algorithm is in time Quasi-P, as the polynomial section will be dominated by the Quasi-P section for large enough x.  
^^Note that the input to the second alg^^^^orithm is of polynomial length, as we've spent polynomial time creating it. If you substitute for some ^^$n^c$^^ for n it falls out. ^^ 
            - Very iffy on this answer
        - Question 8 
            - a.) Start by colouring a certain vertex of the graph green, then colour it's neighbours blue - then colour their neighbours green etc (switching between green and blue each time). If we meet a green node that we were about to colour green, don't search it's neighbours. Continue until the whole graph is coloured or we try and colour a green node blue or vice versa.
If the graph is disconnected, repeat the process on those disconnected sections.
Since we encounter each node at most twice, this algorithm is linear in the number of vertices. Thus we can solve 2-colourability in polynomial time.
            - b.) To show k-colourability (L1) reduces to k+1-colourability (L2) we must show there is a polynomial algorithm from a k-colourable graph to a k+1 colourable graph. So if a graph is in L1, the transformation of this graph is in L2.
An obvious polynomial algorithm is to do nothing, because if a solution exists with k colours then we can solve it with k+1 colours. As we simply use the same colouring, there is no obligation to use all our colours. 

We know 3-colourability is in NP, so as we can reduce 3-colourability to 4-colourability - 4-colourability must be in NP. And we've previously found 3-colourability to be NP complete so 4-colourability (and in fact k>2 colourability) must be NP complete too.
    - 
    - **Lecture 12 **(NOT IN THE COURSE Descriptive Complexity)
        - Descriptive Complexity 
            - Complexity on the basis of how difficult it is to describe the problem. This is independent of particular machine models. 
We look at syntactic resources of definability in logic. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wfsO0DcB6ioJ_c9zQ4ZSHIoYGod931o2lgps0HieGefvgfuMwTGrmr0UoXds4of2Np-B8rNp5NiM0aCbxKbFLAyqVaopEqyAKNlK4NeA_YkpBjQmgtv2QJK7hPrHV2fF.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kn9n8TruetH8F_RX4CwDKoJcbP3UAW4KmerI8iYF3V_Yiog-TOAuNb11nwJcpwWBQrOdK13tVss5cJYaRJMeDNt9mtdKVpyi6UiM_rzPrySmK_MCw-886ZHWDAedunw3.png) 
            1. Needs 3 pointers, each needing logarithmic space 
        - Logical Definability 
            - In what kind of formal language can these decision problems be specified or defined?
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FjBa86DLUzUDZmP7djdq_iS5nTeLWDXc7S1NDjNsluXC-NAxTcGNXhKuz1G9DcnGYIyGTMBiCzWdcoYOwoq9X3Wc3VMFwA1zDTqYcQYWoKH_jIecBQtIiDVoCNP6jU4T.png) 
        - First-Order Logic 
            - First-order predicate logic formed from a collection of variables and formulas: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/84RY9MwIWISFZdjH5ofbyULPofx4-lI8xaVZwAvFeAX5v9_IMF7Ei-3UNOK8e09ZPTK8ALvXoGh5PYiW3XNMOOCszi9RQ1y9EXeTD3SQbdE9fN_EMtwf2yZsAKNDWqag.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xX6m50KF5cl7RmMvtVoJKk-T_tESuQOfjb_yL20GsqCfciiFtFY5qA1B2LE-mBFhlC20CdVPeYJld03AtO-WaWwX8LYaIi66Xrnegc7cnYcxJ_P71BwG3lRAfAq9uB4A.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4HFmk5P8swe0hMHn16Qfbpc5Qk65jwSynUnOHgV5ydiDTIk9qpUa3g-ep2i4jl3LA1PIKKS3fQ9WfONl5rqC46t4sUbuH2XeqUFNp7OlOvFiKqtHC_R7xiTZt4QbwNyx.png) 
            - 
    - 
- Concepts in Programming Languages 
    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4A5MVQ9NBysmMY9eglKY_EDuO5Yiilb-z7KgWZ76X-Qype4kTpeEYNoZX0R3OiDc76GwFC-jIGVfrlaO9cEZwvNlUqsSSI2z0iqwG1JOXf1EGkhbhL-mJxtX6XNaGN7l.png) 
    - **Lecture 1.1** (short)
        - There are many reasons for having multiple languages, evolution, special purposes, personal preference and the fact that no one language is good at expressing all programming styles.
        - Three main reasons Languages evolve ↓ 
            - Changes in hardware 
            - Changes in attitude to safety and risk 
            - New ideas from academia or industry
        - Language Standardisation
            - How can we tell what is a valid piece of code? We must read the reference manual!
            - What is timeliness―When do we standardize a language? We may want to let it settle in first.
            - What is Conformance―What does it mean for a program to adhere to a standard, and a compiler to compile a standard? 
                - A language standard is a  __treaty__  setting out the rights and obligations of the programmer **and **the implementer. 
            - What is Obsolescence and how is it handled?―When does a standard age and how does it get modified? Language creators deprecate features to encourage developers to stop using them.
        - 
    - **Lecture 1.2**(Fortran)
        - Fortran  
            - The first {{high level programming language}} - heavy focus on {{execution efficiency}} to help uptake over Assembly. Easier to optimize than C.
            - Remains the main language for scientific computing.  
            - Compilation 
                - How is a fortran program compiled, and why was it a done this way?―Fortran by combining the main program and subprograms. These were all compiled separately and then linked into a single executable (like C). This was done due to lack of **memory resources.** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MinTKUWOIZKzfKNXXY6uMsggdPlD9cJ9_b5YXidh6WQiWS79Ya5G2Qz2UCIvbU3D73danpa-3cAqeVX8jOm8gk6tzMU1_VWtDeHsKKXYw3ss54YzACiodkRMMHTxe3Zc.png) 
            - Data types and storage allocation 
                - Numerics - Integer, real, complex, double-precision real 
                - Booleans (called logical)
                - Arrays (of fixed declared length)
                - Character strings (of fixed declared length)
                - Files 
                - Fortran 90 added 'derived data types' like C structs 
                - How were data types allocated initially and why?―Originally **all data types were allocated statically**, including local variables. This was because computers didn't have  _index registers_  and so couldn't have a cheap stack ⇒ Leading to having no recursion, meaning no on the fly allocation. 
                - Modern Fortran has recursion and a heap.
            - Control Structure 
                - FORTRAN 66 - labels and GOTO, did have DO (for) loops.
                - FORTRAN 77 - added if-then-else and other modern structures. No WHILE, no recursion.
                - FORTRAN 2008 - support for concurrency and objects
            - Variables need not have their t{{ype declared}} - implicit naming convention determined their {{type}}. IMPLICIT NONE could disable this. 
            - Fortran 90 provided a module system to combat―link/runtime failures due to separate compilation. 
            - Function parameters passed by {{reference (like & in C++)}}. Fortran 2003 added pass-by-{{value }}for C interoperability.
            - Program consistency checks 
                - Describe the type checking ↓ 
                    - Static type checking used, checking incomplete. Many language features not statically checked, including common blocks (because subprograms compiled independently).
                    - Constructs not statically checked left unchecked at runtime, focus on  _speed!_  
            - Parameter-passing mode 
                - What are formal-parameters and actual parameters―pass by reference where the formal param is an alias to the actual one. FORTRAN pass by reference by default.
                - Why can formal parameters be a source of bugs in Fortran?―If a formal param is changed, it must be a variable - however this is a huge source of bugs due to lack of cross-module compilation checking. 
                - Modern Fortran added call by value.
            - 
    - **Lecture 1.3 **(Lisp)
        - Lisp 
            - Stands for List Processing (circa 1960). A scheme for representing partial recursive functions of a certain class of symbolic expressions.
            - Motivating problems were―symbolic computation like differentiation and logic.
            - Programming language phrases 
                - Expressions - a syntactic entity that can be evaluated to find it's value 
                - Statements - A command that alters the state of the machine in some explicit way
                - Declaration - A syntactic entity that introduces a new identifier, often specifying one or more attributes.
            - LISP contributions were  ↓ 
                - LISP is an **expression-based **language, conditionals are done using  __conditional expressions__ . 
                - Lists - dynamic storage allocation
                - Recursive functions
                - Garbage collections
                - Programs as data
                - Self definitional interpreter
            - LISP overview 
                - Values are either atoms (X, FOO, NIL), or cons cells with two values. 
                - Programs are just special case of LISP values known as S-expressions - an S-expression is either an atom or a NIL terminated list of S-expressions e.g.:```lisp
 ((1 X ) NIL ((1 2) 3))
``` 
This means **Programs are just data**/. We can construct values and then execute them as a program.
                - Programs represented as S-expressions are evaluated, the head of the list is the function and the rest are arguments.
                - What does the following program output? ```c
(APPEND (QUOTE (FOO 1 Y)) (CONS 3 (CONS `Z NIL)))
```
QUOTE, tells LISP not to evaluate the s-expression within the quote - so the first argument to APPEND is (FOO 1 Y).
CONS `Z NIL (` is shorthand for QUOTE, so we don't lookup the value of Z) gives ( Z ) we then cons 3 on that giving (3 Z)
The final result is then (FOO 1 Y 3 Z).
                - What converts ` to QUOTE?―The READ function converts all `. It's not actually part of the syntax.
                - Example LISP program:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-8dSoGGOagarB9wSPyGLhEUUhq_s3cgQi5tXG-kDl-1o-0kJc6Z1MOYiCKMOm5GaawRSWF3krMaoxFAqWfTSxR4dXCdjS3hL8GutAiBhL9pP-ZtlEd6ENj_MVZKeLFVS.png) 
            - Core LISP primitives 
                - CONS, CAR, CDR - for working with lists. CAR gets the first item from a cons cell, CDR gets the next
                - CONSP, ATOM - boolean tests for being cons cells or atoms.
                - EQ - identity test for equal atoms
                - COND - conditional expression e.g. (COND ( (EQ X Y) (X 5)) (T NILL)). Any number of (CONDITION EVALUATE) pairs to be tested (will evaluate up the first TRUE one). Note that COND disallows evaluating the second argument until we check the first. 
                - DEFUN top-level form for recursion:
DEFUN F (X Y Z) <BODY>
                - LAMBDA (X Y) (+ X Y)
                - APPLY F ` (1 2)
                - Explain the following code: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bsFQN6onduwP8h0gsndeGBQ_pln2gTqu65ZCtOyFM2rgCs--UxvyK-ahf3fP9Sb6tlV_3rkkB2RnJx6ebvc3_riRHlEk_dcIFrB0x0NekCBEKZfJn8DmnLhu8UgqF3Z9.png)―This substitutes x for y in z recursively. If z is an atom (we've recursed down to an easy substitution) if z and y are the same (and we should replace) then return x otherwise return y.
The rest is obvious.
            - Static and dynamic scope 
                - Describe the two main ways of finding the declaration of an identifier  ↓ 
                    - Static scope - use the closest enclosing scope value.
                    - Dynamic scope - a global identifier refers to the declaration associated with the most recent environment.
                - What would main () evaluate to in the following code? ```c
(DEFUN g (x myfn) (apply myfn ()))
(DEFUN f (x) (g 2 (lambda () x)))
(DEFUN main () (f 1))
```―The questions is if the interpreter looks up the free variable x in its static scope (getting 1) or dynamic scope (getting 2).
Newer dialects use static scoping for this situation. However, top-level defvar can be used to mark a variable as using dynamic binding.
            - Abstract machines 
                - What is an  __abstract machine__ ?―This refers to an idealised machine that can execute a specific programming language directly. Consider the JVM.
                - Describe the LISP abstract machine―the abstract machine for LISP had a heap and garbage collection. 
However, static locations were used to store variables - variables used by a recursive function were saved on entry and restored on exit ⇒ leading to **dynamic scope**.
            - Programs as data 
                - Programs can build data structures, then evaluate that structure as if it were part of the program using  _EVAL_ .  
                - What problem can arise when using EVAL?―The environment of an EVAL program is the environment of it's calling program - this means **if the EVAL expression has free variables issues can arise.** 
                - LISP is defined within itself.
            - Parameter passing in LISP 
                - Function parameters are transmitted either all by {{value }}or all by {{text}}  (QUOTE).
                - Only built-in functions (QUOTE, LAMBDA) should use pass-by-test, why?―Because a special variant of EVAL is used that evaluates the argument in the calling environment.
                - Pass by text is similar to call by name.
                - What two ways of delaying execution are there?―Using QUOTE, and putting the expression in a lambda function to be evaluated.
            - Dangers of eval 
                - Describe the perils of the following code: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VOahZM194oYf2JGBTK-FufvxtMhMgd5ArhFGx72Z2BNX77LiUuR2y22hc4Pe3WaTzxLF-OoUpf2dHuqMx1OE7P7EW5-m3-HeYWsIm31e-7dxADFKhNbyJTOjIOyWsdZ9.png)―The question is, should eval e return 11 or 12. This depends on if it uses dynamic or static scope. 
Thus, use of eval needs to be very careful and should be considered a security hole.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/K_5LeNAExMOi9Q7-J5DJiPJR-rDj57Iyab2lR1ocyExK6HrTp88aXOJNMwyP_jYx-9AvXRnNnQoIDkLdBFjYvyq2Yr3HZjJ-WLaqGaFxPk_S7dX98hDeOZbncuH-gZJP.png) 
    - **Lecture 2.1 **(Algol and Pascal?)
        - Parameter passing 
            - What is call by value?―The actual parameter is evaluated and the value is stored in a new location (which the formal parameter can use).
            - What is call by reference?―The formal parameter is an alias to the actual parameter.
            - What is call by value/result?―Same as call by value - but at the end the final value is copied back to the actual parameter on procedure exit.
            - What does this code test for? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TSudNz72hrJ2zXpdmevYpU7QbPHn7Uvxkajv0jBOfKiRs65UcWx3gB6ctiUQmjQQSf9LMBIElqNReO1rIygSAYW_EOtTEy_XqE-17hmgfpwL5PQutRLCOslo5p4Lo4RE.png)―Test for call by reference - e.g. if x `== y.` 
            - The three main considerations of call-by-value vs call-by-reference are―**efficiency **(don't want to pass massive arrays by value), **side-effects** and **aliasing **(multiple inputs pointing to the same variable).
            - Algol 60 uses {{call-by-name}}, this can cause side-effects. Lazy functional languages handle this by having no {{side effects}}, and maintains speed by  {{caching }}evaluated functions.
        - Positional vs named matching 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/q6hlLxXxAbifCRvpzNV9dJWQMBZ3RMoJa_bLlmAOrzSHneJmbySU_CtdrjbFxQtueqniC78H1XwwZ2em7Ad_6NvZtOOFKO4g7nXQdSyXLROcBf2Hcqah1iHUkM1QvmwE.png) 
        - Algol 
            - **Main characteristics are **   ↓ 
                - Algol attempted to be a middle-ground between Fortran and Lisp. 
                - Semicolon separated sequence of statements
                - Block structure - with scoping rules for local variables which followed the lambda calculus. Can have nested blocks!
                - Functions & procedures - with recursive subroutines.
                - Static typing
                - Explicit type declaration
                - Call-by-value and call-by-name 
            - Algol shortcomings 
                - Give 2 shortcomings of Algol ↓ 
                    - If a function was an argument of another function, the type of input that function took was not specified. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bg1_I62kp-crNjARwPAGPu_TmujPx7EPLO43004P10NXO_Qn9SFqjsXxApPNGs6Fsb9W8UWhYwtRq2JiHPoVb3_ddFUfDgv1gFXCQtdAJ6cT4sRF83phAUyEoR7BJA07.png)
E.g. if p takes strings here we'll have an error. 
                    - An array parameter to a procedure is given type array - **without array bounds!** 
        - Algol 68 
            - Used a stack for local variables and explicitly allocated heap storage. They were also reclaimed by garbage collection.
            - Parameters were passed by value, with pass-by-reference accomplished with pointer types.
            - To complicated and hard to compile for it's time
        - Pascal 
            - Quasi-strong, statically typed language. Rich set of  data-structuring concepts: enumerations, sets, sequential files etc.
            - More expressive than Algol 60 but less than Algol 68 (easier to compile).
            - First language to propose index checking - the index type giving the range of values was associated with the array.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jqiL-HwYE10oEnjtYfRup6My83VHWyaoagtAijbLeHBvlRmcdzMH9voeoOCzLaBz9O7MlCjPFMV7BH-DylbiC3ixKTAFY7Fy5xEUeIlkKD8eWeDLajP6BBBWeqacXHoP.png) 
            - What weaknesses did variant records introduce? ↓ 
                - Compilers didn't check if the value in the tag was consistent with the state of the record - e.g. if it actually had an integer in.
                - Do you update the tag field or the state first? Dangerous for concurrency
                - Tag fields were optional - if omitted, no checking was possible at runtime to determine which variant was present.
            - Similar to struct and union in C.
        - 
    - **Lecture 2.2 **(OOP Languages)
        - Basic concepts in OOP Languages 
            - **Four main concepts** 
                - Dynamic lookup is―When a method is called, dynamically at runtime the implementation of the method is chosen. In c++ this is done using a vtable.
                - Abstraction in OOP is―implementation details are hidden to a caller.
                - Subtyping is―Allows values of one type to be used in place of values of another.
                - Inheritance is―the ability to use the definition of one object, to define another one. This saves the effort of duplicating code.  
            - Can we have inheritance without subtyping and vice versa? ↓ 
                - One can  __simulate __ inheritance using #include to avoid code duplication. 
                - You might be able to use an int in place of a double, without having an idea of inheritance. 
        - Behavioural Subtyping 
            - If I have a bag type, and I override it so that values cannot be repeated (creating a set type) should the set be a subtype? Java says yes.
            - What is behavioural subtyping?―Where members of a subtype have the same base behaviour as the supertype. For example, a set subtype will behave differently than it's array supertype - so is not a behavioural subtype.
            - Why is behavioural subtyping important for security and verification?―If I proved properties of one type (memory safety etc.) if a new subtype has different qualities those proofs are useless.
        - History of objects 
            - SIMULA was the first OOP language - it introduced the idea of objects. Initially designed for simulation.
            - Smalltalk was a dynamically typed OOP language.
            - OOP in simulation: 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4SNsVF_-A3SoagoyjrOfh-Ih0rUPj6TNNYvIQPzDR6pqi4ph8bh44pbSeRao52JNqmuVfrvmLVVd1gZhsN9VonCKqCdKwhK2wKfgqDB1N2I0VL4pcYmPkzMlU5F6QZy8.png) 
            - SIMULA features:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FJlHzoUwjlEqz5Z6mgje51xi4hrn8Mxn41O5vQejrkD18t8qN9k8a-UY12ntuU6CQD6XHckRgPsfVBgh7xiNoZFVoitN5vo2oioItHv9aj89cy6Kefyvj_8IA80LMomB.png)  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hGR5XNyviz-e2VV1NOWL-oX9foIr_-_lbboV2_QFEY2y-N6hhpgA49QZbENdcjTI6WNRzjUkihMZn644xWgtCrH6Iegf4zA7Xk27XS-HqsI552fRITY43e3PJ3BU8RLa.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/z0lVl9unT2-WLqdvypjjB82X7JSsf7oLoBIz683-ithOqmkQLWukPuMZgLEMMrg23B0uMp7ATsex2MVb8XO80rWPJ_L2dfoi-vXbjcMl85ZFhGIq02jNRk8X4_xW1dDF.png) 
        - Smalltalk 
            - Abstraction via **private **instance variables and **public **methods.
            - Everything is an object; even a class. All operations are then messages to objects. Dynamically typed. 
            - Most implementations of Smalltalk were based around IDE environments - with prompts to click places to add classes/methods.
            - Explain what the following Smalltalk code is doing and how
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LeZWdbrsHSZ9aze4DCkuTHKKN9Mmpmc2jq-Jd3Uf2FT1L0i8__RHe-_WzYvjt-jDz0TJF6-aUOQ62wuQ_fqj2jOI8r0Et1QVArg8VRH1IawsDV-FPnnl4flYbU9x5uhb.png)―This extends Integer with the method myfact! First we check if the integer we're dealing with is 0 - this produces a boolean. 
We then send a test if that boolean is true or false, ^ means return.
If the boolean is false, we first generate the integer (self - 1) then we pass myfact to it.
Passing myfact to (self - 1) will produce the result of $(\text{self} -1)!$ which we then multiply by self.
        - Reflection, live coding and IDEs 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/R4VOh4BxHL0LWlTNkRqomOZchR4m7BDGPYnVI19PiQqCf9EZNZbLfPyAltnwbTXAL_UndKPGivuzqJyLyxvzpLWDh5PeWlQn-IeZ7QGgLWtJwgM0hPy8ydtTlyCDqf64.png) 
        - 
    - **Lecture 3 **(Types)
        - Types in Programming 
            - A type is a collection of entities that share some common property.
            - Three main uses of types
                - Naming and organizing concepts
                - Making sure bit sequences in memory are interpreted properly
                - Providing information to the compiler about data manipulated by the program. (e.g. integer addition vs floating point addition)
            - Can be used for many kinds of optimization
        - Type system 
            - A set of rules for associating a type with phrases in the language
            - What is a strongly vs weakly typed language?―Strongly typed languages have a strong type checker, that is if the type checker allows a piece of code then that code will evaluate with no type errors.
A language is weak if it isn't strong.
 __To have a strong type checker, the language will need certain things  - like explicit typing etc.__  
        - Type safety 
            - A language is **type safe **if―no program is allowed to violate it's type distinctions.
We can violate them in C & C++ with type casts and pointer arithmetic.
You cannot in Java, LISP, Smalltalk... 
        - Type Checking 
            - Used to prevent some or all type errors, ensuring that operations in the program are applied properly.
            - Can be done statically or dynamically. 
            - What is expressiveness in a type checker?―- e.g. amongst safe languages, how many strings are accepted. 
One strong type system is the one that rejects all programs.
        - Static vs Dynamic type checking 
            - How are dynamic types achieved? Pros/cons?―The compiler adds tag fields to data representations, which can be checked at runtime.
Lower compile time, slower and more memory used. 
Can find errors at runtime that static would miss.
            - How are static types achieved? Pros/cons?―Compiler checks the program text for potential type errors and rejects code which does not conform.
Faster code and finds errors earlier BUT may restrict programming style.
        - Java Downcasts 
            - Consider the following code: ```java
class A { ... };
class B extends A { ... };
// Which of the following are allowed?
a = b;
a = (A) b;
b = a;
b = (B) a;
// Each line executes independently.
```―```java
// You can think that in assignments, we want to keep the left hand arguments type the same.

a=b; // This is allowed - its an upcast, cast b to an A and then assign
a = (A) b; // Allowed. Explicit upcast

 b = a; // Not Allowed! Non-explicit downcast.
 
 b = (B) a; // Allowed - but needs to be type checked. Explicit downcast
``` 
        - Type equality 
            - Want to know when two types are the same.
            - What are  __structural __ equality and  __nominal __ equality? ↓ 
                - Structural equality means we could look inside the types and find the same structure of bits and subtypes. 
                - Nominal equality means they have the same name.
                - ```java
type x = int * bool;
type y = int * bool;

// Structurally equal but not nominally so.
```
            - What are **transparent **and **opaque **type declarations, and what do they imply for type equality? ↓ 
                - **Transparent **type declarations are when alternative names are given to already existing types. A system using this would require structural type checking. 
                - **Opaque **type declarations means when a type is added, it differs from any other type. Implies nominal type checking will suffice.
            - Examples 
                - In C type equality is structural for typedef, but nominal for unions & structs.
                - ML works similarly to C/C++, structural equality except for datatype names which is nominal.
                - Type equality was left ambiguous in Pascal.
                - Modula-2 had the following rules, two types are compatible if:
                    - They are the same name
                    - They are s and t, and s=t is a type declaration
                    - One is a subrange of the other
                    - They are both subranges of the same basic type
        - Type compatibility and subtyping 
            - Explain the difference between type compatibility vs type equality―Type equality is symmetric, whereas in type compatibility we are interested in a one way relation. E.g. can we pass this variable to a function, or can this type be cast to this other type. 
Do we want an age type to be assigned to a weight type etc. Int to age makes some sense (to perform calculations) but age to int is more sticky.
        - Polymorphism 
            - Parametric polymorphism - a function may be applied to any arguments whose type matches a type expression involving **type variables**. 
E.G. (an e.g thats needed but  the lecturer didn't provide) append  [a] $\times$ [a] ⇒ [a]
Where **a is the type variable**. 
            - Subtype polymorphism - a function expecting a given class can be applied to a subclass instead.
            - Ad-hoc polymorphism or overloading - Two or more implementations of a function with different types are **referred to by the same name**. 
E.g. add(Real x, Real y), add(Int x, Int y)
        - Type inference 
            - Process of determining the types of phrases based on the constructs that appear in them.
            - Describe the idea of Type inference in ML―Give every expression a new type variable, and then emit constraints $\alpha \approx \beta$ whenever two types have to be equal. 
We then unify these constraints.
E.g. with inference rules: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cghUV3AFlGOJeG6oMb1_HQcmRKea9SmbgQ3nyGyt_xX0IesvB5s-V38nfbPCABcByFQKO1H6qFWRZ75Ta8nSLc06QDXmfllhiExtMRdD74Vw7qZfcWIqbNBrAjGCj_Vo.png) 
        - let-polymorphism 
            - The 'obvious' way to type-check ```kotlin
let val x = e in e' end
// Is to treat that as:
(fn x => e') (e)
``` This has issues, e.g.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ea4bJSJt1p8X2YjDkzrJeYDOqwiMWxsVtvHs0urhiflM6Itbq5Tz61c46VB7fAe21vVZOSzbT3lWykb_AL0GWtrEzDwHy2dLrGi4x5SK-lDDBjPef0YOLUGQwE64XWrE.png) 
            - Milner invented a more generous way to type let-expressions, using $\forall$. 
        - Surprises/issues in ML 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QixtG7r9PccH80MpgAWiWipI6m9ZXiP0tMEbScOq9o0yWfqm12eGSl1YF59dKUXAp8h_pLETdNJX4yLof0Preai05rllTaQ0pPFilGRhVVw6Hh9qMixafOKCrke5-Oag.png) 
            - This is a problem, because the type of x changes from a list to an int list. While this will fail type-checking, we need to be careful of things changing behind our backs.
        - Polymorphic Exceptions 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YPvMWprgg__EQ_7dcsHHFqVKbwl_zUXxLuK_jpQwK5MVujBXHe67qY0rbT3MQpasQxogfiNXvqdvyz0tmzIm6mI0p8yYUHG7npxpvyDCQCdiaZ_6iZYB0zZPyNc-ZdKy.png) 
        - Interaction of subtyping and generics - variance. 
            - Given String is a subtype of Object: 
                - String[] be a subtype of Object[]?
                - Should ArrayList<String> be a subtype of ArrayList<Object>?
            - Given a generic G, we say it is {{covariant }}if G<String> is a subtype of G<Object>. {{Contravariant }}if G<Object> is a subtype of G<String>
And {{invariant }}if neither hold.
        - Java arrays are covarient 
            - So String[] is a subtype of Object[].
            - How does Java handle this subtyping issue? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j6p3uqnvDrh0qA2BAHmh4Rl7PQZexr_wBWUdHsC7swT8hj-WKQyRJBJryARkPp6fQ7hjAa0JV5V-OKbN3BZ5yf86jiTYF7x2qdBdJjmZDvDW1sjbA_smRbgqYgxuHe0r.png)―All writes to a Java array are type checked to ensure it's a subtype of the **array they are stored in**. In this case a String array. 
There are no problems with reads.
This means you pay a price every time you write - this was changed for Java generics.
        - Java generics are invariant 
            - For Generics, what would fail to type check here:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VQnn-BBhaf96LTNCVWOZq7-eZgrfHIxp3va12S1euKTybogITCM1ycXhrqezKG5bI4xt45H-d0_qh8XuL4_E_U_8NVigGF1VYhT8yQb8-uHnkudOadqneTuzT9SLUt6Z.png)―o=s would fail to type check, everything else would work fine. 
This would fail because o is a subtype of s, so s would need to be downcast.
            - So, generics are safer than arrays. But covariance and contravariance can be useful.
        - Java variance specifications 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RPIcnJ7o3WyMC29z9f6qZvkHbKljADSHk8tj5T8_3ZxHMbBRaqL0QhdAPKNHl6XJO3WipTWKCK5HBAfEC_OVWx7rDdth-7I8tBK_jiBGwa2-n5tKQ8SQj0rMPBmO1x6A.png) 
            - What is the trade off of using ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/W_IT6wm02cJ-PEUZDsDi-xFaOQNJBoa9jUVcbZI7VbSrtJWntLVK61yqRsK-XoiiprTRT8EQ5Ok11aqysj-n1i6UsBZVoh9z6fZgR2Idz7DKDSS0N9J_wJzGGyQqoCe9.png)―This makes o covariant, however we cannot write to elements of o. We can only write to s. 
        - 
    - **Lecture 4 **(Scripting)
        - Scripting Languages 
            - Scripting languages are generally created to automate human tasks, a script is then just a program written for a scripting language. 
            - The definition is usage-dependent - ML was originally the scripting language for creating proof trees. Similarly Lisp is the scripting language for Emacs.
            - A scripting language means essentially "language with a REPL" or a "language which can run interactively".
They are generally {{dynamically }}typed or use {{type inference.}} 
            - Some static languages are also used for scripting, with type inference and lightweight top-level phrase syntax.
        - Executing code in browsers 
            - Java applets were―a system where Java code was compiled to JVM bytecode and then run in a browser sandbox. This was a security mess and unloved by Apple & Microsoft as they want to keep their apps behind a store.
            - Alternatively, embed Javascript source code and JIT compile it for execution. Then talk to the browser using the DOM model.
        - Javascript 
            - Originally called Mocha. Designed and implemented in 10 days. 
            - Dynamically typed, prototype-based object system.
            - Has both OOP and functional language features (including higher-order functions)
            - Implemented within browsers. So has callback style approach for use in browsers.
            - Language inspirations
                - Java for syntax
                - Scheme for lexical closures
                - Self for prototypes instead of classes
            - Why did Javascript avoid classes? ↓ 
                - Much time spent defining classes, before even thinking about objects. 
                - In flexible design style (agile or spiral) you may want to change the design of a class as you go. This can have problems, as classes who inherit from you will then change too (the  __fragile base class__  problem).
        - Prototypes instead of classes 
            - Describe prototypes in JavaScript―When a constructor function is defined, it acquires a prototype property initially an empty object. When a constructor is called, created objects inherit from the prototype - we look in the object first and then in the prototype - then in the prototypes prototype and so on up the chain until we encounter null.
You can add properties to the prototype object, or replace it with a different object.
            - What is duck typing, and why do we need it in Javascript―If we don't have classes, we can't check the name of our class in Javascript. E.g. we can't test if (x instanceof Duck)...
Instead we check if x quacks like a duck, walks like a duck etc.
We take a structural view of the prototype and decide if a prototype has a certain number of duck methods - then it is a duck.
        - The JavaScript DOM model 
            - JavaScript needs to be tightly connected with web pages, how is this done using the DOM model? ↓ 
                - The browser converts the HTML into a tree of objects representing the HTML page structures. This is made available as the JavaScript variable  __document__ . 
                - Executing JS code reads and modifies  __document __ which the browser then renders on screen. 
        - WebAssembly 
            - JavaScript is the only language universally supported by browsers. So various compilers have been developed to compile from many languages to JavaScript. 
            - But JavaScript is a terrible compiler target language. Instead use WebAssembly a machine-agnostic safety-checked assembly language JIT'd in the browser.
        - Gradual type systems 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FxpogsRGADiOOolbtugV1Sgtyz4WmTSSpFwtCHvFiyYrgQhAHo2UH3uHMBTWbTE70RdjRR3P1DmkosAdDH5ll_GPOtDaRK7GuRF-EFZ6UrEbnxuNy2ozcsYmJpJi9cRb.png) 
            - Statically type languages are better for large programs, why?―Cross-module static checks and documentation provided by types.
            - What are gradual types?―A language in which small programs can be written without types, but the IDE encourages you to add types faster than software rust overtakes your system. I.e. PHP to Hack at Facebook.
Some variables are given types and checked at runtime. And some aren't, so their correctness is dynamically checked at runtime.
            - 
    - **Lecture 5 **(Modules)
        - Need for modules 
            - Why do we need modules? ↓ 
                - We want structure in large scale architecture. 
                - We also want to control name visibility, excessive visibility increases the attack surface for malevolent use.
        - SML 
            - Consists of two sub-languages:
                - The Core language for programming in the small.
                - The Modules language for programming in the large, by grouping related Core definitions of types and variables into self-contained units.
            - What is an abstract data type?―A type equipped with a set of operations only applicable to that type. It's implementation can be changed without affecting the rest of the program.
        - Structures 
            - What are Structures and Signatures?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZegvmLiSqEKTLBSayzTVRWh2d71xyq2h91xR-HfHMntpnO47iZjQe5ybNtmD9hHhCo1QFeZ5lMuYq5TjEjEfmDTmbkkM0bE8DrT0hU8FtciH3Kl-Sii_knJ5kyLnUojV.png) 
            - We can encapsulate a sequence of CORE type and value definitions into a structure. We enclose the definitions between the keywords `struct...end.` 
        - Signatures 
            - A signature consists of a sequence of component specifications, enclosed between `sig...end`.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iqGCwLnMlQU8j7-anw9KuYayQ_RyuI9OxmX32g-E51ovhB5V8-HBaIgHCiPxBbgEL5qtiIMBrkW8FXwkb6f6y4YZGE_2tBkejVNHKdGgDEM0Pafvj-tpg9GLKMPGvslQ.png) 
            - What are opaque signatures?―Signatures that give more freedom of the implementation of the structure:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8TSoTI-au2SIgogwZO-3_B_vFuCPbW5J4QeTzHLPEnDIic43YzTZL58Wse_oGoePo5sYi7WQ_L0CYWYX_J68zd-53MKODDDEKmZasMCI2j4LXnBXXyt3PnhNMjRjiTqu.png) 
        - Naming structures and signatures 
            - We can bind names to structures and signatures using:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oRP7oIR_wDoLOTzAWPsBcdxCjcgo4P9tpmyzdM8NEmfqRsbf94RoeCfmE9gMidougAwY_c056snznQWXtPn-tcj-nH04EiBrqgy3ju3qBesbiSDVedoHgUTS875sCEcr.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/R629rgFM01lg4u-oLtGU-mZdxsYT_j7GSg6wPPX_hCwJLopMIBaJy3ybzAAAn88ZZr0pnQX9SuhsDG8HYrzd2SPjIBnXh-TJZXt1NuBDNHwlS1ZnNfNtE7bbNQaCQNUI.png)
Why is split not exported in MyStack?―It acts as a private method that is part of the implementation. 
        - Signature matching 
            - When does a structure satisfy a signature?―When it implements **at least **the components of the signature. Can have private state/methods. 
A lot like subtyping.
            - Describe signature constraints―Take an already existing structure, and create it using a new signature which constrains the defined values. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/EgyC3CuAR1XDSoQ4wp2AJC2B2-Jp2M9ZUY4oK2uXI_l1ulZ9aoEujZNrEIBUQ1G5nas23VXADqq4wN4sVDJoyRub0z1wj286S8XQbbj18tsKza9Br5S9Th4uRCjORGXV.png) 
        - Signature Constraints
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/G9odY2Z0wrknPNqTPdfH-Zf09nCYPFxv7TYZNEaSywyWpGmng5u0orU30mLI2dccywnjW0CARG4ff9h0T3xAXZ7z8seOjxgaiecy-t8SDlm-u3SnqvqBGaPRUrROcYZa.png) 
            - What are opaque signature constraints and why might we use them?―These hide the identity of types. We might want to hide that our natural number is based of int, as otherwise someone could store a negative integer in our datatype (a.succ(-3))
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/a3mWUWvi76k-M2xayUz6HWHB7wYFW2a5UODvtt0p4SqnJpwLbnh0Dj_JP2mFrnNFEy2r9BLwiM0BLovIZbPCneevLr8DiE9CtWzHBScJ1zffGgWftXEySLCx3CeUCKS8.png)
So AbsNat.nat ≠ int. Even though it uses int 
        - Nested Structures and signature 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/X2ekHF7PqPGe8dFi6zYyJItcn7Ph26o_foV3s-6YWfPqFnyqs6V5zoNdz_0u_BFoqWLSidpRJFFZjO7g56iwUdR8ZdlpsqZofsXIDJ0sN34_oWK87JPJ8j8syVEfF_Y2.png) 
        - Modules in other languages
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PqZH4ZI_DTqYs3zjI_eykyI_4sWp76yqHsh-LarvyiKWNO5L-RVPt4z0OaNOa5guZZwfc-xWrx8X5SnhWpSeEvPiBpE1FrFSyT8-KioXIBAsR4GevhqmBvHs01iEq4A2.png) 
        - 
    - **Lecture 6 **(Concurrency)
        - Painful facts of parallel life 
            - Single core clock speeds stagnated for last 10 years. More transistors, but no more speed.
            - Inter-processor communication is FAR more expensive than computation.
            - Compiler **can't **just take my code and parallelise it!
        - Painful facts of timings 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3PbZIo0g1zJeny5V0iYAg-o7z5ktKcrJLJU8HX0OM0uD1bNXc5wdMBvDbQdKrzHoV44ex1Oh-PFDhr9hEs2ilWxJ0p4MoWfoqmBqDuBuZD5zsXsiuTeobaqjnhln1t5j.png)
CPUs have sped up much faster than memory. 
            - With multi-core:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YQ3RZRAcdtlem_z_NVImEH1H2ugHckHIxefOdOBCbP7jSxnNeHF3cYrWnWs6TwIVPkU-3U433rSeufAsHuxjPlBlIoZYV1HoVBr4hkZqe74LsTvGjzRpnFZw_4Zwywqx.png)
Why could communication take up to 400 cycles?―If CPU 0 writes to cache 0, and CPU 1 reads the value - CACHE 0 needs to flush the value to memory, and CACHE 1 needs to then read that from memory. This takes 400 cycles. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bewosUDp2xBdZhWTtblrrO1Q5MDocEd2qvb9rBUywqv2SFYxMJKRdDB0wW3ktPaJt3bMdiHFCwK29kszr0Zv-vp-AY18qrBceSkFatMf2NyB02V9suHyvOJ3z9LWx-PV.png) 
        - What  __programming abstractions__ ? 
            - We've got more and more processors available with each device. From on cloud to on chip.
            - What are good programming abstractions for a system like this? 
            - Memory is local to the processor units, but message passing between units is much slower.
        - What hardware architecture tells us 
            - Communication latency is far higher than instruction execution time (2-6 orders of magnitude depending on if the core is on/off the chip).
What does this tell you about the number of instructions you should send?―Have to send at least $10^2$ instructions and realistically more like $10^4$ for it to be worth it. 
Long-running independent computations fit the hardware best.
            - "Shared memory" is an illusion. Emulated by message passing in the cache-coherency protocol.
            - Often best to think as CPUs as distributed systems. 
        - Communication abstractions for programming 
            - "Head in the sand" - What communication? 
            - "Principled head in the sand" - leave this to someone else
            - Just use TCP/IP
            - Shared memory, message passing, RMI/RPC?
            - Communication is expensive, expose it to programmer (No lies about shared memory).
        - Concurrent, Parallel, Distributed 
            - Parallel for computation and concurrency for what you have in your language.
            - Concurrent behaviour can happen on single-core CPU, but true concurrency different from interleaving concurrency.
        - SIMD, MIMD 
            - What are SIMD and MIMD―Single instruction multiple Data = GPU.
Multiple instruction multiple data = multi-core CPU.
            - Most parallel systems MIMD
            - GPUs are SIMD, so Programming languages for GPUs differ.
        - Oldest idea: Threads 
            - What's wrong with Threads? 
                - Give some problems with threads >  ↓ 
                    - Need explicit synchronisation  ⇒ means they're error prone.
                    - Because they're implemented as library calls, the compiler cannot work out where they start and end.
                    - pthreads are OS-level threads ⇒ Means we need a context switch which is very slow.
                    - Number of threads generally hard-coded into your program. 
            - Cilk Language 
                - What is Cilk?―Cilk is a superset of C that adds concurrency with threads:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CwXc9qkvj9JkRxBSE4YFWruC9Pr0H_lVcGassLNkEDLDY1J38X-kjfdlQHhGOK_Zn_kiNnLCcoEDIT-ob2srF0NihSocx94CgnoTOdBiQaH9ts1Oo8_u9zPvf_I832xD.png)
Note that there is Compiler management of threads.
                - What is OpenMP?―Again a superset of C, where you can indicate to the compiler what to parallelize and where:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p8dNLLP_xB1bAkghZEMd0slaJu7xf7Am4_-RB7OidPg6KYC-ouwN9wMf4UxOdCy3IHwQEO1JOzyAQVgc7QCPN44RrhaCITvmFhy0ns0K-aRGwUS8J0JSrEO30K7Bg5JU.png)
Note, assumes shared memory. 
            - How do you implement threads in Java?―Either extend Thread or implement Runnable:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fM3gwMC0EL7Utr2Ft1BYX4VUPwZnMAGpJz1cg6FW5RYwr0OlOI0PqqIxKHZGP85bN34cqbk9x6GseCh5hIh4UCBDkxr7iydxq4yprzGltHWnZEHheNj3EHz3WghtbwEL.png) 
        - Clusters and cloud Computing 
            - Cilk and OpenMP centre around shared address space, here we need **message passing.**
            - Software support for message passing: MPI 
                - What does MPI stand for and what is it ↓ 
                    - Message passing interface
                    - It's the standard for communication among processes on a distributed memory system. 
                    - Emphasis on the expensive nature of message passing.
                    - Does a **sweep of computation** and then a **sweep of message** **passing** 
            - Erlang
                - What is Erlang? ↓ 
                    - Language with nothing shared, based on the actor model (Asynchronous message passing).
                    - If tasks reach a problem, they just commit suicide and hope someone will fix things up. 
            - Cloud Computing 
                - Can mean doing one computers work on a server (e.g. Google Docs), or massively parallel combinations of computing  
                - MapReduce invoked in a search engine, where a search term matched against many computers (Map) and then combined (in logarithmic time) using Reduce.
                - Why is functional style preferred in parallel cloud computing? ↓ 
                    - Functional style (idempotency) useful for error resilience. Can easily restart computation if an error occurs (cosmic rays, etc.)
                    - Here idempotency means, we can restart the computation with the same arguments and will get the right result. (e.g. no permanent state change due to error).
                    - Additionally, every tuple and argument list **can be evaluated in parallel!** 
But need to find big units of work to make up for communication time. 
        - Embarrassingly Parallel 
            - Programs with many separate sub-units of work - where they don't interact and the data is large.
        - Garbage Collection
            - How do we do Garbage collection over multiple cores?  ↓ 
                - We could manage data structures so they don't move from one processor to another. (not always possible)
                - Parallel GC - stop the world and do the garbage collection in parallel
                - Concurrent GC - do GC while the program is running (Hard!).
                - Incremental GC - track imported/exported pointers.
        - How have languages adapted to parallel hardware?
            - The hardware change of adding new cores was **huge! **But programming language support is fragmentary. 
            - Concurrency and mutable data structures seems too hard for programmers to use together in large programs.
            - So languages have evolved to use more Function programming ideas.
            - Describe the difference between internal and external iteration ↓ 
                - External iteration is where the looping mechanism (the for) is outside of the body. E.g:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XhX8NT8XbrVP2nH-XmvepNDle3CUESPUyzlxrcrbaKG0lMna0KCjKwgYAQZzgvtgxn3wZ1W8BtskWhEpJS2RwEUky_OHyrWzDFwHZ2cew6K_xUp4RAl51RvUGLuvEbsG.png) 
You need to do the parallelization yourself, e.g. converting to:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pKs52Cqz7ES0RypFDYxe9i58btc9IhXNJFwadEapzb4NjPgqGsEtpfSWK-vlYEn0u-PfQy0TCOC_-Efu_lTWHV3ZtnFPRy879VxiyiXVwDidM21kPPBe2siIGdSKin5q.png) 
Which takes **ages.** We don't want to do this. 
                - Internal iteration means the iterator is built into the library, and the body of the loop is done on top of that:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GY-WSHnwDiVlczM2JjeTXG76bP3kNGLfcTtkCC-xpd7f7yzrMCcawRdFoEf648jc9vKfh90W8cGJ8CIEoecsvXOc8q47rO_LifksL55bf4r86zPM3tsCY3ZUHxMG3vM7.png)
The library can then optimize the iteration based on the number of threads available. 
            - Java Collections vs Streams 
                - How do Java Collections differ from streams?  ↓ 
                    - Collections use traditional for loops - internally using mutable state. 
                    - Streams have lazy allocation, items need to be in memory all at once.
A stream pipeline traverses the stream only once.
.parallel() authorises arbitrary order of calls to the stream pipeline! Good for parallelism.
                - 
    - **Lecture 7 **(Scala)
        - Scala 
            - Describe Smalltalk's main features  ↓ 
                - Minimal expression-oriented language (cut everything to a minimum).
                - Smalltalk-style "everything is an object". 
                - Unifies OO and functional language techniques.
                - Rich polymorphic static type system, without NULL.
                - Can write code procedurally or declaratively.
            - In Scala Array selection is written in {{functional notation}}. Type declarations can often be {{avoided}}, with var used instead. Higher order functions exist, using ⇒. 
        - Parameter passing
            - Scala uses {{call-by-value}} by default, but it switches to {{call-by-name}} evaluation if we put ⇒ before the type. 
            - How does this while loop work? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/x1V_cxWm8wCRg6adNkARK2gBwGJOW-JgREP6wG6rZDYYIAZcRg3oriOyimXD1rZYC9j36uHW7DlaWtjjLg-zpDCstRZjE6ZCejgudshuQudaM1h71Qr3U-5JpadEUe19.png)―Works because of call by name, cond get's re-evaluated and comm does to - where comm would be the body of the while loop. 
        - How lambdas are implemented 
            - What would ```java
 static int test(Function<Integer, Integer> f) {
 	return f.apply(1)
 }
 
 k = 10;
 System.out.println(test( x => x+k));
 k = 20;
 System.out.println(test( x => x+k));
``` Output and why?―It would output 11 and 21, because when a lambda is created it binds the local variables it doesn't pass them. In Java this is how lambda's work.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZhgssnL6HDTonWt8LxnjkiNj2ujIEmZwm4CZuRadDwYODg_fgzte8ZIWFpEImhWlfWVUsUVF-6j1y_ClURiKF70IcD6encUDk43Sx9FtgNLQDOJzz1FSejAlIr9RXpDi.png) 
            - Describe named classes for use with lambda functions―You define different classes, which take and store a free variable, then implement apply which uses that variable for computation.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BR2PeQ2PsqkGDcpmkxOtfNfdlRafSMgUdQtvghRbqgXBi719Jaof_8JabYL21NOAk8kIcOyy1UDwK9kT5q9LnQbnY6b_WkBKuKH6Cu7IW5MCRqc39rdSLB265h2v9Afa.png) 
        - Function types 
            - What type is this function in Scala? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4rM2zsZ4zlDi36-C9PiXmk4RyOft6Gvs5o9j6pcxS2lUv9m1Ssl-dsILvQ8smkpvdRf-SqqJw4IAOEFxoZlP2JGmVkrvCn_gz-w-FFVM8gt99r_skY1K4gxSsDdtqM8Y.png)―Int argument, Array[Int] argument and a Bool output.
In general `functionK[a1, ..., aK, a0]` 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8KtVcynUhJ5UbQbRddJgLGBxw3P3QTmaMp-LyWSFOIMJ22fSmyw9AvLy8W1MY9uICZHK6RBWlsNF07T_vMCJIT14i3aqR6L6JJK9fqm-2y6qMS9cw3ccflzaYn4078El.png) 
        - Data structures in functional and OO style 
            - How would you define a tree datatype in functional (use Ocaml) vs OO style?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uSY2EB5j5yT0Xf71h6JFTtNZto95GuN8OwD12FFqpGH2C5iSfzBnhjUqfqiAOx4fGY6Rd7TL02toOak15LZnXuuki_x0A2Tmj-pqvgfKRkEdA7yD9ciOYJ7XI0Yd8XzO.png)
Note that these are the same at the machine code level.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6wJurPE0hxKO3xJeLoiktGjjgpWG8r7KmE37t7SuMWKKZUm6kiofFC156GuEOFNxR-81ICDlVYr8OTK1YK_OyqnjX4MWst3U-EKzFg-DPMiQxAzUQSwwI8uaP6q_T9Pr.png)
Is it easy or hard to add new forms of data to this scheme, and is it easy or hard to add new functions on the schemes.
Additionally, describe how this changes for a functional version of this. ↓ 
                - This trade-off is known as the expression problem 
                - It's easy to add new forms of data, as the types don't interfere with one another: ```java
class Prod(e1:Expr; e2:Expr) extends Expr {
	def eval: Int = e1.eval() * e2.eval()
}
```
                - It's **hard **to add new functions to every type - as we'd have to add them to the abstract class and then implement them in every subclass. 
                - In ML we would have the opposite. 
We would have some ```java
 datatype Expr = Int of int | Sum of Expr * Expr | Prod of Expr * Expr;
 
 let eval x = 
 	match x with 
 	| Int y => y
 	| Sum a,b => eval a + eval b
 	| Prod a,b => eval a * eval b;;  
``` So every time we add a new datatype **we need to update EVERY case match. 
**But new operations on the existing data is easy. 
            - How does Scala handle the **Expression problem**?―Scala allows the user to implement OOP class inheritance and function implementation - **while **also allowing the ML pattern matching. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_Eezr-yPKzpBdMebfyw3-MWjMSXXUOE_T4PyuKC03Vo974ya-2o_hG7y0jM5B589_nA3wmNvzrXsbJD4aNBur0HgmzTgzpnjEEfNuBmNuqRkMfD6-zBesJZ8VJRsnc67.png)

So you can choose which way you'd like to jump in the tradeoff. Easy to add new operations or easy to add new datatypes.
        - Generics and polymorphism in Scala 
            - How does Scala handle the question
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8bkgjVIrudRNd3q_vk2nlPNvRD5-u5nQkTbArc0YRCX_HRBbpAZ_W0WMwOMu9QKAdPGyuv-Uf-DEg5V0_cSISK0izm3JbZmbG1QgubwB7nTEUnI8WP5ofcaRSeJMUL_G.png) ↓ 
                - By default, generic types are non-varient. E.g. an Object array will **only **allow Objects specifically.  
                - But Scala allows for covariant subtyping by prefixing a type parameter with a '+'.
                - Prefix with a '-' for contravariant arrays.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/k1Zm5OU1_wVCIbN27U8pA0gmbEY9nk_icJ59JcgJxd8kwJNJs-OwBxc5M9UDiiNlFjYh9dB-IvW9SXrNfROFBzUJSjQS4lNNWWv5PFC7wKPl9X6Lzgz3vVKRVY4R00TP.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/USoTd7xmfTu9pG_6o-O6-pUhP860sAR4hr1eWFvP2IhSXgcoZrchkeSPJYxIga8qwISFHv6S6-c5RegHEFOHPjByLWj9AT7Lf4JDlbeyCG9e_dNMRONcMj1Fl8SAVb6h.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/EyXRcuCaKw-OmzTL4yj-1_xlcvw_qEEwPMLOkN9s6KI5HrGhTllAp0VScxOXH5DOInrkChEnP7DynwHu35W9acGXl0_UuXiIq0FvHKih4cC6AU0qrXcLmRxHKR2gLQky.png) 
        - Value types 
            - Describe a value type―A type representing a pure value. They can be compared, copied and their subfields examined but **their subfields cannot be altered**.  
Note that this differs from reference types (Integer vs int in Java). For example for reference types one new Integer(1) is differentiable from another new Integer(1) as every objects has identity.
            - Value types useful as more and more functional APIs are used. 
            - In what two ways can you model a value type in Java?  ↓ 
                - Use final to stop modification
                - Use a deep copy to snapshot values on operations
            - These are both fragile during program enhancement
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OYHQTjwbnwG67-KVmJ491SGRBvDwOKF2_40V1_rQKr0MPuvjc8wJVbYB_boIJ7-T23w49WN3VXqQodAz6S1VczTmd2VAJSvd-agkNDDx0gQITdYWmsEEhrfbg_oBUp9m.png) 
        - Value types and inefficient representation 
            - Why are value types inefficient in Java?―To store 100 complex values, we need to store 100 pointers (800 bytes) to 100 complex types (2400 bytes).
All we want to do is tore 200 double values (only 1600 bytes).
Costs java in memory use and cache effects.  
        - Aliasing and mutability 
            - Aliasing and mutability together can form subtle bugs (concurrency leads to insane bugs). 
            - We would rather use mutability as we like, but use deep copies. OR use aliasing or make data structures immutable.
        - 
    - **Lecture 8 **(MONADS and other random shit)
        - I/O in functional languages 
            - What's wrong with having side-effecting I/O work left to right as normal in Ocaml? Whats the problem for Lazy languages? ↓ 
                - e+e might not give the same result as let x = e in x+x. This isn't how functional languages should work
                - Lazy languages only do the IO fetch when they need it. But this means the order of the side effects would vary depending on how the function was implemented! 
        - Giving different types to pure and impure functions 
            - What are pure and impure functions?―A pure function has no side effects, an impure function has side effects.  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NEmpaRwSbIZuWekB0T9fw1UwcL8lno48L0Y-OozYHxg0G3jMVJQ1UrGRaybX8BB2n_DUbqoxiX64ziA2n82OitT3-dAzbRmDiaVuSB3zAP_nHyZwcCZmQ15XlD-WouqX.png) 
            - How do we represent give different types for pure and impure functions?―We give impure functions the type $$A \rightarrow B M$$ 
E.g. it goes to B with a monad, which stores the side effect. This is saying it returns a monad of type B.
        - Composing I/O functions 
            - How do we compose I/O with monads? (hint sequence and return)  ↓ 
                - We need a sequence operator  `>>= `(called **bind**). It takes some $a' M$ and a function $a' \rightarrow b'M$ and does:   $a'M \rightarrow (a' \rightarrow b'M) \rightarrow b'M$.
                - E.g. pluck out $a'$ (the output of some function), then get some pure function which output $b' M$ given $a'$ as output. 
                - Finally, output a $b'M$ (the $b'$ is different) which is the result of the function if the initial side of $a'$ were concatenated with the side effects of $b'$. 
                - We need a **return **operator. We can convert a pure value as a side effect free computation: $$\text{return}: a' \rightarrow a' \ M$$ 
            - Describe bind and return in monads, what do they do?  ↓ 
                - Bind takes one argument, a function f and **outputs** a function g.
                - $f$ takes an argument, and augments it with some extra data. E.g. ```java
def new_sin(x): return [sin(x), "we called sin"]
// type: Number ⇒ (Number, String)  
```
                - $g$ takes a (Number, String) pair and outputs a (Number, String) - so It pulls out sin(x) and operates on that and then combines the result of the output.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HRvv9xUJX56WbopM6yUF34T2pVCLYbFPn-JoiCIr10SEpDD02yoryy1e2WTakYo3A4lirOwCjEDpfPMrzU3bmvI-Y-4YPfp0SFbrc5Ly9Bk1rL485Od6-V3F-652MbRJ.png)
This allows you to compose new_sin(x)'s which have this side effect of logging. 
                - Return just converts a value to a base monad which you can start logging with: ```java
 def return(value):
 	[value, '']
```
        - Monad Laws 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sMhG4jK0y8pNX706cxwWo7smwsA4AFosvDb86cdKAV2G9_eyKrJwC2yobwKOJYC0ND4fLYU1qt1SRtaOlN1PlTwtNw_WOKAuoK5DlpG9s3FHftvu9XDUb_cV8dY_AX1U.png) 
        - Using the IO monad 
            - How do we read an integer, add one to it and print the result using monads?―```java
 rdint >>= (fn x => wrint(x + 1));
 
 // This has type unit IO
```
            - To do this twice we need: ```java
 let val doit = rdint >>= (fn x => wrint(x + 1)) in
 	doit >>= (fn () => doit);
```
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JTvVPtxenf7AhqcIURMLv7jfu4nJUmuMDcaPeH4AFxKWUlsiyASWc-1wZZv7XCj32q0hltNMKZwZL7aHgoDtlReJ3HTKqTJKweYMr86vNGazMkN4JupXW791F3BgXhHC.png) 
        - Generalised Algebraic Data Types (GADT) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iAHYPdI1-Jy3oVnn1ayYBKJUeaEutG6srUYs54in1HDRM8V0oU5zoAmrzokjW86zwI-t2E5FRtJmnk8Qj1WU79XTEYqubEgOPyrjXS1lNO7uc6oWqcTOBNppSArGpyhV.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b3cZAuydQ1Ynbutxqi25genuUUak14TO9VgejDVUBzDQSkPBdwNQN0yLxnRuWfzJdUYY8q4UjSh5PIq5Lo5VCgaozU4R29EZJdVvBg0CvmxVNZZ9EuRWjfJIGOGwzRjY.png) 
            - We can type check when values appearing in datatypes work correctly. We can ensure add and equality are used correctly.
            - We can write eval where the type of the result depends on the **value **of it's type 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/S5UxtOZkHEvDs5sJiXmhHDRPFm6f7BB6qzgCv-PydsunjyU8wdJ0wdASO-mjGg_2juwh-roXkGrBviVXLyRI1FGfBh7gGZu_h8tydi4mQioyfLReTnVivcGG433My2V2.png) 
            - GADTs can type more things flexibly than in the standard ML type checking system.
        - Reified continuations 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9GqoVc8Fe_yZVAEVUoQph44mtrnJQkiPo98LUpzja2sG-GbKD0IkQnXbNDz8N7U3BJUpmHTcqPNO97XZ9XkSNYemg9MN1V2zrhxKr-sX-9s35mjwZN7Q_K_Tpn2ouqbI.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kqQ7Krzefk5dfNR-bDIxnCkpNPxz-ppmEmd5SFU3k6q_XemCvDlpHDhJvUF1ARSydLtLkbq2Zl4qbIWWMXz_kD4eXCwEdlVspWSGQpoTreuGGyK7ShR8J_FFHFxAYi0g.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KUfD-S3VPJwMAQk_Y-ga4cFYr65LxayD-zBoufdR_kd1LU3lV_eIq5vzc5P9VlL2wuS3EnBVLie4iqdP3PY2HbPPE63VuLCPSbnjOtly_EgHapApqOyKJob_g9LJhfOj.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZiszufrylJEAsZbGk888x-1vRXLka63aBr6VFLISnaXhLZEGLxtH1LHVz0WIynwVzO9IyeDtvR-x47cy16vEzmQGCY3I6czZ-eKovPa6gpihGO5WAe44TFaN8xdXTbRa.png) 
        - Dependant Types 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TX4OVXDt685PuAAmAkwZEgQJDXpNTnsA2cE0Ir5w0fqAr-qm38bppVOK93uNALeW5E4sv2eld-vBImOOh5ILGaK_TFlmL7QiJlR-yetWHAjzyivZ9exr5SDLoJPxU92w.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RBaCqJXkoxDvwpclGOVIj_wfzk2l_TADK4LMC6NrhLicJF8pD8SDlyaQscyLEdWg4h-7joBwwguWIv45lI9qEVDcRmHNI9AOjDBlU_PnNIwG1Ny6lODXjeUReK0LTxA4.png) 
    - 
    - **Supervision 1**
        - Tim Questions 
            1. Abstract machines are an idealised machines which execute the programming language directly, for example the JVM. 
            2. Main Concepts of OOP - Inheritance, Subtyping, Abstraction.
Inheritance: Code reuse by inheriting some or all of a parent class.
Subtyping: Subtypes can be used in place of their supertype.
Abstraction: Callers don't have to know the implementation of a class/method.
            3. Subclassing means you inherit some or all of the attributes of a parent, you cannot necessarily use the subclass in space of the parent. Simpler code reuse.
            4. Strong typing - this means that the type checker for the language is strong. A strong type checker is one which will never fail to catch a type-incorrect string in the language. 
Note that certain things might be needed for this to be possible, such as explicitly giving variable types.
            5. If we statically type our language, that is we specify the types of all variables at compile time then a strong type checker should be easier to come by (might be a requirement...). But you can have a static and dynamically typed language which does not have a strong type checker (the checker could be buggy). 
        - [2007 Paper 6 Question 7](y2007p6q7.md)    
            - c.) What is  __aliasing __ in the context of programming languages? Explain the contexts in which it arises and provide examples of the phenomenon.  
Aliasing is when two variables reference the same physical location, possibly without the knowledge of the parameter using the variables.
This occurs in pass-by-reference languages, where the formal parameter is an alias to the actual parameter. Allowing changing the actual parameter, without having to mess around with a pointer to the actual parameter (or accidentally changing the pointer to point elsewhere).
C++ uses pass by reference, so we could have the following strangeness: ```cpp
int f(int &x, int &y) {
    x = 1;
    y = 2;
    if (x == 2)
        // Even though we haven't explicitely changed x this will print
        std::cout << "!!"; 
    return 0;
}

int t = 3;
f(t, t)
``` Where when changing y, x changes behind our backs - if we don't ensure x & y point to different locations this can lead to problems. 
It can also occur when a parameter to a function is a reference to a global variable used by that function:```kotlin
int some_global;

int g(int &x) {
    x = 1;
    if (some_global == 1)
        std::cout << "!!"; 
        // Even though we haven't explicitely changed some_global this will print
    return 0;
}

g(some_global);
``` 
            - d.) 
First we do a upcast, which is legal, e.g. we cast REF(b) to REF(A). x is now treated as a REF(A).
Then we attempt to set x equal to a REF(A), which the static type system should also allow - as REF(A)'s can clearly be set to other REF(A)'s.
However, at run time when we try and set x to a - the memory layout of x might differ causing a runtime error, or alternatively if the equality is simple the relevant memory locations (which will be the same between the two classes) could be overwritten.
        - [2012 Paper 3 Question 6](y2012p3q6.md)   
            - a.)
Fortran's abstract machine does not have recursion or stack - variables are allocated statically, and deallocated at the end of the program.
Lisp has a heap and garbage collection, however static locations were used to store variables. With dynamic allocation for lists. As there was still no stack.
In C, Java, Algol-60 and ML static and dynamic allocation are both possible. With static allocation for globals and const items - and dynamic heap & stack allocation. Static varaibles are deallocated at the end of the program. Stack allocated items are deallocated at the end of a block. 
Java, ML and algol-60 use garbage collection for heap allocated objects. While C leaves the programmer to handle the heap.
            - b.) Fortran, Lisp, Algol-60, Pascal, C, ML and Java.  
                - i.)
They all provide static scoping. I.e. can reference the variable named in the current scope. Except for LISP.
                - ii.)   
They all provide static type checking. Except for LISP which is dynamically type checked
                - iii.)
Lisp, ML and Java are all type safe.
Fortran doesn't type check common blocks used between programs, as each program was compiled separately - there was no dynamic type checking so a addition function in one subprogram could be called with strings from different subprogram.
C void pointers are not type safe and are only dynamically type checked. Consider a void program that swaps two pointers, that will not be disallowed statically even though it could be used going from int ⇒ char:```cpp
void* add(void* x, void* y) {
    x = y;
    y = x;
}
add(some_string, some_int);
```
Algol-60:
The type of a procedure parameter to a procedure does not include the types of parameters. So an argument procedure could be called on the wrong types. 
Pascal is almost safe, variant records were not statically checked to see if the tag matched the data. Which could cause errors.
            - c.)
The ML method is better, as the parameter cannot be statically type checked in Algol - leading to errors and programmer confusion.
            - d.) 
Non-variant arrays do not allow writes. So while the compile time is lower as less type casting checks need to be done, and run-time error's are lesser you can't do writes.
Covarient arrays have a higher compile time, but run time errors can occur when you try and do something like: ```java
 Array<String>[10] X;
 Array<Object>[10] Y = X;
 Y[1] = 1; // runtime error
```
        - [2013 Paper 3 Question 6](y2013p3q6.md)   
            - a.)
                - i.) Algol-60 has no stack allocation (as it has no stack) while Pascal does.
Algol and Pascal both have static type checkers.
            - b.)
Pass by value means the actual parameter is evaluated (the real parameter) and copied to a new location, which the formal parameter then references.
By reference, the formal parameter acts as an alias to the actual parameter.
By value/result - like pass by value. But at the end of the method, the formal parameter is copied back into the actual parameter.
By name - similar to pass by value, but the argument is evaluated lazily. In Algol-60 the parameters are replaced in the function by the actual parameter.
            - c.)  fn f => fn g => fn x => f( g( f x ) )  
( a' ⇒ b') ⇒ (b' ⇒ a') ⇒ a' ⇒ b'
This is inferred by giving every expression a new type variable and then emit constraints α ≈ β whenever two types have to be equal. These constraints can then be solved with Prolog-style unification.
        - [2015 Paper 3 Question 5](y2015p3q5.md)
            - 5A)
Static type checking came from Fortran, and is still mainstream today.
Stacks allowing for recursive functions with static scoping came from Algol.
Algol-60 introduced arrays with dynamic bounds, where you could change the size of an array.
            - b.)
Index checking for arrays came from Pascal later, ensuring you weren't accessing memory outside of an array.
Dynamic type checking came later.
Object oriented programming, introducing objects, polymorphism etc.
            - c.) 
                - i.)
Java ```java
 public class Variant {
 	private String tag;
 	private Integer int_data;
 	private String string_data;
 	
 	Variant (Integer input_int) {self.tag = "int"; ...}
 	Variant (String input_string) {self.tag = "string"; ...}	
 	
 	public get_data() {
 		Object to_return;
 		if (tag ==...) {...}
 		return to_return;
 	}
 }
```
ML:```java
 type Car = 
 	  Truck of int
 	| Fire_engine of float;;
```ML handles the tagging automatically - e.g. We'll know a type is a Truck.

Pascal:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/o2OGn5c1qAswhIh_7mMJ3bcNsXSn8jFJzY2bxBD-qZxTw4Tk6zwUXYjuUVnVhPUTEgf3pXC7Upn1L00mC6BsJxvbn1Pg1JLXljVisP2fNy46vUnp6QWsIx4fMlgCVXgW.png) 
^^Copied from lecture, would love to go through - don't know what's going on in places.^^ 
            - ii.) 
For the java implementation we return an object, so if they then try and do an operation associated with the wrong type - a runtime type error would occur. Additionally, we aren't checking if the tag and the state match up - which could lead to further runtime errors.

            - d.)
Statically typed languages can be type safe, while dynamically typed languages cannot.
Fortran and C for statically typed languages.
Pascal and JavaScript for dynamically typed languages.
            - e.) 
Type-safe languages will catch all errors at compile time, while type-unsafe languages will not.
Java is type-safe, while Fortran is not.
            - f.) 
...
    - **Supervision 2**
        - Malachy's work:
        - Tim Questions 
            1. **What is duck typing, what benefits does it provide and why?**  
Duck typing is a method to specify the equality of two structures when we don't have classes, that is if they have the same states and methods as each other - this means they do not necessarily have to have the same names. We can decide that only certain methods are needed as well, for example a list structure might just need get() and set() but also implement pop() etc.
            2. **What is the motivation behind gradual typing?**
For a large codebase of a language which is not statically typed (e.g. JavaScript) we may want to slowly update it with static typing (e.g. TypeScript) but not convert the whole codebase all at once. This provides the type safety to new parts of the language while not making the old pieces of code useless.
            3. **When do ML structures match a signature and what is a signature constraint?** 
dsads
A signature constraint is a method of hiding the underlying implementation of a structure, you don't see that your stack object is using an int stack under the hood. This can be helpful if you want to disallow/disincentivise certain behaviours on your type, e.g. you don't want people to store negative numbers in your natural number type (which uses integer in the definition).
            4. **What is a scripting language?**  
A scripting language is a language designed around smaller programs to automate human actions. It's designed to make programs quick to write and fast to interact with, this means they are usually not compiled and are instead interpreted as this leads to a faster write-execute loop (for the programmer).
            5. **How does JavaScript execute within a browser and interact with a web page?**  
The DOM model means the entire HTML of the page is stored in the document as a tree model, this can be accessed and altered in JavaScript and the browser updates these changes on the page in real time.
            6. **How does a GADT enable users to represent data structures more precisely than ML can?** 
If we have a type who's constructors have multiple different return types and multiple argument types, we can't know which of those types we have in our hand at any point. So it would be dangerous to write ```java
 Add(e1, e2) = (eval e1) + (eval e2)
``` If eval can also evaluate booleans, this won't type check as + takes two ints. Additionally, what if e1 or e2 are booleans?
GADT's allow you to explicitly indicate the input and output to your type constructors
        - 
        - [2016 Paper 3 Question 5](y2016p3q5.md)  
        - **Part A**  
            - Monads are a method of adding new operations to state without causing side effects, instead we carry our side effects with us as we compute.  
The fundamental operations are bind (with type a'M -> (a' -> b'M) -> b'M,
and return (with type a' -> a'M)
        - Part B 
            - readint : unit -> int IO
writeint : int -> unit IO
        - Part C 
            - i.) ```java
readint() >>= (y => writeint(y+1)) => (() => y);
```type: unit -> IO int
            - ii.) ```java
 let run2diff x =
 	((x >>= (y => add1(y))) >>= (z => add1(z) - z));
``` Is the question asking for the difference between add1(y) add1(add(y)) or the difference between add1(add1(y)) and x. I assumed the latter.
I don't think my answers right anyway, the add1(z) - z seems wrong. But otherwise how do I carry my version of add1(z) through to use when I have add1(add1(z))?
        - [2014 Paper 3 Question 6](y2014p3q6.md)  
        - Part B 
            - Thread based parallel programming is not clean, especially in a language with mutable objects. Conceptualizing how threads will interact with a mutable data structure in-between is very hard for programmers and can lead to errors.
In Java, to use threads you must implement runnable in the Thread class.
However, using Streams much cleaner thread-based parallel programming can be handled by the Streams library - without breaking a for loop down to pieces.
Writing code in a functional language does not make the problem embarrassingly parallel (this is a feature of the problem), while functional languages afford you the possibility of breaking your problem into smaller functions (subproblems) which can be computed independently (because there are no side-effects) - if the underlying problem cannot be broken down into large enough pieces that the cost of IPC is not assuaged then you'll get no speedup.
This also doesn't incorporate languages for distributed systems like Erlang.
        - Part D 
            - Z.z = A.z will work and will result in true, the type of A.z is int which is the same as t.  
            - Z.z = B.z will work and result in true, the type of A.z and B.z is int. And the t's are the same, even though the structure is opaque.
            - Z.z = C.z will not work, the structure is opaque and the underlying types are different. C.z doesn't have a type while Z.z does.
            - 
        - [2011 Paper 3 Question 6](y2011p3q6.md)   
        - Part D 
            - Parameter passing in Scala can be done using call-by-name or call-by-value - calling-by-value is used when the symbol '⇒' is used before the variable type. This means the value is evaluated every time it's needed - this is how whileLoop works, the condition is evaluated each time as is the body of the while loop (comm). 
In qsort, the = > is overloaded to also be used in lambda functions within the body.
Call-by-name can cause confusion, so it's given as an option for more programming style freedom. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hP_vmIDlQLDakWc91a0s4byAgFHwHQgQGrGz8qMVsla7M9BR2VP5sYwTUudUAwWi4X72-MXwHvfpJ5p0dC0Rl8AK34fvaPZ9uXzdvSYVneUAbxtJ_2yHlqOe_ljs742U.png) 
        - [2010 Paper 3 Question 5](y2010p3q5.md)  
        - Part E 
            - Case classes allows you to use ML pattern matching (a functional language feature) with normal imperative logic on top. We can define classes like the following: ```java
abstract class Expr
case class Number(n : int) extends Expr
case class Sum(e1 : Expr, e2 : Expr) extends Expr

// Which can then be pattern matched like:
def eval(e:Expr): Int = 
	e match{
		case Number(x) => ...
		case Sum(e1, e2) =>  ...
		...
	}
```This means you can choose how to approach the Expression problem, whether using a case matching or a normal inheritance system. This freedom to program using multiple disciplines can be very helpful.
Case classes and case objects implicitly come with implementations of methods toString, equals, and hashCode. 
Case classes implicitly come with nullary accessor methods which retrieve the constructor arguments. 
        - [2008 Paper 6 Question 7](y2008p6q7.md)   
        - Part C 
            - Explain how function types are encoded in the programming language Scala, exemplifying your answer.  
            - The function type is encoded as functionN[v1,v2,...,vN,v0] where v1-vN are the argument types and v0 is the output type of the function and functionN is the type of a function with N arguments. E.g.:```java
 // Function to add an integer to every value in a list
 // This will have type function3[Int, Array[Int], Int]
 def add_this(to_add : Int, added_to : Array[Int]) : Int {
 	...
 }
``` E.g. an ML function v1*v2*...*vn -> v0 would be equivalent to [v1,v2,...,vn,v0].
        - 
    - 
- Formal models of language
    - **Lecture 1** (Regular grammars)
        - Natural languages 
            - A natural language is a mutually understandable communication, used in a population. Speakers tacitly agree on what strings are allows (grammatical). 
                - Dialects and social media langue are natural languages in their own right.
            - Natural languages have **high ambiguity**. As opposed to a programming language.
e.g. What does "I made her duck" mean? 
            - Types of **ambiguity**:
                - Morphological ⇒ her can be a dative pronoun (I cooked duck for her) or possessive pronoun (I created her duck out of clay).
                - Syntactic ⇒ Make can behave transitively or ditransitively (takes 1 or takes 2 objects respectively). I made **her duck** vs I made **her **duck. 
                - Semantic ⇒ Make can mean many things (create, cook, cause etc.)
        - Formal languages 
            - A formal language is a set of strings over a finite alphabet.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oL-mPUR-xQv2wUbTgvxIR6dZhpfRZZ9bqaopoNCFE8ScHgMaG8vlVbJ21Saef5VlLX_zPobKW6Q6xcoNFyqvM-CmAbGMoxlJsuNSsgjlLdzbeCT7SOhS2h_zD74xN1nB.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KSTciC4AT1plKHmhONryRr2vBWB-bV9d-kI2iP53e_DoOtxotuG0Mx7Dg2d1YWECJcc_CLOleb9QNhLoLGxjuntzHIc2zVDBi6jhb1DDSsHIlmVHClI9iSfSJT__J7n0.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ozxrdAafqcXNQT-tF6c-CzVwyy9tfQbqiSTjcIFtVw-BWA2RnLEnCHSIfEwWJ1ztYjv6mWblZabs_Cc03yo3oRDN4z4VBjmQvy2wNGkFoiAyzTC3UtlSdEZyn46Y6jDq.png) 
            - When is a language regular?―If it is equal to the set of strings accepted by some deterministic finite-state automata. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MYgVPEcl_CAdi-hdhwk0-effFlQGZKXR4rMpYETW-QQrkFs02klsNXiA5ZUroCjZdV6m7ngqQfZH1CAYnXNL_7R3bAhKnQOaiKVUJDyORhH0_WT7AcD9UBVauUZf1RBN.png) 
        - Regular grammars 
            - For every finite automaton, if we write the production rules we find another way to generate our language - i.e. we find a regular grammar:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kPx38aheWfPaTT_JDsq4BpFAuLrXYrD73eJ74FC8glqgTfp2gXLqTrjF_HZ2beM_A2nZeLTyBEr24Iy1KRUBWTPX2I2K8e2I7_KvcKMhELE8tpFlZh-PpP76BNoJ_rCf.png)
 ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i2JbPWNnxpvPN7pummQsukkxykSDP3RQZ3mCFneavc6gmfvNqUU68KMFn9WeyUhW1RqY5N2CYW5RaIDOPjIYDI9nxYNunfQxTPUNc6xqzbaTCSp07BAFaVsqxAZzw8ox.png) 
            - $$S \rightarrow bA$$
This production rule states - if I start at state S, I can output a "b" and progress to state A. 
            - More formally, the language of strings accepted by a given DFA can be generated by a regular grammar.
            - Describe what each of the following symbols represent:$$G_{reg} = (\mathcal{N}, \Sigma, S, \mathcal{P})$$ ↓ 
                - $\mathcal{N} = \{\mathcal{Q}\}$  the **non-terminals **are the states of M. 
                - $\Sigma$ = the **terminals **are the set of transition symbols of M 
                - $S = s$ the **starting symbols **of the machine M. 
                - $\mathcal{P} = q_i \rightarrow aq_j$ when the machine would transition from state q_i to q_j when it encountered the string a. 
            - Within a regular grammar, a derivation consists of repeatedly expanding the non-terminals until we cannot do so any further. 
            - Every regular language has a **left and right-linear **grammar: 
                - The rules of a regular grammar can only be expressed in the form:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YsFDgy5fcrHEsBQXXUU8EU_5xLcWIOMik3X7ogyPiv57LQzkXLZtuYlj5R7Q0lbzsc9t3WF5NCZJdKZUgPKcQ08qVEZTTxEs8e4xnMNjrEhPIjq2rAUHDlA68xebY_CK.png) 
or in the form:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yLhMYgrFPgJrNZl-XRvq89p3G7g2AL9SNuSdYGiRCzLnR8uh6lVE4WpWFdcdK9cWW6RH5E3cUOEPIFBb4xa9CMilhMJQ3xGwh9rY31yALT32jCf4TEBqJnC_M12Tmmum.png) 
Are these two forms equivalent?―The two grammars are **weakly **equivalent since they generate the same set of strings. 
However, they are not **strongly-equivalent **because they do not generate the same structure to strings (I.e. the derivation trees are different).
        - Phrase structure grammar 
            - More general than a regular grammar, simply require that the left side of a rule has at {{least one non-terminal}} - while on the right side we have {{any combination of terminals and non-terminals.}} 
            -  _Phrase structure grammar derivation_ :
                - If $u_1, u_2$ are some string of terminals and non terminals - we can convert from $w = u_1 \alpha u_2$ to $v = u_1 \beta u_2$ **if **$\alpha \rightarrow \beta \in \mathcal{P}$.
                - We then say ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/llIrrS3qeM3eTvoplfovEZCK3qfBdIr771yQuSOH3hHKEMc3Z1GkHk0_RWziKJuwZn-wpVbuUEmEoVpHx6F1nnSIX9tbo2-n3aOBgq_Y_hWuSVgjup8ukFC8iMgflfRe.png) , w can transition to v under this grammar.
                - The set of strings in a grammar is then the set of all strings derivable in a **finite number of derivation steps **from the starting symbol S. 
            - Chomsky suggested that phrase structure grammars can be grouped together by the properties of their production rules:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SF3CwGkdDC_3aBxaMxEvqaECU2OY4GFz-FrpZJj5s7oegFp95OntGg2t7zscFuY1srRfRoHonK4F-XY2RTjRjnL7DuJwG6Xw7Fcvlz3fNHccFBxPOJwgfpz68nAmCKcu.png) 
                - Context free ⇒ Still have a single terminal on the left, but can have a combination of terminals and non-terminals on the right.
                - Context sensitive ⇒ Can have more than one terminal on the left (there is a **context**). 
                - Recursively enumerable ⇒ anything goes.
            - How does a **class **of languages relate to grammars (e.g. regular languages)―A class of languages are the  languages that can be generated by a particular type of grammar.
            - The term **power **then means―The number of **subsets** of $\Sigma^*$ that a particular language can generate. 
            - Are Chomsky language classes **closed under union**?―Yes, if I take the union of two regular languages I will always get another regular language.
            - Are Chomsky language classes **closed under intersection**?―They are closed under **intersection with a regular language.** e.g. a context-free language intersected with a regular language yields another context-free language. 
Consider that we won't necessarily get all the values in the regular language, and a regular language may not be able to generate that lack of strings.
            - The **complexity **of a language class is―defined in terms of the recognition, how long would it take to recognise a string from that language:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2CGxDC-5ghW-KwGQG1kJWH7a6jM6D-YZPkWaOSpsJD_l3VGQ5g6y6CItoruCAaj57zTEscPjHnHvsT2hk6rDO_6HMnn-FHuS70xE8IyaK32SRsECqAlmmJQYflKwokoH.png)
Where  _recognition occurs if we end up in an accepting state_ . 
        - Can regular grammar model natural language? 
            - Short answer, no (in general). Would be nice, as we could form linear algorithms to read text.
            - **Centre embedding**
                - A centre embedding is―an infinitely recursive structure described by the rule $A \rightarrow \alpha A \beta$, which generates language examples of the form $a^nb^n$. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UpUbxsTMQDbnOYtuQZPJQp1yoHtl3Z6aMI8lqXmJGWOgNZ6C2b1zB863yb_Y1CayTPe0r8En9ZKKlalKLQjTrqrXxNTKBOgaYwHw7KrFd2XcvbeysI47ndIQhp3f2kHD.png)
Could continue:
The students that the police that the informant helped arrested complained. 
                - The **pumping lemma **was used to prove **not **regular. 
                - Does the existence of centre embeddings prove the English language is irregular?―**No, **the  _complexity of a sub language within a language is not necessarily the same as the overall language_ . E.g. $a^nb^n$ is a subset of $a^*b^*$ - but the latter is regular! 
            - Describe the Pumping lemma  ↓ 
                - The pumping lemma builds off the fact, that if I have a string longer than the number of states in my machine **I must have gone in a loop!** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/N317Vy-_VFuQMHoQ3BzaDvThavpBOjiVI9NJF2Rln2_kPTi8ReeHMmE8nJG70NJgwOkLvKInFHcjmT64g5RSzKMFDPH0eeHhn4SLBkHUx4GiT_XVBPgSwy3L9YXvXqtS.png)
l is the number of states, v is the loop, and u1 & u2 are the pieces before and after the loop respectively.
                - $|v| > 1$ - the loop exists
                - $|u_1 v| \le l$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SM1Khqzpxbg7qVI6fwUrgtBpfDzRxDICbud4KnqLdachZic3Gtx1aJSuW8VQAKaAaE7litTBb9arS_vX_v410AyA7zLQIfgieCMqgtzxQxoTaUN1PLwVHkEH18xQGmuq.png)
If I go around the loop once, I must be able to go around it **any number of times.** 
            - How do you prove English is not regular?  ↓ 
                - First consider that a regular language intersected with another regular language is regular.
                - Next consider that regular languages are **closed under homomorphism**, we can map all nouns to a and all verbs to b and remain regular. 
                - This mapping gives us the language $\text{the } a\ ( \text{that the }a)^* \ b^*$ which we know is regular.
                - If we intersect that with English, we get centre embedding $a^nb^n$ (which isn't regular by the pumping lemma) - ($\text{the } a\ ( \text{that the }a)^{n-1} \ b^n$ ⇒ **Therefore, **our assumption that English was regular must be incorrect.
            - But for finite n we can still model English using a DFA (consider that for n=3 the processing load for us is pretty high).
            - Why not use a regular language to model English?  ↓ 
                - Context free vs regular:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lHingeygt1UyLLS09lO26kciLYotXwf_aw25knxGop-1qOfEW6yMFnLkR3oj9Ze1erHWC5yi_F_vSAxRbkSA0NHhhxCShM9TpJUFTRcb7gjOL42ohyRwLSXlJAhUmbF7.png) 
                - English not regular, can't model in general. 
                - Redundancy - need many many rules
                - Non-useful internal structures - the structures generated by regular grammars are not very general or representative of the language as a whole. We need informative internal structure to build up good semantic representations.

Context free vs regular:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lHingeygt1UyLLS09lO26kciLYotXwf_aw25knxGop-1qOfEW6yMFnLkR3oj9Ze1erHWC5yi_F_vSAxRbkSA0NHhhxCShM9TpJUFTRcb7gjOL42ohyRwLSXlJAhUmbF7.png) 
    - **Lecture 2 **(PDA, phrase-structure grammars) 
        - Phrase Structure 
            - **Context free grammars capture ** _**phrase structure**_  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GcZGOKcQangEeK8KXL_-1HFldGiO8HLetSLiO1x82KD2kT1O0I6-efJOHerFZh5bmEFlrwMAnPGG5L7ssD41iUxl1zLRpndgeAwpqrU1pJ5QWW7f2lREXPgy-hANdPmP.png) 
            - NP = Noun phrases
PP = Preposition phrase
V = Verb
Adjective
            - The most influential word in a phrase is called the head. For example, flamingos is the most influential word in the NP non-terminal - pink is more information.  
            - The head of the entire string for context free grammars is always―The main verb.
            - With a context free grammar, we can change around any branches within the tree with the same name: E.g. croquet plays Pink flamingos with Alice
        - Chomsky Normal Form 
            - Every production rule has the form $$A \rightarrow BC \ \ \ \ \ \text{or} \ \ \ \ \ \ A \rightarrow a$$ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KvnfwciChcYFXcEQJjQqngBi-8NnibfmsVj3Wnvtq67UR-gG0tJNNcHJ6kh8tpa3zqlnNKg2FVeWDc-9rg9sN6bduc-AQf8zEz_UHHJYnTOgEpaO67Bqq4M2-zq2Kg9w.png) 
Here A ⇒ BCD becomes A ⇒ BX AND X⇒CD
            - Why is Chomsky Normal Form used?―So we can write algorithms where our data structures are always of the same form. Convenient and can allow for more efficient algos.
        - Push Down Automata 
            - A finite state automata with some memory
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6QFVsAI8e5gF3_xXYT-XOIfpRgWlbD36BqI_iVxQy6ZeEKBxPeKGeXwuU5jAt_8Qx2ePNG8acqvFtlEP9KDHh2AGwwuk-CUm-aCipL5Vfv8LUgjnawubIZ-NIT5o5DOe.png) 
            - When we move from one state to the next we may push or pop.
            - Explain these two diagrams:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/afN-4q6dRIsPS4DyvR67hB3CzPOE7_v_Wo_Fc-B1z7UQgrd7JinzpsSylxbtKc4VEkBs1c1q3SDDdk-_rUDyNk6GbbKap_4GJ7DosyPUWz2s-eeezD7Qj2dfTc25QePP.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bu0aCExBkru9iT6fU62_gIvuJgovVyzUubyHGjbtDYKfqH8cR0d81VTE8SCVYUd0Tzsp5QBkROl4WgO4RIe1Ni7Kiq7tCtLPbmTSac2EdXYFWVsZdbvAbBcejPq2hHtQ.png)―These are both is part of a diagrams for pushdown automata. 
Diagram 1. Here, if our machine is in state $q_x$ and it encounters an a on the tape. It will pop an A from it's stack and push a B onto it's stack.
Diagram 2. Simply saying push A onto the stack in state $q_x$. 
        - Can context-free grammars model natural language? 
            - What are cross serial dependencies?―Strings where dependencies are interleaved within a sentence:
We have wanted to let the children help Hans paint the house.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oYTiANb13Y4emLT5EezgIp587bVpy2krn_eKtXwetxqWOfkcEXM6oND3pnRr6ZpxeuqH-i13IuMYAliifa8cUVWxkN4erHRK9nT-yLUnJ9Fzo0-wvZPCozWXxg-an-vr.png) 
            - We can then map this construction to the form$$wa^nb^mxc^nd^my$$ 
            - Pumping Lemma Proof:

            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hHwUdZyhku0KR7CFT9stgi-K9dpSFtvBwR4KgXYjthWb4xuqEsIQJiuVtwMPyB2jVNbgnPIZ-xF-t-XamGUQNgojQyYsszJO9R1aqlV2g1PPZO-sPUFnuvGCBKH7ty1w.png) 
        - Mildly Context-sensitive grammars 
            - More expressive than context-free languages, less expressive than context-sensitive languages. Between the two in the Chomsky hierarchy.
            - Have the following properties 
                - Includes all the context-free languages
                - Members of the languages in this class must be recognisable in polynomial time
                - Must allow for all constructions in natural languages - i.e. can represent cross-serial dependencies. 
        - Tree adjoining Grammar 
            - Trees rewritten as other trees, rather than symbols rewritten as other symbols.
            - $\mathcal{I}$ - is the set of **Initial trees **(also known as $\alpha$-trees).  
            - $\mathcal{A}$ - is the set of **auxiliary trees **(also known as $\beta$-trees). One leaf of a $\beta$-tree is distinguished as the foot and will be the same non-terminal as the root. (Often indicated with an Asterisk). 
            - Describe substitution and ... in Tree adjoining grammars ↓ 
                - **Substitution: **Replace a non-terminal leaf with an $\alpha$-tree with A at it's root:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-dljmU_Ztvn6ppm3Hh37icRm6rJX4DxA86E0OWrAgTjS_MOu2Lm_nM8hAwoSf7wuS1pnyKq0WAsBBzNw79O_v7d7gNjnL1sbvnxWRLxZZcVFtcr0ujOJdaVlah-kuu6f.png) 
                - **Adjunction: **In 
        - 
    - **Lecture 3** (Parsing)
        - Shift-reduce parsers 
            - This is in the context of **deterministic languages **where no string has more than one tree i.e. the grammar is **unambiguous**. 
            - Initially the input string is held in the buffer, and the stack is empty. Symbols are shifted from the buffer to the stack.
            - When the top items in the stack, match the RHS of a rule in our grammar. They can be reduced - e.g. replaced with the LHS of that rule.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-UIUX0aiu53AuyE33ZDUaQCbZaAz-5anOZABpyg2TYCv01cO6fkZAZBqGb76EjForqrqFCqyUH_FnKTFv1DB40SB7GPOs_hB0RPHDxEdw1iQDNICNp_rn0ZyV-87KIte.png) 
        - Deterministic context-free languages 
            - Proper subset of the context-free languages
            - Are accepted by deterministic push-down automata
            - Can be modelled by an unambiguous grammar
            - Can be parsed in linear time
            - Parser can automatically be generated from the grammar
            - Note that Natural languages generally don't work with shift-reduce parsers, as we can have multiple choices of decisions to make.
We could choose the path using a machine-learning classifier.
        - Ambiguous grammar results 
            - The number of binary trees is proportional to the Catalan number, 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sdbsPL_5oRAxIvi7_7fZfpaBVJlMrZObv_Of-9opP1tawl1OEVKc_d-Lu8un0PGDudxc8F76xHqYJsn38_QI2WpUNZn3kaH2IhRdZn2CUEcG1vkOagqWEDUwRujIP9YP.png)
 I.e. for a sentence with 12 words in - the number of possible trees to go down is 58786.
            - What are parse forests and chart parses?―A collection of parses is a parse forest. A chart forest is a pars method with hash table lookback.
        - The Earley parser 
            - This is a dynamic programming algorithm that records partial derivations in a CHART.
            - What is a dotted rule?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/00JiGkJoes5-WpA3Q5RFIbbdXiaozpvSi_g7kpttbTxLsbpjrCT8pU3G-wY4vH4mNgMnt8Uv7Y6D8dBedg8GIp8LKdUrQJLzK6PfA9e6vEOVMwsC8da0mJURKMWlQYLp.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ncgfIkddYNdf889mTyqYWxiy-SmLTQD949v99KsYLn-6WGR6SecDKBZ_hr4IiTXMNtodWW6QR-5TnzSLKxVoHUUqn6cn1jeX_he9du0ApbK_Ai47GKM2ESKeok2Wb0BC.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8X26iP4vERb91q2RUexqNYB-uENUbc_9swXNraIZrCVTbymR9xR0HWaTVX90w8mIgI2iI-2pwxOMUWOt9TXhv1U8igvbFKAuAvrI4dl-y-jutQOSYf8-BCRJl9v_1UMw.png) 
            - What are the 3 steps of the Earley parser?―Predict, scan and complete.
            - What are the privileged set of non-terminals―In the predict step, for something like $NP \rightarrow \bullet N$ - we would have to add **every noun **in the language to the chart during the predict step. We don't want to do this, for size & time.
So we privilege a set of non-terminals and perform a look-up of the next $a_j$ to see whether it will be consistent. 
            - Describe the predict step ↓ 
                - We look for the non terminals just to the right of the dot, and look at all the rules which generate those non terminals and add them to our chart
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4iYyiix0VUGap_OWCrJRCZuOvx3axuohmaK8r3g7hvKvLEUBWgtUONszYrH2fpVlQW20qxfjIHp4icDW7Q_9SOM0oCFpMe1F_7v_claz3qPEhdfTuIKVCKvfG9YlLCe8.png) 
                - In rule induction notation:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oggF-KwcYsI8bHlROprsy-PlQYdKIHJyfJwz3LG5Sf7CzBymSbfEJyZUet09LhAah3eKpyX2GYhBnGnSmE_FzQyoLRwykVpvzXfsa_cBLTLQ2eOTNl88O-mTv4IyHNPs.png)
The lower half say's we're **starting at j**, and **waiting at j**. 
                - Note that here we're privileging $\{N,V,P\}$ 
            - Describe the scan step ↓ 
                - This step allows us to check if we have a node that is consistent with the input sentence. I.e. they is derived from one of our rules.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/icZW7i9FxieJ4l1pDIBpHQQ_k0Bzy1HDD6SUW5G_PlC5-MD9nUd-C-8QZ1fujfp3mzjGSEpnToTExZoAq9KSd0Nnln2lMAybIDic5OsmHWhThr_YqF4H0YT0x3lel47a.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/l5rVp5O7T3A3tOzaPTwjrvhAeEpjNxeCr_SFYrpHknKPwRXNu1VMQ0NsfL6IPS_S20NVUHWDCoykoAq38-RqLCN-pVS327j7tX60YhIAQo439LUwsyqUsFmxeN9SR_hO.png)
In rule induction notation, we've seen $a_j == a$ - so we say we started at i and we're **waiting at j now **(we advanced where we were waiting at by one). 
            - Describe the complete step ↓ 
                - We take all the rules generated in the scan step (e.g. N⇒they) and test them against all our rules from the scan step, seeing if we can advance anything. Then if we complete any more derivations, we need to test **those **against words made in the scan step too.
Moves dots along, signifies exploring nodes.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YOzJi9vVF5qaHubirzPkB_qI27LzMzs58FFFYCxvAZXHMueyEmX1TIg4srmtpVVIDRC6QveyKODCYa1DBmjzK230iPili4RZlQy8FQo-oZo7Dxuz4UsYmW_7HnUn1HDK.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yhiJ2_hSBwPqSjDwEV02GnHcumjzi9lrhwdJgI9sKC_y9LDL84MeUXGQB-pWZQBcRIbcHu_mdmABX_IP6--J8zhPcoI-W_RdRyK-LU4hIoDdH5gG1lGaf_J3rF1SryLM.png)
On the left, if we have alpha and are waiting for B. On the right, if we've found B.
Then we can move past B. 
            - Example:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nYN0UDYlqepYX46jUR-6m0rnNBndg4a1J9G8wQKRGCRihhJ7Vk-CgHuFcXlkY6oKqq_Ca8OWYYKamJK8UcsgZ7IBPM7ZaCRMMEvAsNtZCjowsha8rcBwEk1cMG8X6fp-.png) 
            - What is the time complexity of this algorithm, and why mate?―It's $O(n^3),$ because the complete step dominates with $O(n^2)$ runtime and you do that step $\propto n$ times.
        - Complexity for humans 
            - Complexity can refer to: 
                - The time and space requirements for your brain to process the sentence.
                - The information theoretic content of the sentence itself in  _isolation from the human processor_  
            - Traditional work in this area gave humans problems, and observed if the difficulty of parsing a given sentence correlated with a parsing algorithms difficulty.
            - There are two assumptions in this work
                1. The longer a sentence takes to process, the more complex it is
                2. A complicated sentence will not occur frequently in the spoken language.
            - The horse raced past the barn 
The horse raced past the barn fell
Sentence two, while still correct, takes much longer to parse.
        - The Human Parser 
            - What is surprisal?―Negative log conditional probability, the more probable the less surprising.$$\log \frac{1}{P(w_i | w_1..._{i-1})}$$ 
            - The suggestion is that we can model humans using a probabilistic context-free grammar. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DO5NXwDGecVA0SnciDIBMBlxSIzw-af39PNpaJ8DrzusXVjvEgAFmmO6mwbtbqzvOKjXdjCfTQq-9QlsHJByRPD_Am8weahvqCVq9kpg2q1PNTAF_OX5RahB-64fQ_dK.png) 
            - This model differs from the Earley parser, where ALL PARSES are found. Instead we follow the **most likely **path, and then **double back **if we're found to be wrong.
            - What does this sentence mean:
The hypothesis is that the cognitive effort to parse a given prefix, is proportional to the total probability of all other analyses not compatible with that prefix.―Means that more surprising sentences take longer to parse, because we try loads of other parsing trees before finding the correct one.
            - The probability of a derivation is―the product of the probability of all rules used to make that derivation. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3c_9GqzCaHqqQMRMOcWvSozo2wwQZPwt86jpzli1zyUsDh9BDWGKUpV19vIwwgItY1MIRvFC-wDsbAkIksxXepr6PsORR-IXM_cio2AwNslpoJlFrcfXrE0G-RvH2a8r.png) 
        - PDA as a model of sentence processing (Yngve)
            - **Hypothesis**: The larger the stack, the higher the working memory load.
            - **Prediction**: More complex ⇒ Difficult to process ⇒ Less probable. So sentences with larger stacks will be less frequent.
            - **Prediction**: When multiple parses are possible, we should prefer the one with the minimised stack.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GdNNnYwASAVVy0eqrSR6iH9oAthE5Plm78ChrwYTuK8KqAq55eLj_-pgJEBtPwvGP5YkJNBwvCkdJNx9qTFokSTOu9rU5SXCLsKZ11krXRba8o40W4VHSp4SNZm_E2yT.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mOdkW0JqMCszthAGOzC6yIFgon9KMziFAf6ftdMfOuay-RD0GP1aSv3G64KLMEl6ompIAl60LiMHvgTuy9saXJpj1l7Lpr5MtBuxpHM4ua5IOXOMEq9qBO17yMnhXH-i.png)
The max stack size here is 2, meaning a sentence with a larger max stack is considered harder to parse. 
            - Great example 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/a3csr3NwS-hJcUvsr5YDQvjUZdj7dFKTBMDYLdwzxzNv1un_5Z_cbDISHoI28-T3GtjBrET9iKWAsy2jmwCebSJ_HtCextJ2YZEwjlTSzaVUenx2KZh6MiUmupLojeoG.png)
Nouns and verbs resolved locally in sentence 2. 
        - 
    - **Lecture 4 **(Dependency Trees)
        - Dependency Trees 
            - A dependency tree is a―directed graph representation of a tree - where every edge represents a grammatical relationship between the symbols:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fnOjSdkXDa9DMXTVIrZs2kxa1HnckgaywjI8mQRrqjJ-fA_wU8Ter2f0Dwz6IVRUcsJy5M_pNJPIeYf8s0_l6EERJEwwnuw2j3iyssYstOx6yIZZhRe8jX1xCNtZWr69.png) 
            - A dependency grammar derives dependency trees:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vJdyEly6JKk42TJRyO_frnEY4JJOMYbH_RT4YEW3_j8HYD-dMko0mXh8l8Fg2woDCuFTjqeonjfYzdCTs09UmoAVXAj-KLYWfd9pCEnQj6QVTjafbbRlAQkvsBg_wSZB.png) 
            - Using these rules, how would you test if the string bacdfe is in the language:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IVlhvDPmDEl7OW-CHPMGS1yDSJaELVRHpmLIKTFvdVqYK4tPcRZfJpiDtxELYS0PEy5x5-3c3B8poIcB_v1nIpN7JPlrqMMjxe4Yip9N-f24VZX_iUprVEuS-bxDLk60.png)―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZbWPB-3DuqkykqzgC_oW4cpuZZbuxAQO_rggGjzW2f51e7dZ-xPlgGt6tLTf_1VILYGTxq2zRkVxIed6G8kZwyRDZq9FQP3nPW7cvlmreNAMtp_okX6FrtAR43w-HGbt.png) I.e. use the rules one by one until something doesn't work, or you're done.
            - Note that by the above grammar, we could also generate badfec. The fact that this grammar can handle differing word order means it could be useful for modelling natural language with flexible word order.
            - A valid derivation is one that is rooted in s and weakly connected. What does this mean?―Means it starts in the start state, and you can reach any node from any other node (if you ignore direction). 
It's a bloody tree, of course it's weakly connected...
            - Trees can be projective or non-projective, what do these terms mean?―Non-projective means there's no way to draw the arrows without at least one crossing another
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/L4tbDyALjccvtgVQ1-z2Fk3wodEPrU4bvm0oVxbgN87bjw5Wa9HTqacsSJwY9ruxaPdNm08IMhPpRTMRSQQH-poJvBDwFDUCLMclxOEgqSrbtcGtJFu-wh130BoYNzxB.png)
 This has implications for parsing complexity.
            - Labels 
                - You can also add labels to dependency edges
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/88dQ2eXiq3fq9RAiluZmr68D5mAes3lUXqWGVp0C9AHm2xPiU6W6_ZZWVAOOt9OA7gUTU92CLjQhuKsIZffClIc3pD9TVPG9F4cFBvDAnIBgCNyKiDTeh9VAos_XZexb.png) 
                - Where the labels are r in:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V--9y6L5vgEsdBojdwa6NQQFwCj52V2cbusaGFhrhiqPLZQ-_Yf4Hn5kX9OrMHdC9dvu1YYn4gg6OwYXCf6VaVaCslztbE6vySaLMtxquBAEeAm8Bb4u-aHmNzAQm7tu.png) 
                - In the sentence "Alice plays croquet with pink flamingos", give a **subject, object **and **modifier** ↓ 
                    - Subject: Alice 
                    - Object: Croquet / with
                    - Modifier: Pink
        - Dependency Grammar equivalency 
            - **Projective **dependency grammars can be shown to be **weakly equivalent **to context-free grammars. 
            - We can convert context free grammar trees to a dependency grammar tree
                - Start with the CFG
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1UO9Kkh2FyDnzt5NPzeTbmwT6kH697N6LezokJPqqPcQWSMgAnFm6Z8bW8CmENedfBWnPkzfGFHzgE1vWxP6F0M4ow3oK7RcYkmYq1R2vbmk4AD_8ZKk6Jhx750vgrpZ.png) 
                - Find all the lexical heads:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bjnLWm8nnG0rxodTRYb0AZ2ZDaA179WG8C0Mou8C_XR8bRwQ4TUIn0K6G1ls7fs4f3XYExbe5WHJsgj2cVKkchlbS-w8lbWg0AMkSCEXAMVwRJdMrj3q44Vc6mdCyoDo.png) 
                - Then note the **highest **position of any lexical head: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KccGk17DvxzmZ-XxGOcZUZVBtUvdN5uPNozCo_Y7Vj_jbww6DENQhqLFso9jqI7ywt1R6uDyLCBhNOn-kJKlyHnQTwRpLLqgWX1ZAEssJS6nR3nPfSJQpINReSpA6u9W.png) 
                - Then remove all parts of the tree that don't link one of the boxes:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jr86z7mA4oTfuU2rTJ4_abB18lR_bwQfu3AxjTUFRF_BfOetFc77xH0VCrCkePh0MIa7GV2a3z41R_0ke8PQPhQLnpEXixSVXOvttDs9p7TGprvxgDqtynTCs-rcrHpV.png) 
                - Finally, merge together all nodes with the same lexical head:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6OuZx2NnwjllIu1Q4FzOICEbFy-tiyVNMFh4gPLC9P4sGbLZhYipEXGNtpywOYgnJUeWHiAga_pzG-JElrLl1Gqk-jUiY1KNojVQ8A4l6MsjzyiN-4rYX58fBt5EQR6l.png) 
                - Resulting in:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dgxFCWR5ABlSJzBwESM0iDDZAz-ERNhfBwCjx7hvaJd8uxhudqk2xmUcyOah0fnchdLjPY4B83ZM1QH5EFUU2PllhBinI5Un3DG488Rg0wOhnQeJFb28U56kWmYk46Ke.png)
Which is a dependency tree. 
        - Dependency Parsing 
            - Use a modified shift-reduce parser, instead of a reduce we have―a left arc and a right arc operator which reduce the top two stack symbols leaving the head on the stack.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bb9ysqDZy3uYwUw87ChWsN7BcSf-EqNgxFw_9TgBgJy-AF1vOhFfteBWVwjJ3TwLbFKeg3GZ65NdEF258_XaYxok7OUXM6Qp0MUKgmhFC5LWqHKoivR_U80r0X5DrAOJ.png) 
            - Parse bacdfe using a modified shift-reduce parser and the following rules: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/EMFn6bTnGRiFshBJ11SJecbTWJ7X9jR2deeZCGZQl15O6GDemIKeD38bw1kSCgMEdJMaDBOY0wl_H2kKoFHRaatnckANG9yLbYqNmQwAhfB8KBO_R3CZlNPxsGimplY-.png)―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/foIkUOVFVHEpnzaKOO0uuIi4_c7pYJSlPVhVgBFUbONCxRhXoEQS7MVQbiyEYgukQgXpcyfrM5zpELzCh4nF6UGIN3Ifn9yF_V1IXYmg02Q7q1W5CMHKgRbwl0fDYmRN.png)
Note that for a deterministic parse, a lookahead would be needed. Because we could use the d right rule in step 6, but that would lead to an incorrect parse. 
        - Data driven dependency parsing 
            - For natural language, defining P would be impossible - i.e. defining all dependencies between all words in the lang.
            - Creating a det grammar would be impossible (nat lang ambiguous)
            - Dependency parsing can be done deterministically by {{choosing the parsers actions}} using a {{machine learning classifier}}.
            - Training is performed on **dependency banks **that is―sentences that have been manually annotated with their correct dependencies. 
            - This parsing is grammarless, no grammar is designed ahead of training. 
            - The classifier can return a **probability **of an action. To avoid the problem of early incorrect resolution of an ambiguous parse―Multiple competing parses can be recorded, and a beam search (expand most promising one) used to keep track of the best alternative parses. 
        - Spoken Language
            - We can mark speech features as features for the dependency parser. Prosody, stress, intonation:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gqDlDXz6E1-QxRIjhpJXeqqlmA2UW086zkXM3puktIBVCq_OiKkbF9bE5rmOa_4HwSUSGsoIeyxcaliKKnjp_CHBjHj5mv-RAGFbj5LTfND8fBoxQ3ThPzNh0Syr6lNl.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1y7vjOVls7Wfpo2zi2QSoIg4vtvtJtFZyfse4pi_rZPPSRoCXO_jhxMjaiBdP0rml53VNiqO4uXG1kczMBjVbT1_sTwdJ0rAsozEST4BGVUSlNfYzL739ttOY0iHwssv.png) 
            - A fundamental issue affecting syntactic parsing of spoken language, is the lack of the sentence unit. No full stops or capital letters. Instead these can be identified by pauses, intonation and change of speaker.
However:
Speaker-overlap, ellipsis, hesitation and false starts can wreck this.
            - Speech units often contain words and grammatical constructions that do not appear in written language.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QyK83YNOLGQqajyPHixoLJUXQMazBtO-PsZDzbnO4omsvOsgsqNWl8Jtv9UyqC6DiSFfLQKGkXyhqdoMzksI9OG7mzzLdd3FPCq0i3Z6kTKqZPbUw8gDxIVkEEuM-de_.png) 
            - What are disfluency, and what is added to a dependency parser to handle them?―Disfluencies are pauses in the natural flow of speech. To handle them we add an edit action, which discards all the connections to the current head and scrolls the stack back to the previous head:
In "his company went broke I-mean went bankrupt" - I-mean marks a place where we need to redo.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AGDkHjN8U-b8kNXF6XNZdvMyTi8ow4R9kqAR9kbC6Py96HVZcoHM6355u4YLGTSpakfazzGCel6Dsf8BlqHXGIRx0L1Za5lfE9hfvoROSUYPF_LEYsR4AWuDgFJdeG1m.png)
Here,  
        - 
    - **Lecture 5 ** (Grammar induction)
        - Inferring Grammars 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/D-ADiiOVKdNwDb4-Spfs9OqjsJ20r1uZRAiWEi3M2ZtlzpzWMGkG2YGuSdPdjt8ZZFE7gN_VT5JUL7HZODkClPZ1ReiZJXwJR1XvTadR9wG4K3Qb1l_6ogfiEtX6NFLw.png) 
            - Describe Byte-Pair encoding ↓ 
                - Count the most frequent pairs 
                - Convert those pairs into a non-terminal
                - Repeat until all pairs appear at most once
            - Byte pair encoding has benefits for encryptions and compression. However, it has multiple issues.
                - It's frequency driven, this is a problem because―it might not lead to appropriate constituency. E.g. for "the cat ate (a mouse)" we can replace a mouse. But (ate a) will be replaced, because a cat is eating **something **more often than it's eating a mouse. 
                - If two pairs have the same frequency, we make an arbitrary choice of which to reduce.
                - The data is assumed to be non-noisy.
                - The algorithm learns from strings alone, no extra-linguistic information.
                - Two improvements could be―ternary branching (HHH ⇒ K) or adding extra information to break ties.  
        - Learning paradigms  
            - Grammatical systems 
                - What is a grammatical system comprised of?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1OIIf_Bd5qetlxuM1D2zSXUyp_UQvVmLWHajy9983kCOXq2MFhgESHfKiuHAM8639XTpIjDEZoJ2Jww7iezcjJu_GTLCX596E-74MIz4wdzySiT0YNY0tFgAPgHw1hUE.png) 
                - What is a learning function?―A function maps a subset of $\Omega$ to a member of $H$. E.g. makes a guess at the grammar given some strings. 
                - Learnability is a property of a language class when F is surjective.
            - What are learning paradigms?―Learning paradigms specify the type of input given to a learner.
            - Negative evidence is―the learner receives strings not in the target language, and they are flagged as such.
            - Exhaustive evidence is―The learner receives every relevant sample from the sample space.
            - Non-string evidence is―non-string samples. E.g. verbal cues.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bSBZxehFbaKDhioDagcj253oc0ZP-s4UhM0zaLtEgImXNC3Dj3ApvhWnqIaTIyyLg15JQoDG3VbO-FSNBExCD0iSNGgsq3luHzWtVHUH3rmsOPPbCSp8rTF_4t-MTT4q.png) 
            - Positive evidence is―the learner receives only valid examples from the sample space.
        - Gold's learning paradigms 
            - Describe Gold's learning paradigm ↓ 
                - Learning is an infinite process, where the learner receives an infinite stream of strings of the target language. 
                - Positive evidence is presented one sample at a time. 
                - After each sample, the learner produces a hypothesis. Outputs some grammar $G_n$ after seeing n samples. 
                - Every string in the language will be presented 
            - What is identification in the limit―Gold described that at some point the hypothesis language will not change. In the limit.
            - The class of **suprafinite **languages are {{**not **}}learnable. Those are languages that contain all {{finite languages}} and at least one {{infinite language}}. This means context free languages are {{not learnable}}.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7tRCV5ng3niE9ACtHVXefmUN0tkcoYGDTwX3oVU-VC2gK8HgbaL7I1vHB5xDZH3FascQvk7Dg1GEP3txN_4Z9JN72Mxn7Q5s2r_Qu2pTMVY7-45q_fVTZ9V6HC9WsRuD.png) 
        - Categorial grammars 
            - Describe classical categorial grammar―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8-cPmC_AEsqdcAmf8660Yp0qPyhsBTUlr9FYvI8SkQ8zoLSmdK1vt84-j5a4b0VaWrmhpbTZzDoslamHNEuzHuQlILU5XWLTWj07XGiXqrr8DvOVej6AIGgYWCR92PRq.png) 
            - What is a rigid grammar and what is a k-valued grammar ↓ 
                - A categorial grammar that associates one type to each symbol in the alphabet.
                - A k-valued grammar has that types are associated with at most k types.
            - In a classical categorial grammar when is a type $A$ a subtype of a type $B$  ↓ 
                - If $A==B$ 
                - Or, $B = B1 \backslash B2 \ \ \lor \ \ B=B1/B2 \ \ \text{ AND A is a subtype of B1 or B2}$ 
            - What are forward applications and backwards applications in Categorial grammars? ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3QE3ShdsaLRw0DLEgTWfnTkVF9VOCNIhpCVqqYYWQU5UNXPpWc5B7625r0PRHssKZYRA0CK7zBX9KF8xdJ-eQJClJWSzBYIW24s5W-JlrQYzUk6DTKNjL0JEdQAUGJNw.png)
I will be an A, once I have a B on my right hand side. FORWARD SLASH
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tM7JMj7CW794RFsuCPKwHq7Jb4FvYEzT8q5qr9Ix7bGDgkvQJySLvjwU9bOYTpJy9te7EHwl_4jfLLwmjpoh9ObggqDzDlyCmLKSFuEr9vj09CtvID0N7gKqOIsDC9B9.png)
I will be an A, once I have a B on my left hand side. BACK SLASH 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jqufYc8Ql8qqA-gYUs5_2PyKvoBx8LzdHvsRGl-Uop1EnH629taN04PS7oXzoF49fheTJ0KxJBByLfq2A-33B--1Lg0zWQ7ljbbCEBYDdo_tQHzXk7wSJNwPM5Nm3I8n.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MBYqWN0LZwhCdhykYtZVxEJ96jhpP2X0KJMVmD0khQTCC1iuOOi02lD3G1Bo_wXMaLqzBU3lZCnk4zC5mgTOLpu__hkWIV_0gw3LlR-paOd59B_4jpDzmKsY1AspKpRa.png) 
        - Constructing equivalence between CFG's and categorial grammars 
            - Note that for the tree formed from a categorial grammar e.g.:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/x3MAcjOKGIsRXbRpp3qtQTg1kq_aE0ObfoY0jGjlt2np0NDBE8ktPsvCmt5u_HQEpW-bDOS3LrwMkwcJ52LHqAry4LKPT9gpRBS03jdZN0QbksNKz9vDyCHA34Dld2lU.png)
The left child will be the argument to the right in a backwards application, and vice versa for a forwards app. 
            - So to form an equivalent grammar to a CFG we create the following rules  ↓ 
                - $\{ A \rightarrow B \ \ A \backslash B   \ \ | \ \ A \backslash B \in T_p  \}$
A is formed by combining B and A\B 
                - $\{ A \rightarrow  A / B  \ \ B \ \ | \ \ A / B \in T_p  \}$ 
A is formed by combining A/B and B
                - $\{ A\rightarrow a \ \ | \ \ \mathcal{R }:a\rightarrow A \}$ 
The non terminals just go to a.
        - A categorial grammar learner within Gold's paradigm 
            - Given simply **functor-argument structures **e.g. we just have ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fUjtZ20uP9dr6r2A5RGNOorORkc9FCjytFZzuwemrmx3sqOxirLxb9tF_HJTIiS8uRlRi5uZ7Yr7lTjfUUx3dVzVqC4rcxQbmsy8yrMnxzJFhy1dOk8C0yix20Lh8GVg.png) and all we know is that a {{forwards application}} took place - there is an algorithm that could learn the class of {{rigid grammars}} from an infinite stream of {{functor-argument structures}}. Satisfying Gold's paradigm.
            - How does learning the categorial grammar in Gold's paradigm work? Given an initial hypothesis ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QCHldSmmvncPq0H5jTBKOvf-9ldCeoXXyDga4XUNyM2sJqFuRQnWPqNumo8GfCm4PabK5TJluJ6qsNeqUKInu1T1ufaBxblNPoXLLYUAa6UHSNsuara-z4DIjIcHA6tq.png) 
and a functor-argument stream like
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qtU3n9gXq8awHSEjlNuQ4QKTofwL33CXKdNnJzb-BULF_SoFt2-l0YvwqA2Cwq_wOp3eA7L-VrYg-izHkXInDINvdMEDcfSwlQsp1Y3ANL4wJouNMVkOCbLft6jUrONB.png)  ↓ 
                - We can infer from the functor-argument stream that:
alice has type $x_2$ 
quickly has type $\langle s \backslash x_2  \rangle\backslash x_3$ 
grows has type $x_3$ 
                - We then unify that with our prior knowledge (rigid grammar, so has to unify)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hFjj9DabtstmhlWDclpJdrQuz25wFvtMyBhds_2mI9VW3SDUwp_iBuprEgYjCBXL8fJMHJytpW7V9WqHFrqXFGeG_NwgFi6v2GuhPxh3ADGGVdJ_m5VKeYW604f13rlE.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vTRh-K-dDwPu5VU0TnmPR2Mijt04roV8qYyDZfw1TNnmc40WTlODPFd-0FVWidqFqTGZvsh6UeNzU-5hwgV_CJHadarN71MEqje1NUOfxqUJsAsjIn6cc-e5idhOYFbu.png) 
        - Golds paradigm not like human acquisition 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AYvd8FN1ElKG0dl2iBATQwjM7y_0J4tTjcmnixjWLi3Gjb82IXjTo2Lxuaa6bpBs0TQTdDaeb-U8jYNakMxaqz6HzdBUo9zrX4vstclgrpHK-JE4sUyWkFnlwyPLYU4d.png) 
            - Humans are not required to exactly identify the target language.
            - Gold's learner hypothesis a grammar at every step, but children only attend to selective evidence - the parts that are helpful to them (goldilocks effect).
Dunno WTF this means.
        - Extended Categorial grammars 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NnHSUZ-WaPVb-JFXeZUaYd5l47oIKbJRAvN_kNvCgerg6vWT42bLUqYOUxGyps3XacxPEmv2JjH-C-keSSCjxnSNDrZJvUF7cVroaU9PcRYIUtWIbdMsn2CztVxuRxYD.png) 
    - **Lecture 6** (Entropy and surprisal)  
        - It's easier to guess the meaning of a sentence with vowels removed than consonants. 
        - It can be difficult to spot typos in sentences. Why is that? Would it be easier to spot other missing words
        - How can we tell if a made up word will seem real?
        - When do we insert **that**? E.g. Glad  __that__  it was over VS glad it was over. 
        - Entropy is a measure of information 
            - Information sources produce information as {{events }}or {{messages}}. We represent our information sources as X, producing discrete information over a dataset.
            - What is Entropy? Give a couple of ways of thinking about it  ↓ 
                - The average information produced by a source.
                - The average amount of information gained by a message.
                - The average amount of information we lack before receiving a message.
                - The average uncertainty of a random variable.
                - The average amount of uncertainty we have in a message we're about to receive
            - Entropy, $H$, is measured in **bits**. If X has M equally likely events, what is $H(X)$?―$$H(X) = log_2(M)$$
E.g. X can be represented in log_2(M) bits of information.
Note that this is a lower limit.
        - Surprisal  
            - Describe surprisal's formula―$$-\log_2 (p(x))$$
Where p(x) is the probability of a given string in our alphabet. 
The more probable the word, the less surprised we are to see it.
            - We can represent entropy produce by X, as the average of how surprising each word is: $$H(X) = -\sum_{x \in \chi} p(x)\log_2(p(x))$$ 
            - If all items are equally likely, we just get log2(M)
            - When examining corpuses, we find that vowels are less surprising than consonants. Meaning consonants encode more information, and thus removing them makes the sentence harder to read.
            - If English is efficiently encoded, then the shorter words should be less surprising (we use them more) while longer words should be more surprising. 
            - Does length of words correlate more with frequency (number of times it's used) or information content?―Information content.
            - What is **Joint Entropy**?―The amount of information needed to specify two discrete random variables 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b9UoPsw3x49pZb7kus3TxZY4el9ta4qpX1vlcIRVEp5bj4OB__mNT9nzddjogDnvBi_oAK53TEqWuWG92pqg6jZ7ToBLQ-04TMXYO8x1ufLfaKlXYf20U028ztnTs6_t.png) 
            - What is **Conditional Entropy**?―The amount of information needed to calculate x, given y is already known. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6cXv5xo7LZ43d5_hnbuQA3rom1OP9-MRk-jUgPQDSqiLkMrp8kGNo5_wQlQ3GPn5ao-TF9-3WJPkPuTXciqZ9imVr4D6-1Y8G5l-nevj5SOds4LOy-yJ1bINlaCvQLoP.png) 
            - Chain rule:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-oYHGsjYK5kLGxmtRwetXVf7wXWp2uKYv4VJ5-AeSS-1_cRmpuWWnlJ_3eE3h9t5IZ3sL3CWY5BtvCOAu5F_P5WlI5KOipxGOmAINPk8KwLinlktDgeOjr-3HBr7RCNL.png) 
            - The information in the transitions of Bandersnatch is (e.g. Ba, an, nd etc.) much lower than the overall word. What does that tell us?―It explains why the word seems like plausible English - as even if the entire word is surprising, it's components aren't. 
        - Entropy Rate 
            - What is the **entropy rate **of a language?―If we model language as a stochastic process generating random words, then we can measure the entropy at the limit $$H_{rate}(L)= \lim_{n \rightarrow \infin} \frac{1}{n} H(X_1,...,X_n)$$
This gives the entropy rate - the limit of the entropy of a random sample of the language. 
            - The capacity of a channel is―the number of bits on average it can transmit
            - We assume language users want to {{maximize }}information transmission, while making it easy for the "receiver" of information.
They do this by keeping the information rate {{equal to }}the {{channel capacity}}. This explains the use of words like {{"that"}} which slow down the information rate in an otherwise information dense sentence.
        - Smooth signal redundancy Hypothesis 
            - It was found that there's an inverse correlation between **redundancy **and **length **of words. 
        - 
    - **Lecture 7 **(Noisy channels)
        - In communication, Information needs to be transmitted 
            - This leads to a trade-off between compression (removing redundancy) and accuracy (allow information to be recovered) in the presence of a noisy channel.
        - Modelling transmission using a noisy channel 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tq1FLdbDpRXBSam3HjA_O8dJoakwUiWgXYaEVx36YpVCNfRmo--IWTw8H6AyXa8phzXoxEKT1gez6xsk4vTfqJu4AxuEErqVAKIgzdgpDf_HK5cDHVB5WIpqeEe-kZpr.png) 
            - Output of channel depends probabilistically on the input. Decoder finds most likely sentence given Y.
        - Mutual Information 
            - What is **Mutual Information**?―The measure in the reduction of uncertainty in one random variable, based on information gained about another. 
$$I(X;Y) = H(X) - H(X|Y) = H(Y) - H(Y|X)$$
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vje52Ja56Y7TmsOOmkJk8wUF-he8dXmglDFAtJVYwr7AsLFZUevtwhhGuseoHUQZbll8xXWO_XmaVzLS3w5dHf9o-iZckFGt1npg4sMpt24ukknKSTInfL5a5tXxKdX7.png)
The information in Y that tells us about X. 
            - How does channel capacity relate to mutual information?―The channel capacity is the maximum of the mutual information of X and Y over all input distributions of the input $p(X)$: $$C = \max_{p(X)} I(X;Y)$$
I.e. the higher the mutual information, the better the channel. 
        - Ambiguity has communicative benefit 
            - Ambiguity is not a problem in normal language - Alice wanted to cry, Alice saw two rabbits etc. 
            - Only ambiguous out of context. In order to make best use of our channel, we overload the small words for efficient transmission. In general, **shorter words have more meanings**. 
        - Noisy channel can account for word order 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/C9L1zWf2hLtZ9MaN_6abr0BUHbvqNLcR9kKPeHPr9AnaOu_i4Zc4826HWdpv1ombL2kyKi5MssEqz5eQGzy6pRrLC0gp8JeOxP7LtjJPVg3Kn5fg7z8UVStYbHzT0XMF.png) 
            - In an experiment where characters and objects were the same, but the objects were changed: 
They found that people act out Subject-Object-Verb for human on object interaction. 
On the other hand, people act out Subject-Verb-Object for human on human interaction. 
            - Explains SOV because the subject and the object were old information, while the verb was new information. 
            - Subject-Verb-Objects preserves information better, even if information is lost we know who is kicking and who is being kicked:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/91JxKNqeLKUnfskHWgeM-D3Hui7ThF7BscBksn6xZlLxLtixCivrNUNx3NDdq0c2Za1XXzfwbld8kvF2Wb84F3_VUwV_U-NJRG7Q8egmcazgCPh0l9odYEwXZTssoGg1.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vH_TSFxL_gvnwF_GN-fH75Q3vv0T3WyuxSomJjugV-GdUidvda8mo-O9FDTfvb7Zz_RXONga6Uvl9IMSCHV0IMcSGiP77x1jShgMN7cjWcotKTeAI1q0Z8mkbmwxWu6I.png)  
        - Noisy channel for NLP problem solving 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gd5oKbFgbLjvO_DtrtPMsPPsbFSxnwrwAw8wEWt1ankhz-p-f_mfgJv34qRWokw5wmOHwL4FTyUDdpBT42AhpXAsgl095Z924xS9m6jEIgSvEFgeS_sKkDiv5464be_j.png)
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bRRm9FjBW1mULqnIflMC-R_pFxYvgxT3FYvjeP0Tg4HEeMPVTPvdEmWb7L8lVVYsEiQlHCT4QcK1B51586KZd-qPHmAfj2YdChYNDlil6qF1IeXl5W5EujQmicaV9_0_.png) 
What does this equation mean?―To find $I'$ we find the most likely input, given the output. E.g. the element with the highest probability. 
Note that $p(i)$ is the probability of the input.
And, $p(o|i)$ is the **channel probability**.
        - Translating from English to French 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/utpSM_KNsO_uYwjGqMJFE_WNUy1gRp31pKHbwIvmxTbxyjIWvUwAoetRSPK7tMoDB2A4J9dpKDrHnm0YSqQ_oxl1V4K5KmxzQmCv6IY85nYX2HrgI1B8Dr3PeeqIeuWE.png)Let's pretend the original text comes through a noisy channel and comes out as English - (bonjour ⇒ hello). To recover the French we need to decode the English.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nV27rK1vGP9zq6e5-OIoNupob4mCLDGTeQGicSd7Au7fIaN_sLvBIMoUUbnGkKp7xsM5O5RYcAsiNwUSs80woWU2p-eMSmtJ9MHtWobv88-8iRjOCpBu6PkaXlozStgO.png) 
            - E.g. we use this idea of a noisy channel, to build a translation tool.
        - Spelling correction using noisy channel method 
            - Two types of spelling error:
                - Non-word error: fall ⇒ flal
                - Real-word error: Three ⇒ There
            - Detection of non-word errors is easy (not in dictionary). So we'll detect and correct.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qKlvjXSlAmDHcMJCGRWMD8_fmSW2wYSTdKcuN0r7Qktt9IgPGp20peSRbJuiegU36SMFJfHYm5zDBa54GilRhAkuJZuey95noaitVT5ANdzB1oDv49edB4i132Lc8Nir.png)
How can we model $p(word)$ and $p(error|word)$?  ↓ 
                - $\text{p(word)}$ can be obtained from a corpus. Could use some n-word lookback or similar. 
                - $\text{p(error|word)}$ can be obtained using minimum text edit distance or minimum pronunciation distance. 
            - Edit distance model 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IzVmhjREdxY0kDmH0O9KzGg3Lf7YddOYG9vMX_QDPCb8avT9X6CCaBpF4d1rKqIbKmqKZAnm10n04rLOOORS9p618bf0XQNGIN5RKXE06f7J-I1DfUd3jNCcazICOBGc.png) 
                - Uses insertions, deletions, substitutions and transpositions (ac ⇒ ca).
                - We form loads of candidate corrections based on different letters to apply to and different methods of fixing.
                - Note that 80% of words are within 1 edit difference.
                - We then choose the best edit based on confusion matrices:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GfMJZRRLR-4hUW5_U0cvKeaxacHkLIGuIJe117lS8ExCKSE05iLsuCi4bEL8iOf7SSIjiQebakRl0n0K3LSybRpbqj2x6clkZbmTvQoAbVKYXAz81Q5L9J0P8WmN9D7_.png) 
        - 
    - **Lecture 8 **(
        - Words local context 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/t7xpgzYJt4Fh5iv7bCsD00rbw9nf9xQaOea2MfWR2MfAXi52XsTXQUK_KbTziNbDPyZXP6y29TuLI-kfZuTiHmVEpidb2HOdzPJcRLxvsiji55stoZA1NxXDAKm9w2v_.png) 
            - We've been examining words as discrete symbols, but we need an indication of words similarity:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rFLS7E9vvV51vutshH_XC9tgpOfsPz1VKDnuc6hzco--gWcnW8lnhas0Vwi5Qb7MeAupuXE3fBBX3xiJ-12sA3hKuvFBdRVEWZuMscFlpzjiNwQVV1YhXpQdtFFFtLqh.png) 
            - Instead of symbols, to find similarities we can represent a word by―a collection of keywords from its context (as a proxy for meaning).
            - How do we weight words in our context window around a target word?―Based on their frequency. E.g. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hOHI6lY2sdLRDF7O2ioVXahPDZJlIkn_4vLt4af-QICETifswpQCeAvmnRnwizjR5Hbdii-Q2B-_5jmXXH_xW8sCqO-cCaotnW6snoS1dUqPuFR_AQGwTEdLdkjO1Yew.png)
This becomes more informative if we then remove the function words: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vNRXPeS9DNxBO1AySIf_ZyQF6zOP5sBRpOVo6X8FVLbwb2g8ob6bOKvf7T2NR64hCeWpuSz-DBDx6b6K8Eg3DcZ-7BOC9T5K33N4FfsJNTtp-D70k2t2PKxnFu9lS6zW.png) 
        - Replace symbols with vector representations 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/R0CFzKKXtBX2g7s0G54HhDwViU0EdRGxr6mN0TQM53ZBZF9koy23XGWpmDrYPvJmHdio7WwFrXV7o_eCZuySYV6kVMFxZo89ntaKNFEdlGYK2wq1X65N2NkrznDehken.png) 
                - Give one problem with finding similarity using it's "context" vector.―If a word has multiple meanings, we can get the incorrect meaning of the word. E.g. Cheshire cat and domestic cat in Alice in wonderland.
            - We then measure two vectors **proximity in word space **and correlate that with **similarity **in meaning. We can measure that similarity with any distance measure - dot product, Euclidean distance etc. 
        - Devising context vectors 
            - These can be generated expertly, or by just using the surrounding words for each word. This will result in **large, sparse **context vectors. 
            - Is there some k-dimensional space that is sufficient to encode the word meanings of natural language? They could encode tense, count (singular vs plural), gender etc.
        - Reducing generated context vectors 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QpcAstaHpCJGRkEQFzZQCAWYOpMTc5rF3fVpxTZYIVNSUsaEAjqRDD7yJgftxoV-CtuiPpzafOxZf2QWt_VtWkqeFDWv9gFiE-4fbgoFS_Hij_9qpgkwI-9W6UYAcl4e.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/obV-lZJuvIZxKDSgmmE6EFZ6jAXqt-U-yB6ixXghjrX6NJwZHlaxlWJH-mn4KLGOdK--WdC4YDKvljaYUtHq_OhcSnu4Xqini_3U5IkU0AmaNeFKvFouRp-kW9WMzJTW.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7KI1Fi934RTXPZhXsEb3swzMemuwD4PU9vb1USEhiY5U_OYK5spaPR0cHTVpjKp9MS1OYBvnvx8tjs2kFzkp8pu7c1309OOvEMuv_4ov9XNM0h7okNt51X6XRt5J7aUF.png) 
        - Predict models 
            - What is a predict model?―A model that learns iteratively to output the probability of a word given it's context. 
            - The parameters of the model are the word embeddings. The model is trained on a certain objective.
            - At every iteration we run our model, evaluate the errors, and then adjust the model parameters that caused the error.
            - Describe the Continuous Bag of Words technique―We predict the target's word embeddings, given the word embeddings for all the context words around it. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/z_lMt-FJf_FcLxJTYNgLb84GotA6AldwSdrS7nyZkHtzIjli6FU-12-fZcCNt2WoPABv1cW_mc-6Ps6gQ7EE07yWsnbgVioNl4xwE2_80kMldIXuFL1gDtIpQig3jQo2.png) 
            - Describe the Skip-gram technique―Given a target word embedding, predict the context word embeddings for words around it. After a prediction update based on the ground truth.
        - Distributional models 
            - Count models and predict models are distributional models, both are representative of how the word was used.
Why do distributional models make Multi-modal (including extra information like speech) experiments more straightforward?―We can easily add new components to the vectors describing information about what we're hearing, seeing etc.
            - These have much improved NLP - change in the state-of-the-art e.g. Google Translate.
            - These models are statistical, and thus need very large amounts of data - and thus need a way to handle unseen words.
        - Training word embeddings methods 
            - Many different methods for grammatical error detection:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/u8qsprX6GA1iKf17F-nVjUY12mUYbzHfhtyMb26-aOSHUjfU5Ih98_F72tmh3_yZD1F2_tDlJQiVFVOSYL_SNpfygX2pPJK8YZWUX06C-DHrF9PvcW525mXm_aEsrnOC.png) 
            - These train on sub-word units, e.g. characters, so we can make predictions on unseen words based on character sequences.
        - Predict models vs count models 
            - Predict models can be more efficient, don't need to hold statistics on the whole dataset. 
            - Need to initialise the word embeddings.
            - The size of the embeddings is a chosen parameter and the best number isn't known. 
            - Predict models need no hand-crafting.
            - Dimensionality of the embeddings are assumed to capture meaningful generalisations, but **we don't actually know what each dimension means.** 
            - Predict models perform better on some tasks. 
        - Word embeddings correlated with human intuitions 
            - We can rank relatedness of words, based on human similarity judgements. 
            - We can then find a rank correlation between embeddings **and **human judgements. Where good embeddings would have a correlation of 0.8 or more. 
        - Reasoning may be possible based on word embeddings 
            - To solve the problem "Man is to woman, as King is to ..." (answer being Queen).
                - Find the difference vector between man and woman, and add that to Queen. Then search for the closest word to the result in vector space.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1x5-9n5fzqludXtXU1OGPTMYslwK3xo6miT_jvExgruKocNrwd3T2inYu7KNTccsEcH4MMcciz3G3UatGSfzkE5u4awy4mhGE5Ay2iUgzRF9l1xpC-yQtvkS65Mq9riS.png) 
        - Relationships between embeddings and **brain activity?** 
            - We must have some mental representation of meaning that are mapped to language, but no direct access to the representations.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AMNsNhU-8wBWrKjVryJPVMI4e1SkukxzzdjFqEi5ekmv0Tblx14oqRSWX0EM3iF0d-RV21SRG_DpBRdl4qhIzjxncJzmMFW2yAw9lIjqK_yMof-xYUN3AJIs9bdXFsSf.png) 
            - 
    - 
    - **Supervision 1**
        - Natural Languages 
        - Question 1 
            - a.) She fed her cat food. 
The subject for fed is ambiguous, she could be feeding her cat some food - or she could be feeding her "cat food" somehow.
            - b.) She saw the man with one eye.
Can't tell which part of the sentence "with one eye" is associated with. She could be looking at the man with one eye closed, or the man she's looking at could only have 1 eye.
            - c.) She saw the queen in the garden with the telescope.
Again, you cannot tell which actor in the sentence "the telescope" is associated with.
It could be the girl looking, the queen or the garden which has the telescope.
            - He'll probs give as a note, but because binary - need to split a VP into a VP and something else (PP), so the stuff to the right then modifies the VP. Same for NP and PP. 
        - Question 2 
            - a.) I told the girl the rabbit knew the caterpillar would help her.  
Deciding which object goes with which subject is complex in this sentence. There are multiple parse trees which you have to consider, and this takes time. You need to remember things during the parse - "pop" things off and off your cognitive stack.
Additionally, there are multiple correct parses. Do you decide the rabbit knew the caterpillar would help the girl **or **does the rabbit know the girl and the "I" thinks the caterpillar will help her.
Craft sentences with various numbers of parse trees and record human parse time.
            - b.)The twins the rabbit the girl chased liked laughed.  
This is another example when an unusual amount of memory is required for a parse, we have a sentence in the general form $\text{noun}^n \text{verb}^n$ where we must remember which noun goes with which verb. This increased memory usage makes the parse more complicated. The main point is that the noun and the verbs are spread out, meaning we must remember things for longer.
You could test this by crafting various sentences where dependencies between words in the sentences are needed to be remembered for various times - then record the parse time for each sentence.
            - c.) She shook the bottle containing the potion which had made her grow very tall up.  
Another example of b, we need to remember "the bottle" until the very end were we note that she's shaking it up. Additionally, the up is surprising as we're more used to combining up with grow up (grow is close by) than with bottle.
Long range dependency.
        - 
        - Formal Languages 
        - Question 1 
            - Can do all of these using product construction with DFAs.
            - a.) Given machines M1 and M2 which recognise strings in L1 and L2 respectively. Simply form the DFA which non-deterministically decides between using L1 or L2 to parse the string.
            - b.) Simply concatenate machines M1 and M2, replacing the end state of M1 with the start state of M2.
            - c.) First note that if we have a machine M accepting language L, the complement of L (L') is accepted by the machine M' where all the accepting states become rejecting and vice versa. L' is regular because M' is regular and accepts L'.
Then we can use De Morgan's laws:
$\overline{L1} \ \cup \ \overline{L1}$    This is a regular language by a.) and complement.
If we apply the complement again (using De Morgans laws) we get:
$L1 \ \cap \ L2$. And as this is the complement of a regular language, this must be regular. 
        - Question 2 
            - a.) Prove if L1 regular, L2 context-free then $L1 \ \cap \ L2$ is context-free.

Assume $L1 \ \cap \ L2$ is regular.
Consider that a pushdown automata can be converted to accept the complement of it's context-free language by making the accepting states non accepting and vice versa. Therefore, the complement of a context free grammar is also a context free grammar - as it's accepted by a pushdown automata.
Using that fact and the method in c.) we can derive that $L1 \ \cup \ L2$ must also be regular. 
Then, by our assumption above, the following must also be regular:  $(L1 \ \cup \ L2) \ \cap L2$. 
However, this is just $L2$, so $L2$ must be regular. But this is a contradiction!
Therefore we must discard our assumption that $L1 \ \cap \ L2$ is regular. 

^^Not sure how to conclude from this that the language is context-free - i.e. how do I say, if its not Regular it must be context free because... 
If we have the fact that languages in the Chomsky hierarchy are closed under union and intersection then the proof is easier. Simply build ^^$L1 \cup L2$^^ then intersect with ^^$L2$^^ which is context-free. ^^

        - Pumping Lemma 
            - At the end of the PDF:
        - 
        - Top-down Parsing 
            - Question 1 
                - I'm getting 3 for a.) and b.). I think the right answer from using online parsers should be 4 and 9. Spent >3 hours on this already not going to troubleshoot anymore.
I've gained an understanding of the Earley parser.
                - ```python
S, NP, VP, PP, N, V, P = "S ", "NP ", "VP ", "PP ", "N ", "V ", "P "
dot = "• "

rules = {
    NP + VP: S,
    N: NP,
    N + PP: NP,
    P + NP: PP,
    V: VP,
    V + NP: VP,
    V + VP: VP,
    VP + PP: VP,
    "can": N,
    "fish": V,
    "rivers": N,
    "december": N,
    "they": N,
    "in": P,
    "can": V,
}
chart = []

print(rules.items())


class Step:
    predict = []
    scan = []
    complete = []


class Rule:
    def __init__(self, name, body, i, j, derived_from):
        self.name = name
        self.body = body
        self.i = i
        self.j = j
        self.derived_from = derived_from

    def __repr__(self):
        return self.name + "-> " + self.body

    def __eq__(self, other):
        return (
            self.name == other.name
            and self.body == other.body
            and self.i == other.i
            and self.j == other.j
        )

    def advance_dot(self):
        symbol_list = self.body.split(" ")
        for index, symbol in enumerate(symbol_list):
            if symbol + " " == dot:
                symbol_list[index], symbol_list[index + 1] = (
                    symbol_list[index + 1],
                    symbol_list[index],
                )
                return Rule(self.name, " ".join(symbol_list), self.i, self.i + 1, None)


def get_rules(rule, non_terminal):
    results = []
    for key, value in rules.items():
        if value == non_terminal:
            new_rule = Rule(value, dot + key, rule.i, rule.j + 1, None)
            results.append(new_rule)
    return results


def get_symbol_after_dot(rule):
    symbol_list = rule.body.split(" ")
    for index, symbol in enumerate(symbol_list):
        if symbol + " " == dot:
            return symbol_list[index + 1]


def predict(prev_step):
    results = []
    added = {}
    for rule in prev_step.complete:
        new_symbol = get_symbol_after_dot(rule)
        if new_symbol == "":
            continue
        for new_rule in get_rules(rule, new_symbol + " "):
            if new_rule.name + new_rule.body not in added:
                added[new_rule.name + new_rule.body] = True
                results.append(new_rule)
    return results


def scan(current_step, current_word):
    i, j = current_step.predict[0].i, current_step.predict[0].j

    # BIG time bodge, didn't think about having a word both a verb and a noun
    if current_word == "fish":
        rule_1 = Rule(V, current_word + dot, i, j + 1, None)
        rule_2 = Rule(N, current_word + dot, i, j + 1, None)
        current_step.scan = [rule_1, rule_2]
        return current_step

    rule_name = rules[current_word]
    new_rule = Rule(rule_name, current_word + dot, i, j + 1, None)
    current_step.scan = [new_rule]
    return current_step


derived = []


def complete(previous_step, current_step):
    to_advance = current_step.scan[:]
    for finished_rule in to_advance:
        non_terminal = finished_rule.name
        for rule in current_step.predict + previous_step.complete:
            next_symbol = get_symbol_after_dot(rule) + " "
            if next_symbol == non_terminal:
                new_rule = rule.advance_dot()
                if new_rule.body[-2] == dot[0]:
                    if not (new_rule in to_advance):
                        to_advance.append(new_rule)
                    derived.append(new_rule)
                current_step.complete.append(new_rule)
    return current_step


# test = Rule(P, N + dot, 1, 2, None)
# print(list(get_symbol_after_dot(test)))
# input()

start_state = Rule(S, dot + NP + VP, 0, 0, None)
previous_step = Step()
previous_step.complete = [start_state]

import copy

log = []
string = "They can fish in rivers".split(" ")

for i in range(len(string)):

    print("STEP", i)
    new_step = Step()
    # new_step.complete = []
    new_step.predict = predict(previous_step)
    print(new_step.predict)

    scan(new_step, string[i].lower())
    print(new_step.scan)

    derived = []
    complete(previous_step, new_step)
    print(new_step.complete)
    print(len(new_step.complete))

    new_step.predict = []
    new_step.scan = []
    log.append(copy.deepcopy(new_step.complete))
    previous_step = new_step

    print()

print(derived)
print(len([x for x in derived if x.name == S]))

# 1 for the first.

```
                - a.) 3
                - b.) 4
        - 
        - Comparing Grammar Formalisms 
            - Question 1 
                - The grammar is:```python
 S = NP VP
 VP = V N | V NP | PP V | VP NP
 NP = Det N | N
 PP = P NP
```
                - Question 2 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/34VkdDHE7iHWyNB1FEC78owFxGCaY8e5HXcSvvvQGGpvSHVJQSkiHp32o1FjSIhyX0IFZgc-Au7gtM8ZYrynB5J2S8zarV-n9OaG6E_BpdmYjiON7eqM7g0y8M4quHsD.jpeg) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZfJkwr8R9HW7zK3WgZjyWbm7jpeCy_ysBQ7rrCz7ol3ZHc-79Fs0KLXGJB1kcsmPnNh0WcKZGgx4gLVp9a-zPoeZCMCtCYT85K0R3mTucvYudSry1p3VUcXWzeKssQfO.png) 
            - Question 3 
                - Don't understand tree-adjoining grammars at all, can we go through. 
        - Pumping Lemma: 
            - 
        - 
        - 
    - **Supervision 2**
        - Natural Language 
        - Question 1 
            - Is frequency information or structural information more important when considering processing difficulty?
            - This question boils down to deciding if a rare/complex word is more difficult to understand than a rare or complex sentence structure. If a rare/complex word that a reader has never seen before is included in a sentence, the reader can only look towards the context to understand the sentence. Similarly, if a confusing sentence structure that the reader doesn't understand appears, they have to look at the individual words and build an ordering that would make sense. I would argue that a reader would have more chance with the latter, if I simply don't understand a word in a sentence and I cannot reconstruct it from context - I have no chance of processing the sentence (given any amount of time). Contrarily, if I understand the meaning of the words in the sentence but not the structure - I can ponder for long enough (building parse trees etc.) until I happen upon an ordering that makes sense.
        - Question 2 
            - Give examples and counter-examples of sentences in English (or any other language) that would support theories of constant information rate:  
            - Swear words are often added for emphasis, but you could hypothesize that a sentence with a swear word is want to be understood (and is often said quickly) and the swear words add redundant information to inhibit word loss:
What the `****` are you talking about? - Where the redundant section would be the `****` 
            - Many songs provide counter-examples to this, where words that could be implied from a sentence are stressed:
♪ I'm in **looooove **with you  ♪   
In this case, the singer is providing emphasis and not slowing down the sentence for listener comprehension.
            - Often when giving instructions, an information dense section will be followed by a period of slowing down the information rate: (Assume X, Y and Z are information dense):
"I want you to do X, Y, Z. And I think that's all there is too it."
This is perhaps used as a time for the speaker to catch their breath.
        - Formal Languages and Learnability
        - Question 1 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/e1jeV9p6yknoMriBArBZU2G75l9F7bHH5ElweSTAgfl3z33qTK4AaR2PLtQY96Mnf_-W969f8XmapC6zb4ny8fXOJ5Wui3aIZyFqw8G3DhuCQJlbiz0bn8-dXUXAhoen.jpeg) 
        - Question 2 
            - ^^For a finite language, in the limit the learner would have seen (and memorized) every combination of strings in that language. For two languages to be different the must have at least a single string that can be generated in one language, but not in another. 
So even if the learner does not understand the structure of a language, in the limit they will observe every string in the language and will either continue predicting their learned language until a string that doesn't match is found ^^^^**or **^^^^they'll continue predicting the given language forever as no incorrect string can be generated. 
Either way, in the limit they will predict the correct language. ^^ Makes no sense
            - For a finite language, it must have a finite number of rules and a finite number of characters. Thus at each step, the learner can build the shortest regular expression that matches every previously seen word in the language and will eventually reach the correct language.
- Not really sure on this question.
        - Question 3 
            - Every string could also identify the language it belongs to (language 1 or language 2) and the learner would then learn each in the normal ways, with different areas of "memory" devoted to the learning of each language. 
The string the learner would be faced with, would then be strings from a random choice of language 1 or language 2 annotated with the appropriate language.
        - Information Theory  
        - Question 1 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9yCTGkcPm7TAjEjHsYxZbr2t0JG1R4L_DHUt-13kbtazERHwVa3Hi_2SIPiTdjgnHtJObVK5zA3EioKcjfK1UoAGPz_iWLL99_1bE7ZjHGWmoxMuaKYXOW-jFPNqIOR-.jpeg) 
        - Question 2 
            - I generated:  ['theren', 'theere', 'itheel', 'thitou', 'ineath', 'dothed', 'heneth', 'shitha', 'thenll', 'tlinth']  
            - ```java
pair_freq = {}

for word in alice:
    for i in range(len(word) - 1):
        pair = word[i] + word[i + 1]
        pair_freq[pair] = pair_freq.get(pair, 0) + 1


for key, value in pair_freq.items():
    pair_freq[key] = (value / len(alice)) ** 0.3


def generate_nonsense(length):
    word = "".join(
        choices(list(pair_freq.keys()), weights=pair_freq.values(), k=(length + 1) // 2)
    )
    return word


nonsense = [generate_nonsense(randint(2, 6)) for x in range(100000)]
ten_mins = [-100000 for x in range(10)]
words = ["" for x in range(10)]


for word in nonsense:
    probability = 0
    for i in range(len(word) - 1):
        pair = word[i] + word[i + 1]
        probability += pair_freq.get(pair, -100000)
    for i, x in enumerate(ten_mins):
        if x < probability:
            ten_mins[i] = probability
            words[i] = word
            break

print(words)
```
        - Question 3 
            - Framing "automatically answering questions" 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ICQwWOsuaKl2BdpVKky0zXiCzlv88qcw1bXnXAff0AAFYBq3MJXtAJxt6LYnwY1UMotDF8v5NbU0sf0F90qk21dT2QU0DcB_YiOyG0EjYPiPiRyEhjmDvgoiS7c6nHum.jpeg) 
                - P(answer) is the probability of a given answer to a question, this could be estimated from a large corpora of question-answer pairs. 
P(question | answer) could be found from the same corpora, by measuring the number of times a given answer was given to a certain question. To improve this system we could extract meaning from the question rather than literal words, allowing for alternate phrasings of questions to register as the same question.
            - Framing "disambiguating multiple senses of a word" 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_PSnzxvE94woSMrR6v1CcaryVJhyCIzDuGPw9z_DO9sg3nQAfNFoghOg5SW2dTGEJgN1JhL_4QbRP7bwDpWmxIkts6slpaXz8zJbcui9Wh92gplIhKowYRdkMzMuy-19.jpeg) 
                - P(meaning) would be a measure of how often a given meaning of a word is used in some large corpora, that corpora would have to be annotated by humans to specify the meaning of each word in each sentence. 
                - P(sentence | meaning) would be the probability of the given sentence, given the words meaning in that sentence. However, as matching an entire sentence would result in very few results in the corpora (and thus a unsound probability metric) we should only look at the n-words surrounding the word who's meaning we're trying to assign. E.g. If we were trying to extract meaning from: "You killed it on the mic" we might examine just "you killed it on".
        - Distributional models 
            - We could examine the frequency certain characters appear together, for higher frequencies this means the characters are used as a unit very commonly and thus have a similar function (e.g. 'qu', 'th' or 'an').
            - We could also examine the frequency that characters appear in certain positions in words, if a given word pair often appear in the same positions then they may have similar functions in the structure of words.
            - We could examine the characters that appear most 'n' number of times in words, they may also play similar roles in the structure of words. And for the special case when the length of the word is 1, who are words in their own right, we could draw that they also function as common structural elements in sentences. This is because of their very low length, and resulting low surprisal, they are encoded to contain little information - instead used structurally (I, a, o (in more Shakespearean texts)).
        - 
    - 
    - **Assorted Flashcards**
        - Are regular languages context-free?―Yes, you go out from the Chomsky hierarchy. 
        - 
- Further HCI
    -  _**Lecture 1**_   Theory Driven approaches to HCI
        - **UI Design** 
            - How would you go about designing UIs
            - How do we know what a good UI is?
            - Could our UI be improved?
            - How do the answers to these questions differ between a **Family home printer,** **Facebook privacy** settings and a **visual programming UI**.
        - HCI Theories
            - **Theories give a ** __**critical perspective. **__  
            - What is the Gestalt theory ↓ 
                - The Gestalt theory of perceptual organisation, is a **theory on how people enjoy and perceive** **marks on a screen**. 
                - **Continuity **-  Continuity is that our brains tend to see objects as continuous or smooth rather than disjointed or discontinuous  
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/S9nuVLYthKXuGuFdgE0vUibDhynR1XvRBkxj7A49bUFCDbklzBEEYrBfGvydkIWsIyHIMaS-PA83-IOGmAcF8p1gxDgRaoMxYj1dWxV41qa34GaHdv9GBZPGHPAR_SWO.png) 
                - **Similarity **- how we piece information together by how similar objects are  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eUxUjVwn49Oo06KksV7SpLxLR8BMg9p8X2E0cxeCb1bRrPDOn6RYPGsj4EAS7gDVUAiqf9cKiFeJIx70EqqrqdJSfF3NyNcwFotE37YD1Tv0dpr6RNgRp9bceYXyEQ2H.png) 
                - **Closure** - when individuals fill in the blanks
  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YZvz-laQSfMkMiW4HmZ0iqXrK6S0VistpU_v_KyJ73PnM1Yk1MJeF7-yj6Wnuuc6k9wtYW6bbQ0jXMQzsQ219QwhXqe2GlXJbvVMcpbHZ4dk7a2eKnuXgTuD-EezuoG5.png)** ** 
            - Using Closures for visual programming design of lines: Lines between blocks could be blocked.
            - Problematic Similarity in Visual programming - Given that objects look the same, code block and a number, is that a problem? Non-programmers think a number & a computation resulting in a numbers are not the same. 
            - **Summary of Gestalt theory application** 
                - How can we use Gestalt theory to **evaluate a design**?―Take a candidate design - predict some properties that **will work well** and some that **will cause problems**. E.g. in visual programming using blocks, the blocks might look too similar - **so wont work**. Lines between blocks that are hidden use closure - **so will work.**![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2MczzW4gbyTgZC1oV9UKKiGWX9i7WXxqj_Eaftmw8XBuh6bQ8y01DEq4ScxqDXxBxlHrD-qgwmlA4kPUDG5LprvCw0768Bf81HwlGIzm-C1uHJxStbrBq7LPvAyXzNym.png) 
        - **Iterative Design**
            - Describe **iterative design**―Iterative design is the **process of expanding and contracting your designs over time**. At first you **generate a batch of designs**, then **distil the good parts** and **combine them** - discarding some ideas. **Then you generate more ideas** this is called 'creative disruption' (make sure you've explored the problem space and have not hit a local maxima) and** repeat this process. **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ubld7KHOuUQKWOjU9NtbzKy3_pwVT6Ywop-fIqjwxA0Dcm7ATSKnN8uZSBPjAP7jcZZgEn_po9dBjrIQZVyVvgmS9F3GTQXEIkPfSrj30judQBs86_ndNfgwMVGwmVpY.png) 
            - **Gestalt swapping** is―If a **design depends upon a certain Gestalt property** - force yourself to **use a different Gestalt property**. It's not intended to be an end answer, rather to g**ive new ideas** from which the good parts can be pulled.
For example, instead of emojis as variable names for similarity - perhaps we can colour variables instead.
        - **Why theory in HCI?**
            - Interested in making interaction 'better' - theories s us ways of criticising proposed designs and ...
        - **Three waves of HCI**
            - First Wave - Theory from Human factors, Ergonomics and Cognitive Science
            - Second Wave - Theory from Anthropology, Sociology and Work Psychology
            - Third Wave - Theory from Art, Philosophy and Design
            - **First Wave**
                - HCI as a engineering discipline, analyse the person as a part of a system. E.g. the Apollo-Soyuz controls. Additionally, ergonomic factors - can they reach that etc.
                - The "user interface" is a separate module, designed independently of the main system
                - Design goal is efficiency (speed and accuracy) for a human operator to achieve well-defined functions.
                - Use methods from cognitive science to model users' perception, decision and action processes and predict usability.
            - **Second Wave**
                - HCI as a social system - take account of information systems outside the computer, including conversations, paper and physical settings.
                - More and more people using computers - the system becomes a whole organisation with many computers
                - Study the context where people work, understand different ways of seeing the world around the world.
                - Integrate stakeholders into the design process.
            - **Third Wave**
                - HCI as culture and experience. Computers everywhere mixes public (office) and private (bedroom).
                - Outside the workplace, efficiency not necessarily a priority - Usage discretionary (no choice of software in the workplace, but can decide at home) and UX includes aesthetics, affect.
                - Design experiments are speculative and interpretive (Not as concrete as ergonomics) - need a Critical assessment of how this is meaningful. 
            - **Alternative Perspectives** 
                - Positive computing that focuses on wellbeing, flow, empathy, mindfulness, altruism (Calvo and Peters), work  on inclusion and accessibility that addresses physical and sensory capabilities, ageing, low income  and human rights, or explicitly critical points of view such as Bardzell’s feminist utopianism, where  design critique directly attacks the mechanisms of institutional privilege, using practices that are  designed to amplify marginalized voices when thinking about the future.
        - 
    -  _**Lecture 2**_   Visual Representation
        - **The range of visual representations** 
            - **Typography and text** can communicate lots of information, additionally how you arrange text on a screen. Also colour, bold, italic font .etc.
            - ![](https://lh4.googleusercontent.com/RI6Oav-jMszLJZPiJsmQgduSUno7oBocjOxb8m2DssH7vzGRCQa3mpLhmkHDNz-skqnjYBfo5CHhP1SqOQpoXXdnjTyQIs2PveLiiUdBvwHPCZsBYozGnKFa05r2LX0wZcl_4Vgi0P9y)   
            - **Maps and Graphs**
                - **Graphs **used to show trends, time along x. 
                - ![](https://lh4.googleusercontent.com/ZRQ-igOVW5q4KUxC0TF0I4SW1a0_rX1Tl0kxGGL8jSLQC_p5hPgzk9wdxwXeRHb6Lxo0OWfSWOGVwTaoZ72_hS1VqdzWO-0sjaYVaJGwDCDvmZIQvqZ0e2-ub8p3ajzgxUCuDjvghGwL)   
                - **Maps**
                - ![](https://lh4.googleusercontent.com/H4cahK72-SP_vZB20EHTUsVnwqJ50TaJ8pRwp6tdvAJjr9H29yKrSNpg05E7s6Lh7wAVXaqTN297mcdEiE58QGZ8pIPXtklF_JjqcHsGGFY2xkPTWkXe9hjZZHzSF0vETNUYblzKgh9W)   
            - **Schematic Drawings**
                - Making pictures of things more useful, by making more abstract/computational. 
                - Lines carrying force, an example of an image that calculated itself - Bridge: 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pkGAfJCu1IiSaVYkAptCxfoyio1KNU-9RakGH3hGrfL8pU8uCCZgjRTX8zKHYXioXkXSYVU4D6tPCqwjS4BeGKJeLo9pIzFenfqFYNyOpBno2V-uUnhbb9Quqarppb-w.png) 
                - ![](https://lh4.googleusercontent.com/HAjJ8k6s9k5M5g54pTN0GdmOJD3AarSfUvbSnK0ze_m0MbgZ2AvpcbicNQ9G6Gt0WkGyIPwgMDgzYVH-8mqe8E15t7WEOK9W9aKXpkXeO7BK8FOjJFzkdz5_a1qY_P-x1_p9frEHfWa9)   **VS  **![](https://lh5.googleusercontent.com/MnhQ3OSR32DU7bX5WzX8JcAD4rsla0i7HlsRT1LllmwB9P2t-U-FxVoELS2UHtACsq0f4kLwYaa7H1_Yl4gpoU9sYfxtfQhnAwQMoZNK3U80hgmfw_s2NrOJMzu5fEMRh_44hhjTmus1)
                - London underground map designed by electrical engineer.
                - Direct mapping vs set of logical relations. Realism not important goal, rather information transferral.
            - **Node & Link diagrams**
                - Additional information held, than just what's obvious. E.g. in electrical diagram outputs on the right inputs on the left - and higher voltages generally on the top.
                - ![](https://lh3.googleusercontent.com/0puT7aFIsUsEPIZXVeAztkuFe_A4QoYFH-BM4BSACvwcsAlYJlCNhFbTCofCW9rEK3AKw0ow4B2gJ3oB_y3jNEeU_dD6tu208pgE_M8qZnI9R89ueZNUHGh0qDS-FgvuMAuiTZqVE5UP)   
            - **Icons and Symbols**
                - Pictorial way to imagine abstract and invisible things. 
                - Often used to spare on translation.
                - ![](https://lh5.googleusercontent.com/mDjefD5Re4TT8eRYR_eO1s0gJU3OQOSYOe42Z8OHDwfeNtR3k--bx5dSN1qmk9oKTZ107SEWRwHaKBtqTqOYd85KdFnf9JezjAFyrclDRXwbEsjEe6ZyM9eaTM8nI8-imuox3PTrz0O4)   
            - **Visual Metaphor**
                - Describing icons using well understood visual metaphors.
                - ![](https://lh4.googleusercontent.com/t6Pr9efDUTXgJGzGnOdV1mr2bnZonO15xpYeLt4UoG73T25c8_J-mj3w60w8yIrS6j6atvVLIYDnnAv1rnxfPosIsMbrCXTkSczAGN9y6K1XcWQP2RDh7GWmIyKZ5ZA8w2lRgeiNfUoV)   
                - This example has the pictorial and the reality truly linked. However this is a backwards step.
                - Another example of pictorial representations linked to reality.
![](https://lh6.googleusercontent.com/Mp-Bo470_SKnnOJS-509IzYvOkfuIH5vKqqoFf2BvtqjMkBur2V00zgE5Oiayg4pVBqPg1FG2nNiqaMHLbX2T3uburvZ7gDbrce275XvwSb6NSV_A6j32azXPZ-GSxyGEy6GxL6StN27)   
            - **Pictures** 
                - Perspective is a convention. More important people made bigger, less important better. Perspective is some set of conventions where the real image is mapped to a representation.
                - Pictorial representations **are not **necessarily just **seeing the same through the camera as through your eye.** 
                - ![](https://lh6.googleusercontent.com/QLU6UrrtyGvAmLYWcatL6Tp9iLqwomy17HpzJI3x2HjVLtz2dhz0MMWkC8IK2FavcGl-xU2X4hxL1FzMLPaK7_bKfuCw2OoVJ5vtJ0TXhIJJka_3sUYHYYrsUvcpYbq8B8a5eXoO9kKC) 
                - ![](https://lh4.googleusercontent.com/l3imO908S94W-NkbIdSZZ71NS7b3ToNOzw8f7y901XJZRL_7qIQFCE4SUybCONmyTGa1WNgOX5dnHi8r9noHDQiLj_Rt2oDZb52fAx-gdgmaQt5CIcm2JLxl4s9LhOXbOov3TL0bq2k2)   
        - **Theories of visual design **
            - Categorization (taxonomy): ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GfCU1QRYGN2ucr98Aw_LIdWJtfnsgFrYOcW_3dNMwT6FIdIsUn3xz68TDhT6qvH6oLScSncZ8kW57UbgrWXhULM74rFRhB00eVN0KKdaYiwnrxxkODO6xq7Es4qs7YZe.png) 
            - Use 1: Usability analysis
                - Analyse a design by considering the expected encoding and the actual encoding: 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qfhWw9Bfmhd-IfhdsvXNAnRXFzyadPU1fF_GLfBnYs0y51fK70-B9W2z6kqjIltkeH9PWNzhqEgWa8C3xRcWOA-VE8Pq-_l40IcH9nLoqlCW-CaNml2u_wyDzicVQ24X.png) 
                - Selecting an item uses Colour, the convention that the colour is blue, and categorical selection of the item.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/s6AtkXXvZbtQpGYObn2tXhApUHcX3hQARDlFBAL85LrgFFDEvXLaoh0KjsDu__N-NuazJH7Tlhy1v_NohQdzGHaIdRJwKp2uWFDEkVU8Z1oXc8xJ05SEwxu6pCfuqQFl.png) 
                - 
    - 
    -  _**Lecture 4**_   Designing efficient systems
        - Fundamental trade off in efficiency - speed vs accuracy. Need to consider, does you application require speed or accuracy?
        - **Fitts' Law**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7Mt2ZvmgHNDuTg277_WW-eAMkuG5nOjy2He6mY59X-UAlWB-4C9AFp5XxOKkCf66ZLAVBflAd9WnXXTLy52kI2GZz2ueUjkhYFF6WLMMPEXIgPsNjdD5rRxEkEER66NT.png) 
            - Selecting large thing from small group easier than small things from large group  
            - **How long does it take to point at something**
            - Proportional to the Distance to the target, Inversely proportional to the Width of the target.  
            - Time = k log(2D / W)
            - **Hacking Fitt's Law**
                - Semantic pointing - cursor slows down over the save button:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/n1fW4C9vTrQPdRc1-3VHn5caAmpfzu8WCJ6Y9diloWE8Rj-1siuBsK0BWNTmQrTN5spy3B5xKWBV6ABCmVqSzb0CXFCZmY4jyhR8O3EHlAMQPqjwAW59Fck0exRfoSCE.png) 
        - **Small changes can have a big effect**
            - Nested hierarchical structure of IF ELSES, use JUMPS - which is better?
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MCkLIrGwCRQ1wKtgW-cGUeqK9CPuWlsntCoMYkA63eq6A6UnuBHo66jkVaK9hWng-ozDf8Gh_XrwrxxzM4fRDvUtozg1yLqj3qPO64wMfyTsaekTHBEWxu4icb9KuvqV.png) 
            - Statistically significant increase in performance.
        - **KLM.GOMS: Predicting time**
            - Break time down into discrete stages, and apply some heuristics (TM) and figure out the time taken to perform an action.
            - Predictive model based on theory.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DHDcWvz_y6O3HNUAMI0bSRRbPJt-dQXSin0povO__CoNk1lkrijvqIjIsYP8V0GT0s70Wwir2gBA3t0a0O1kb57ob70419d571K0PhL4F4hx3nWYtsVji85jBSxWXhAw.png) 
        - **A/ B Experiments**
            - **How many links should be on a search results page?**
                - User studies found that 30 is better - however, serving an extra 20 results on a page added another 0.4 seconds of latency.
                - Latency experiment
                    - Have an experiment group with an added 400ms of latency (still with 10 items). Also have a control group with no changes. 
                    - Result was that usage dropped 0.74% after 6 weeks 
            - Fit a gaussian to a histogram. Then introduce an  __experimental treatment __ (some modification expected to have an effect on usability). Then examine the distribution of results after the change. Use  __Hypothesis Testing.__  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qM3yJvfPX8tAx0JNAofERXKb6dUfyVo1DUEwRm19FNeGrQoEeLMyWRmyPfu6-vw4NudlDQTEKRs2zC8QPymfBc_tgUQgqOEEEedOBbZvlPmxEOk2fKq7PPMnb4ztT9ET.png) 
            - **Sign tests**
                - Have each person complete the task twice, using the two different systems. Explores the null hypothesis that the median of the pairs is zero??? What this mean?? 
                - Change could be milliseconds, not necessarily important.
                - Apparently not very powerful?
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mLj1gOa5FZAKcVF6PxNFXiRDLSvAX3563WOuAIXgIqxf5CLXaXLdXd-xwURl6Lwg8c2gkdbyB8p8OIFXrsVZIVrfQheTBJv4NLhTgeFB8dj5w49qiscELPnxe_pci8PN.png) 
            - **Sources of variation**
                - People differ, need quantitative and statistical approaches
                - Might have distractions
                - Might have varying motivations (mondays)
                - Might have accidental intervention by experimenter (hints)
            - **Problem with controlled experiments**
                - **Huge **variation between people! (~200%)
                - Small mistakes can result in huge variation in accuracy (~1000%)
                - Improvements often small (~20%)
                    - or negative (because new & unfamiliar)
                    - or improvement can result form something unrelated to the design
            - **The Hawthorne Effect** 
                - Does lighting levels affect productivity? Studies appeared to show improvements when lights got brighter **and **when they brought the lights back down again. 
                - The **motivational effect of being studied, improved productivity.** 
            - **Taylorism**  
                - Productivity and efficiency driven desiign - studied **scientific management. **Measure workers as parts in a machine, **optimize by measurement and correction.** 
                - Not popular with trade unions.
            - HCI studies often seek to optimize for goals of employers rather than users - efficiency vs creativity? 
            - **Efficient Creativity?**
                - What if there isn't a good measure of productivity. I.e. maximise number of notes player per second?
                - What if measure user enjoyment?
                - 
    -  _**Lecture 5**_   Designing smart systems
        - Uniform text entry 
            - Should the keys be placed in a different order?
            - Why is caps lock bigger than the letter e?
            - Information gain per key press = $\log (\frac{1}{p(x_i)})$ 
            - Consider, u almost always follows q. 
            - Similar to hacking Fitt's law - shouldn't we have a non-uniform system as the probabilty of picking a certain key is non-uniform
        - Problem with:
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CC5K94uM6EtOQBnYaX8ka7pQzc7wlcxUszhvUx7AJdna7stzIthmjLa_4kGC35j3zeT99gJl1aqwyjxEnduUcYf5AB2h7iBJIl6-bAnTfZuDey-dmr2ubh5ZTRWz5QU_.png) 
            - Engrams vs Bigrams - sequence of two characters more common. 
            - No punctuation - even if you had it - source code uses # a lot people use it very rarely. 
        - **Some lessons from DasherUI**
            - Converting an information theoretic model into a UI requires creativity
            - Simply models can be more effective than complex ones (nGrams vs neural nets)
        - **Artificial Languages**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qtp9TFvD5DYmo5-uRzyyaQkPBVjGlnuCCjA1yCSNnner4uLVZ9-Qag5_7ctiSSPTe8B13tJMrP5XawvRDmgHq_XxnRC5DOV-n1mqBkJN03OAOHVtdGS5tyfG4l9VFDPc.png) 
            - Ordering code completion suggestions
                - Consider a stopwatch API, we'll never want to stop the stopwatch before it's started. 
                - Rather than manually encoding this - we can try loading this from previous source code. We use Bayes rule, with:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/W_WDPhOoWl8akDX08RNMxdUp-ofzLDmtrMYDl0kf6cV4GBm_YZdWCTlO1qMI8f1a3gWUmrB3PGwRlKwsTBEXpaAKdm6Uao-R7karFjMsatpf6uh-PfS1Kqfbun1iP_MK.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pSSlUplcHko3HgV1W6ht1qGCGzZoM7kBSGS0-Fd2lSumtij5qjf04vKHSlhsHOQ2E-wN9H6V6y5J5kAdeHGtXqjMSpzERIiS5hbdAyTGkgUw0IWdEqMpYcazuozLF1jT.png) 
                - Problems with code completion based on efficiency
                    - Now can't search alphabetically
                    - If your doing abnormal things in the language - it's less likely to suggest it
                    - Norms reinforced by this system - if encoding defects bad
            - **Building User interfaces**
                - Many ways of text input to phones, 
                - ![](https://lh3.googleusercontent.com/Tpe3BWZclFubSvrjx0zC7TKZAUgjhnZ1RB-uQ_rQkdZugF0KY7mrbXTIBE3lCOsrhmjdUmg8odGrcIZJCiGzNh07SleErTgUDsEryjTjbZrfD4_Mi7qu9z-GF6uD-7TxBgeWYJs_j3VN)   
                - When will people switch over?
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ugMSzEHQSltF4nf9sUTSMRTJLH7sUx5-kPzAXAQVUNcUrXd2Pm2ulSAAcjWL8gNLcu3sjG7w783chHHn8V5ySwRQj9Iwxgdy90VoqiZjLGPu9vhxgTZj0Pyg7tMXJzq2.png) 
                - Entry and error rate
                - Learning curve, familiarity and immediate efficacy
                - Form factor, presentation, time and comfort
                - User engagement
                - Visual attention and cognitive resources  - **Dasher, faster but user fatigue** 
                - Privacy - **Smartphone based inputs, personal learning model could reveal things. Entering your password?** 
                - Single vs Multi-character entry - **Entry mode differs depending on context** 
                - Specification vs Navigation
                - One/Two handed
                - Task integration
                - Robustness
                - Device independence
                - Computational demands
                - Manufacturing and support cost
                - Localisation
                - Market acceptance
                - 
                - In text entry, we want to **avoid the need for a visual feedback loop! No cognitive load. **So move from closed to open-loop. **Different from machine learning** 
                - Continuous novice-to-expert transition - so **avoid explicit learning** 
                - Path dependency - make sure it works the same independent of path taken
                - Flexibility - we have no way to know what our users will do, don't be prohibitive
                - Efficiency - Let users' creativity be the bottle-neck. Writing at the speed of thought
    - 
    -  _**Supervision 1**_  
        - **Q1 Visual Representation**  
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eZa9x50qbkHSVaY7-fPALMbDvEAI48nFGWJv5mkfpm2EHYoBF5Qq7_zosFp-AkjhuQDPxUV12rab7Um41YwEpcMEeE0KyyfTC0IKsQsCqBCLaaX09nn-MREPqis44fBn.png) 
            - **Explain the nature of the information structure that the user creates and interacts with  when using the site/application.**
The user has two main forms of interaction when using VLC media player - they have the interactions directly related to the current playback of the video being displayed, e.g. pause, resume, fast forward, change the volume etc. The other form of interaction is changing how the video is displayed - this can include changing the aspect ratio, enabling or disabling subtitles, changing the timing of said subtitles and more. 
While the immediate aspects of video control are made clear by permanently being displayed at the bottom of the screen (only hidden in full-screen mode when the mouse isn't moving), represented by ubiquitous symbols, the more complex controls are reached two main ways:
1. By selecting the class of setting you believe you'd like to access from the top bar (or from the right click menu):
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1c78eNxZ6Rv1fK4sU2v-Rvfou7xdBCEEaQWe9OZo6pETdF6sMOgovqRBvBIEZLP95xP_1C8wYDJ1H_HRI2Db9ijwL1YyYNF6bQd_kw2-iNws7Sgf65el5Bhgv05CWN-K.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WmDV2MsXr52rBMSYAswm_ReaFfbYPGjvKrqKXLI7p4WMX_wNszJFXzPCAMe-LthGw_w9wNtBIf4Fv8w7rEhya3Gt5lnwfshS8p3rvV52aW9dEUdlhB6A7lKlV7S91SGS.png) 
2. By navigating to the search menu, and searching for the specific setting you'd like to change. Where an in depth list of possible settings is shown:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/H5QhIRMbJa4rEpgQOcnwlaAX8RbGWcuZ-a11Cxs-41fLDs4hAIFNhnuXck16sOAZNCA-hM3pRPcygmTbETZyn0RTGA5MST2crZYSGY4cve1AKQJQlrK_bxhXrpe5k2oB.png) 

However, for some requirements the second option is not possible. For example, if we wish to select a video to watch - we can only use the top/right click bar, at which point you are taken to your file manager to search for the video:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xgS8bzU5yrqZDvnlCIse5IZMC2OgfTOvsVmQEK8ghbFk7z_QXwf2ceAiDdtaqL-XaBIl4PNiayRGSJV1Amu1jaG4RFIrpDsbtPZXdYTAPZ7nWQkvQE-INetmoIuEgDM9.png)

            - **Describe the aspects that make it an enjoyable/efficient (or an unenjoyable /  inefficient) interaction experience by focusing on the aspects of the visual language  (marks, symbols, regions, surfaces). For each aspect, explain the nature of the  correspondence between the visual appearance and its meaning or purpose within  the interaction design.  **
            - The use of **well know symbols** to represent actions the user can perform has benefits and downsides. The benefits are that the most important features for a video player (pause, play, fast forward and stop) are obvious and easy to use - and anyone who has any experience with a TV remote (almost everyone) can jump in and use the software straight away. However, the other symbols are less obvious: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vWxgypLYTy78rBWXyalEfjsrV3Kx285-_adTP_nq7ELZlrbUFbZzNuxjzTM3GIFWeepyCv-L34pp67EHuDtAwulZAyZzHnC9ozHCCGbaEzgzH7Ha7NlMH2YkedNFC7sS.png)
And even as a user of VLC for many years I would have to guess at what the last 3 buttons do. Whether the symbols could be improved notwithstanding, there is no explanation of the buttons to the user - the result of this is they become useless. While they are supposed to be a faster alternative to a long winded settings search, because their usage is opaque they don't see much use.
VLC also uses intelligent symbols within dropdown settings bar, a very clever addition that often draws your eye to the settings your looking for:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fzuw2mAfObbfRp2qaQ6UG94sVai5ZuhQxwZZEwc5Gr6tyt6dLe2qHBuYTA4JEMfA4dCQOoyxW7iO2wyu5e-CMnLByE0qa5Ol-rAmmur-rtlG8bQnDpuENbMg6LzuQg5L.png) 
            - **Information hiding** (within categories of settings, or within the larger settings bar) is used to hide unneeded detail from the average user, while making individual settings easier to find if you do need them. This allows VLC to have a large suite of useful video settings (and allows for plugins that can add even more features) while still making the program intuitive and easy to use for the average user.
The downsides of such a system, is that the categorization of settings can be confusing. For example, if I want to find out the framerate of the film I'm watching - instead of going to video, I need to go to Tools and click on Media Information.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Xn4Ay53siSiJbK6TTXhUoa3IhQ66uhd1L9p68Ez2f1Pjv4PYNNGfN366WjqMN7Nw1whGtMIs-KQBGNrrXnTp-Ai4Ew7m9CBf-dXMpYcJIQpBhUtE1HWIo3Nd-uVI2hsh.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fzuw2mAfObbfRp2qaQ6UG94sVai5ZuhQxwZZEwc5Gr6tyt6dLe2qHBuYTA4JEMfA4dCQOoyxW7iO2wyu5e-CMnLByE0qa5Ol-rAmmur-rtlG8bQnDpuENbMg6LzuQg5L.png) 
Additionally, the visuals of having a cleanly separated concise bottom bar is much more pleasing than looking at a wall of text:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/H5QhIRMbJa4rEpgQOcnwlaAX8RbGWcuZ-a11Cxs-41fLDs4hAIFNhnuXck16sOAZNCA-hM3pRPcygmTbETZyn0RTGA5MST2crZYSGY4cve1AKQJQlrK_bxhXrpe5k2oB.png) 
Where do I look? Just Video as a setting is far to coarse, perhaps the settings I'm really looking for should be highlighted. Or the settings should be arranged into smaller groups.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j4pqw3Xf7xAugNL3yD4p5Gxo5tWQgv-q87KB3DdvJTN8vOQmtHs5yoSwAgLp6eM6x3iKB-lzNNJr3Vtu2GkrOKEXacLSPTn_6SyK_SxFVIkTUDXcVmED8yhk8JTr6w5i.png) 
            - **Explain the nature of the information structure that the user creates and interacts with  when using the site/application.**  
The site displays 3 main classes of information:
1. The symbol input mechanism - this groups different types of input into blocks to allow for easy visual categorization, for example digits 0-9 are grouped into a block of digits and mathematical formulae like $a^2 \  \text{ and } \  \| a \|$ are similarly grouped.
2. Previously evaluated expressions - computations are arranged in rectangular strips where the input expression and the output are clearly separated by a large gap in-between the two.
3. Higher level website features like Sign in / Sign up, these are made smaller (as in general they are less important) and positioned at the top of the screen where they are unlikely to be a distraction. 
The average user will go interacting with 2 to interacting with 1 after they've evaluated their expression, perhaps comparing to a previous computation or changing the expression upon viewing the output.
            - **Describe the aspects that make it an enjoyable/efficient (or an unenjoyable /  inefficient) interaction experience by focusing on the aspects of the visual language  (marks, symbols, regions, surfaces). For each aspect, explain the nature of the  correspondence between the visual appearance and its meaning or purpose within  the interaction design.**   

**Important information is hidden **as in VLC, this is done to hide rarely used features to lessen the mental load on the user - however for a program like this, using sin & cos is **very **common. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/itzgXFZVQ5wWqGSX5PIeX_1L6vrELQW4kNvSHzw1ZtNCScnZ4tEPGKE1ztcvc8wq1-xcLQh-nnFqFi_j4h3aWT9gUI109MHHCaNtAnY1w46dxaEhXz6HJLU8UdgBOCTZ.png)
**Useless input mechanisms, **many of the options provided by the calculator are useless in the general use-case as 99% of devices have them built in. For example, when using my laptop I have no use for the number input mechanism, the backwards/forwards mechanism (with delete and enter) nor the letter input mechanism:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nsKPbV_sQCflpZp2_31ICY23txKNxcAx9LgWjNh72Q1kycj563eW4vHvuK7jdtvDlFAKK8q-4HWSf_yauD7CF9wxRPz0b3eN2yBrq1dSrkT-ZC3J-gthIreV6w9j8t9n.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-4kMrmv5gwdb3A7RbN7yqO8Nb3zsdO8QGf8hRyrvej_3hF4XitnUfAT9C5jt9FMHpPaXAjLz6gRokof5ttXfyF3ZWJoOiSQl5HAf4t2AZkhKOMRNBzLmOBg7BLsNfuEm.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4w_IL0pGhVosrYgfySC56RW-RgelJQaORBjkU89q38_wYxktQPuYh5JY82tQ4d7N00zIpVEkxzxhyw5rKXI1ozSXEYnME4d6zuZWKXIRdEoOmGfSuAlCTFaDo09uMadX.png)
While the first is unimportant as this section is filed away in "abc", the latter **is **of import as it takes up a large amount of the main screen with what could instead be less obvious functions the user may find useful (for example the non-obvious nCr function organized nCr(n, r)). 

The user **reorganize previous lines **if a previous calculation is important to the current one you need to rewrite it. Below we can't reorganize this to have $a$'s definition just above $a^{10}-3$ 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/koToGcJfAryzThfZGEvsx14cC80qjms4IyfTajRK4WS3UZWkDhmZTFV0Bx5qeudKsOZtyVgnWZ11E0-v7_bl8MTq3l4ZiqYL1PCObuYPSBx4TP_6DAUXTTBmlsfiX_VM.png)

This also illustrates another important issue, there is **no clear disambiguation between mathematical constants and variables. **In the above examples $e=3131$ has thrown an error because $e$ is a constant which you can't give a value to. 
 
            - **Redesign the second interface in order to address its poorly designed aspects. Provide a  sketch of your design and comment on how the deficiencies you noted above are specifically  addressed and any trade-offs that you had to make.**
In a redesign (targeting non‒mobile usage where the usages will be more simplistic), I would solve the problem of important information being hidden and useless input mechanisms being present by first **moving the number keys input and arrow navigation to a different tab **(as is done with letters normally). I would further add a method of reorganizing lines, the user would do this by clicking and dragging and a method of adding items you use a lot on the right hand side of  the input - these added items should always be present on the right side of the input bar.
Finally, I would **make the mathematical constants bold** - and the logic of accessing them would be if you type e without having a variable e defined, the bold e would appear (as in most cases the user would want to use the constant, not define a new variable). However, if you define your own version of e this would take precedence and the constant would have to be accessed by the menu (or by special keyboard input method like "e"). 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j99RsA08D2Bi2Lb0Jz51QLMlGAt5ntG_Hwc37ecmYtbvdXlHFJdz6sDmjZK6KApbP2WXrDPln1YnTqRVLdY5IAHLOMi-acbKetbt8VjnhPZC74S7UmK9PrOgXzpaQQvA.png) 
        - 
        - **Q2 Iterative design**   
            1. **Start by sketching at least 10 different possible ideas of how this interface may look like
**![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HpdAHPwjigF6woSOkF65DksRVYIWZzfDNruMPFdy1VinGkPsH_AEHLpwRVqaUsLgovu-hzgnjL81lXgPP9vkZ37ddXiU1gwD7iqq_PIBVPxd2_gN42W8u_TF7pXtMNC-.png)**   **  
            2. **Using one or more of the analytical methods discussed so far in the lectures, discuss  which parts of the interfaces you sketched are better than the others  

**According to Gestalt principles the grouping of input tokens into blocks allows for better readability, thus grouping the keypad in designs 3 and 9 is better than 5 who groups based on arbitrary circles.
The lectures discuss the trade-off of Speed VS Accuracy of human motor skills, thus design 8 poses a problem - as the speeds required to punch the speedball will allow for little accuracy in setting a temperature.
Well understood metaphors for human-computer interaction lead to faster understanding of a system, and results in less initial errors. Thus, systems that are common already will perform well - e.g. 1,2 and 3. 
Given how human thinking is characterized as being boundedly rational (and with a limited attention span), we can determine opaque designs like 8 and 7 will not get far without additional explanation. While 1, 2, 3 and 10 are easier to understand at first glance. 
Hidden state in a system can lead to confusion and inefficient usage (A common example being more than 1 CLEAR presses is required to clear a calculator memory, leading to users pressing the button multiple times before moving on), in that way the current temperature is hidden almost everywhere except in 3. Meaning a slow working central heating system could result in the user thinking the thermostat isn't working.
            3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/y5bNgrV3uvKdhCJNU4gDluJ2LDdJR98eB2w_k7FEqnZfYeh-TqzEe3Z-V0gi3Z7qD6FwztWdjNQO84wYhRIMCHRqRBsE7azE0j62McGrJkpaNIBVb8NCTK2qmuPes6FZ.png) 
        - 
        - **Q3 Three waves of HCI **
            - If HCI methods were applied to the design of a programming language and waves of HCI tools, what research questions might be explored, according to the concerns of  first wave, second wave, and third wave HCI respectively? What empirical methods might be appropriate for studying programming from the  perspective of each of these three waves?
                - First Wave: The efficiency of the programmer when interfacing with the programming language would be studied, this interface being a separate module to the system itself. This could be the design of the keyboard used to input the commands, or the design of the screen used to display text on the screen. Methods from cognitive science would be used to model users’ perception, decision and action processes and predict usability.
                - Second Wave: The programming language would have to be considered as part of a larger social system, so the mug with different git commands written on it might have to be considered. More generally, communication between developers and the parts of the "program" stored cognitively would have to be designed around. An empirical study into the context people work via ethnography and Contextual Inquiry could be undertaken to understand other people's way of seeing the world.
                - Third Wave: Programming languages would have to be designed in a culture where computers are ubiquitous, and a programmer may use one language at work and another at home. The second being a discretionary choice. Languages might consider the aesthetics of the programming language (Is scoping with {} uglier than scoping with tabs?) and the fact that if not mandated to keep using a programming language by their boss, developers might move on. Design experiments become more like works of art, speculative and interpretive, with critical assessment of how this is meaningful within a particular  tradition.  
            - 
            - 
    -  _**Supervision 2**_ 
        - **Q1** : 
            - Fitt's law says that the time taken for a human being to point at an item (this could be pointing at button with a mouse cursor) is a function of the distance from the item divided by the width of the item: $$\text{Fitts Law: \ \ \ Time} \propto \log{\frac{2D}{W}}$$
This means that larger buttons are easier (and thus faster) to click on - additionally if buttons are introduced close to the users cursor, they can be reached faster. 

This ratio of distance to width is the  __index of difficulty __ and can be understood as the potential amount of information gained by the system when the user points (selecting a small target from a wide range reflects greater information gain).
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/l3EEwcZaXHBkhmwX-BGmeOUfKKiJ60RKYloQXLM8G-7LBIUov7lUT3OBvck_EDKXdb0aQNImIYry425QE3WVTFXay1ljqF-2KP_7qzZunozGrEdkxw80ChQw6NfbzXAr.png) 
            - Consider Fitt's law we quickly note that layout B has wider buttons (decreasing the index of difficulty and making the buttons faster to click) arranged in a grid, while the average distance to each button is further in layout A if the mouse starts at the centre; if the mouse starts at the top of the screen the average distance is lower in Layout A (lowering the index of difficulty).

However, such an approach to selecting the better interface is too simplistic - we must also consider which button is used the most: If the settings button is the most used button, then the decrease in average distance from the button by making it larger could be worth the trade-off in making the other buttons smaller. However, if all the buttons are used the same amount Fitts law would tell us Layout B would be more effective.
        - 
        - 
        - 
        - 
        - **Q2: **
            - **Is efficiency always a design goal? **
While efficiency can be a admirable design goal, every resultant system resides on a Pareto frontier of optimization decisions; trade-offs are always present, and designing solely for efficiency has its own trade-offs. 

One school of thought for design is Taylorism, this method describes the optimization of workers in an industrial context wherein workers are modelled akin to machines. Within Taylorism overseers are introduced who use various scientific management techniques to measure workers effectiveness and productivity, these measurements are then leveraged to improve efficiency. This has immediate problems, one being that humans change their behaviours under study (called the Hawthorne effect) - however even if we correct for this issue other philosophies disagree with this method.

However different paradigms exist for example akin to the Second wave of HCI: rather than the workers being a machine to be studied and improved, they should be involved in the design of the system and treated as collaborators in improving efficiency. Ethnography and contextual inquiry are employed in an effort to reach that goal, these methods rely on the fact that the workers have the greatest knowledge of how they work and are invested in removing obstacles reducing their effectiveness.

A third philosophy (Driving the Third wave of HCI) describes workers as discretionary users who are not under any job related obligation to use a system. This user has their own wants and goals, and efficiency may be last among those goals - instead a system can be designed to optimize for creative expression or personal enjoyment. Contrary to Taylorism, these goals may be difficult or impossible to quantify in an objective and scientific manner, instead qualitative investigation techniques must be employed.  
            - New designs 
                1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CNfkXNGhM2Nts9ciTVJ35uL6bKnHpZtT8ltaveqF5oXfZznI7mbEg5mt98VzDZDWwpZgwBvW7mPY4ppfNWUpTDU9Haqx0znpoiqiANnvOpP5oJJ08k4d36wDP6Aw5Vcx.png)
The goal of this system is improving the mindfulness of the user, within every option a zen quote related to the option is shown (these could be cycled daily) with the goal of helping the user reach a state of calm reflection. Taking time to read and digest these quotes and encourage, and the only efficiency consideration will be that the buttons will always be in the same place so the user can skip past the quotes if needs be.
Mindfulness is a nebulous concept so it cannot be totally quantified in a meaningful way, however reading such zen quotes is a well known technique for reaching (in vain) towards mindfulness. 
                2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U4Y7woOBx5dDo-0MIsjbb9f25XUDTNKcYACnAsI78RZPZJWz2iEs9EwCGneQa1zfjeOVUbeKkeSH-Gc1dBT0SY8GHdOWAMSlLMlkOc8TngjCpaqYtUTPdpFWD2ytCHOS.png) 
This system has buttons to play short sections of music, these music sections will be related to the function of the buttons and the user will be prompted to guess the function of each button! Once the user has guessed all the buttons correctly they can use the application. 
This system is designed to give the user a sense of satisfaction once they've correctly guessed the buttons, and provide some entertainment alongside an otherwise dry and regular app. The enjoyment is difficult to quantify meaningfully, however a poll of users could be taken and the enjoyment vs irritation at such a system could be measured.
        - **Q3:**
            - Scratch and TypeScript are very different languages, while Scratch is a visual **block-based Programming language **while TypeScript is a more traditional text based language built on top of JavaScript   
            - TRADEOFFS - why did they make this tradeoff
            - **Dimensions - Like viscosity:**
            - **Environment - surrounding options around the language, block selection tool - autocorrect - etc: **  
            - **Activities - What you do with the language:** 
            - The environment of scratch provides many utilities to the user, including all available variable combination functions, all available variables, Events, Sounds etc. These are grouped well which could reduce the  __Error-proneness __ of the system, however some of the menus require extensive scrolling to find what you're looking so  __Visibility __ is compromised. This trade-off of the number of categories vs the number of contained items is understandable, and in practise the less used items are placed lower where you'd have to scroll to find them. The environment also shows you the arrangement of items on the screen in real time, and allows you to drag items onto the screen - this immediate visibility makes the system feel more  __responsive __ and reduces  __error-proneness.__ 
The Typescript environment provides a different set of utilities, such as autocomplete and error checking. Autocomplete provides  __Visibility __ of the options for a specific object (e.g. the methods one can apply) however the options are often irrelevant and offers up  __Premature Commitment__  where you aren't yet sure what you want to autocomplete to!
Scratch and TypeScript share editor error-checking, this can be very helpful for spotting bugs early on and is a type of  __Progressive-Evaluation. __ However, there are cases where you are in the middle of changing a piece of code and (temporarily) your code is incorrect and thus covered in red errors - this does introduce some  __Viscosity __ and is a visual distraction where the  __Secondary Notation __ is otherwise stellar. This is a trade-off, as if a certain time period was waited before applying the highlighting the user could have switched tab and not noticed the error AND some users may find this added latency unpleasant. 
            - When considering the  __Viscosity __ of TypeScript vs Scratch, one must consider the facilities these languages provide to reduce resistance to change - TypeScript has features that could be considered resistance to change, for example if we have the following code: ```javascript
const arr = ["1", "2"];
function compact(arr: string[]) {...}
compact(arr)
``` if at some point I would like to change "arr" to contain integers rather than strings, I would either need to change the type signature in all function using arr - or create new functions to handle integers. The trade-off here being type safety versus viscosity.
Scratch could be considered even more resistant to change, for example consider the following code:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_IwxIxkD8kvCea2HOuURmTPUzuJ8U_JaM-ws-nd8rUmgUNvevc0PTLrhKMpxS5RggOL6doKDlar-YgR7IXW-qF76TvH1qwxf40GkHBvG1eaGshkquIUXVUpsFijlKwRK.png) 
If I want to change the x velocity variable, I would need to go through every example here (and in the surrounding code) and access a drop down (which in large programs could be lengthy) and find my variable to change it. This does eliminate the complexity of an automatic variable switching system, and as this is designed for younger users this reduction of complexity could be worthwhile.
            - Scratch has many  __Abstractions, __ user's don't have to think about how the canvas works or how to change the colour of a single pixel - this is replaced with controlling sprites **on **the canvas, easily modifying their position, rotation and size. This is a trade-off between low level control and ease of use, and as Scratch is aimed at a younger audience for whom the barrier of entry should be low, this trade-off is well worth the price. TypeScript also provides forms of abstractions, you don't have to specify the number of bits for types or describe where in memory they're to be stored (more a Javascript feature), TypeScript also adds interfaces which allow Object Oriented abstraction on types. 
        - **Q4:**
            - **Firework displays: Suggest an analytical method that would be appropriate for evaluating and refining the usability of this language and associated tools.**
            - Cognitive dimensional of notations analysis would be appropriate the usability of the language and associated tools, it forms a language of terms that can be used to clearly communicate language features and holdups - and through this language design decisions and the trade-offs they result in can be clearly discussed and understood.
        - **Q5:**
            - In terms of Cognitive dimensions analytical method proposed in Q4, define the target user, the nature of their task, and several specific usability requirements that would result from that task.  
            -  __Viscosity
__ The target user is someone who is required to run a fireworks display, thus target user will require a low level of viscosity - consider that once a single firework display has been designed, rearranging large chunks of the elements around creates a seemingly new display while requiring no new types of fireworks. Additionally, if a certain brand/type of firework cannot be found for the display, it should be possible to change a type of firework (the colour, brand, sound etc) in the display easily without disrupting other elements.
            -  __Hidden Dependencies__ 
The target user would like the minimum number of hidden dependencies as possible, this is because these dependencies can cause confusion and mistakes and as large firework displays can cost thousands of pounds the user of such a system would require clarity and ease of understanding in the code.    
            -  __Visibility__ 
The visibility of elements will be a priority for our users, they would like to be able to clearly see the arrangement, order of their fireworks and possible effect of their fireworks. To this end, a simulation of the display would be desirable by the user so they can be sure their design is exactly as they wanted it.
            -  __Premature Commitment
__ Premature commitment could be a problem, as often certain features of the fireworks or the display would not be known by the user to begin with - for example the user may be perplexed if immediately required to input the brand of firework when first attempting to design their display. On the other hand, for large displays the resources at the designers disposal will likely be outlined long beforehand - thus a middle-ground must be found between premature commitment while still allowing for early specification of resources. Additionally, the user would likely like there to be no early commitment to the layout or length of the display - as that may change over the design period.
        - **Q6:**
            - Choose one requirement identified in Q6, and describe in detail an empirical approach that  you would take to evaluating whether this requirement has been met.  
            - To test viscosity of the program, we could design a set of tasks like " __change the type of firework to pinwheel and the colour to green in this display__ " and measure the time it takes for a group of users to perform these tasks - we could then repeat these tasks on other state of the art fireworks programming languages and again measure the times taken. Thus, the programs viscosity can be empirically tested against other programs - or we can simply examine the results from our programming language and decide if they are within desireable bounds.
- Logic & Proof
    - **Lecture 1** 
        - Logic concerns relationships between statements: satisfiability, entailment,... Logical proofs **supposedly **model human reasoning (symbolic logical AI dead end).
        - **Statements (informal) **are declarative assertions: "The colour of my dog is brown"
        - Schematic Statements - letting variables range over 'real' objects - "The colour of **X **is **Y**" 
        - **Interpretations and Validity**
            - An interpretation―maps variables to real objects. $Y \mapsto \text{coal}$ satisfies the statement, Black is the colour of **Y. **But the interpretation $Y \mapsto \text{strawberries}$ does not! A STATEMENT IS VALID IF...
        - **Satisfiability**
            - A set of statements is satisfiable if―some interpretaiton satisfies **all elements of S at the same time.** Otherwise, S is **unsatisfiable.** 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/w3fzWcKlgdmKEsLXTEjRH3BxEY4A14Pqs4VY6lqw1ppnnwsh7m-4HulXW_KFGSNeKRPj7xppuJAYDSN5YqcV7TRWxuOpU-Y0VUiCgzRTIwk-Un-flkjcmnvJ8FVHEIw8.png) 
        - **Entailment, or Logical Consequence**
            - A set S of statements **entails A **if every interpretation that satisfies S, also satisfies A. We write: TURNSTILE ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sX9svuHUGCdpgbcNMNqOpCtsjTZIzv2YMEHjld1GsyF6yVkCoytNRpW3H-KwTnobcI6JkSgmRKpPLPvGMlK8ong_5c5lhpUJsm2RhlMfE4nCay8XiXui5MlUYHvzQ8cO.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JJiC06M_P7NnjUEXujItCK4DOFyV2nR6UdmA6gXgCzgfsnHnqtYRgIaMQ8EGgEDzcMsHcngGBgOrGRwg8Mpv5n_ciSwL3YLrqX6Yi-Qb3WR_H_86p-qGgY5HCLWcdTf0.png) 
            - Last statement true for A being a tautology ok!
        - **Inference Rules** 
            - An **Inference rule **yields―A conclusion from one or more **premises.** ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Qcu-8WH_-qqJNucQyUaQnBBjmiIZYodNQu5JBxlNjSxi1iEqjheRfNXlYgUi8uMRA86F5jlB12I9JAlRlV0VKtRRCtOWP9smI79WkRylEEdxRDhLIb0vujBuIqr6PkYT.png) 
            - A proof using **Schematic Inference Rules **is correct if―it has the **right syntactic form. **Regardless if the premises or conclusions or true.
        - **Consistency vs Satisfiability**
            - An inconsistent system will have a proof for **every statement. **Including 1=2. 
            - Satisfiability is the **semantic counterpart of consistency.** ?????
        - **Richard's Paradox**
            - Consider the list of English phrases that define real numbers (base of the natural log).
                - If we sort this list alphabetically, yielding a series of real numbers
                - Define a new real number, based on the other definitions (diagonalization) 
                - This is a real number not in the list, that we've defined in English - paradox!
        - **Why should we use a formal language** 
            - The smallest positive integer not definable using nine words ⇐ defined using 9 words.
            - This number is so large, it is greater than itself.
            - **A formal language prevents ambiguity**
        - **Different Formal Logics**
            - **Propositional logic **is traditional boolean algebra.
**First-order **logic can say for all and there exists.
**Higher-order** logic reasons about sets and functions.
**Modal/temporal **logics reason about what must, or may, happen.
**Type theories **support constructive mathematics.
All have been used to prove correctness of computer systems.  
    - **Lecture 2**
        - What is **Propositional Logic**?―It's traditional **boolean algebra**.
        - **t **means true. **f **means false. P,Q,R,... are propositional letters. **Propositional letters are** **input variables** that can be either true or false.
        - Statement truth tables:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gwQF7HcduGp11BuKHCpYXzBc2RnEFgMLqXtDhlyf22MrZI2FgQ_GVr1EmZG4KmfXv6SnCsOstz2dGTBiXWJk6JzXJT5XseJJt5wTKYqhh_cWDD6_tv1o_nZ60kRgRPH4.png) 
        - **Interpretations of propositional logic** 
            - An **Interpretation **is―a function **from the propositional letters to 0 or 1**. It's like an  _instantiation of a formula_ . 
            - When does an **interpretation ** _satisfy a formula_ ,  _satisfy a set_  and  _when is a formula valid_ ? ↓ 
                - An interpretation **satisfies a formula** if it **evaluates to true**. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/A-x2713LtmHjO0NrCEZd-EplqgvcXFdknIkPBAE8tVJ6fe8xBsQLsDuXyjM460j-8h6BX8in_Sj5B8h1kh-LiXIRuu0mYDew1xJX3Mr9xLAqQKjXXPc7nt5vwd-2-7pU.png) 
                - A set S is **satisfiable **if all elements are **satisfied by an interpretation** 
                - A is valid (a **tautology**) if every interpretation satisfies A. I.e. for all instantiations of the formula it's true.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/my8XoQ7hhJ5cmsmlcSJ5ww_luBcrwhE0K4K5nged-gPlXy4aJDGWnGEYcNQJgnIT9r4yJcbs50TIzZTUGT_Xu8SYVTDTP8GAk_qKqm9QNnUHPAZDwYI77lP-l_to5Jjt.png) 
        - **Implication, Entailment, Equivalence** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/thKW7VRYRg85vxnUsgt-Lan80a3nqILoObMg2fhjX4CYT7Rx23oujOydA-M3EOKqMDf8M2Kzjr_zIi_O5gU3NS4WOHhVx-mvux-d_uGJ-jscbVAVVBEvAC-6NC1UydGL.png) 
            - So in **propositional logic**, $A \rightarrow B$ is false iff―$A=1, B=0$. 
            - What is the relationship between **entails and implies** in **propositional logic** you  _nitwit_ ?―$$A \vDash B \iff \vDash (A \rightarrow B)$$
In other words **A can only entail B if we don't have (A=1, B=0)**. 
^^Entails is more like the implies we know and love^^, e.g. we have $$A \vDash B \iff \vDash_I A \ \ \text{then} \ \vDash B_I \ \text{for every interpretation I}$$ 
            - Although $A \rightarrow B$ is the same as $\neg A \ \lor \ B$ , they have different syntax.  __No shit__  
            - Entails is talking about formulae in the symbolic language of mathematics.
            - The approx equal symbol in equivalence, is saying that the formulas may have different syntax.
        - **Equivalences** 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BZeUSUXzGFY19r_EqkYHJH_Dco2mjSvGnEtjATEYx53m9pGLmVRmd48gG5bX9piyxL4gghDLeomoWeUIIkK0iqVo32JifBIIkuHfB1W0grrAAz8Mej0zMEKiwjGr-gIh.png) 
            - We can exchange $\land$ with $\lor$ and **t** with **f** - and it all bloody holds
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SjjwTHT_9YFv8dCuUzpyUYH8hA9At-3q78JgJ3CPWtOPLnqxe5YIvnJGlKt5hQv14gfJzDMqJwaBbX3tMjHPNCoBu4Gz0iZndXbWZB9LlWOOgaCPEm5Awet0fK9GHYVl.png) 
        - **Negation Normal Form**
            - What is **Negation Normal Form,** you bloody fool?―Negation normal form is the result of **taking propositional logic** and **removing **$\leftrightarrow$** and** $\rightarrow$. Then **adding negation using de Morgan's laws**. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Xobe1WgmgkBqqzUQjOOSvHO8hJFHnHmGar71k2V23AWBaakJnjSIfleMXx0Q5GxTUUaM7czdFXdUWwM9ZZkEsFNphv7Omw_i0Nrx90sjr9jP_trzS5-qrXP4mooIGPNc.png) 
        - **From NNF to Conjunctive normal form** 
            - What is **CNF**―**Conjunctive Normal Form**, remember from Digital Electronics? Load of **formulas ANDed together**, and all the formulas are a **load of** **propositions OR'd together**.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jNk7LnaKad2RAY_GBrTmACVKWSSqIqo8lIFMkh2lE6sTOJikEyppFhMJDCJUMiotjkYlrwnWsuV-WX-kOjk9uaZsZDTo7EpX__eVJukCc960keSb6YaKL0dvY1nNO7Gv.png) 
            - We can simplify to reduce huge exponential growth:
                - Delete P and not P in the same disjunction (OR)
                - Delete any disjunction that contains a different disjunction![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bYVgqnMGfa6vZ8TkWLcWUe47VH1wJ42H_MUS9UAY5JRkydMTMl2W6qcdJJoU32EQYlpUkwVOtKZjZ3JrUGZlz0JH7F3UPJm7dDTZnbX688ivzm3CWWIGVFavhzx8mgg2.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gTX5OIsJ4WkgtyvhXLQspyxwTpuf8HLqLdR4STOt9jryufJY7epQY5S3htNruuGWNo5GZ0-IWhF-zQWhQIXrIIM8ARRrcCp5aHww5a6Iox-vzaxyhKLEWimqO49HUCDx.png) 
        - **Converting a Non-tautology to CNF**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LoitiiSr-64lC2Umfdy1orOVlvj6EhUuux5UfCmxGCTudEigbOoTcbS-2Z4tnQY-0ct-CIpo7EGzm1nPEycum2QI8pAmegrpH5nCHhNpQaf-phi1oPUN3T7v4_FmGljk.png) 
            - If it simplifies to True, it's a {{tautology.}} 
        - CNF helpful for theorem solving, we can check each part to find a counter-example.
        - 
    - **Lecture 3**
        - **A Simple Proof System** 
            - **Axiom Schemes**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/98wX1oS5FUBaTIhxIac07AKFp2BGLmwcFCHiKoVvVH456WDscqKPe6fq2uAQsG1nRSUhLjc7JdgXD2aQnto4VUliQd1ZWDIEz5pU2oX-QmAMr1jg_zUmj8dHdTyIXlw2.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/igw5iyOMNP-8OQT-IVHYPJa7TJ21zWwhLScqyaPwDKfVVkZ5mhV4Qe26jtxwNJ7rgrl24ECxEasUzSApCFJA1ANSc3HMPVyVHSIpKXBiiT0fwUrN8KnfDyIQDzYSv8bV.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Pwlt-vTqUsra0YrbWcHyICwPaUcUWjKXSOxrzf3Ic_UxQdU-dVoB2ZBeEeROYKjdLo-NQrD3SAnVDl5mp5CDINiktn8Gf_cQjN_upXVfiM0xIjmEqQZN3uXCOsAJ3DXX.png) 
            - **Proof of **$A \rightarrow A$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aeGM9dUE82EmQg6-jovP705GVCrJlqGirHb-Ib88i_33qaki-IMLDI0AtW0963K_z4MDKaPN39F5YedNs8lPNkH_PDutV00Mtdg9yGbOhgEhs5a-LC-0irN7CrDE5Pb-.png) 
        - **Some facts about Deducibility**
            - A is deducible from the set S, if there is a finite proof of A starting from elements of S. Write: $S \vdash A$. 
            - **Soundness Theorem. **If $S \vdash A$ then $S \vDash A$.  
            - **Completeness Theorem. **  If $S \vDash A$ then $S \vdash A$.  
            - **Deduction Theorem. If **$S \ \cup \ \{A\} \vdash B$ then $S \vdash A \rightarrow B.$ 
        - **Gentzen's Natural Deduction Systems**
            - To deduce $A \rightarrow B$ assume $A$ and go on to prove $B$. 
            - Each logical connective defined independently. We have Introduction and elimination rules:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0cYZlY_NkVpBbk66O2_dKmJGK7Mv-p2VYpTdwpKg19jLD5IZTbpJ8irrdrlqRSABpmuh_CFHVgEUqVV-tgOIJ9cvMkSwTWAVRrSeA_Y5TGfeGf-_vP2O_lnQzYANEyy0.png) 
        - **A Typical Natural Deduction Proof**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/shNrufYnnvXQiKpxTyvDrV-QXRk3r141Eg6YW3V-gv_KsyD31N5EEkuIKRdYM0JVdUmN0VtPB1dINlfBrO4DGJWQ0lw_Opvaxir8fWx-ocwZXUOr_VLpdxGKY-6tci3M.png) 
        - **The Sequent Calculus**
            - If ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Vg-Ff8NEAXnnoW2QjksUIbJ9-az8Rs3DFMNcGcR7iaMiNSYsT7A2R0D-bSah6Ijs3ZEuzO7IQaDU3X3T9AvAMdgyVc11pmzQ85FunyUK4KSDqReJrYDN9LeMk6qSTDoa.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/m2r_lQKtg3xlf6t3FY-uaOdcOX_IpAQcmV94QOGs0BHsOIJwDy1t10Z102DwtdsRq3aLUWUb-5UUKtzxVv6UtmSEGJ9y7gq6X8StSGpAy1d15xVzW9oDxIX_MoNuCFkE.png) 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Xl9FiHFJxf7jnlJcDM5r3QiPpfNKme5-5rkr5Xm42keFFRJUHe9_h2Zumcxp0IfTjjp8rvdqlbTG-S-1CpdGtC9yFtUDrjrlidZCZe5Tjqrk_hb0CezyUr5GJtCEXZYq.png) 
            - **Sequent Calculus Rules**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RxCWq5wVKfY8Ds1wSQONw-4E_5_pbzz-z6hNg_XUpbamkSOrI1SHZuSfZmaoRHuT6xFC8w2by6sYNNi3-onqYcZKZUKbdg9-44B-z7OLjIUCr5Ux4B1rpIcsNuLdULIP.png) 
If we can prove A, we can use it as a Lemma to prove Delta.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6lQtd3KF5qRUBYVIDwTu9eRtCYayY3G-ApFY4fEycb8glzxXnD3s9oBYeN0WhKKpgDAQ3ibgNwXlV5Zrovnw_JtmWRxv6gSpkVjqapGaSK9nM0mxLzFoK91Lr-gAfLoV.png)  
We want to show **delta is the goal that pops out. **So assume not A, and a proof must mean delta is the true goal. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xLmrS8zsoCk9X_K7zWZzSFl8_52ZmtNB4a2lEu7brcB0vwCRA8vMUnqRSR81aq11nIG4RLVmlxfnYZ3MzsByTvgsY1O-foFXK-olYioNZkBi1xMenTR4qDq6CARux_6r.png) 
To Prove not A, it is sufficient to assume A and prove a contradiction
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Gsw4GDUN__EvNMf6cpweZwcg5FpCxG3EF9i6rdTxKlHQGnXseO-kNaygHaWLk5430HuaNKD6QEMCFXhWf2PN1cpSh9fnGVPBHS8fMYhNirYayrRdn_wuNRRZAn-Rf35X.png)
Straightforward. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JnCAXrF6P-eHLm8o1vXRgKP0qlXTCoot8bEM5NAmhCrVR1rr9TOOs9Ij5gc89P0GeNXzWLYrJOVSgf7YvYbMBh73_e_tmJMffSOb-aim4R666pDr5ouIxlNa7NwsyIR6.png)
(delta or a) AND (delta or b) = 
delta or (detlta and b) or (detlta and a) or (a AND b) =
delta or (a AND b) //Think about when the whole thing would be true
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sayFRzBtrTMj4phE2w8sAh0a9A3rM9CuLX3oSLZkbCfO1LNE3td02ztkdW00gDPt6lGKidjodagzZx9dXTZwwYeXcEMBmR_lFHYt6fmUrR_Kan-ShzelsAWkfV8eFmA7.png)
Straightforward.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yhT0awtb4vtMhRtSlKlhzYrV4nA2mJW3l4EqCfUr4SPZT-Tn180U7FzwSP5U8KczqGPWNnGtr4ZscylVUKsaS1yUGAkS5rUJ8nzt6w8zfNXubUgymke5tHe7OK_7RS5Y.png) 
This is simply using less assumptions, can always toss away assumptions
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VfHacf16Omw_4B_dprc_fisJ1tKGrXY6LRQ9rBR_peOPKQe9oA78YCqEPp0LTImvei3CNA1QdknOHqWXLx1CM2ucp5JXuLmkMoRPaakdG9I-YOWjKVMS6t0BfISSlH_x.png)
Assume A - prove B.  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6lnlyKSjoMXPdQDbL013sUXBZGGWwpd0jpeEV2Gg5puZxYhQNvWWD87nhs32TN_YA9akTVbmqTRrCJLUTMACrtPANppPMcfAu3MlIIbLS2Z1BFE0MONNt98RHrUS-ox_.png)
If we have A, and B can prove delta. Then A implies B can prove delta.
        - **Example Proof**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FH7-DjuDAugv75LfWETVlYTL3jxntapB2P9JCKG0vRVYbhsLXoPPTY2ycrJcFHjW7wSFWm8bk2aRHFUQQkxVVIT1DR-dyrcmMbkI01L1uOg3idqaS-gWpAnJq2fmGcHT.png) 
            - First write the sequent to be proven
            - Then use the sequent rules and step up
            - Work with the outermost symbol at each point
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/69FhkHEateWIh7hBTTwFaOQIXRr0jbUO7xZxcwuavKAEhaYXFBJn466OpE8koCgd2PEcKMgEZclsJf0gIEhJiew6ccXYMfy8wjAS_PGrjiB3pmvXskKS4koIZY7RUj6H.png) 
    - **Lecture 4**
        - **Outline of first-order logic**
            - Reasons about functions and relations over a set of individuals
            - Cannot reason about all functions or relations 
        - **Function Symbols; Terms **
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sbitxM-URtE5mW2iTUwtyrjSzOPsQsF7FhOXBvUg0uwFKB6oOV0_YVgfOs7TYhjznWo8jBW0SdNAuxz6lOzNX0koyF3hOAai0NYrOWY0feJRvvum45bnZqkLmP3rpfTc.png) 
        - **Relation Symbols; Formulae** 
            - Each relation symbol stands for a n-place relation 
            - E.g. Equality is the 2-place relation symbol
            - Formula built up from 
        - **Quantifiers**
            - $\exists  \ \ \forall$ 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/MWflgxSbwZ9Fze0vw3STem3j3heSuyto0cUEeYsQOp3kS1QD_OHnk4p1IoGKJBjnc-ya5DAtp0v0jlrZ7K7K0XOh36NdywZqPFxvA5MJwGbK-hweFQyH9edpbcNZAcCU.png) 
        - **The point of Semantics** 
            - Why not just let 1 mean 1, rather then a complicated symbol that represents 1. Well because an unforeseen usage of a general symbol can be very useful! Think about dot product multiplication. Vector calculus.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TjfwwfmHCJ-AyJT04eAfhKIwittVTA2_wHhQxB3IlBsYwcBkClKS_nfzsnVUh7oWrliyXUz9g9UNXFryZr-smUaZjvoMJQH7ZJUifixtJqM-V3WDPGsHFpOLbFZJG7WW.png) 
        - **Tarski's Truth-Definition**
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/33pvB6qWyex4QduJH7JpF833jqbcY7uE6CF4ifF0Ndxy4ChKeLyKREDD1plNISKuMPXgtaFPM8OGdQzZ0wcg8NmWj_nnHIS39GBKZiX_f1VjFX--zy1KdN-yIWWx9L8W.png) 
            - An interpretation and valuation function V specify the truth value of any formulae A
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/srppJ7JDtSURpGwbNptfLBcvslsvcbEvG_4uZkA7h7Bx9hXykCkhYDTqYb-DIldUhe4koPeAuq5TKvV3STlX95fQngP1g7h1GqGKyNAe0b5xs1mgnYuor6MUEfNeXJmH.png) 
            - 
        - 
        - 
        - 
        - 
    - **Lecture 5**
        - 
        - 
    - 
    - **NOTES**  
        - 
        - 
        - 
    - 
    - **Questions for supo 2**
        - Don't understand the pure literal removal in the DPLL method
        - 
    - **Assorted Flashcards**
        - If we have the following in sequent calculus, what does this imply? $$A \implies$$―This means A is necessarily false, as we can step to $$\implies \neg A$$ 
        - How would you solve ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lj8IvKudhXXWEhQnk1xDRXKZIIWe_XMUFYP85IxbA-WHL4NUe8rp5C2-ze95kgOd_u_GFlDx7M3gXD29u6a6PyMoRjzg3flvQRWCfFQhf8ula2dsN7_X5oQ2Y9pfSGcq.png) ?―Put these connectives in terms of existing connectives and do a sequent calculus proof.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wY2QXQTAgUk-oPghScfKYUTjZIKePPEAv9M9SKsxr4MDl3jtTNCdRduNd1ufSMloet8rMPPu-nyv-ctqpe4jkrxRbb_3zOzkOQLzgKgG4uCJIKMqxNkvS4XFaHMfjVhC.png) 
        - What's the difference between linear and general resolution?―In linear resolution you can only use you starting clauses, and the current clause you just generated.
        - For the herbrand universe, applying functions has to be done in a way that is valid. ALSO predicate symbols are seperate from the functions, e.g. < or >. 
        - Do you push in Nots first or skolemize first?―Push the nots in first, then skolemize. Otherwise the quantifiers will be flipped.
        - What do you get if you factor these ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4knpW6zek7HtdVCA-CmLkMsS7M8yO2JH-xowKDAxN9Eq1-XhMV-gpb98IjzcEUwXquGX2LBKGgLha-c9PC9xNnQNJIxAGp9obJ412FtETdFIKU4MnfO9w5T7XDLqXcIy.png)―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pswtBqpep-ekDHtzoqoHlUjRRC4dvFgk8A5MhMVo_8CqRHqmFqbCKkjPKRaEkKcxXTG6q__l4RPhBTtyZ3LlOuN_QnCmkgnGoR86g-ASqAnMMhrTrGOLHVDPtFiliDpl.png)
Always start by factoring if you can, you lose nothing and it just gives you free clauses for free. 
        - Describe the procedure for combining BDDs―Write out your first tree, but when they lead down to 0s or 1s attach your second tree:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sxPm1tm3p1PnE-meFGIaERHdopWMMGZM2IwwTA3-XhtuAvrgSpFJm1DOXfuAihD7uIiNHLwFOZNY54reLmuXE6Yx539vYnV3oD36RFNWjTBcD7Q_WEMyirwCdwZKGUc0.png)    IMPLIES  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4hP-neSWPMPjGiupttwjlr2wbQ8joUIGSKEH7jd3v0kXF0emRUa71G_vK5zUFZEgNcXUdZN3w-UMWNhogiIDpI1ZOgJKtyM-2gQaT_gop_Tl-WbRddFMe2bo-hMbKIbC.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BkVbQ4bIz6pzsL7yr6iks9HvRtFQYC57UwwINL5cYUyjnOKhzB5Qw2VM8MApq4TNJzRY8Zkru8ulDVZnXh_zzH6ut35IDPBf9CWqvK49zPv44JJFsS75NEQYRLiLI_1y.png) 
Then simplify
        - How do you know the dual of an operator string equivalence also holds?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/izC8XKFSfTJc-Dv0yZnfovRAL5S-Htovps3kWpWCiwFCR2bMY_cH_fnN_1iG1smjfewz9roLuJRJuyJd1QfGQJTpSGtni2taK3VJ5KkKUN0gteoOqB-hhgnz9bRNjRLf.png) 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/o6vy1vAwO6dsOU1YZec_UVTpr1y8H4Ca5M5VMjNDhZdcVxhGZ88PcIzTW4Xj51uK3jvvB8BZ-e9-z1sQWUJ3qDQJqIvAmvhJCdWWu1RkkOe6bg8ShUe3O7xWnOEewkSL.png) 
- Prolog
    - **Lecture 1**
        - In Logic Programming, we're describing the result we desire not the procedure to reach that result. Below is a declarative way of finding the sum:```perl
 sum([], 0)
 sum([H|T], N) :- sum(T, M), N is H+M
```
        - To get to user mode to enter facts, use [user]. ctrl + D.
To load a program,  swipl -s program.pl  
        - milestone(X,Y) - prolog will iterate through all the facts where this is true using semi-colon 
        - Terms
            - Constants - like 1, 2, 3.14, tiger ⇐ an Atom, 'Acre Wood' 
            - Variables - strings with capital letters , X, Sticks. Or _ which is the wildcard
            - Compound - likes(dog, bones). We have the top function symbol (likes) and the **arity **which is 2 in this case (number of args).
**Note**, tree(A,B,C) is a different tree from tree(A,B). Arity is important
        - Prolog tries to unify terms:
            - Atoms unify if they're identical - tiger = tiger
            - Variables unify with anything
            - Compound terms unify if the top function symbols and arities match and all parameters unify recursively.
        - Built in relations in Prolog: 
            - You can declare infix operators: op(500, xfx, taller)
Allows for : andy taller ian. andy taller X. X = ian.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7_wHu1Vi1jgou0UMBpawJwRJXdhiDvAENmM-EsWKkfwZIrTC0iaCCTWC2zmJ0jrGEEESb8wMjR3V_UPmI0atnih7WF_JfuZs_EV1iyEEE5vWKI8Q2ztCqFx15Xi6MLLL.png) 
        - Prolog Backtracking
            - Can be interpreted as a tree, try the first rule and if no progress is made try the second etc.
        - THINK DECLARATIVE, len([], 0) asserts that [] and 0 are associated by the len relation. Write declarative comments %.
Good comment, len(L,N) succeeds if L is a list and N is the length of that list.
        - Prolog Execution strategy -
            - First try the first rule, then the second etc. So ```perl
 sum(X, 0) 
``` This will spit out [] and then continue looping over the second rule forever until you stop it.
        - 
    - **Lecture 2 **  
        - ```php
house(Nationality, Pet, Smoke, Drinks, Colour).
(H1, H2, H3, H4, H5).

exists(A, (A, _, _, _, _)).
exists(A, (_, A, _, _, _)).
exists(A, (_, _, A, _, _)).
exists(A, (_, _, _, A, _)).
exists(A, (_, _, _, _, A)).

rightOf(A, B, (B, A, _, _, _)).
rightOf(A, B, (_, B, A, _, _)).
rightOf(A, B, (_, _, B, A, _)).
rightOf(A, B, (_, _, _, B, A)).

middleHouse(A, (_, _, A, _, _)).
firstHouse(A, (A, _, _, _, _)).

nextTo(A, B, C) :- rightOf(A, B, C) ; rightOf(B, A, C).

        // Generate candidates
:-  exists(house(british,_,_,_,red),Houses),
    exists(house(spanish,dog,_,_,_), Houses),
    exists(house(_,_,_,coffee,green), Houses),
    exists(house(ukraine,_,_,tea,_), Houses),
    exists(house(_,snails,old_gold,_,_), Houses),
    exists(house(_,_,kools,_,yellow), Houses),
    exists(house(_,_,lucky_strikes,orange_juice,_), Houses),
    exists(house(japanese,_,parliments,_,_), Houses),
    exists(house(WaterDrinker,_,_,water,_), Houses),
    exists(house(ZebraOwner,zebra,_,_,_), Houses),
        // Test candidates and then backtrack
    rightOf(house(_,_,_,_,green), house(_,_,_,_,ivory), Houses),
    nextTo(house(_,_,kools,_,_), house(_,horse,_,_,_), Houses),
    middleHouse(house(_,_,_,milk,_), Houses),
    firstHouse(house(norwegian, _, _, _, _), Houses),
    nextTo(house(_,_,chesterfields,_,_), house(_,fox,_,_,_), Houses),
    nextTo(house(norwegian,_,_,_,_), house(_,_,_,_,blue), Houses),
    print(ZebraOwner), nl,
    print(WaterDrinker).
``` 
        - Consider, what does exists(house(british,_,_,_,red),Houses) actually do?
            - It instantiates a guess at Houses that fit's the exists rule, e.g.:
Houses = (house(british,_,_,_,red), _, _, _, _)
            - Then it continues to  exists(house(spanish,dog,_,_,_), Houses) and will try with the first rule exists(A, (A, _, _, _, _)) - **this will fail! **Then it backtracks and tries another rule to place the Spanish house. Note, it will only backtrack if it runs out of Spanish options. 
            - This is **non-deterministic **behaviour, Prolog backtracks and tries other rules until it finds the correct set. 
        - Rules
            - rule(X,Y)―part1(X), part2(X,Y). 
            - The rule head is true if all of the body is true. Variables can be internal to the rule.
            - Rules can be recursive:
rule3(ground).
rule3(In)―anotherRule(In, Out), rule3(Out).
        - Lists
            - [1,2,3,4]. [H|T], [1,2,3|T] works too. Also [1 | [2,3,4]]
        - Remember try to read declaratively, so read: ```php
last([H], H).
last([H|T], W) :- last(T, W)
```as last with [H] gives H. Last with a list with a head and a tail should give the last value of the tail. 
        - Don't use OR's i.e. semicolons, instead write the two rules separately:```php
R(a,b) :- X(a) ; Y(b) // no, because its too much like imperative programming
// Instead::
R(a,b) :- X(a)
R(a,b) :- Y(b)
``` 
        - Don't think true or false, think succeed or fail - i.e. Prolog will go off and try and find some unification of variables such that the query succeeds - not true or false. 
        - Unification: 
            - Note that 1+1 doesn't unify with 2 - consider what would happen with 1+x, what would that unify with? "is" is specially purposed to have the side-effect of doing arithmetic.
            - X \= Y - tests if X will not unify with Y.
    - **Lecture 3**
        - Arithmetic: 1+2 is just infix notation for the compound term, +(1,2). So 1+2 **does not unify **to 3. 
        - The **is **operator: 
            - To do arithmetic we must use the **is **operator,  1+2 is 3. This is a ... with a side-effect.
            - We **cannot have **non-constants in the right-hand term. 3 is B+2 fails. 
            - **NOTE: **only the right hand side gets mathematically evaluated.** So 1+1 ≠ 1+1.** 
        - Using arithmetic we can write things like: ```php
 len([], 0).
 len([H|T], L) :- len(T, K), L is K+1.
```This says, find the len of a simpler list and then come back - and we'll add 1 to that answer and continue. 
Note that with this is construction, we need to remember to come back to it and so our stack space grows linearly. To solve this we could use an accumulator which uses O(1) space: ```php
 len([], 0).
 len([H|T], Acc, Result) :- B is Acc+1, len(T, B, Result)
``` ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vrYLqC0eXQdUNIsQ1TWbhQkydlV55PeheQgh6EVGp-RMtk3jiFek48wE2NdIO8NQV1bzrpaiunwTQrPLgYvqITheaHsdf42K6snwZZPrM-dpOWp1cgO3lxeMZse8OK2t.png) 
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/B5Y9LoMVqmV7Vi852HaGnD07TznN0_iA-ly2MmZKWrYrkfwO7uEp2XmPokEnp3X7YGm2NYh8yCPHPSWDC_Mpof3HVFVB9ikczXSbH-xdsgWoDZTKXbVYl4hH1ZAGVrah.png) 
        - Last Call Optimization
            - If the last clause of a rule is a branch, we can forget we were ever interested in the head at all. I.e. there were no other choices, so Prolog will never have to backtrack to test those other choices!
            - Can only do this if the rule is determinate up to this point.
            - Note that last call optimizations and accumulators are distinct concepts - for example the following code will be last call optimized: ```php
 last([L], L).
 last([_|T], L) :- last(T, L).
```As there is no reason to backtrack if last(T,L) fails - we'd have no other choice anyway.
**However: **Accumulators are the only way of finding out what your answer actually is, rather than just finding out if your input fits the mold 
        - Generating a list:
            - ```php
bigList(0, []).
bigList(N, [_|T]) :- M is N-1, bigList(M, T).
```
        - Backtracking:
            - Prolog searches depth-first left to right.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fWGF4FkXHtnFdkxkyh0G0cXeBiPTbDnHo35JqKV30wUClLp6nb5w-DS_axzTYojkXQrWjd0uTLzEdbNLzWhn-Ho1QsFuwKdcOSfzIr2O-DH8UDO_FWgSRCadxvOesPYX.png) 
        - Code for taking values from a list```php
take([H|T], H, T).
take([H|T], A, [H|B]) :- take(T, A, B).
``` results in 1, [2,3] ; 2, [1,3] ; 3, [1,2].
        - When take backtracks, it needs to undo the variable binding that came from the first successful run. We leave a trail of choice-points where we need to backtrack from and work off of. 
        - Note, for > **both sides need to be ground terms. **So we can't do N > 3 if N is a variable. 
        - Comments syntax:
            - + in front of a variable means you expect it to be instantiated - if it's not then all bets are off.
? means you expect it to be a variable or instantiated - note that if you don't instantiate it, Prolog will just go off and do the computation and then unify it with what you gave at the end.```php
 // % len(+List, ?Length)
 len([A], 1).
 ...
```
        - 
    - **Lecture 4**
        - Permutation Code:
            - ```php
perm([], []).
perm(L, [H|T]) :- take(L, H, R), perm(R, T).
```
            - We repeatedly take an element of L, and then perm the rest.
        - Dutch Flag implementation, using the **Generate and test paradigm**: 
```php
take([H|T], H, T).
take([H|T], X, [H|T1]) :- take(T, X, T1).
perm([], []).
perm(L, Perm) :- take(L, X, Y), perm(Y, S), Perm = [X | S].
dutch([blue]).
dutch([X | [Y | T]]) :- X=Y, dutch([Y|T]).
dutch([red | [white | T]]) :- dutch([_|T]).
dutch([white | [blue | T]]) :- dutch([_|T]).

dutchFlag(L, Perms) :- perm(L, Perms), dutch(Perms).
``` 
        - Eval implementation: ```php
eval(plus(A,B), C) :- eval(A, X), eval(B, Y), C is X+Y.
eval(times(A,B), C) :- eval(A, X), eval(B, Y), C is X*Y.
eval(A, A).
``` 
Consider evaluating plus(1, times(4,5)) Note that the second possible answer will error, this is because the value times(4,5) will be input to the C is X+Y - which is an error.
Instead we could wrap our query and answer in some gnd term - this **makes our clauses orthogonal - **i.e. we separate our clauses by cases:```php
eval(plus(A,B), C) :- eval(A, X), eval(B, Y), C is X+Y.
eval(times(A,B), C) :- eval(A, X), eval(B, Y), C is X*Y.
eval(gnd(A), A).
``` 
Note: This now requires plus(gnd(1), times(gnd(4), gnd(5)). 
        - Note that this evaluation can be used to add function support. We can flatten an ML function and then eval it after generating the right rules.
        - Prolog does not lack functions, ML functions can always be converted to the equivalent prolog query. Prolog is Turing complete.
        - DONT USE CUT! 
        - 
    - **Lecture 5**
        - Cut 
            - ! - stops Prolog from going backwards from it's current decision, pruning out portions of the search tree. This **only occurs when we cross the cut! ** Note that cut only effects it's parent choice point and the current rule being carried out.
            - A green cut is a cut which simply improves execution speed without changing the logic of the program.
            - A red cut changes the logic of the program.
            - The Danger of cut: 
                - Consider: ```php
 a(1).
 a(2) :- !.
 a(3).
 
 b(X) :- a(X).
 b(4).
```
                - a(Y). will give Y=1; Y=2; 
                - b(Y). will give Y=1; Y=2; Y=4;
                -  _a(3). Will give true!!! _ This is because the unification occurs **before **the cut. 
                - The issue being, all of these queries rely on understanding the Prolog execution strategy - the logical query "**Tell me the Y's for which a(Y) is true**" no longer gives the 'correct' answer because If I asked "**Is a(3) true?**" Prolog would contradict itself and say it is.

This creeps up on you in larger programs.
        - Negation
            - Failure using cut : ```php
 foo(A,A) :- !, fail.
 foo(_,_).
``` This fails if A unifies with A and succeeds otherwise.
            - Negation by failure: ```php
 not(A) :- A, !, fail.
 not(_).
``` If A is true the clause will fail and we cannot backtrack.
            - \+A means not A
            - Negation is dangerous! not(expensive(Restaurant)) will always fail - Prolog will find an expensive restaurant and then fail!
        - Databases in Prolog
            - ```php
tName(mro31, 'Malachy OConnor').

tGrade(mro31, '1A', 2.1).
tGrade(mro31, '1B', 1).
tGrade(mro31, 'II', 1).

// Gets all the names
filter_name(N) :- tName(_, N).

// Get all the grades given a name

get_grades(Name, Y, G) :- tName(Crsid, Name), tGrade(Crsid, Y, G).


``` 
        - The **Search Tree **interpretation of Prolog execution, the tree formed is a runtime stack - this tree exists in space but never in time! Parts of the stack will be whittled down and reformed overtime.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5sneLaR5pDg_AJ_FGpbh8aXkzTmJ-TJkkH1VtIrjRAAKhEjoPr8qKgNca1hdCe2gGj6z9v30QUlNMbtpZ2H-IPAkfRKdOwa3uE8QQ15QLe522WLfSYIgTUqR8SgDIRwr.png) 
    - **Lecture 6** 
        - Countdown game
            - Select 6 numbers out of (25, 50, 75) and (1,1,2,2,...,10,10) - get as close as possible to a randomly chosen 3 digit number using ( +,-,*,/ ).
            - Strategy: Maintain a list of arithmetic terms, each "iteration" check if the result is on the head (if it is halt) then pick two of the elements of the list and combine them using arithmetic operations and put the result on the head.
            - My solution: ```php
combinations([A | _], [A], A).
combinations([H | T], [Y-H = R | Mem] , R) :- combinations(T, Mem, Y), R is Y - H.
combinations([H | T], [Y+H = R | Mem] , R) :- combinations(T, Mem,  Y), R is Y + H.
combinations([H | T], [Y*H = R | Mem] , R) :- combinations(T, Mem, Y), R is Y * H.
combinations([H | T], [Y/H = R | Mem] , R) :- combinations(T, Mem, Y), R is Y / H.

:-  perm([125, 100, 75, 100, 6, 3], List),
    combinations(List, S, 300), 
    print(List),nl,
    print(S).
```This is inefficient, as we simply generate every possible permutation to solve the inherent issues with the method (i.e. we should be choosing one item and testing the effects of combining that, not all the effects of combining a permutation).  A better solution would use choose.
        - Choose implementation: ```php
choose(1, L, [X]) :- take(L, X, _).
choose(X, [H|T], [H|B]) :- X>1, Y is X-1, choose(Y, T, B).
choose(X, [_|T], B) :- X>1, choose(X, T, B).
``` Took me a while, but is just a case of choosing or not choosing the head (being careful to not decrement the amount to take when you don't choose the head AND being sure that we can't choose 0 of something and that only the choose 1 rule is used when we wish to choose 1).
        - Iterative deepening 
            - Iterative deepening is having some D generated using range() and iterating through that D, allowing a greater distance from the correct answer if no answer with 0 distance is found. 
        - 
        - Not Provable operator:
            - \+ Goal succeeds if the goal cannot be proven, and fails otherwise. Similar to not. 
        - 
        - Graph Searching
            - First we just label each opening in our maze with a vertex, then encode **some **transitions as vertices: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VKN1iTbbEFM9GpAc_YMKrr6rUWEA8zLr7gCeF6P-8_CyDvzoAHXY7dIGD6UmCGIKxDkP9YcAzhFDNgp3iowboFe5WFlOsuyKjm1ynMUK5FN0WaOvJQiHmgMG7kMFIRuU.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gLmnGw_LCMoUTZVnyaBcPZpR-SiJS-ylAp046MxRPN5rvMwvQlpfcggUzuD4uLAT8VzlPfot9Fc1LQnKd-Fsr9txYmko96W7jFg4QZQ6zvTGF5j166OoAOy6K3oPpW-2.png) 
Note that we only choose the ones that we can reach that haven't been reached already, minimizing the number of vertices.
            - Now we can draw our vertices and edges as a graph.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xxg3SB5kA3O7fGK_1wvShsW2LLvwk3z2pmFRAJ0Xemp3RTRZnnLDj-znn-c4O-ae3ORBtNdZe99kcliS1k5KESK54uer02QYD_UpgFlSg2x3jdCYWFCpji7UaDPezmgT.png) 
            - We define this as: ```php
 route(a,g).
 route(g,l).
 route(g, f).
 route(l,s).
 route(a,b).
 route(b,c).
 route(b,h).
 route(c,d).
 ...
 travel(A,A).
 travel(A,B) :- route(A,X), travel(X,B).
```
            - What if we have a cycle in our graph?
                - We can simply add a list storing all the nodes we've been to, and check for membership before we travel to a node.
        - 
    - **Lecture 7**
        - Difference Lists
            - First note that the usual method for defining append is O(N) in space and time. Instead we'd like to append without copying:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_qcs22klGdOGRJBlukaFkNxN_rZMKxvbkpOUOf5zdXFHhbBDfWcess8xcyx3ZiZj7_Ll44Yk-5lxYmrdokEGJLiTX_pLjxiEcf2MPS5JcOQTZmAcoijgwfU87H-TzmFP.png) 
We can do this by making our lists have a spare variable at the end, when we want to append we simply append that variable to the second list.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mCBfB1cLpHyhHtnZ385xFlJMMa4NLdoXjyya-qYON_j9FHU-fkgQUMFlmBnqsl4jHgsQXUprmxvyI5789aE3kwJg8neVzsDpyvRzIYziSOZWRG3-2hv2ahRZFQGjeosc.png) 
We can use the syntax $$[1,2,3 | A]$$ 
            - The resulting clause for combining two lists is (Where the T's are pointers to the variable at the end):
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Aee4NYU-eDiAN5SCI6r4joCOp_L4Fg072Ztexnemh_jrgqTNFNzCeUgP7Zj3OzC_NeZHFQ28GvtAFR0WFo0jzJLkNrEQb2JS5YL2nvr2RP5YS386LC7Aw1OiUnAKjb12.png) 
This can then be simplified by rewriting L2 as T1 everywhere then L3 as L1... resulting in: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3zE0JRZHvDKPaLgk8GMInKaF9_wdeBTqrOCwvsC1nbPkJyDXcF_lzQZd1Mi4lnImylyRT6I2jbGtjuDKGcRgmrCK8LO6XTkOM0_Ve8M5qh2nkGjR3p4NlLPr3In1Qlpl.png) 
            - We can then form compound terms to represent that the arguments are related (The minus symbol could be any number of different symbols):
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gjAclqBQGngK26Q3Q8gupLHuFcWrNMiaxtJeJWVPK6t3XS2iLVnYswBilWrUqbX74KYH3P7_peoF-CHKpnahDql66iUj2XwmH5JtLq6Y1dR3W9keRKIvcvKfqD1ZXUcB.png) 
            - When writing code  with difference lists, first write it without difference lists and then rewrite that code to include them. Then rewrite and finally simplify using substitution.
        - Empty Difference lists 
            - An empty difference list would then be represented as A-A. 
            - If we try and unify an empty list with a non-empty list, we find that we get an infinite nesting: $$A-A = [1,2,3|B]-B$$
We've matched A such that it contains itself - resulting in [1,2,3|[1,2,3|...]] 
            - Note that if we **ever **try and match an empty list with a non-empty one, prolog will find that that is possible and happily return an infinite term! So for example if we're trying to find the length of a diff list: ```php
 len(A-A, 0).
 len([_|T]-T1, N) :- len(T, M), M is N-1.
 
 :- len([1,2,3|A], X).
``` This will immediately return an infinite term and 0, as the first rule will be matched with successfully.
            - Solutions: 
                - Grounding our difference list: ```php
 len([]-[], 0).
 len([_|T]-T1, N) :- len(T, M), M is N-1.
``` This will match the final variable with [] successfully, destroying our difference list (the final variable can no longer be unified with anything else). This is a destructive but working solution.
                - Forcing an occurs check: ```php
 len(A-A1, 0) :- unify_with_occurs_check(A-A1).
 len([_|T]-T1, N) :- len(T, M), M is N-1.
``` This checks if the unification works, while ensuring the first variable doesn't occur in the second.
                - ALWAYS force an occurs check, set a prolog flag which ensures we always do this occurs check: ```php
 set_prolog_flag(occurs_check, true).
 // Note: can also do this, which throws an error when an occurs error is found
 set_prolog_flag(occurs_check, error).
```
        - 
    - **Lecture 8**
    - 
    -  _Supervision Work_   
        1. Question 1 
            - 2)```php
|tree(tree(tree(1,2),A,B),tree(C,tree(E,F,G)))   
|tree(C,tree(Z,C))

Unify C with tree(tree(1,2),A,B) resulting in:

|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(E,F,G)))   
|tree(tree(tree(1,2),A,B),tree(Z,tree(tree(1,2),A,B)))

Unify Z with tree(tree(1,2),A,B) resulting in:

|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(E,F,G)))   
|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(tree(1,2),A,B)))

Unify E with tree(1,2) resulting in:

|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(tree(1,2),F,G)))   
|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(tree(1,2),A,B)))

Finally unify F with A and G with B. Resulting in:

|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(tree(1,2),A,B)))   
|tree(tree(tree(1,2),A,B),tree(tree(tree(1,2),A,B),tree(tree(1,2),A,B)))
```
            - 3) Either it violates the contains check, that is A is contained in a(A) so cannot be unified with it, OR it could produce a unification where A becomes a(a(a(a(...)))) where the two terms are unified to be the same infinite term.
            - 4) When Prolog unifies a variable with a ground term, you can say it has found the type (in this decision branch) of the variable.
        2. Question 2 
            - 1) ```php
house(Nationality, Pet, Smoke, Drinks, Colour).
(H1, H2, H3, H4, H5).

exists(A, (A, _, _, _, _)).
exists(A, (_, A, _, _, _)).
exists(A, (_, _, A, _, _)).
exists(A, (_, _, _, A, _)).
exists(A, (_, _, _, _, A)).

rightOf(A, B, (B, A, _, _, _)).
rightOf(A, B, (_, B, A, _, _)).
rightOf(A, B, (_, _, B, A, _)).
rightOf(A, B, (_, _, _, B, A)).

middleHouse(A, (_, _, A, _, _)).
firstHouse(A, (A, _, _, _, _)).

nextTo(A, B, C) :- rightOf(A, B, C) ; rightOf(B, A, C).

        % Generate candidates
:-  exists(house(british,_,_,_,red),Houses),
    exists(house(spanish,dog,_,_,_), Houses),
    exists(house(_,_,_,coffee,green), Houses),
    exists(house(ukraine,_,_,tea,_), Houses),
    exists(house(_,snails,old_gold,_,_), Houses),
    exists(house(_,_,kools,_,yellow), Houses),
    exists(house(_,_,lucky_strikes,orange_juice,_), Houses),
    exists(house(japanese,_,parliments,_,_), Houses),
    exists(house(WaterDrinker,_,_,water,_), Houses),
    exists(house(ZebraOwner,zebra,_,_,_), Houses),
        % Test candidates and then backtrack
    rightOf(house(_,_,_,_,green), house(_,_,_,_,ivory), Houses),
    nextTo(house(_,_,kools,_,_), house(_,horse,_,_,_), Houses),
    middleHouse(house(_,_,_,milk,_), Houses),
    firstHouse(house(norwegian, _, _, _, _), Houses),
    nextTo(house(_,_,chesterfields,_,_), house(_,fox,_,_,_), Houses),
    nextTo(house(norwegian,_,_,_,_), house(_,_,_,_,blue), Houses),
    print(ZebraOwner), nl,
    print(WaterDrinker).
``` 
            - 2) exists(house(spanish,dog,_,_,_), Houses)
            - 
            - This generates a candidate house where the occupant is spanish and owns a dog - the composite data-structure Houses previously generated must then be unified to contain this house.
            - 
        3. Question 3 
            - 2) ```php
last([1,2], A).
last([L], L).
last([_|T], L) :- last(T, L).
``` 
            - 3) ```php
append([],A,A).
append([H|T],A,[H|R]) :- append(T,A,R).
``` This should be used to append to lists, the second argument is appended to the first one. This is done by first moving all the items from the first list into a storage list, and then adding the second list to that storage list all in one recursive call.
            - 4) ```php
member(H,[H|_]).
member(H,[_|T]) :- member(H,T).
// or, alternatively
member(X,Y) :- append(_,[X|_],Y).

append([],A,A).
append([H|T],A,[H|R]) :- append(T,A,R).
```
                1. If you view the prolog term append as a "function", one could view this as a partial application as only the 3rd "argument" is specified. However it differs in that the "result" of the "function" is specified which you would not usually be able to do - additionally you would end up with a **new **function with one fewer arguments under partial application, while here you end up with a true or false statement.
                2. While the result would be the same, this would make the code far less readable. 
                3. The first implementation is last call optimized, we can repeatedly tear the head off without needing to come back down the stack frame - meaning we only need a single stack frame. In the implementation of append however, we tack on the head to the result when the nested call to append returns - this means we need to keep track of the values we're going to append in the stack frame. So the stack frame grows in order O(n).
The second implementation does have the advantage of using one less rule.
                4. The first list asks if a value H is at the head of the list, if not then it asks if the value H can be found in the tail of the list. Clearly if H is not in the list this will fail, and if H is in the list it wiwll eventually be at the head of the list to be checked and thus member will succeed.
The second implementation asks if there exists two lists, where the second list has X at the head - such that the two lists appended together results in Y. If X is not in Y, this will clearly not be possible but will always be possible if X is in Y. 
So they both only succeed if their second argument is in the list, hence they are logically equivalent.
            - 5) This checks if a list is sorted in ascending order. We are first given a list to check, we then repeatedly check if the first item in the list is smaller or equal to the next.
            - 6) ```php
b(X,X) :- a(X).
b(X,Y) :- append(A,[H1,H2|B],X), H1 > H2, append(A,[H2,H1|B],X1), b(X1,Y).
```
This sorts an input list. It does this by repeatedly finding a point in the input array where two items in the array are out of order - and then correcting that order. 
        - 
        4. Question 4 
            - 2) Last call optimization is used a branch is only generated in the last portion of a rule, meaning we can know we never have to return to that rule and perform any further calculation - using this fact Prolog does not need to hold onto the stack frame and can simply call the last rule.
            - 4) ```php
// Applies X s( _ )
apply(0, M, M).
apply(X, M, s(R)) :- X>0, Y is X-1, apply(Y, M, R).

prim(X, R) :- apply(X, z, R).

plus(z, B, B).
plus(s(X), B, s(R)) :- plus(X, B, R).

mult(s(z), B, B).
mult(s(s(A)), B, R) :- mult(s(A), B, R1), plus(R1, B, R).
```
            - 5) 
One can always reverse it using the following code or similar: ```php
count(z, 0).
count(s(X), R) :- count(X, R1), R is R1+1.
```
            - 6)
Simply reverse using the above code. Think I'm missing something in this question, it does specifically make "prim" reversible.
            - 7)
1+1 = 2: False, the equals operator does not perform arithmetic - it simply tests to see if the two clauses unify and 1+1 cannot unify with 2 as there is a + separating 1+1.
1+1 is 2: False, is does perform arithmetic but only on the right side - so the 1+1 does not get evaluated.
1 + 1 =:= 2: True, this arithmetic equal performs arithmetic on both sides - but only works with numbers.
One + One = Two: Two = One+One, this unifies when the variable Two has the value One+One.
prim(1, One), prim(2, Two), plus(One, One, Two): One = s(z), Two=s(s(z)), this simply generates primitives for One and Two and then verifies that 1+1=2.
            - 8)
Consider : ```php
 :- prim(3, Three), prim(2, Two), plus(A, Two, Three).
``` We in effect say 3 is 2+A, solve for A. The difference is 
            - 9) ```php
// Without last call optimization
fact(0, 1).
fact(X, R) :- X>0, Y is X-1, fact(Y, A), R is A * X.

// With last call optimization
fact(0, Store, Store).
fact(X, Store, R) :- X>0, Y is X-1, R1 is Store * X, fact(Y, R1, R).

factLastCall(X, R) :- fact(X, 1, R).

// One test to the accuracy would be to observe the ram usage by the two programs during a computation
// A slightly unorthadox method is to first remove the failsafe clauses X>0 :

fact(X, R) :- Y is X-1, fact(Y, A), R is A * X.
fact(X, Store, R) :- Y is X-1, R1 is Store * X, fact(Y, R1, R).

// And then request:
:- fact(-1, Y).
// and
:- factLastCall(-1, Y).
``` 
I found that the non last call recursive version failed in a few seconds reporting:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aG04O-otXj6aytOUF5heispisnNEywihUhVIvnadHwpi6w4iZzhtHXA7Qtcx91Jb8lMAIwU0IoJkbgZNHZSJ6IwcFRZFUUIzH7ll6WZ4rcVPiAWOrXKsWd92NziWEuVF.png) 
While the last call recursive version would happily continue for a lot longer, with the terminal window I was using still using a constant amount of memory while I was watching it:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Xn_4zpEMTEs6VbDCAMCy6Za_bEQzEVfLxLhhquq-iANK_JO0tS7TCnRQ62huJRtmuNBttLwbTvb_31HY6v9SBeQcBGOu71tJR6-HhvCUhZmUIMssdrK0_MCmgBw7PhpV.png) 
        - 
        5. 
            - 1)```php
len([], Acc, Acc).
len([_|T], Acc, R) :- B is Acc+1, len(T, B, R).
len(I, R) :- len(I, 0, R).

len(X, 3)

// First we try the first rule and it fails (0 != 3)
// Then we insert a blank into the list we're generating and
// add to the accumulator, we'll then try the first rule and find
// 1 != 0. This will repeat, finally resulting in [_,_,_]
```
            - 2) ```php
take([H|T], H, T).
take([H|T], A, [H|B]) :- take(T, A, B).

take(Y, 1, [2,3]).
// First it'll match with the first rule and return [1,2,3]
// Then it'll match with the second rule and match:
// 1 with A, 2 with H, [3] with B

// Then it needs to prove take(T, 1, [3])
// This will first match with the first rule returning [1,3]
// resulting in backtracking and a new result of [2,1,3]

// For the next value we need to match take(T, 1, [3]) with the second rule
// Resulting in A=1, H = 3, B = []
// The first rule is the only option (the second would fail)
// And we get [2,3,1]

// This gives all the lists you could take 1 from and have [2,3] left
// over
```
            - 3) ```php
append([],A,A).
append([H|T],A,[H|R]) :- append(T,A,R).

append(X,Y, [1,2,3])
// Just from looking at it you can guess it's going to output:
// [], [1,2,3]
// [1] [2,3]
// [1,2] [3]
// [1,2,3] []

// This is because the head will be torn off the input list,
// appended to X and then the first rule will come into effect.
// This will happen again with another item being torn off the head
// and so on.
```
        - 
        6. 
            - 2) ```php
dutch([blue]).
dutch([Y | [Y | T]]) :- dutch([Y|T]).
dutch([red | [Y | T]]) :- Y=white, dutch([Y|T]).
dutch([white | [Y | T]]) :- Y=blue, dutch([Y|T]).

dutchFlag(L, Perms) :- perm(L, Perms), dutch(Perms).
```
            - 5) ```php
 anagramGenerate(Word, R) :- perm(Word, R), Word \= R, word(R).
```
            - 6) 
        - 
        7. 
    - Assorted Flashcards
        - What is the FOL expression for ```python
 not(X), case(X).
 and:
 case(X), not(X).
```
- Security
    - 
    - **Lecture 2**  (File system security)
        - What is POSIX?―POSIX is a standard, describing unix-like operating systems.  
        - Supervisor mode 
            - What stops a normal user simply executing the same machine code commands as a root command?―Processor level support for determining privilege mode of operation. So 1-bit is set to decide if the processer is in supervisor mode or real mode.
        - Discretionary access control 
            - What is the bell-lapadula security policy?―Subjects and objects have a classification level, can read any objects at their security level and below bue cannot write to objects at a lower security level. 
**Write up, read down.**
            - Discretionary access control is where the creator of the file decides who can access the file.
            - This could be done by deciding for every user and ever file who can do what with the file. However, the resulting massive matrix is undesirable - thus instead users tend to be grouped.
            - In POSIX, what are the 3 user groupings? ↓ 
                - The owner of the file
                - The members of the files group
                - Everyone else
            - POSIX associates all users with an {{integer ID internally,}} where the administrator has {{id 0}}. The admin can create {{new users}} and impersonate {{other users}}. Furthermore, groups are {{named sets of users with integer IDs (internally)}}. Each user is associated with **at least **{{**one primary **}}{{group }}(listed in {{etc/passwords}}) and possibly more (listed in {{etc/group}})
            - The unix command id displays the current user, and the groups that user is a member of.
            - Each file has an owner and a group.
            - A directory is a special file that stores a mapping between file names and iNodes. Inodes contain pointers to the disk regions containing the contents of the files and metadata.
            - The same inodes can be pointed to by multiple directories. And thus the same file can be known under different names - these names are called **hard links **and can be created using **ln.** 
            - Permission bits 
                - An important piece of metadata stored in the Inode are the permission bits. These are 4 triplets - these sets of 3 bits are often represented as octal numbers. These bits represent **the user, the group **and **others**.  
                - r if you can read the file, w if you can write to the file and x if you can execute the file. If you have the permission the letter will be displayed.
                - For a directory, the permissions are subtly different - how?―r means you can list the files in the directory. w means you can add/remove/rename files in the directory (if you can enter the dir). x means you may access the metadata in the inodes and access the contents of the files (can see permissions and length of files) - e.g. you can enter the directory (execute it). 
                - How do you change permissions of files?―Using chmod. To add read permissions to user (u), group (g) and other (o) you can do :```c
 chmod go+r photo.jpeg
 chmod ug+r, og-w something.jpg
 chmod u=wrx, go=r code.py
 
 chmod 664 photo.jpg
 // sets user, group and other permissions using octal
     rwx
 6 = 110 | user
 6 = 110 | group
 4 = 010 | other
``` 
Chmod **only works** if issued by the owner of the file. It can also be executed recursively on a directory using -R.
            - OS permission check 
                - How does the OS compute permission checks? ↓ 
                    - First, if the command comes from root it is automatically allowed. 
                    - Then the OS decides which of the 3 triples applies (user, group and other) - it only checks that triplet (EVEN IF THE GROUP TRIPLET YOU'RE IN WOULD GIVE YOU MORE RIGHTS)
            - How do you change the file owner/file group?―chown bob:staff potato 
Sets the owner of potato to bob and the group to staff. **Note: **Only the owner can change the group, and only root can change the owner. 
            - What does the su command do?―This allows you to impersonate another user. su bob, opens a new shell under that user.
            - How do you list permissions?―ls -la
            - What is the principle of least privilege?―Every program and every privileged user should operate with the lowest level of privilege possible.
People who have root access use sudo, only using the privilege when necessary.
            - Describe setuid, what it's useful for and how it works.―setuid is used for more fine grained access controlled for users. The linux access controls don't generally allow you to say a user can only read/write a single line in a file.
setuid() sets the **effective user ID** of the process being called - unprivileged process can only set that to the real ID of the caller, otherwise **the effective ID is set to the ID of the file owner**. 
            - What does umask do, how do you use it and when would it be used?―This allows you to change the default file permissions. umask 022 means you disable write for group & other. It would generally be used in a startup file.
            - What are the default file and directory permissions?―666 are the default permissions for files, rw but no e for all. Directories get 777, everyone can do everything.
            - What is the sticky bit? ↓ 
                - For files -  this marks frequently used executable, to keep them in RAM rather than have them in secondary storage (more useful in the past).
                - For directories - the sticky bit handles shared directories. Consider, if Bob has w & x permission he can delete/rename Alice's files. The sticky bit means Bob can only access files he owns.
            - 
    - **Lecture 3 **(Insecure Programs)
        - Attack Surfaces 
            - The attack surfaces describes all of the points an attacker could get into a system and where they could get data out.
            - find -L -uid 0 -perm -u=s -type f
            - What is stored in the etc/passwd file?―The user name, either a hash of their password or an x indicating their passwd is in etc/shadow. Their UID and GID, a comment field, the home directory and the login shell they use.
            - What's stopping you from putting a newline in chsh and creating a new user with UID 0―chsh is prudent enough that it only allows one of the inputs listed in etc/shells.
            - What is the attack surface of this program and what could you use it for? ```c
#include <stdlib.h>
void main() {
	system("ls");
}
```―The path the program is executed from. To make use of this program you could simply change the path to somewhere you can access, create another "ls" program that performs privilege escalation and then run this program. As it only runs ls in a console.```c
 export PATH=.:$PATH
 ./demo-ls
```
            - What could you do for this program: ```c
void main(int argc, char* argv[]) {
	char command[80];
	sprintf(command, "/usr/bin/cat %s", argv[1]);
	system(command);
}
```―They've used the countermeasure of specifying a directory (with a space after the cat so you cant simply ../).  However as system just uses the command line, we can simply do : ```c
 ./catprogram testing.txt;sudo /bin/sh
```
            - A huge amount of attacks are possible when an attacker can trick a program into interpreting data as commands. 
        - Environment variables 
            - What is dynamic linking?―Dynamic linking is the alternative to static linking - in which libraries are included in the binary. In dynamic linking, the libraries are found in your filesystem at runtime and linked with the rest of the executable. This allows for easy updating of libraries and reduces the size of the binary.
            - There are environment variables that allow you to manipulate the dynamic linker. LD_LIBRARY_PATH, LD_PRELOAD sets a list of programs to be loaded first (whether the program requested them or not). These are commonly used for debugging without having to recompile - however we could clearly add arbitrary code. Therefore, these paths can only be set if the effective uid is the same as the real id.
            - 
        - 
    - **Lecture 4 **(Buffer overflow)
        - Memory arrangement
            - When you declare two variables at once, c is not obligated to place them next to each other in memory - it could insert gaps, swap them etc.
        - Stack frame x86
            - In what order do we push items into x86 stack frames?―First we push the parameters of the function in reverse order - so when we read **up **in memory, we encounter the first parameter first etc.
Then we push the return address.
Then we push the previous frame pointer
            - What do the stack pointer and frame pointer point to?―The stack pointer points to the very bottom of the stack. Even below the local variables of the final stack frame.
The Frame pointer points to the "bottom" of a stack frame, above any local variables of the function. I.e. it points to it's own location, remember it is used to provide an offset **that doesn't change**.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0vBJgDfKrJ6vU233zvrDj_Hb8uqx_QLMUEVXbmFxS3oJR47aylkeUEGMcKWn8lszyQoRyCDlvwVJrdActcGM3dzVU-Adzynj6asonYpmeccez2RaRexYDWA31VzUM4f1.png) 
            - How does a buffer overflow (which executes code) work?―First you overflow a buffer in the stack and smash the stack. This overflow must flow into the return address of the stack frame.
Then the return address must be overwritten to point at some machine code payload which will be executed.
        - NOP Sled 
            - What is a NOP sled?―A NOP sled is used in a buffer overflow attack and contains your malicious code followed by a number of NOP commands. A NOP command simply "does nothing" and then moves the Next instruction register up by 1.
These mean you don't have to point to the exact location of your payload - which is good because we don't know exactly where in memory it'll end up.
        - Stack spraying 
            - What is Stack spraying?―This is a method for dealing with uncertainty about the structure of the stack frame - to combat this you overwrite all the registers in a range where the stack pointer could be.
        - Countermeasures 
            - Languages other than C or assembler will do bounds checking. 
            - What is the Stack canary approach?―Defender stores a special marker between the local variables and the return address. Then when the function returns, check if the marker has been changed.
This is made more difficult for the attacker by making the canary a random value.
            - A shadow stack is―a method of keeping two stacks and keeping them in sync - then comparing them to see if they are the same.
            - What is ASLR?―Address space layout randomization. Randomly allocate the start segment of everything in memory.
Aren't that many bits of entropy available, so brute force is feasible.
        - 
    - **Lecture 5 **(Return to libc)
        - What does disabling stack execution disable?―Stops you from putting your shellcode in the stack to be executed, you'd have to point to executable code elsewhere.
        - In return to libc, what do we change the stack frame to point to?―We point to something in the associated C libraries, like system. Which will run with the priviledge of the program. 
        - What do we need to find for a return to LIBC attack? ↓ 
            - Find the address of the required system call
            - Pass the intended parameters in the way the system call expects
            - (optionally) clean up afterwards to ensure the process doesn't crash afterwards
        - Structure of the stack 
            - Describe what happens on the stack when a caller invokes a subroutine (called the prologue)  ↓ 
                - First push the parameters to the function in reverse order. (note that every time something is pushed, the stack pointer is incremented).
                - Then when the caller invokes the function, the call machine code instruction pushes the return address on the stack.
                - The callee (the subroutine) then pushes the base pointer onto the stack - this points to the previous stack frame.
                - The callee then updates the EBP to point to that location.
                - Then the stack pointer is moved to accommodate the local variables.
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NMonqGB5ZInWgFwlSoFMg6wGao4QesD999MGcZAabagAqxzXXCdpzFtk8euFtFvL6fIc5aj8f-jD4woV9r_jU_gwyntUFeddJcVn1DnrbMEpL-SFru5UlXsKsAdxaGnu.png) 
            - Note in Intel opcode we have:
move **dest source** 
While in Unix we have
move **source dest** 
            - Describe what happens at the end of a subroutine (the epilogue).  ↓ 
                - First the base pointer is copied into the stack pointer. Effectively deleting the values below the base pointer. 
                - We then pop the previous frame pointer into the base pointer. (Which also moves the stack pointer up)
                - We finally call a return, which pops the return address into the instruction pointer. Transferring execution to that address.
            - In our soon to be smashed stack, we have the following layout:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/p9pMYFfdEBz87gIsyocaHXV6O1teTMiYxhNmkb6uporeohSknSwjuj434TD4OwsAVOSuV3lXmNGLJZgGohfVSMURydBUdF0al0P4o2VdHfDLxe3bmhd54_nogvax3HVZ.png) 
What do we need to put in the first 3 slots? ↓ 
                - We know we need the address of system() in the RA - that's how we're calling system. 
                - First note that when this function goes to return, the ESP will be popped into the EBP leaving:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PiEYEb2wMa0qULmXWHTZIapL3Cn2GI31n48f6Ev3BCsuFYwrIinVES9GZo0IMkRqg4Wd7zFVmO9rs_84w0yq-8M_HF62yII_Ldd5uDpXI6wRaiQp-O5fkm3gamrFBbwK.png) 
                - System has 1 argument, and will look for that at the top of the stack meaning in order to access a stack we need:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YgXeXTNHXY7TbxMNdLqfxlSGMGXLRA_7BCkMKMhTUAnVVnvxlsg8xa9V7ESIYpU387OwMt2VaTXY9naY5c1APJtMybXBdECE-NW9P_tJpcYN_um_eXKuxa0VJTZRTQbI.png) 
                - Finally **because system only takes 1 argument **it will look for the return address just below that. Meaning we need out exit() function there to ensure a seg fault doesn't occur: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/d-fvugakIsEo_xmImnPS2o09Q-RmW0J19UThoo_i4JQkAp-RBwO_Rq6jnP2bUGXybk7rn7U0Mk99uvRkpGVS119XWrCfzIvsfAIL1HvJl9U30rwt--64IT-qfvV5wSCj.png) 
        - 
        - 
    - **Lecture 6 **(SQL injection)
        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DjmnMJP99UvkuDeRxBlv0WoCLUeLhPDDoozX-icQrHdFovwXPDdpnw-Np-eOILIe7Tng1QVHGGrVEhgTT4X4gLTZTtjcZZzo-9tdrDQyvvc8pMbIGTgd8R6YLv0nucOD.png) 
        - The double hyphen space comments out the rest of the input.
        - How can we solve SQL injections―We can precompile the code sections, and leave space for what can ONLY be data - i.e. do no parsing on the code.
    - **Lecture 7 **(Passwords)
        - Authorisation 
            - 3 main factors Confidentiality, Integrity, Availability.
            - Authentication can be unidirectional or bidirectional (each proves their identity to the other).
            - The verifier should check something you know, have or are.
        - How do passwords work 
            - What are the underlying assumptions of passwords? ↓ 
                - No one but me knows my password.
                - No one can guess it.
                - The verifier can verify my password.
            - How are hashes used with passwords?―Instead of storing a plaintext password, store a hash of the password and check that each time. The hashed password is called a "digest".
            - How can an attacker use hashed passwords?―With a long list of hashed password, hash guessed passwords and match them to users.
            - If Alice notices Bob has the same digest as her, she can log into Bobs account.
            - Describe "salting" a password―When a password is created, a random string (a salt) is added on the end before hashing. Then the digest and the salt is stored in the passwords file.
This means the attacker would have to guess the password AND the salt (or try all salts with all passwords).
This helps stop lookup attacks, where the attacker runs through pre-generated hashes. For a salt of length k, the attacker must store 2^k more bits.
            - What is key stretching?―Using the hash function hundreds of times for each password - making cracking the passwords take hundreds of times longer.
            - What are lookup tables of passwords?―Massive lists of pre-generated hashes (without salts).
You can run through these asynchronously and tear through them.
            - What are rainbow tables?  ↓ 
                - They are a method of reducing the space complexity of storing loads of hashed passwords.
                - We have a hashing function $h : P \mapsto D$ (maps passwords to digests.). Then imagine some $r : D \mapsto P$ which maps digests to passwords.
However, it does so somewhat randomly - jumping somewhere else in the password space. 
                - We first generate passwords and digests in a large table, we then repeatedly apply $h$ and $r$ to a digests in that table. Resulting in jumps around the table. We compute l "hops" and store a start and end digest in our table.
                - We repeat that process until our table is exhausted.
                - Finally, when we encounter a password - we first check if its digest is in our new table (under the final digest column), If so we work forwards from the start digest to get the associated password.
                - If the password is not, we apply h and r to get a new digest and check that. We repeat this process $l$ times, and if we never find our password we know it was never in our original table! If we do identify the chain, we need to work forward from the start digest again
        - How passwords fail
            - Complex passwords. Passwords you don't write down. Passwords with upper and lowercase letters - each one defensible on it's own, but too hard for users when combined.
            - Users reuse passwords, so if any site gets cracked then their vulnerable on all other sites. Then results in needing users to use different passwords for every site - results in many passwords where we can't remember all of them.
            - How do online password attacks differ from offline attacks?―Online attacks are slower (need to send a request) and a large number of failed login attempts should alert an admin.
This points to the fact that admins should secure the password file, rather than imposing draconian rules on the users password.
        - Why passwords still with us 
            - What are moral hazards? How do they apply to passwords?―Moral hazards is when an actor increases it's risk factor because it doesn't bear the full responsibility of that risk. 
E.g. if a big company takes a risk, it'll get bailed out by the bank.
Passwords are easiest to deploy for a website, and they don't bear the usability issues of them. Marginal cost per additional user zero.
            - Issues of biometrics ↓ 
                - replay attacks.
                - Biometrics are not private. Need a liveness check (e.g. say this word, must makes it unsuitable for unsupervised login).
                - You can't change your biometrics, if they get leaked you're fucked mate. 
            - What's the problem with single sign on systems?―Usually not "single", e.g. we can use raven to sign onto cambridge systems - but need other services to sign onto other systems.
        - 
    - **Lecture 8 **(Cross-site request forgery)
        - Web Cookies 
            - In HTTP, distinct requests are independent. But we want to create sessions, were state is recorded. 
            - Cookies are stored instead, which record data about the user - also have a TTL. Then whenever the user makes a new request, the cookie is attached to the message (assuming the cookie has not expired).
            - However, if the server doesn't store any data - we can manipulate the cookie. e.g. Can we manipulate the price?
            - What is a sessionID, how does it relate to cookies?―A sessionID is a unique identifier for a session on the website. The server stores the session data and the **cookie **stores the sessionID. 
        - Phishing 
            - Describe HTTPS, how does it help against Phishing?―HTTPS is a transfer protocol that encrypts your communication and also confirms a website server is who they say they are. Via a certificate. So a fake hsbc-website.org would not have the HTTPS. 
            - Multi-factor authentication is another countermeasure.
        - CSRF 
            - How does a CSRF (Cross-site request forgery) attack work?―The attacker crafts a link which will send a request to their bank (for example) initiating a transfer into the attackers account. If the victim is logged in, then the login cookies will be attached and the transfer will go through.
You don't even need a link, could be a 0x0 pixel image in your email.
            - What's the difference between GET and POST? ↓ 
                - In a GET request, the values of fields are included in the URL e.g. 
GET https`:www.bank.com/get?amount=5&to=Charlie` 
                - In a POST request, the parameters are encoded as part of the request body of the HTTP request. You don't see it in the address bar.
Might just have the url `https://www.bank.com/pay-action-post ` 
            - Describe counter measures for CSRF ↓ 
                - The webserver could only honour requests coming from it's own site - however HTTP is stateless so they can't tell that. 
                - The browser **can **tell what website you're accessing a page from. So it uses the following Schemes:
                - The **referrer header**: Mention the website the user sent the request from. However, it is optional and is often disabled - can lead to false positives. 
                - The **same site cookie attribute**: Set an attribute to the cookies 
                - The **secure token**: Which can be implemented at the web application level - and can thus be deployed without waiting for browsers to standardize. Every web app would need to reimplement.
The server embeds a secret with every form, the attacker cannot see it as they haven't seen the form.
The timestamp is also sent, allowing the server to recompute the secret.
        - 
    - **Lecture 9 **(TCP attacks)  
        - Packet Sniffing 
            - The two endpoints connect to the network using a NIC, the physical medium is usually shared with other computers on the LAN. Usually the NIC would only accept the messages addressed to the NIC. But we can enable promiscuous mode which forwards all received packets at the NIC to the kernel.
            - The kernel can filter based on some criteria. This is written using BSD packet filter.  
        - Spoofing Packets 
            - Using raw sockets, we can write into the header. And claim a message comes from a different host.
        - SYN flooding 
            - Sequence of ACKS:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vQXz4GTquDH8p4bLn8vNk7C6uSqOUQPyK9bwcElvZBqEdY4MrAtXN8xUiICu9VUy5e3c_U6IcTWC4BV0sAYA6IUT0SSEwo1xeWb_spRwguOu1eavmhxmcT1OtwU6DdMM.png) 
            - Bob discards an ACK packet if it doesn't adhere to it's previously sent syn and ack values. The values of x and y are stored in a TCB by Bob - Bob resends the SYNACK a few time and finally deletes the TCB if he doesn't receive an ACC.
            - This list of TCB's is finite. So SYN flooding works by  
            - What is SYN flooding and how does it work?―It is a denial of service attack. It works by flooding a user with SYN messages (requesting to open a TCP stream) and for each one the victim will allocate a TCB (a transmission control block). When no more TCBs can be allocated, the attack has succeeded.
The attacker must spoof their address to ensure a firewall cannot stop them.
            - Describe the SYN cookie defence. ↓ 
                - This works by no longer allocating a TCB - defeating the SYN flooding attack.
Instead all the information is embedded in the ACK number of the final ACK sent by Alice. 
                - Bob simply makes the ACK he sends a function of the values in the packet (and this function is secret, only he can compute it) - using the source address, port number and sequence number  
                - Then when Alice sends a SYN packet, Bob would expect the y+1 value to match the computed value. So he simply runs the computation again and tests it. A malicious party cannot spoof this, as they do not know Bob's function.
            - Describe a different defence, without SYN cookies―We set aside some privileged space to store TCB's of hosts who have already connected to Bob in the past - so they are not affected.
So the attack only effects new hosts.
        - TCP Reset Attack 
            - Recall the usual way of closing a TCP connection:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Zfx8LiGQwk72Y_EMI_QMGUu5i_pGuevqD3v2rQO2WK6QwCe06McqnxFkYZaXyzv5GbBflwk_sReHZCLdzV3LqyjPVIWQm3EQswGTwhrzOyLNtXQBnxNiElcseO6p21tU.png) 
We can also reset.
            - What is a TCP reset attack and how does it work?―Alice sends a reset attack to Bob and spoofs the message as if it came from Dave.
She must fill in the correct ports, addresses AND sequence and acknowledgement numbers.
        - TCP session hijacking 
            - What is TCP session hijacking and how does it work?―We sniff the connection of an outgoing message and instead of replacing it with a reset - we send a new set of messages with correct ports, addresses, sequence and acknowledgement numbers AND we send a new command to Bob. 
E.g. if Bob is a fileserver, we send a command to delete a certain file.
        - 
        - 
    - **Lecture 10 **(Human factors in security)  
        - Users are not the enemy
            - Insufficient communication with users, results in unusable systems. 
            - Users forced to comply with securities incompatible with their usual work practises will look for workarounds.
            - The claim that users are never motivated to behave securely is wrong. Treat the users as stakeholders and they will provide feedback and usable security mechanisms. 
        - The Compliance Budget 
            - Users have a finite supply of goodwill (compliance budget) every act of following an annoying security policy will reduce that goodwill. Any further acts will result in the user constructing workarounds.
            - Manage the compliance budgets **wisely**. Harassing on many small security issues may result in the user failing to follow more crucial security requests. 
        - Prospect Theory 
            - How does your utility of moneye grow as your wealth increases.―The utility of money does not grow proportionally to the amount of money you have.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/e6ALH7tRr-Nsxh5ViavnOfLt99S6skZ74rWVvBHtG-xujH5Hq-m24Rlo9mJGNb5L1cxlXKwww-BdCCN33XM2BaiD7H48m3LeKQl4Uj9mdrOry7ARUWEWBtH9JYSIXmrJ.png) 
Instead it grows logarithmically.
            - What is utility theory?―Because you're utility of wealth grows logarithmically, the rational outcome of a question like:
$$\text{would you risk £100 to win £101?}$$ 
should be based on the utility of each outcome.
e.g. the increase in utility in winning 101 dollars is far less than winning 100 dollars.
So the expected utility is a loss.
            - Where does utility theory fall down?―People are often averse to gambling to secure a gain, but are willing to gamble to avoid a loss.
People are significantly more sensitive to losses. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3w2HtTbD3pdtLisfNi7EQyQErLZjD6XpMYqW9s6zwcta21rn8UNBcAQe4TkAqeIGvlra9-Mi3eMSirjc1h41ZIoC69yMyAlZYIvTO7OcroBs4lXDfk4MCnw1DHLDeZLt.png) 
        - Understanding Scam victims 
            - Scam barman by taking advantage of him scamming customer out of large reward. E.g. barman says the reward is £50 when it's £200. He advances the £50 and never hears back from the person offering it.
            - The dishonesty principle is―People are not likely to come forward to having being scammed, if they've acted dishonestly themselves.
E.g. Nigerian scams where they want you to help them launder money.
            - Need-and-greed - urgent cravings and greed used.
            - Time principle - the fact that an opportunity will disappear soon means the victim will use fallible heuristics quickly.
            - Almost all scams can be reduced to a handful of principles. 
        - 
        - 
    - **Lecture 11 **(Viruses, worms, Trojans and quines)
        - Malware 
            - Any software that will damage software or networks. 
        - Viruses 
            - A **virus **attaches itself to executable, and replicates itself affecting other executable. They lie dormant and eventually deploy a payload. 
            - Initially the antivirus companies looked for {{byte sequences}}. Virus writers started {{encrypting}} their virus code, hiding it differently {{at each infection}}.
Antivirus writers then look for the signature of the {{decryption engine }}- which needed to remain in plaintext.
Virus writers wrote polymorphic decryptors, which themselves are morphed.
        - Worms 
            - Worms doesn't infect executables, it simply sends copies of itself through the network. 
        - Trojans 
            - Propagates through some kind of social engineering - hide the software as something else and trick the user into launching it.
        - Spyware 
            - Sits on the attackers machine and logs data. Could log key presses, camera data etc. Usually designed to be stealthy.
        - Adware 
            - Malware that shows advertisements on your screen.
        - Ransomware 
            - Encrypts your file until you pay some ransom, at which point they decrypt it.
            - What's the order ransomware uses of keys to encrypt your files?―First it encrypts your files with a key, then it encrypts that key with the attackers public key.
It then asks the user to send the encrypted key to the crook, who promises to decrypt it.
        - 
    - **Lecture 12 **(Lockpicking)  
        - Pin tumbler lock 
            - Pins get placed in holes, key pushes up the pins to different heights. Driver pins pushed by springs above sit in the holes, and the pins force the driver pins to be flush above the barrel - allowing the key to turn the barrel.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2aqyZ4uNSflzGZCByGliHBHE7gbRhof5Jmkxq6o73EMYTEYOG9Efp8_5GPwMU6JlF_iobkhq68ryChi0zG8ovu9z97yecWpExRCp09L0ts_Ocpf-aNOA1IwJAwezORa2.png) 
            - Describe single-pin picking―We apply torque to the lock, and find the pin which is resisting the housing the most. We then move this pin until it's flush and continue.
The attack is $O(s^2)$ where s is the number of pin stacks. 
            - Describe Raking?―Apply torque and simply rake a tool back and forth in the barrel. Applying single-pin picking at high speed. Needs little dexterity.
            - Describe bumping―Prepare a skeleton key with the maximum depth in every key-way. Insert it into the lock, apply tension and smack the key. This knocks the pins and the driver pins up, and if we turn at the right time they return to their flush position as we turn the key.
            - Give methods to protect against raking and lock-snapping  ↓ 
                - For raking, include driver pins who's springs are of various strengths. Or include pins of strange shapes.
                - For lock-snapping insert a sacrificial section, which will break first.
        - Privilege escalation on mechanical master-lock systems 
            - Describe how master keys work on mechanical locks?―Insert multiple pins into a single pin stack, so an employees key will push all of the pins up while the master key would push some of the pins out and allow the barrel to turn.
E.g. consider a lock with pin heights 34738, for the master key 44217 to work - the lock must pins of size (1+3) (4) (5+2) (2+1) (1+7)
Then the lock can be added by both.
            - However, note that at each pin we've now got **two possible choices of key height**. Resulting in $2^4 = 16$ (Pin 2 only has one cut) - so there are 14 more keys that can open this lock.
            - Describe privilege escalation in master-keys―Given a differ key, we can find the master key by the following. First form the keys:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vZEvYmC-WgSJ06Fp1b3JkvBGsTaybO-1cz7ueH-QipUD3sFynKSDfQUieKumH8MW1BYeUP-rP_Z1pD7A-FSksjWagL3hF-jX6iiXwmAVgscRLJn3GDFU-2tZlQDJyYcl.png)
Then try file down to height 9, then 8 then 7 etc. Until the lock turns for each key.
We then know the height of the master key. 
        - Security is risk management 
            - Identify the motivation of attackers (based on value), identify the possible attacks and the weaknesses in your system. Then find the possible mitigations against these attacks.
We then consider the costs of the safeguards vs loss of the items.
        - 
        - 
        - 
    - 
    - Assorted flashcards
        - You cannot create users or leave a group without root permissions.
        - You can write to open file descriptors if you have the write permissions.
    - 
    - 
- 
- 
- Term 1
    - 
    - Economics Law & Ethics
        - Supervision 2
            - **Exam Question 1**  
                - a.)  Explain the criminal offences created by the various sections of the Computer Misuse Act.  [100 words] 
                    - Section 1 makes unauthorised access of computer systems a criminal offense, however you have to **know **that the access is unauthorised. This can carry a maximum 2 year sentence but intent can be difficult to prove leading to large obvious banners parroting legal access rules when you turn on certain computer systems. Section 2 appends the intent to commit another serious offence after unauthorised access, making logging on to someone's computer and reading off their credit card info in order to commit fraud an offence worthy of 5 years in prison. Finally, section 3 covers the modification of items after unauthorised access, meaning writing viruses can now carry a 10 year punishment. This covers DDOS and the creation of hacking tools. 
                - b.) What offences are likely to be committed in the following circumstances?
                    - a.) Alice is clearly running a distributed denial of service attack, and furthermore she is doing it with the **intent **to harm - I.e. she knows this form of access to the system is unauthorised. Note that if the volunteers were informed of their part in the scheme, they could also be charged. For precedence for this case, we could examine the Wimbledon case where 5 million emails were sent to a company - rendering their email useless. This was classed as a Section 3 offence and carried a prison sentence, while Wimbledon's lawyers used the defence that this usage of the system is legal as if 1 or 2 emails were sent that would be fine (so why not 5,000,000), however the test of reasonable use of a system should be "what would the system owners say if you were to ask them if you could use the system in this way" - and of course the use would be disallowed in Alice's case. Furthermore, denial of service attacks were specifically added to the law in 2008 meaning her attack would definitely be a section 3 offence which could lead to jail time of up to 10 years. ^^Always discuss precedent - write notes on that.^^ 
                    - b.) Bob has committed three (or possibly four) separate infractions of Section 3 of the computer misuse act. Firstly, illegally accessed a website and modified it without the permission of the owners. Secondly, he has distributed a virus to customers, e.g. software that uses the customers computers in a way they gave no permission for. Thirdly, he is running a Denial of service attack on the baking firm. And finally, he could be accused of distributing hacking tools to all that installed the software - but this would be more debateable, as the customers would have no idea of the tools existence.  Overall, this could result in a combined jail sentence of up to 40 years as Bob has committed multiple severe criminal offences.  ^^Apparently section 1 in there?^^ 
            - **Exam Question 2**
                - You have an opportunity to resell limited supplies of a discontinued model of printer at a good price.  You have doubts about how reliable the printers will be. You will sell them through a website, and want to avoid becoming committed to sell more.  
                - a.) How do you plan to set up your website and use the law of contract to achieve these results? [200 words]
                    - I would have to make clear the difference between offering the printer, and "inviting the customer to treat" where the customer makes the offer for the printer (at the specified price) and I can choose to accept or decline the offer (meaning if I have no more to sell, I can decline the offer). This can be done by creating a Terms of Service document and linking to it clearly on the website, this should be done with the advice of a lawyer to ensure no loopholes exist. I should also draw up an electronic contract describing that the offer is an invitation to treat, and also iron out details about defective goods. Due to our limited stock, defective items should be repaired or refunded - we must make clear in the contract that the item will not be replaced. Then once they electronically accept the contract, it is legally binding. ^^Jurisdiction need to remember that it's handled through English/Welsh law. ^^ 
                - b.)  How effective will you be? [100 words]
                    - My effectiveness would be in question if the lack of a replacement policy was taken to court, as the customer has the right to the repair or replacement of an item within 6 years if it was faulty. So if I am unable to repair the item (and all my printers have sold out) the customer could take me to court, and dispute the contract as being unfair to the consumer. In this case a legal battle would ensue, and the results would indicate my effectiveness. The "invitation to treat" is a well known practise, and would be effective.  
            - **Exam Question 3**
                - You are commissioned by a customer to design a toy robot that children will be able to control using a smartphone app. This app will also enable them to program the robot using a simple scripting language. To simplify the networking, all communications between the app and the robot flow over Wi-Fi via your server.  
                - a.) Discuss the ethical and legal implications. [200 words]
                    - The legal implications include problems of ensuring intellectual property rights around the scripts that customers use, ensuring we are not liable for any harm caused by the robot (ensuring the correct usage is explained in the TOS) and ensuring correct functionality. Furthermore, because the communications are routed through our servers, precautions must be taken so we act as a mere conduit. This gives the legal defence that we are not liable for damage caused by the customers use of the robot. We must make it clear in the contract, that we are not liable for scripts written that cause harm (if the script executes correctly). We must ensure the parents sign for this contract in order for it to be legally binding. May have to employ a Data protection officer depending on the scale.
                    - Ethically, we would like to ensure the robot cannot cause harm - and abort operation if triggers that predict harm are found. However, we have the simultaneous responsibility of respect for persons and our customer may use the tool without our meddling. We would like to uphold the law, but this could require inspection of the users code that could be viewed as a breach of privacy. Additionally, we must take into account that the users of the system are children - non-rational actors who do not have the sense to analyse a harmful use of the robot. One solution could be to make the robot very weak, so certain harmful manipulations of it are impossible.^^ Hardware, if it breaks shouldn't hurt the child^^ 
                - b.)  Your customer decides to incorporate a microphone so that the robot can also recognise  spoken commands. To save battery life, the speech recognition will be done in the server.  What effect does this have on the ethical and legal situation? [200 words]   
                    - The legal situation now must include accordance to GDPR laws, as we are processing data about our customers. We must ensure the data is processed lawfully, used only for the stated purpose, the data is not kept after it is no longer needed and the processing of the data is secure enough to ensure no loss or damage to the data. We are also under obligations to keep internal records of the database as well as garner consent from our customers (must get permission from parents!). Finally, we must ensure that a process is in place so customers can retrieve any data stored about them - the simple solution being to very temporarily store the data while processing it, and promptly delete it afterwards. 
                    - The ethical situation changes slightly as we now have more sensitive data, that could include information from parties **other than our client**. The ACM code of ethics would have us respect privacy and honour confidentiality, meaning very few people should have access to the data. Additionally, we should ensure the models we use for speech recognition are not discriminatory - although there are limits, as we should not be expected to provide a universal translator for all languages if the product is only sold in England. If vulnerabilities are found we have an ethical (and legal) obligation to disclose that to the government and to parents.
                - c.) What practical advice can you give your customer about mitigating the legal risks? [200  words]  
                    - Ensure data is stored no longer than it is needed, ideally the data should be discarded immediately after processing, this protects against GDPR laws and removes the need for a data handover mechanism. Ensure the toy is not strong enough to commit harm in obvious ways like speeding into people, this protects them from liability. Collect the parents consent before the child is allowed to use the system. Hire security experts to decrease the likelihood of a data breach or hacking, they should then implement a bug bounty program to ensure problems are caught. Ensure no data is sent from the robot to the server when the user is not trying to use it, an initiation phrase akin to 'hey Siri' or 'ok google' should be implemented. ^^Needs to be distinct so not accidentally activated^^ 
                - d.) Your customer now wants to include a camera so that the robot can recognise gestures as  well. Does this create any further ethical or legal risks, and if so, what might be done about  them? [200 words]  
                    - Some further legal risks are included around the photography of children, these data are far more sensitive than audio data and the punishment for failure to uphold GDPR could be much greater. One solution to this is to disregard battery life when this feature is used, and have all the processing done on the device; meaning the data is never held on our customers servers. This also ensures we are never in possession of any illegal data. It must be made very clear and the parents should have to give informed consent that the data is to be sent to our servers if this is not put in place. ^^Alternative is to send features like edges, no sensitive data held^^ 
                    - Further ethical risks arise as this is information that can be used to identify the user and anyone in the scope of the camera, meaning the data should be kept with the upmost privacy. 
                - e.)  How might the situation be affected by Brexit? [200 words]  
                    - While the UK is no longer a part of the EU and GDPR laws cover handling of EU based citizens, it is unlikely that GDPR will be discarded in the UK. This is because, significant altering of the GDPR laws could result in the EU deciding the UK is an unsafe place for data to be sent - vastly reducing the possible customers to UK businesses that handle data from EU citizens. However, slight altercations to the laws could occur post Brexit. E-commerce laws relating to running of the business are also unchanged after Brexit, and laws around when you need permission from parents always differed between the EU and Britain (and thus will be unchanged). ^^If gap between UK and EU laws, would need a dedicated EU server^^ 
            - **Exercise 1:**
                - (a) Describe three different philosophies of ethics. [300 words]   
                    - Consequentialism states that actions should be decided right or wrong, dependent only on their consequences. Furthermore, more positive results leads to an act that is "more right" and the opposite for more negative results. We with to maximise $W = \sum U_i$. However, utilitarianism requires perfect knowledge of all situations in order to assess all the good and bad consequences of an action (knowledge that any actors within such a system cannot have) it additionally requires a method of deciding if an action is good or bad and how good or bad an action is. 
                    - The veil of ignorance or Original position, this is a thought experiment where rule makers are given no knowledge of their family, wealth, race or creed before they are reincarnated into society - it harnesses peoples natural self interest and funnels it into the creation of a fair society. Clearly, this is because you would imagine people would want the best life possible for themselves regardless of where/to whom they are born. This could potentially suffer issues depending on the values of the rule makers, one could imagine someone who would rather die be poor who gives half the population all the resources and flips the coin to establish their life.
                    - The Kantian theory of duty states that an action is morally correct, if it would be willed to be a universal law. Additionally, one should treat people as an end in themselves not simply a means to an end (this could be seem as an instantiation of the first law). This mimics ideas found in many religious texts, where one should treat others as you would wish to be treated. This does face problems of perspective, as while some people would wish things to be universal law, others may not - for example an exhibitionist could be thrilled at clothes being made illegal, to the dismay of everyone in cold climates.
                - b.) Which of these philosophies might be more, or less, attractive to a successful businessman  who made his money from coal or steel? Justify your answer. [200 words]
                    - Clearly the Kantian philosophy does not hold, as to be truly successful in business one must often treat people as pawns - additionally, they may not the utilisation of fossil fuels to become a universal law. The veil of ignorance could be more appealing, as highly successful individuals are often benefited the best upbringing - however they may balk at their hard earned money being redistributed to allow for such a scheme to take effect. Consequentialism may be their best option as there are effects that are impossible to observe, for example while the employment of people within the business is obviously positive the effects of pollution are less obvious. Additionally, one brings ones own moral compass to Consequentialism when it is decided how virtuous an action is - and the businessman may attribute his own morals as he sees fit.
            - 
            - 
        - Supervision 1
            - **Exam Question 1** 
                - a.) ** Explain what economists mean by a lemons market. [150 words] **
                    - A lemon market is a market where information on the products in asymmetric, and customers cannot differentiate the higher quality products from the lower quality. As sellers have a vested interest in selling their product for what its worth (they have the knowledge on its worth), and buyers are unwilling to risk buying at higher prices for fear of buying a 'lemon', this leads to sellers selling the low quality goods rather than selling the higher quality goods at a loss until only the low quality items are on the market at all.
                - b.) **What is the difference between hidden information and hidden action? Give examples of  each. [150 words] ** 
                    - Hidden actions are actions taken by one side of an economic relationship that the other side cannot observe, while hidden information is information held by only one side of an economic relationship. For example when buying cars, the fact that you're a bad driver is hidden information, and making the decision to buy a safer car because you're a bad driver is a hidden action. Another example would be a worker deciding to slack off, this is a hidden action that can lead to a worse product - the employer has an incentive to associate a cost with this action, this could mean only paying the worker for good products or monitoring their work schedule.
                - c.)
                    - a.)  **You form a trade association with several other anti-malware firms and promote a quality assurance mark, perhaps with assistance from the government. [200 words]** 
                        - This signals to the user that your item is of high quality, as the government and . While this doesn't eliminate competition (as other firms also have this quality-assurance mark) it results in poor-quality providers who can provide a cheap enough service to allow for massive undercutting of price to be less favourable by customers. This means a greater share of customers land inside the quality-assurance holding group, resulting in a larger share of the profit. However the asymmetric knowledge of the user could **include** the existence of this mark, and they could end up buying the cheap product they see without knowing about the mark. Additionally, the validity of quality-assurance marks (especially for anti-malware programs) can be difficult to validate by the user, as illegitimate companies could produce their own mark to trick users. There's also the problem that you may be further legitimizing your competition, where alternatives with better products where the legitimacy was previously in doubt can now be chosen safely in place of your product. ^^Signal is good if cost high for low quality but low for high quality - to the point where lying about lemons is not profitable. Assumption being that ^^ 
                    - b.)  **You approach the UK banks with a proposal that they certify your product for use along with their banking app products, in the sense that a customer using your  system will have exercised due diligence. [200 words]  ** 
                        - This would likely be successful in making your product seem more trustworthy, as it is bundled with the air of legitimacy banks have but don't deserve. However, this would still have to combat lock-in, where people already with a malware protection service may be reticent to swap. Also, the price that would need to be paid to the banks to advertise your service would likely be very significant - and the firm would have to consider if the potential increase in customers is worth the outgoing cost. This method does have the advantage of using people propensity to go with the flow - if their banking app tells them to install a certain program, they simply go with it and not question if there are cheaper or better alternatives. ^^Assumption being that banks have technical knowhow to detect lemons, and lemons cannot trick the banks. This would then be a good signal. ^^ 
                    - c.) ** You tell customers that if they are the victims of a scam that used malware on their  phone you will pay their legal bills. [200 words]** 
                        - This gives the customer a signal that you are a efficient malware detection site, as a failure in your system becomes more expensive to you meaning you are incentivized to stop such failures (very similar to car warranty). However, this will come against the behavioural psychology problem that most people don't think they would fall for a scam or trick. Additionally, if a problem with your service is found and exploited by scammers you may end up having to pay for hundreds of users refunds while the bug is still in place - this means very robust bug-checking features must be in place. This method does have the benefit that it sounds good, but few customers will be able to use it - as a tiny percentage of scam victims are able to pursue any legal action (many scammers being overseas). However, when scam victims attempt to use this service and find there's no recourse - there could be public backlash against your firm. If a firm was truly certain of their product, perhaps they would advertise refunding scam victims (who are scammed through malware their service failed to detect) rather than paying for their legal bills. ^^Make assumptions and solve problem based off those assumptions, assume code is really bug free (obvs not realistic) - assume competitors code worse than yours, and assume claims do occur. Finally point out the drawbacks of your assumptions. Because hyper-rational customer would know few claims go to court, would know the signal is worthless.^^ 
            - **Exam Question 2** 
                - a.)
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fmDPF-dInQpQH71USeyACbGDBgB3nscLlH3JJzNT4er96vIhCtjR1TYQGylX4N1pvTc6Vt6Sr3_pZcqlcEMQgX1KadmjmFAHIMDqaEx9SY8cG9oGrHlHWDcwUI1pK1WI.png) 
                    - b.) In case v>c, then it's always better to choose hawk (as you don't run the risk of getting 0) so must have case v<c:
If the utility of choosing hawk is the same of that of choosing doves, where hawks are chosen with some probability p, this will form an equilibrium.
                    - c.) Set the initial conditions and calculate:
                    - $$\frac{v-c}{2} \cdot p + v(1-p) = \frac{(1-p)v}{2}$$ 
                    - $$\frac{vp}{2}-\frac{cp}{2}+\frac{v}{2}(1-p)=0$$ 
                    - $$- \frac{cp}{2} + \frac{v}{2}=0 \implies p=\frac{v}{c}$$ 
                - b.) In real life encounters, the probability of death is 0 - if you strictly consider this (without replacing c with some other factor) then the optimal strategy will always to be aggressive (choose hawk) as you gain at least $\frac{v}{2}$ and don't stand to gain $0$.  
                - However, if you replace c with some embarrassment factor where the other aggressive user wins the argument then the game plays out the same way as the hawk and dove game. Depending on the probability of getting embarrassed (a function of how good you are at arguing and how embarrassed you get at losing) you will decide to be a hawk or a dove .
            - **Exam Question 3**
                - a) **What are the first and second theorems of welfare economics? [200 words]** 
                    - The first theorem states that market equilibrium is pareto optimal, that is there is no further way for anyone to be made better off without making anyone else worse off - further changes would negatively impact some players. 
                    - The second theorem states that any pareto optimal allocation can be achieved by market forces provided preferences are convex. Preferences being convex means any line between two bundles on an indifference curve will be made up of points that are **weakly preferred** to the bundles on the indifference curve. So given some initial conditions, we can reach any pareto optimal allocation (whether that be communism, monarchy or anywhere in-between) can be reached using a market.
                    - Both of these theorems behave under certain assumptions, such as:
                        - Complete markets, everything is traded on the markets. 
                        - No transaction costs on the market.
                        - Perfect information with rational actors
                        - All consumers and firms are price takers
                - (b) **Give three examples of ways in which markets can fail to reach competitive equilibrium  when the assumptions of the first theorem do not hold, discussing the implications for the  information goods and services industries in each case.** 
                    - One assumption is that the markets are complete, that is everything can be sold on the market. Consider a country deciding that food should not be sold on the free market, this will result in farmers suddenly unable to make money resulting in a decrease in a supply (without a corresponding decrease in demand). A change to government funding will have to be put in place, resulting in a lack of competition as farmers will be given a set rate. The equivalent for information goods and services industries would be if information on users could no longer be sold, platforms like Facebook and Google would have a large chunk of their business model wiped out as selling information on users through real time bidding for targeted ads is a large part of their business models.
                    - If the assumptions that actors in the market are rational with perfect information were not fulfilled (and generally they aren't), this could lead to people purchasing things with little to no utility - meaning people who actually require the item could suffer, and results in people having less money to spend on utility rich items - potentially leading to a decrease in price as the price people are willing to pay decreases, finally this could lead to a stagnation of growth in those industries as they have less money to expand. In relation to the tech industry, this could be people spending all their money on NFTs with incomplete information on their worth - leaving nothing to be spent on the items YouTube, Google and Facebook advertises to them.
                    - If the assumption that consumers and firms are price takers isn't met, then firms may list items at a price too low where they cannot keep up with demand - while they struggle and battle with the initial throws of this supply and demand curve:     ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4rqcmEIjQt_7SHMQvvfC0rawX7bN5sS307ywCIuC9CtuiDA4SXZ6n-m_2m2tyJjY8jsZmnz5i4uL858ZndmTTYwcLCrjvqOMFW34IqhJP-2knWk6Nca6sixpTfBWWhHs.png)                                                                                           Until they reach the later stages, other firms will be met with a huge decrease in demand - leading to stagnation of growth. Contrarily, if consumers buy the more expensive items when cheaper alternatives exists, competitors will have to change their product or lower prices even further to appear palatable. In regards to the information technology industry, this would be the equivalent of word becoming free to win back users of google docs - or if github started charging for the service and people kept using it.
            - Exercise 1:
                - a.) **  Suppose that we say that an allocation x is socially preferred to an allocation y only if  everyone prefers x to y. (This is sometimes called the Pareto ordering, since it is closely  related to the idea of Pareto efficiency.) What shortcoming does this have as a rule for  making social decisions? [100 words]   ** 
                    - Everyone needs to be polled in order to make any small decision, so decision making will be slow and cumbersome. Additionally, If even one person disagrees, no matter how absurd their reason is the idea will be thrown out, and as almost all decisions are likely to have some level of disagreement very few decisions will be accepted. 
                - b.)** A Rawlsian welfare function counts only the welfare of the worst-off agent. The opposite of  the Rawlsian welfare function might be called the “Nietzschean” welfare function—a welfare  function that says the value of an allocation depends only on the welfare of the best-off  agent. What mathematical form would the Nietzschean welfare function take? [100 words]   ** 
                    - $\max U_i$  
                    - We select for the maximum utility of our population, and try and boost that. ^^Assume we're looking at the utility of a single good^^ 
                - c.) **Suppose that the utility possibilities set is a convex set and that consumers care only about  their own consumption. What kind of allocations represent welfare maxima of the  Nietzschean welfare function? [100 words]** 
                    - At face value, improving the utility of the best off person seems to be giving them all the resources. However, then the surrounding agents will suffer and the world around the richest person will degrade. Additionally, due to the convexity of utility functions resources become less desirable the more you have of the resource - meaning more money means less to a rich person than to a poor one. Thus, while some effort must be spent further enriching the best off agent - some money must be spent to maintain their surrounding population so the best off agent needn't witness poverty or drive on broken roads. 
                - d.) ** The ability to set the voting agenda can often be a powerful asset. Assuming that social  preferences are decided by pair-wise majority voting and that the preferences given in the  table below hold, demonstrate this fact by producing a voting agenda that results in  allocation y winning. Find an agenda that has z as the winner. What property of the social  preferences is responsible for this agenda-setting power? [200 words]** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/S1XX-5lu6CMf8Oex4OuNutrHIHl8lA_z2RtN62sSS1UOlyLVRJ7fXN8frGL6TGGjzsMr_YJbGNr_STTvSPBZZuGJtZJmTvClb6EsVz4a2kqikwXXrgbQSJqvtTl9RW_j.png) 
                    - ^^Not sure if my understanding of voting agenda is correct^^
                    - Obviously, without an agenda the entire vote is a three way tie. If we set the agenda to who wins out of y vs z, we have y winning - as we get to wins for y and one for z. If the agenda is x vs z, we have z winning out with 2 votes to 1. ^^Agenda means, first have a and b fight then have b and c fight^^ 
                    - I believe it's the property that people vote for the candidate they actually want to win first, and the following results are murky - especially if given a choice of the top X candidates rather than ranking all candidates. Thus, if specific candidates are chosen the results can vary wildly as less strict rules hold for the last two options.
            - 
        -  _**Lecture 1:**_  
            - Macro vs MicroEconomics―Macro: Performance and structure of global economy or a nation or region.  Micro: Individuals and firms responding to incentives, how market mechanisms fail and circumstances in which markets fail.
            -  _**Prices and Markets**_ 
                - Consider searching for a flat, one bed or house share - people who can afford flats will get them, and others will cycle to far away house shares.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RJdFdwqCAq_YvvqEJmjnukPI87T0GMU2tOel0cVyW8yoJAQxx6SCnpH0QIfVz6MJLmNtUDpXBR3-7ZUCIzErrtZwX-0bvHUkYRsmImVt4wuojOMT32vY-EO8qTHX4Fw3.png) The equilibrium price is where the supply and demand curves corss - e.g. £500
                - Consider if there's rigging - the cartel meet and restrict supply, 800 flats at £700 can earn more than 1000 at £500 - **This is inefficient, houses are left empty for which there is demand.** 
            - **Efficiency:**
                - A monopolist might leave flats empty, despite people being prepared to pay for them.
                - Pareto Improvement―A way to make some people better off, without making anyone worse off
                - A Pareto efficient allocation―Is such that no Pareto improvement is possible
                - Pure monarch and pure communism are **both** pareto efficient.
                - Discriminating Monopolist ↓ 
                    - If you know what the person can pay, charge them exactly that, this is pareto efficient and lets you extract the most from the market. The monopolist captures all of the consumer surplus:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i1z7Qw6bTJvxLthQPGUlCWVpvDvoBp5rLqa46oeI4ScBvHRJLeroPu7YnmfCNlFY6GR9u6z00gATNgS873ZixfReC3zNi38M_aOH05ZUcVGhMgjh0HrrSxZ1PfEtQVyj.png) 
                    - This is what the IT industry tries to do with different prices of service (microsoft word). 
                - **Consumer Surplus** 
                    - Consumer surplus―Is the total amount people saved off their reservation price (What they were willing to pay)
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/O-15rQakD1bu-vSC_cXcj6TSpt-v5tqk6yRcyAdBYwMXKfwTC8k5N7ZwWLTX67VhATkCvqjj4imubQ4tjjQOKA31QHEIX9a6Ll_wioRt23rWQcnf0lPgQfy5oGLVwZ2-.png) 
                    - People would have payed 2000 payed only 700. Lost out on A & B. The discriminating monopolist gets the lot 
            - **Basic Consumer Theory:**
                - Consumers choose best bundle of goods they can afford. Most of the time two goods enough, books versus everything else. 
                - Assume a budget constraint m, $p_1 x_1 + p_2x_2 <= m$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sECy__ijlVN8kbj_fZJR4bWZyWg-uGKgWjhyHCKYxtPsD-0wwqGAl3LhbhkozcnIjzbW3PgidkM-WVKJ5K0AxxozqZvOWKCXdwyGDpeX3FC3TUfOzSNjcp2rbod-3wda.png) Choices lie within this line
                - **Preference:** 
                    - Using Indifference curves or isoquants, we plot where a user has no preference between bundle $(x_1, x_2) \ vs \ (x_1', x_2')$. They are indifferent:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Rnc8D1UP6kPGTUwukPeOKun0fV8lBEH4Pz6V5FnQKDiFoq6_cLuS8-Km9zTYqZQLT37RzJxSTJFAGVfvU9vUxXxf4920JH-yUEbBjt8RE_d4VqR7Z4LVW7lvN96wR_dW.png) 
                    - We assume they're well behaved and don't cross, **this is the weak axiom of revealed preference**. I.e. If I'm indifferent to having 10 apples and 10 chocolate bars, I'll be happier with 20 apples and 10 chocolate bars.
                - **Perfect Substitutes:** 
                    - Perfect Substitutes―Don't care whether I have good 1 or good 2, e.g. sugar from Tesco vs Sainsburys.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/RtW4sVt6ZsJ0q8l-QmqUbEUw5Q9eryLcS5Nmn4D30fl0DS-w5BQo2QkEPPSKuqAaimDiKYHLkdB_LUJhkNMkuPJLsjWGQh3y4EiHy9cptDrBpAwQp8itUTiUnYVSdsv3.png) 
                - **Perfect Complements:** 
                    - Perfect Complements―Want exact same quantity of good 1 and good 2, left & right shoes for example.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/v0o8b3wdSbHqfQhwfS0ixECIKjMrHcSB7onxgFp8l3iqdca2mLhezud9q8iNgz1_qgaWwYzpn6arhkGmVjkMK_hPuLo29m99yrgEHrbLa6ILYEXnIkSAHhjX-RNr1hHF.png) This indifference curve says, once I have 1 left shoe and 1 right shoe, it doesn't matter if I have 1 left shoe and 300 right shoes.
                - **Bads:**
                    - These are goods I'd rather avoid, sometimes I have to consume of the bad in order to have some of the goods.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/M4iSNms1tnx-YOSJMhigTNsGoB6JonMSKNy76ZC2gStAI835LxRgzx6dSJyXqwCj8Fy0f8dlXwTcxoT_z-upEfAFNXbTHk1ptbErRrIgNayhrmjOruwqCN_0Zgmap3Yi.png) 
                    - I'm indifferent to getting more sprouts as long as I get more turkey.
                - **Marginal rate of substitution**
                    - The tangent to an isoquant gives the marginal rate of substitution. This is the exchange rate at which the consumer will trade the two.
                    - Convex curves: You're more likely to trade a good if you have more of it
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7ECMsjYfQPiyz0X6fyHargCzgFHlL44jINYU5fjzGEQRlvSLSC-07qn4Yv5HIkq8o6B5WLRxAb276LOR8M7wg3m49zPeW6AFS_b3Uvm1NaLp7oarKvPhe57wFz4VDhrS.png) 
                    - **Diminishing MRS**:
                        - You are less willing to pay for more books if you have less money. 
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xdD_GZn9yyeAJ9L-H3Cin_MTBznLB2lJirWVTYvNfZAVBSQFCXjanoE6nI-63ytQbJfOXKTnKPuwCd8IuPO4zmLGld-XmtAn2JTbUuU_JyTAcqtzGiJGsxygUPncLikN.png) 
                    - **Utility**
                        - Indifference curves can be parametrised.
                        - Marginal cost―Cost of producing one more good or service
                        - Marginal Utility―Is  MU_1 = dU / dx1 - e.g. the change in utility with respect to a given good.
                        - Then MRS is -MU_1 / MU_2 , utility functions can be useful for describing customer choices. And can be inferred from things like shopping patterns.
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/U6CZ7hN8XHwXnTqE3AbKr7UoyFEWUMREiibQn8XtkMKG0s-TWRHFj_hXoRwIZqG7mLqAeX2iNaWLS90BuXcWIAlvmgZCO2VpqCXD6Xv96xFaPQlqE7kltJAJI6nUpc0q.png) 
            - **The Marginalist revolution:**
                - Why is water cheap and diamonds expensive. 
                - The value of the last and least wanted addition to your consumption of a good sets its value to you. 
                - Marginalism asserts that individuals make purchasing decisions on an additional item, based on the added utility it will garner them. This idea shifted thinking from costs of production to demand.  
                - Local coal market has 3 producers and consumers:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-vko3s4LW2USaWft_HrsAWSr10bXcb_C5wmB0s8pFnN531Eb6BWtGhU0l2dMlf523KiyQYq-k3mu56BBm7lQT_sJbEaOgR3Yj3JN8Bv_G87FdEBd-bdGFHRjpQEEBIYY.png) The price of coal will fluctuate between winter and summer with demand. It's determined by the marginal transaction
            - **Demand** 
                - Market demand is the sum of the demand over the consumers. We can get a consumers demand from their utility or vice versa.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dYeW6tK9xXJ8L56YeOFbm-OJiuK9YxaS8lvYvMJKVcB0APpamzdLloeSgDbpOPJSnRrl8IR71jFS7wt2wsZLyAoYzdyYUSo5DJBQMOfksz8TqipMWqFJG9oTi_A41Nmi.png) 
            - **Elasticity** 
                - Elasticity measure the effect on demand of a small change in price. When do people stop buying your product given an increase in price.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/vTT7b5HI05V2gkljJuvA-N__lA99IpgPl85EaPEArA7LQI3OBb_14H0vUQULw9QgVAUM_GycldqTKIyHMo2J1HZw3pYRqif6-1eqyzoqtzvSwxdul-yfTPqtZm9LkaoP.png) 
                - 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IwIUmuMf3EuWulCyFKAzRgs5RWZMSx4okIlM-S8wfP39AZrtjtg33kzqwB3dbZ6ETSBR92QD4B0jO2nFDj6mOSD4JMGjeB8dwCIH5gRYg2kPLMRLUdzllgofWY-7Zqsb.png) 
                - Elasticity = 1 means theres likely to be a substitute.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7-y8UFFxlppXF8VuLxiOQsmI4CwPQKhulJqIngb1n74FMQtaiTw18DBRmMqIVadikqJqjN-pHU7e-3nXiz_yNqBa914UqdGRQxCNTVYdm0xd0zL9LJ_6rIueMmNNsF9a.png) 
                - Elasticity = $\frac{\text{Percentage change in quantity}}{\text{Percentage change in price}}$ - so if we have 10%/30% - we have an elasticity of 1/3, meaning that change doesnt have a large effect. 
            - **Supply** 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4rqcmEIjQt_7SHMQvvfC0rawX7bN5sS307ywCIuC9CtuiDA4SXZ6n-m_2m2tyJjY8jsZmnz5i4uL858ZndmTTYwcLCrjvqOMFW34IqhJP-2knWk6Nca6sixpTfBWWhHs.png) 
                - Average cost of goods initially falls are more are produced, then something occurs (overtime etc) and costs rice quickly due to capacity constraints. Thus supply curve is typically convex.
            - **Cost Evolution**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/j8i2xcfsdw00xI7OybDEvjmbqTMqFbrib9AoTvvNW9kGwRQP5GxFErq8238MCh1M1BHafGLiIzkfUU1dsuUCP5NgHIVSy4clXG7KGm0JnJHRRI4EUHr_5oLEnz0j8uGf.png) 
                - Firms can build more factories to build capacity constraints, gives nearly constant fixed cost as firm expands.
            - **Firm Supply**  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0eUwnpy4Evz5Y61Fw6bosytT0EYGJI4OXlf9bJsIBIyAqmN2f9C5U6bnVahOWpTroGe-JTmuDthRyGSI_wtsOKstpmXmGeAZ6iaFnRzpUr6AhGksSFSBl0tfHkJ5Muvt.png) 
                - MC = Average cost
                - In a competitive market, at a price above p* the firm would have no demand and at a price below p* the firm would be faced with all the demand. The firms profit is maximised when it sets output so that its marginal cost equals the price p*.
            - **Putting it all together** 
                - Prices are set where supply and demand curves intersect.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2dG1jmObyO9oF7hWBzX3xm60RFWD5Z-wH5Ue-LJ9e_nn1_fam7JbMvMs266_GAa36ufhBP5oPksvynADsergwaYZE3VMQyVQSlMujO1wKRLkxT0mk-KOLp3fuOLnJSly.png) 
                - p* = marginal cost of marginal supplier.
                - Intrinsic advantages of non-marginal suppliers (good farmlands or easily mined coal) get build into rental values - more expensive. 
            - **Equilibrium** 
                - Supply and demand for 1 good―partial equilibrium analysis
                - General equilibrium analysis adds labour, capital etc. 
                - Theorems of welfare economics 
                    - Theorem 1: Market equilibrium is pareto optimal
                    - Theorem 2: Any pareto optimal allocation can be achieved by market forces provided preferences are convex.
                - This has lots of conditions to be correct.
            - **Efficiency, welfare and justice** 
                - There are different theories of justice: 
                    - $W = \sum U_i$  - The average citizen, classical utilitarian welfare
                    - $W = \min U_i$  - the most miserable citizen, Rawlsian welfare
                - Diminishing marginal utility of money means that transferring £1 from a rich person to a poor one improves welfare.
                - Arrows impossibility theorem―There is no perfect way to aggregate personal choices into social welfare that's consistent with democracy.
            - **Transaction costs**
                - Trades are not free, time effort comissions bargaining policing and enforcement.
                - External transactions costs higher than internal ones
                - Agency costs within firms also matter hugely
                - Incomplete contracts, opportunistic behaviour comes out.
                - So should tech make firms smaller on average? 
            - 
            - 
        -  _**Lecture 2:**_ 
            - Effect of technology on supply and demand: 
                - Increase of supply much easier than other industries, **marginal costs may never rise**. Microsoft enjoys ever increasing returns to scale. 
                - Technology can also improve efficiency.
            - Competition and information:
                - Marginal cost of producing information is zero. Market clearing price. Encyclopedia vs wikapedia
                - Machine readable phon ebooks, Nynex charges 10000 per disk, ProCD starts selling for 300 - finally price dropped to $20.
                - Nowadays free online, how do you make money from selling information?
            - Lock-In:
                - Buying a product commits you to buying more of it, or spending money on one or more of (consider apple): 
                    - Accessories - apps for phone
                    - Skills - fluency with microsoft
                    - Services - network service for phone
                - Time and effort and bother to change.
                - Fewer people change their bankers than their spouses.
                - Fundamental Theorem:
                    - The net present value of your customer base, is the total cost of switching.
                    - Suppose it costs £25 pounds to get a new customer, and it costs a customer £50 to switch. If you offer them £60 cashback to switch and customers are worth £100 to you - The customer is £10 ahead and you're £15 ahead.
                    - **SO** the value of microsoft is what it would cost people to switch to google docs and linux. 
                - The incumbent will strive to maximise switching costs, competitors to minimize them
                    - File format wars
                    - Loyalty programs 
                    - Phone number portability
                - Incumbents promote complementary goods and services that increase lock in, tied printer cartridges to G suite.
                - Asymmetric switching costs, a phone network may supply a phone to win a customer, but keeping them they can simply offer minutes which costs nothing.
            - Network Externalities:
                - Networks more valuable the more people use them.
                - Metcalfe's law―The value of a network is proportional to the square of the number of users.
                - More complex than this, local effects are stronger, but still more than linear.
                - Overall effect - past some threshold, network use takes off rapidly and creates lock-in (telephone takes off as more people have them).
                - Real networks like fax and email, virtual networks like pcs and software. 
                - Most people choose to buy PCs rather than macs because of software. Then people decided pc was winning, so people just developed software for PCs. This pushed microsoft forwards.
                - It works for bads as well as goods, malware writers target windows while mac and linux are also vulnerable.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4zvGoVnMRgE48-8A6GJHCZmDyD5mS0Pkp0xFV_cUPCjZdKgAKmX9BWKFCAaTHMIzYkMqoguOzoC1jDcS5YatuMeEzaDD9zfs-PBtenaEFP3BTJCum_yNmSdrM3d7THgW.png) 
                - Markets with network effects can "tip", one suddenly taking over. Consider rail gauges in the 19th century. Colour TV standards in the 1950s. Paypal vs other payment startups. Facebook vs myspace. Google meet, skype, zoom etc.
            - Strategic issues:
                - High fixed cost + low marginal cost. Significant switching cost due to lock in and network externalities. Tends to lead to a dominant firm market model.
                - Given all three monopoly VeRY likely. 
                - Hence the race for market share when a new product or service market opens. IBM very well engineered, windows ship it tuesday and get it right by version 3. 
                - Is your customer acquisition cost still less than the lifetime revenue.
                - How bad are monopolies? No competition to allow equilibrium, however what if consumers arent paying anything? EU LAW: A fairly-won monopoly is ok, but cant leverage monopoly in one field to another - google cant direct people to their travel service.
                - US - monopoly used to be measured by consumer surplus, doesn't work for google and amazon. 
            - Price discrimination:
                - An efficient monopolist sells to each customer at their reservation price.
                - Pigou's three degrees of price discrimination:
                    - Personalized pricing - haggling or loyalty cards
                    - Versioning - first class vs economy
                    - Group pricing - student
                - Tech increases the motive for price discrimination, have more information about you. Also firms are more likely to have market power.
                - Price discrimination is often unpopular, people don't want to pay more for the same things. 
            - Bundling: 
                - How to conceal discrimination - selling a number of products together.
                - A & B price willing to pay for word and excel:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nbzIJ1zjMLLSUb48JiYJcBC556k1-06cjLSkbAqBf6PyOqKYZbC_s1vV0Ki0-js5medhE1e8q6zaTxUO_7wt7tludXk-1sj8prILOrpRYCUd70Rdg7GhAAmosxXqN4Ts.png)            By bundling word and excel together, they can make £125 per customer, rather than £50 or £75 each.
            - Income distribution:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b8F_Zq-Rdrxikjw2aDuXGu8KvyP2Pbo09L8OLyDQoIuQ7J4Wtngcz0QSrmWTUCCMnxFFR5mOytEZsC0j1mAA7S3NsuLECBZVm4AE23df2c4a8eGPiOXZlC5-RADWPNWL.png) 
                - The Gini coefficient is used to measure inequality. Gini = A/(A+B) where B is the cumulative income distribution. If Gini = 0 then communism, Gini =1 then the king has the lot.
                - Gini falls with development, rate of violent crime correlates with the Gini coefficient. US has similar Gini coefficient to a 3rd world country. The poor fight harder for welfare than the rich resist them.
                - Democracy is strongly corelated with equality, however cuts both ways. Farm subsidy that gives each farmer £200000 but costs non farmers £200. 
            - 
        -  _**Lecture 3:**_ 
            - The Business Cycle: 
                - Global economic crisis, money out of banks, banks bought out leading to economic debt doubling. The more recent economic crisis was not as deep as the last, but the recover has not been as thorough:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zoTwERlnGfC_RiVFcJ1dOuWTgSPSSAYBF3IdssGfOc6JqVzNJPfGNqJHhPFTr637zqbghRfc0-vT2-qVgxU6xSlW0wkQn7JM0qezdregQ8wDhc5LhSPxAU-J1aLmdu0K.png) 
                - Pandemic causes greater impact on economy than the 2007 crisis, tech industry doing much better than other industries. 
                - Why the pattern of boom and bust?  
                - Mill and Ricardo argued that: demand for goods + savings = supply of goods + investments. Further savings = investment, so demand = supply. Meaning that the market for money needs to be considered, just the market for goods.
                - Keynes’ liquidity preference: people want a certain level of savings, maybe 3 months salary. In a recession, liquidity preference rises.
                - In a boom, people and firms borrow assets that can be sold later. A bank that takes in £100 pounds in deposits might lend out £94, meaning £6 of capital underwrites £94 of lending. 94/6 = 15.7  
                - In a recession, loans go bad, share prices of banks fall and banks call in loans, capital requirements increase so governments compete for available loans. Money supply contracted leading to large unemployment.
            - Recession and Tech:
                - Booms as people built railways**, Electricity replacing** steam lead to boom, mass production of cars led to a boom. Whole industries replaced with online alternatives, amazon half of book market, newspapers move to online. 
                - Increase in demand of online shopping.
            - Trade:
                - Wealth of Nations - if a foreign country can sell something cheaper, buy it with produce from own industry, employed in a way in which we have some advantage. Was a radical view, previously maximizing exports and minimizing imports.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Pj6uafDRyN_Xgjw4HIGLkLjzqN033NruSKXd6dKINmjEs4wCRkco_Dnr73azj7MY6vrAFk6m1ZVyUsnAmytxBDho2eP6yNvIQNKiK9g2dy49PjKClnxycSM4Yy576RwD.png) 
                - Ricardo, 1817: it’s comparative advantage  that matters, England unit of wheat costs half a unit of wine, while Portugal costs 2/3 a unit of wine.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4IQclGj4j4zfCGoEPFsD7fpo_xlYYips86GGOC2nfPQneZvkEeEGBjrgaYIX8eiTs5Zi5XpdvU69zkTog9TUpcIhQaqb9ljag_MKYQhQzXlIUHuyFl3kvF5vW2ye-TwW.png) 
                - If each play to their advantage, each are better off. 
                - Capital v labour, outsourcing.
                - Under perfect competition, free trade optimal but there are still losers in this case English Vintners.
            - Growth:
                - Output = f(land, labour, capital). Implies colonization and increase in capital. 
                - States invested in industry for time, as governments could borrow money cheaper than private companies.
                - Neoclassical school, all about technology and population growth.
                - Modern view, mostly knowledge that leads to growth. 
                - Prescription, world should spend 4 times more on research and development.
            - Tragedy of the commons:
                - If 100 people each graze a sheep on the commons, if one person adds another sheep he gets 100% more and you get 1% less. That small decrease is unlikely to cause a row, meaning the logically correct move is to have more sheep.
                - Leads to overgrazing, overfishing etc.
                - Welfare theorem assumes complete property rights, this can be used as a reason to privatize common property and fence it off.
            - Externalities:
                - Goods/bads that people care about but not traded - typically side effects.
ONLINE DEFINITION: "Costs/boons to 3rd parties as a result of producers". 
                - Consumption externalities include smoking in restaurants, increased education decreases crime. Competitive equilibria are unlikely to be pareto efficient in light of consumption externalities.
                - Can in theory fix with property rights, can only have 100 sheep on the commons.
            - Public Goods:
                - Scientific knowledge is a public good. 
                - Public bad being CO2 emissions, every country affects it equally meaning temptation to free ride.
                - Can **capture benefit from scientific discovery, without contributing**. Need to institute grants, nobel prizes, doctorate programs etc.
            - Club Goods:
                - Traditional communities can limit scale.
                - Fishermen in a community can gather and form a rota, signed by the mayor. This is self-enforcing, have the right to chase people off.
                - Needs to be a small enough group to come together and make decisions. 
            - Enter Politics when the club breaks down:
                - Buchanan: " Politics is  a structure of complex exchange among individuals, a structure within which persons  seek to secure collectively their own privately  defined objectives that cannot be efficiently  secured through simple market exchanges  "
            - Monopoly Rents:
                - Firms will enter a market until excess profits competed away, **if no barriers to entry in place**. 
                - Economists define **a rent** as an excess, undeserved income resulting from barriers to competitions. 
                - Rent seeking drives much of politics.
                - What if we regulate prices?
                    - Sometimes an increase in prices through regulation can help the owners rather than the workers, taxi license cost.
                    - Taxi license bubble.
            - Asymmetric information:
                - 100 used cars, 50 which break down $1000 and 50 which work well $2000 - would think price would be the average. **But buyers cant tell the difference, so price is $1000.** 
                - Additionally, if the price was $1500 those with the good cars wouldn't sell - leading to only the bad cars getting to the market.
                - Can offer a warranty, this is cheaper for those with good cars and acts as a **signal **for the hidden information. Signalling theory important for recommendation systems like Google, eBay, Uber... 
                - Uber drivers more likely to be courteous than black cab drivers,  due to their attached rating. 
                - Do Volvo drivers have more accidents because:
                    - Bad drivers buy volvos to survive - adverse selection (hidden information, the drivers know they can survive in volvos). 
                    - Drivers go faster due to increased safety - moral hazard (hidden action, might be subconscious)
                - These are examples of hidden information and hidden actions.  _Adverse selection is a lemons market._  I.e. the information is asymmetric, so the actors with more information participate selectively in trades. "when one party holds information that the other party does not have, they have the opportunity to damage the other party by maximising self-utility, concealing relevant information, and perhaps even lying. Taking advantage in an economic contract or trade of possession of undisclosed information is known as  **adverse selection**  "
            - Behavioural Economics:
                - Classical economics - individuals are rational, they maximise utility with no cognitive limitations.
                - Behavioural economics:
                    - Behaviours deviate from this, based on experimental psychology. 
            - Bounded Rationality:
                - People tend to act intuitively rather than rationally, Prospect theory: People offered £10 or a 50% chance of £20 people prefer the former. If it's a loss, they usually prefer the latter.
                - **Framing actions as saving can make them more efficient.** Political marketing with terrorism takes advantage of this.
                - Cyber crime vs terrorism. 
                - Satisfice―People want to make just-good-enough decisions. Stop once meet goals.
                - Hyperbolic discounting, "people disregard far-future events  ",  discount events likely to occur in the future. 
                - The endowment effect―People are more willing to buy an object than sell the same object.
            - Cultural Biases:
                - The way in which people make consistently irrational decisions. It was noted that machine translation from gender-neutral turkish text made Doctors hes and nurses shes. 
                - How to capture implicite biases ingrained in culture?
            - Nudge Theory:
                - Application of behavioural economics to policy. Consiiders how choices are presented, this can have a powerful effect. Can induce individuals to make better choices, **but does not affect underlying structural issues**. 
            - The Power of defaults:
                - Most people go with the flow. Accept product as it comes out of the box. Checkboxes to opt out of market hard to find, used to have to sign up for pension now its opt out rather than in.
                - Organ donation laws in Spain opt-out, now has highest donation rate in the world.  Same in the UK.
                - What is the ethical requirements related to opting in/out to sharing of medical data for research.
            - Agency effects:
                - Classical economics sees institutions as rational, however managers make decisions that improve their **personal** utility as well. 
                - Some companies give stock options to align interest, public choice economics apply this incetive analysis to civil servants and politicians.
                - Why do public sector IT projects fail more than private sector projects? 2/3 fail in public sector, vs 1/3 in the private sector. 
        -  _**Lecture 4:**_ 
            - Auctions:
                - Corporate takeovers to house sales are also really auctions. Auctions are a big success of the internet, from eBay to Google. 
                - Types of auctions: 
                    - English, start at reserve price and raise till a winner is left.
                    - Second price sealed-bid auctions, highest bidder wins and pays second highest bids.
                    - All-pay auctions: everyone pays at every round until one remaining bidder gets the goods. Times of war or litigation.
                    - Dutch, start high and cut till somebody bids.
                    - First-price sealed-bid auctions: one bid per bidder. Higher bidder wins.
                - Strategic equivalence:
                    - Dutch and first price the same result, highest bidder gets the goods at their reservation price. Should bid low if you think your valuation is much higher than everybody else's.
                    - Second price and English the same - best to bid truthfully. 
                - Revenue Equivalence:
                    - Not who will win, but how much is paid on average.
                    - According to the revenue equivalence theorem, you get the same revenue from any well-behaved auction under ideal conditions.
                    - Conditions Include:
                        - No collusion
                        - risk-neutral bidders
                        - Pareto efficiency (highest bidder wins)
                        - reserve price
                        - independent valuations
                - What goes wrong?
                    - Private value auction, every bidders value is personal and the piece generally has no intrinsic value - say art.
                    - In public value auctions, the items do have an intrinsic value - say oil drilling rights. The buyer is the sucker who overestimated the most - the winners curse.
                    - Most real auctions lie somewhere between the two.
                    - Bidding rings: 
                        - Bidders collude to buy low, have a private auction later and split the proceeds. 
                        - First price auctions harder to rig, everyone must collude. Second price easier to bid. New Zealand bit of 7000000 payed only 5000.
                        - Deter people from entering low quality bids, TV rights where detailed programming plans need to be drawn up. However, placing barriers can result in larger companies scooping up all the TV rights at low prices.
                        - Predation: we'll top any other bid - aggressive behaviour designed to scare people off. 
                        - Also sniping, where a bid is placed in at the last second.
                    - Bidders should be risk-neutral, however rationality is bounded - with most people being risk averse. People put in bids that are far to high, from fear of not getting the item.
                    - Bidders may pay signalling games, show aggression by a price hike - bidding for TV, do a price hike in their area if they are trying to buy in your area.
                    - Also budgets constraints, revenue equivalent theorem only works for infinite money. 
                    - Externalities between bidders - profit from selling to both sides with arms.
                - Combinatorial Auctions: 
                    - Externalities may lead to preferences for particular bundles of goods.
                    - Bid $x for A+B+C or $y for A+D+E
                    - Critical app for CS, routing in presence of congestion. This is NP complete.
                    - How can we make an auction strategy-proof, if its second price people have the incentive to tell the truth (pay too much and someone else may have as well, suffer winners curse).
                - Ad Auctions:
                    - Google makes about a third of all digital advertising revenues.
                    - Basic idea, second price auction mechanism but tweaked to optimise platform revenue.
                    - Bidders bid prices $p_i$ platform estimates the quality e, and then ad rank $a_i = p_i e_i$
Where ad quality is a function of the relevance and the clickthrough rate.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rZvVd8BnX4p36wkAIOnBIrPmXwuFBJdQxmIh8Qe9GK6s4uUrME6cRllFuxR2NMrCB3yoWAgdgy1N6zL0wUu-KcXkC20MyaUQWYnmTvmuNJyIQOsuDfzhzRisOx-fBZf3.png) 
                    - With four people bidding for the first ad position, jerry has the highest rank. And has to pay 1.50 per click - This is calculated by taking Elaine's score divided by Jerry's score multiplied by his bid $\frac{6}{8}\cdot2 = 1.5$ 
                    - Each advertiser is paying less than they initially bid, but as their bid affects their ad rank they have an incentive to tell the truth about their valuation. 
                    - Ethical Aspects of ad auctions:
                        - Ad quality can easily transform into virality, so if your ad is good as clickbait you pay less. Trump paid less than Clinton.
                        - Many sites then tend to serve more provocative and extreme content, as they have a high quality score.
            - Game Theory:
                - Cooperation or Conflict:
                    - If you want something, you can: Make something of value and trade for it - Economics.
                    - Just take it, by force or the ballot box - Politics.
                - Game theory is a focus on games of strategy, with problems of cooperation and conflict among independent decision makers.
                - Games of perfect (chess) or imperfect (battleship) information
                - Example matching pennies, if two pennies are different Alice gets bobs penny - else he gets hers. The strategic form is:   ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E9YwIxeKkXu1lqHplqGdrv_SHFUVKUHeKCQ0LjNFA2RkUPgpGYpM9dx0TQDat9fJSZHyo3ucSbKnSSli5sD1DGJ6U4X0iuD4kGbUSbku1aF_nviqMyBS4KXuRX45cTNQ.png) 
                - Zero sum game―One players gain is anothers loss.
                - Consider this strategic form: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7TKd0Fp1aHGZbdkyQUxKi5Lxr39MDqVSauBOuS5_ILDagnfuq3y8xDZpKU7WO3cUdRUOxI39qP_e_gTMxp77RedwPik8XjbZIJFsO-d9ygFuVS4fwcq-Lq2yktrAgeqf.png)         Bob is always better off playing left, regardless of whatever Alice plays. A strategy is an algorithm - input state and output play.
                - Nash Equilibrium:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J9BK-4asv8GkG0WFHEGH2Ivz9dwSg2HWDoeAOGFE-aSRAY4bHh3dXjS0Hvr5UV3offClGwlr7A8bhcXq86_K-1AzlFUCkc8C7OIkI1aT2YjaerrHGfYmTPjBsoKQt9Fn.png) 
                    - **The optimal strategy depends on what they think the other will do. **
                    - Nash Equilibrium―Two strategies are in Nash's equilibrium when A's choice is optimal given B's and vice versa.
                - Pure v Mixed Strategies:
                    - Rock paper scissors - has no Nash equilibrium. 
                    - Alice plays scissors ⇒Bob plays stone ⇒ Alice plays paper... Fix this using a random algorithm.
                    - **Deterministic algorithms called pure.**
                - Prisoners Dilemma:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4_VH7AgZnVE6DQrL2943-HqDL8F7f1NDAfUYJZB-X8mT4VDHQqgzh-JYPMGEf9hLXsKvfxXNcOz9Pvih0aGZU8jv4owcwStUmIe7GRsQcAJ4TUzbhKHfXmC4Q8XcihTI.png) 
                    - Both will cheat rather than cooperate, applicable to defense spending - fishing quotas etc.
                    - If played repeatedly - Tit for Tat solution. Cooperate at round n, do what other guy did at round n-1.
                - Price Fixing:
                    - If it costs x to fly from A to B, to flights compete and spend x + 5, OR collude and charge 2x?
                    - Competition laws forbid price fixing cartels. Bug can occur naturally. Try charging 500 and see what other airlines do. If they defect by competing, play tit-for-tat.
                - Stag Hunt:
                    - People have to work together to hunt stag, but hares can be caught individually. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/phJ_0IA1kUxgZYTwYfjs5TWPxZiCXUMMC1qx9kAoUpv0roCC9Cls5Rr9qdpSL-CjWTPL2-8RQ6N1tEj2kYlbRduANgpGaXXQL0Tz0-Zyps4fQF0SD6nqGzWru57hCkci.png) 
                    - Only chase hare if you believe your buddy will defect.
                - Volunteer's dilemma:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4TatYBq4ak-QZMZdc2hj8oynqq_AaHmyBrGd6Ykw8EoRQLCVM5Nq6tjPAMeWuEZdjr88WrIUBrGCm-gLpzVv4L-qBZ9zWodZffo_2QzfuJLCg4a3_o6ME9AKW6ca1s-P.png) 
                    - Leader shows bravery.
                - Chicken:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/1ns9L4OCTV0Luda7C0jR0aQ6SMnCZPNYWqJI6637KmuvrYiTGh1Y5Oj-WVYv9J3lkUB7894mIUe5BHvLaViUXT4UVVbs-d1wlaVKF2LXe8ZMd7UNuzY7MxJx0XseT_5p.png) 
                    - Iterated version of chicken ⇒ hawk dove game.
                - Hawk Dove Game:
                    - Food v at each round, doves share and hawks steal from doves. Hawks fight with risk of death c.
                    - If v > c, whole population would become hawks - if c>v then hawks will start to die off and an equilibrium reached.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fmDPF-dInQpQH71USeyACbGDBgB3nscLlH3JJzNT4er96vIhCtjR1TYQGylX4N1pvTc6Vt6Sr3_pZcqlcEMQgX1KadmjmFAHIMDqaEx9SY8cG9oGrHlHWDcwUI1pK1WI.png) 
                    - Look along columns, and multiply probability of hawk by your gain - e.g. for a dove if they're a hawk gain is 0, is they're not gain is v/2.
                    - $\text{note}: (1 - c)v/2 = \frac{v-c}{2}$ 
                    - if v > c:
                        - If one player chooses Hawk, the other should also choose Hawk, as (v-c)/2 > 0
                        - If one player chooses Dove, the other should choose Hawk, for the same reason.
                        - **So hawk dominates.** 
                    - if v < c: 
                        - If one player chooses hawk, choose dove.
                        - If one player chooses dove, choose hawk. 
                    - Small number of hawks prosper, as most interactions will be with doves. DO THIS: at hawk probability p setting hawk payoff = dove payoff.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xXsTJGAs1j2Rt3ZGXAFFl7tRuvM7ICZf_NUdOoVkV-OjMxssCw1B8-XRpKiWrV3pIf9DIIQ8kF3Ui556E7zsM9rrmUU11er2-fUmGlMbsso-wIczS2xn9-OZyTxDxd9G.png) 
                    - So stable equilibrium at p=v/c, Models the probability that population in a species will be aggressive.
                - Broader Implications:
                    - In pre-state societies, better kill someone you don't know. We know live in more fair society. Evolutionary basis of morality, fairness from tit-fot-tat - hierarchy from hawk-dove.
                    - Internet - less cooperative social mechanisms and more echo chambers. No equilibrium reached as in hawk dove. 
                - 
                - 
            - 
            - 
        -  _**Lecture 5:**_ 
            - 
            - What is law?
                - Can't get all we want through buying and selling through marketplace - because of externalities
                - Politics system which persons seek to secure their own objectives, which cannot be achieved through simple market exchanges.
                - The main mechanism is law!
                - Many origins & flavours, state religion common Roman Napolean etc. **We are interested in Criminal and civil law** 
                - Criminal: Alice harms bob seriously, so state prosecutes her
                - Civil law: Alice harms Bob or breaks a contract, Bob can sue Alice 
                - SIGNIFICANT OVERLAP - if police too busy and there's an assault can sue.
                - Difference between showing image in video to pirating large scale
            - Criminal Law:
                - Requires:
                    - A guilty act
                    - A guilty mind - if no intent cant be prosecuted.  "  so legal advice or  going to the ethics committee may shield you!  But some offences are ‘strict liability’   
                - Prosecution must prove guilt beyond reasonable doubt
                - CPS guidelines matter and agreements - e.g. with the IWF. Hacking tools are offensive if they are intended to be used for damaging or stealing from computer systems. **Wireshark could be considered a hacking tool!** Need a good reason.
            - Civil Law:
                - Contract - making the agreements you want
                - Tort - avoiding infringement of the rights of others, give adequate notice to other of your rights you want to enforce
                - Regulations - specific things needed to avoid penalties and enforce your rights
                - International law - agreement with customer in other countries
            - Contracts:
                - Offer and acceptance my competent people, for a lawful purpose. Must be at **least 10 years old!** Need both people to supply something
                - Can be made in writing, orally, by conduct
                - We make dozens of informal contracts every day. 
                - When you have offers on an online shop, this isn't an offer but an 'invitation to treat'. The customer then makes the offer and the shopkeeper accepts!
                - **This is important if you run out of stock, won't get sued.**  Need to link to terms and conditions.
                - Linking to terms and conditions generally enough - train ticket too small
                - Many laws require some contracts in writing - in USA all goods over $500
                - Many jurisdictions have electronic signature laws; electronic writing fine as **essence of signature is intent.** 
                - Clicking on button evidence of intent in the us since 2000
            - Limits:
                - You're now liable for any malware you give to customers 
                - Retailer has one chance to repair or replace - - else refund.
                - Can't enforce unfair contracts against retail customers
                - Can't exclude liability for death or injury, even if excluded in contract
                - **However, this doesn't apply to services. **If your satnav sends you to an inappropriate place, the makers can be sued - **not so for google maps** 
            - Globalisation:
                - Can be tiresome for a firm in the UK to be sued in Australia, need to make it clear who's laws apply and **separately **where claims should be heard.
                - Enforcement of foreign judgments not straight-forward, USA is rogue
                - One fix is to specify arbitration - private civil law 
            - Arbitration:
                - Contract can specify binding dispute resolution by an arbitrator
                - Can also specify applicable laws and other things **like** limits on cost
                - Arbitration awards are recognized and enforceable everywhere.
                - **This is a method of optimizing and privatizing the law to settle disputes between companies.** 
            - Costs:
                - US system - Each side pays own costs in suing. Can be expensive for some firms 
                - UK system - Loser pays the winners cost, over £5000 pound threshold outside of small claims court - rich consumers can ruin you, but poor customers may lose their house.
            - Tort:
                - Second main way you can become liable online, after contract
                - A tort, is a wrong which unfairly causes someone else to suffer loss or harm
                - Examples are negligence, defamation or copyright infringement
            - Negligence:
                - Arises if you break duty of care, e.g. if you cause a car crash, you are liable for damages to cars
                - **Doesn't apply to indirect harm, **if you cause a traffic jam its too hard to measure the damage 
                - Usual yardstick is the standard of the industry. E.g. if some banks start using 2fa, all banks need to do that to not be negligent
                - Insurance laws tied up with liabilty, car crashes - medical malpractise.
                - If you software harms a **non-customer**, you didn't disclaim liability as they didn't make a contract with you - **negligence rather than breach of contract**  
            - Defamation:
                - Libel (if spoken, slander) is a tort, **UK is a popular venue for this** 
                - Direct defamation; innuendo; linking
                - Burden of proof on defendant in UK
                - Uk system of costs shifting, loser pays winner's costs.
                - Defamation act 2013, excludes trivial claims, creates public interest defence - journalist can claim public interest. Makes the claimant pursue the author first rather than the organization they work for
            - Intellectual Property:
                - Patents:
                    - Mechanism to tackle lack of money given to R&D from externality in research
                    - Protects an invention which must be: 
                        - Novel (no prior ideas)
                        - Useful (Not something that doesnt work)
                        - Non-obvious (to something skilled in the art) 
                    - Typical duration 20 years - **Only granted if applied for** - **Also will most likely want to apply for one in ** _**multiple countries.**_  
                    - Traditionally only physical inventions
                    - Public key encryption made huge amounts of money
                    - But the economic case is weak, except in the pharmaceuticals - to IT firms, patents are a nuisance many thousands of patents that are said to conflict 
                    - Software patents not allowed in Europe **in theory, often discarded by courts. **The court keeps stretching this - not to be believed. 
                    - In general innovation in CS very incremental - thousands of ideas in code, as opposed to a blockbuster molecule drug.
                    - So far only 4 CS patents earn serious money
                    - Microsoft has an open invention network, "trade patents"
                - Trademarks:
                    - Marks that distinguish your good or service (IBM)
                    - May be registered (®) or not (TM) - registering can make litigation easier. If registered, usually win in domain name disputes
                    - Can sue infringers, but have to show misrepresentation **damages your business** 
                    - McDonalds used to sue anyone with Mc in the name in catering - too aggressive. 
                - Copyright:
                    - Statute of Anne, protects your literary works - extending from novels and drama to art, music. **Beforehand, courts gave monopolies to businesses to write books of particular types. **Oxford making dictionaries 
                    - Is the main protection of software - No need to register but asserting copyright can make litigation easier
                    - Duration of copyright has steadily increased, lifetime + 70 years. Walt Disney
                    - Protects against copying - but fair use and fair dealing get outs from criticism
                    - Moral right - **right to be recognized as creator **remain yours even if copyright is sold. Can refuse that your sold work be published if damaged
                    - Many orphan works, where author not known. This stalled the Google Books project
                    - How to avoid software having thousand of competing claims -  Stallman GPL Licence if you use free work, yours additions must be free too. BSD license allows companies to use as they like
                    - Creative commons gives a general framework for sharing 
                - Other IPRs 
                    - Specialist rights
                        - Database rights 
                        - US semiconductor chip protection act
                        - Plant breeder's rights
                        - Design rights
                    - Rights based on contract
                        - Materials transfer agreements 
                        - Confidential information NDAs
                    - Limits - employers cant restrict knowledge that becomes part of the tools of your trade - if become very good at coding at Google, can go elsewhere
                - DRM - Digital Rights Management
                    - Copyright owners panicked at printing, internet, cassetes 
                    - Huge push to introduce DRM - but shifted power to Apple, Google, Amazon from old-style record companies
                    - US law made it illegal to mess with DRM mechanism
                    - Lexmark vs SCC case allowed for reverse engineering for compatibility - allowed people to circumvent Lexmaark ink cartridge certification
                    - October 2018 - John Deer put software in tractors that made them stop working if taken to unauthorised repairers - **breaking this legal, but selling tools to break it illegal.  **Reverse engineering for compatibility allowed
                    - Open-source tools grey area still
                - Strategy:
                    - IPR often a combination of patents, software copyright, MTA
                    - IT industry strat, patent portfolios mostly defensive, used to get access by cross-licensing
                    - Compound models, GPL the linux version and sell the Windows version - can then charge for support and other things
                    - Startups: VCs like to see some IP
        -  _**Lecture 6:**_ 
            - UK Law and the Internet
            - Computer Evidence:
                - Until 1968, relying on computer evidence was akin to hearsay - e.g. if Fred says something, Fred should speak in the witness box. **Civil Evidence Act 1968** solved this, computer must be operating properly.
                - **Police & Criminal Evidence Act 1984**: Required evidence to be brought by an expert that system was operating correctly. Now replaced by presumption that its operating correctly, if disputed the relying party must demonstrate their computer works right
            - GDPR:
                - Applies to EU firms from 25 May 2018. Law has survived Brexit, unchanged so far. If Uk changes too much, EU might stop sending data. **Applies to those who process data about people residing in EU** 
                - Aim is to protect the interests of the Data Subject. Differs from US privacy protection landscape, companies **volunteer to not do types of processing for privacy.** 
                - Six Principles to be compleid with, data must be:
                    - Fairly and lawfully processed
                    - processed for limited purposes 
                    - adequate, relevant and not excessive
                    - Accurate and up to date 
                    - Not kept in  a form that identifies for longer than you need it 
                    - Processed securely and protected against loss or damage - losing just as bad as having it stolen
                - Extra protection applies for "sensitive personal data" - health, about political affiliation, trade union etc.
                - Requirements to keep internal records of your database:
                    - Who you are, the type of data and who provided it
                    - Retention schedules, how long until its discarded or anonymised
                    - Security arrangements, technical & organisational 
                    - Details of transfers (especially when 3rd countries involved) 
                - Essential to identify why processing is allowed:
                    - Consent: for each purpose, data must be freely given (no bribes), specific, informed and unambiguous (no pre-ticked boxes)
                    - Contract - will say what data gas company keeps and who they share it with
                    - Legal compliance, banks have to keep some data
                    - Vital interest of a human, public interest, legitimate interest (have a legitimate reason to process and run their business - complex), member state specific reasons, crime & justice ... etc 
                    - Must get permission from parents if under 16 (UK: 13)
                    - Regulations apply all across the EU right from when it's put in place, unlike directives. **Intent to have consistent set of rules across EU.** 
                - GDPR provides the following rights for individuals:
                    - The right to be informed - privacy notice that explains processing
                    - The right of access - systems need to be designed to provide data
                    - The right to rectification - complicated when opinions come in
                    - The right to erasure - if you have no compelling reason to keep the data, right to remove it. Google has this problem, man was bankrupt 10 years ago and didn't want that to be on Google.
                    - Right to data portability - allowed to get a copy to feed it into a different system
                    - Right to object - they have to record this, can hold but not process or remove
                - New systems must have data protection designed in - may have to do impact assessment
                - Data breaches must be reported to regulators **within 72 hours - **plus a req to notify data subjects (if data high risk) 
                - Fines can now be much bigger - used to be 500,000 now percentages of world wide turnover! BA got a 1.5% fine got reduced to 20,000,000 as shopping cart got hacked
                - Firms processing data at scale (& public authorities) must have a Data Protection Officer
                    - Can be a contractor
                    - Must be capable of advising on GDPR obligations
                    - must monitor compliance with GDPR
                    - must report to the board and cannot be fired for doing their job!
                - DPO optional for other firms, but must have sufficient staff & skills to discharge their duties under GDPR
            - **Computer Misuse Act 1990:** 
                - Various hacking activities in the 1980s, prosecuted with forgery or criminal damage legislation
                    - Gold & Schifreen gained top level access, altered messages in the Duke of Edinburgh's mailbox. Originally found guilty and fined, forgery convictions overturned on appeal
                - Failure of existing legislation to be effective led to legislation cover hacking, virus propagation etc.
                - Section 1:
                    - Unauthorised access to a program or data, - need to **know **it's unauthorised 
                    - Need not be a specific machine (or in the UK) 
                - Section 2:
                    - As S1 but done with intent to commit another serious offence
                    - Raises the stakes from 2 to 5 years - s1 was a mere 6 months but amended in 2008
                - Section 3:
                    - Unauthorised modification - tariff is up to 10 years 
                    - Intended to make virus writing illegal
                    - Added denial of service of attacks in 2008 - **unauthorised modification to your service.** 
                    - Making/distributing hacking tools is illegal since 2008 - confusing when white hats use
                - Case Law is Chequered:
                    - Fines often much smaller than damages caused 
                    - Only around 20 cases a year, often easier to charge under Fraud act
                    - Paul Bedworth got off on an "addiction" defence - couldn't know what he was doing was wrong. " alleged that Bedworth and two others modified code at the Financial  Times share index, and disrupted research work at a European Cancer foundation.   
                    - Whitaker convicted (but conditional discharge) for not disclosing a time-lock that froze the software when clients were late on making payments
                    - Pile convicted and received custodial sentence for writing virus
                    - AMEX case shows multi-level access can matter - not entitled to access part of system so unaurthoised access
                    - police officer found to access data on a car parked outside ex-wifes house to find out who it belonged to. **Found to be legal, but subject to disciplinary action** 
                    - Wimbledon case, mail bombing with 5 million emails is an s3 offence - test of unauthorised becomes "If I were to ask would they say 'yes'" I.e. Can I send you 5 million emails, No.
                    - Cuthbert ("tsunami hacker") convicted of s1 offence for trying out ../../../ URLS. Donated money and poked around in the website, lied to the police.
            - **Electronic Communications Act 2000:**
                - Part II - electronic signatures:
                    - Admissible in evidence
                    - Creates power to modify legislation to allow the use of electronic communications or storage
                    - Not as relevant in practise. Most companies care more about if you have the money, than who you are
            - Investigatory Powers Act 2016: 
                - Replaces RIP Act 2000
                    - Much remains the same, but legalises lots of things that Snowden revealed - made to allow GCHQ and the NSA to keep doing what they were doing before
                - Deals with interception - revealing content other than the sender/receiver 
                - Deals with communications Data 
                    - Metadata describing communication - length of communication, IPs, etc.
                    - Provides for retention regime by ISPs
                - Permits equipment interference (with a warrent) cop put malware on your system
                - Permits bulk initerception, bulk acquisition, bulk equipment interference and collection of bulk personal datasets. Allows GCHQ to access all data coming out of UK, get all database data from Swansea etc.
                - Interception:
                    - Tapping a phone, must be authorised by warrant signed by the Secretary of State:
                        - Product is **not currently admissible in court** - would only disclose some of the information, as don't want to show the holes in the collection regime.
                        - GCHQ can scan international communications for "factors" (keywords)
                    - Some sensible exceptions:
                        - Delivered data
                        - Permission from both parties
                        - Stored data can be accessed by production order - just a judge
                        - Techies running a network, can intercept for debugging
                - Lawful Business Practise:
                    - Regulations describe how not to commit an offence under the RIP/IPA acts. Do not specify how to avoid problems with data protection legislation or other relevant laws.
                        - Only applies to business
                        - Must be by system controller
                        - For recording facts, quality control etc
                        - Detecting business communications
                        - Or for keeping the system running
                    - Must make all reasonable efforts to tell all users that interceptions may occur
                    - RIP Act 2000 - Encryption:
                        - Still in place, deals with encryption
                            - End of  along road, starting with "key escrow" where encryption keys had to be given to the government
                        - Basic requirements is to put material into an intelligible form - can be required to decrypt
                            - Can apply to messages
                            - Stored data 
                            - If you claim to have lost or forgotten the key, prosecution must prove otherwise
                        - Keys can be demanded:
                            - Signed by Chief Constable
                            - Notice can only be served at top level of company
                            - Reasoning must be reported to commissioner - ensure different police forces use the power consistently
                        - Specific "tipping off" provisions may occur, must not tell anyone you've been served the Notice
            - E-Commerce Law:
                - Stayed the same after Brexit
                - Consumer Rights Directive (2011):
                    - Remote sellers must identify themselves, and where they're based 
                    - Details of contract must be delivered, email ok
                    - Right to cancel (unless service already delivered)
                - E-Commerce Directive (2002):
                    - Online selling and advertising is subject to UK law if you are established in the UK - no matter who you sell to
                    - Complexities if foreign consumers have rights in their country, **the test is if you marketed them. E.g. £ and all in English, clearly advertising to UK people** 
                    - E-Commerce Directive also provides key immunities for ISPs:
                        - Hosting, Caching, Mere Conduit - if you do any of those things, not your fault if there's bad things on those.
                - Privacy & Electronic Communications:
                    - Rules on phone directories and location info etc
                    - Bans unsolicited marketing email to natural persons. But see your ISPs acceptable use policy
                    - Controls on the use of cookies, superceded by 2010 legislation
                        - Must give clear and comprehensive information
                        - AND must have consent ...unless cookies are strictly necessary for provision of an information service
                    - Was intended to be replaced by time GDPR in force - now left EU not clear what will happen
                - Lots of other Legislation!
                    - Lots more E-Commerce stuff:
                        - Sale of Goods, Contract law, Unfair terms, Unsolicited faxes etc etc etc
                    - Lots of rules for adult stuff
                        - Children stuff illegal
                        - Extreme porn making + poss illegal
                        - Obscene publications act - webmaster conviced
                    - Lots of other specialist issues
                        - Fund raising for political parties
                        - Selling age-restricted goods
        -  _**Lecture 7:**_  
            - **Philosophies of Ethics:** 
                - Ethics:
                    - Laws are often 10 years behind, and even then don't often fit reality very well
                    - Practical Ethics - in what circumstances should we restrain ourselves, more than the law requires
                    - Analogy: medical ethics constrains doctors behaviours - how can we form these for software developers
                - Philosophies of ethics:
                    - Often authority theories arise, coming from religion - these often have disputes that need to be resolved. E.g. should slavery be legal, scriptures often allow for it.
                    - Intuitionist theories say we can tell what's good or bad - but intuitions can differ. 
                    - Egoist theories say people act rationally in their own self interest.
                    - Consequentialism:
                        - If an act is right or wrong depends only on consequences.
                        - If more positive acts, the better or more right the act
                    - Maximise $W = \sum U_i$ , however the consequences cannot be worked out in detail, and welfare is difficult to define.
                    - Ticking bomb argument, torture should be allowed if terrorist knows the unlock code - does the end justify the means
                    - Modern debate: act vs rule utilitarianism
                    - John Rawls ‘Theory of Justice’: we should make  moral decisions about a society behind a “veil of  ignorance” of whether we’ll be born high or low  
would you rather be reincarnated in the USA or Portugal - poorer but with better welfare.
                    - Aristotle: Consequentialist theories are for beasts, you'd be happier if you were stupid. Prefers people acting in accordance with nature and duty
                    - It's not all about the consequence of actions, but the motives as well.
                    - The many flavours include Kantian theory of duty - act only on maxims you'd like to be universal, and treat people not as means to an end
                    - John Rawls Theory of Justice - should make moral decision based on ignorance, ignorance of whether we'll be reincarnated poor or rich - leads to maximising $W = \min U_i$. 
                - Moral Reasoning:
                    - Koglberg's theory of moral development
                    - -Pre-conventional:
                        - Stage 1: Punishment and Obedience (greater the harm the greater the wrong, law breaking morally okay if no punishment) - act as if doing wrong earns punishment
                        - Stage 2: Instrumental hedonism (Conformity to gain rewards)
                    - -Conventional: 
                        - Stage 3: Conformity, what is right is what your family views as right. Conforming to those rules preserves relationships. Fulfil social roles
                        - Stage 4: Authority and social order, what is right is according to authority and duties 
                    - -Post Conventional: 
                        - Stage 5: Morality of contract, individual right and democratically accepted law. Rules based on consensus, lawbreaking alright if based on social justice and preserving human rights. Changing laws preserved to breaking.
                        - Stage 7: Morality of universal principles of conscience. Behaving in the way that one believes to be right, hold beliefs and behave in line with them
            - **Professional codes of Ethics:**
                - **ACM's code of ethics**, a computing professional should: 
                    - Contribute to society and human well-being
                    - Avoid harm
                    - Be honest and trustworthy
                    - Be fair and take action not to discriminate
                    - Respect the work required to produce new ideas, inventions, creative works, and computing artifacts
                    - Respect privacy 
                    - Honour confidentiality
                - Responsible vulnerability disclosure:
                    - If vulnerabilities found, do we keep quiet or tell everyone at once
                    - Responsible disclosure: confidentially disclose to those that can remedy or mitigate the impacts - heart bleed. Meltdown and spectre
                    - Bug bounty programs
                    - Should we make it public, if no efforts are made to fix the bug post responsible disclosure
                - Ethics in research
                    - 1940s: Nazi human experiments
                    - 1930-1970s: Tuskegee syphilis experiment
                    - 1970s: Stanford prison experiment
                    - 1960s: The Milgram experiment
                    - 2010s: Facebook emotional manipulation study
                    - 2019: use of organs of executed prisoners without consent in China
                    - People now screened before research, trauma, mental fortitude etc.
                    - Nuremberg code:
                        - Voluntary and informed consent of subjects essential. Must be able to leave the experiment at any time
                    - Research Ethics Boards  - declaration of Helsinki independent review board or committee
                    - Research funding bodies must consider ethics
                    - Program committees and journal editors, consider ethics after research is done but before publishing
                    - Professional ethical guidelines or codes of practice - ethical framework that provide ethical guidelines
                    - For Computer science: The Menlo Report:
                        - Acknowledges the speed of distribution of computer science research
                        - Core principles: respect for persons, beneficence (minimze harm, maximize benefits) , justice (risks and benefits distributed fairly) and respect for law & public interest. 
                    - Your Part II project may involve human experimental subjects
                        - Independent review by uninvolved scientists greatly reduce risks of civil litigation and criminal prosecution if things go wrong
                        - Pay attention to the procedures for ethics committee approval - if they say no don't do it (unlike Cambridge Analytica).
        - 
    - Semantics
        - Semantics Supervision  1
            1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/EWCgcOK-lZJ6GXtKgqpmCeQA2MFAPMXNYxRMBbtq1Xo64BIrKQCe2_wG2RV3mMZDM0vlnXIIDh2jgmHZ7JV5hYlLSXv7Nh7gdgyv65mlLn2cT_dn6BefcHmjX5Q-Un2e.png) 
                - ```python
l2 := 1;
while !l1 >= 1 do (
	l3 := !l2;
	l2 := 0;
	while l3 >= 1 do (
		l2 := !l2 + !l1
		l3 := !l3 + -1
	)
	l1 := !l1 + -1;
)
l1;
``` 
            2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5Ris8GT10bHMokG27aJov3qS-y0LOsB4EbaA3x1h1pbTkoRyJWK9FX4GYRcTAdUtR-ckWJZ8cnaVcBBGlOy6idjILbTxVkbiAEgSiSujgYSpbiCSXSOq3cc6xGtHBf4x.png)  
                - Assign1: $\langle (skip); (l_1 := (!l_0 + 2)), \{l_0 \rightarrow 7, l_1 \rightarrow 0\} \rangle \rightarrow$ 
                - seq1:      $\langle (l_1 := (!l_0 + 2)), \{l_0 \rightarrow 7, l_1 \rightarrow 0\} \rangle \rightarrow$ 
                - deref:     $\langle (l_1 := (7 + 2)), \{l_0 \rightarrow 7, l_1 \rightarrow 0\} \rangle \rightarrow$ 
                - op+:       $\langle (l_1 := (9)), \{l_0 \rightarrow 7, l_1 \rightarrow 0\} \rangle \rightarrow$ 
                - assign1: $\langle (skip), \{l_0 \rightarrow 7, l_1 \rightarrow 9\} \rangle$ 
                - $\not\rightarrow$ 
            3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PU6c_xWMwTB5BMOi_AkS3jCdEHAoljIZzyNF1tKO8M5b7SWREeV8y14p8GfIL5rYW4YehyDDK53ae1Lbm1Agt0aUFcc-bcBJTW_NXNnZsDT23rxT1KosrOxxyUvB6YkD.png) 
                - Assign1: $\langle  (skip;0)+(l:=2;0),\{ l \rightarrow 1\} \rangle \rightarrow$ 
                - seq1:      $\langle  (0)+(l:=2;0),\{ l \rightarrow 1\} \rangle \rightarrow$ 
                - op1         $\langle  (0)+(skip;0),\{ l \rightarrow 2\} \rangle \rightarrow$ 
                - assign1   $\langle  (0)+(0),\{ l \rightarrow 2\} \rangle \rightarrow$ 
            - 6)
            - 7)
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Rc4c9TOhFHPbRYzj828cEU4_JRuZDmfE-v24Gu_YmS6y--EURzhWW-PMU88sEU22nb49y_9OYtEjwwEdB_PleXYOnxhWitd-yfqix22QhzlPCYXoVZTXboLjKpahlJJQ.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Jc0qhbdhd-lL9d7htzVB0_f9SqP9bb5cg1QrRt-2_XH6PLNFBcCgD0PslnWjyxw__WxN4QVXJjagXmCzgDniPmUKrGjhscxgVhtRB8CdcFzhVshxtcn2trM9rlsZMn9w.png) 
            - 8) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tphLaWwDL-YsZsNbnqyIY3lPP1hldIbTHJjTmHTf32HFBRl65rLnYtqVRM6pgTP8FCPyBd__LGWK4u1OgePF-XJQuSVxTgMWJ4kxnnMBdwSzgPEuCnol18OwFxHrv_y4.png) 
            4. 9) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qWfnPEWfH_HIYJemqT-IHCZx3cpmYU4lSexlKMO_mKxcgZzZw9j6HqDFubB9XnHoPVzY1gO3e4NRsLSceJ4jPHuDdtlSIX0w8DPVnLA4Z84VFK6YPlm2P36wGpaDocVO.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Vx3Ur63En_V4zF2JiCllUlKE3nqF6yIrgRJgxZDUTiVBZbtgPw95U_0dzJ9ArCj0M2dHGq0ShIQvgEU7-qOfFNlq71eF0K92PslbFFBcAfcdHZe2JftJGAqZdtED7v6t.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E7T2oUrHiW5yHfKarhk0Rw6izgx2OfDpiJeCAOGa7s0oL6DieyFBMB28SgTmCmvKGdjPiEmjsPbeNy5KSJZaTM30AIA4oJYf3Mu9mm24NPYbMmqtuFjMnQp_SGLdEvp0.png) 
                - N̶o̶,̶ ̶i̶f̶ ̶e̶ ̶i̶s̶ ̶v̶ ̶i̶n̶ ̶v̶;̶e̶2̶v̶;̶ ̶e̶_̶2̶ ̶v̶;̶e̶2̶ ̶​̶ ̶$v; e_2$ ̶ ̶t̶h̶e̶n̶ ̶v̶'̶s̶ ̶v̶a̶l̶u̶e̶ ̶i̶s̶ ̶a̶t̶ ̶f̶i̶r̶s̶t̶ ̶i̶n̶t̶,̶ ̶b̶u̶t̶ ̶u̶p̶o̶n̶ ̶t̶h̶e̶ ̶n̶e̶x̶t̶ ̶s̶t̶e̶p̶ ̶t̶h̶e̶ ̶v̶a̶l̶u̶e̶ ̶i̶s̶ ̶n̶o̶n̶e̶ ̶  - No cant step in a section of a statement.
                - I believe type preservation does still hold, I don't see how assign1 could change that, as the type should be unchanged - and seq1 shouldn't affect the final 'return' type, as we evaluate left to right - meaning our new int value is stuck at the front.
            - 
        - 
        - **Assorted Flashcards** ↓ 
            - What is a transition system?―A transition system is a method of describing changing state. We take a starting configuration, and have a transition relation $\rightarrow$ that goes from that to the next state.
E.g. $c \rightarrow c'$ means c can transition to c'.  
            - When is a configuration stuck?―For a config  <e,s> if e is not a value, and we cannot transition from <e,s>
            - Describe three things about language design we could vary  ↓ 
                - Could make right to left evaluation of ops rather than left to right
                - Could make assigning a value return that value, rather than a skip
                - We can only assign to values when it's already in the domain of the state at the moment, we could change this so we initialize a new l we we assign to it. Or assign everything to 0 initially. 
                - Can only store integers in L1, could change this include booleans, programs etc.
            - What does ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FGsB9CKnsytJMJO9kGgtdJDZbofaYdVyABkS2ofVlkGDUsWqLT2oN_f_np8Flp12NkjY6pN3GqAHPpz3oqGnqrAc8dsGQTyjHmu6-k95-YxQgrjhzrHLnoyq_qRtv71z.png)mean in words?―Means $e$ has type $T$ under the assumptions $\Gamma$ of the types of locations that can occur in e. E.g. $\Gamma$ is the fact that $\text{l1:intref, l2:intref...}$ 
            - What typing rule would you give if checking if $l ::= e : unit$―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V9e4T22_6_Ir_uMLFZi9vC0lDGX1yXPgyDpYaDJSWIs4EPhgQM4WkaGKEzz3h4lcSEmfs4xMqWcjFkMTGBURuar_YZmZJzHK1UmwTHl8e9WFBJBOoCrT_63pBB-Phspc.png) 
            - What is the progress theorem?―For <e,s> If we have ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JukJZtGp45sM6SjvPpmc93WFCkf7FT-glJPkwPNg8m1eYI9w6rV-CMjx0EQ30w_v8cK37uw5A9Qarx_yJ7gddjVcaQ7qxIzIl39tKD3fhY6gc6QOUq9bMF4jLY1yn3eu.png) i.e. The expression e is of type T under the assumptions in Gamma, AND the domain of gamma is a subset of the domain of s. Then either e is a value OR $\langle e,s \rangle \rightarrow \langle e',s'\rangle$. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pgg5f-2Us-DBod_3-Wzwg-jGiwfSVkUk54Mtyz9hJaYyh5f09HPRxUPnlqewNKQZogsqgc3339aPQ-0tVcvkeSjdlQKZ7xedAsKXAwKkUAElnRzJwoiwr0BleOcD8qwC.png) 
            - What is the type preservation theorem―For <e,s> If we have ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JukJZtGp45sM6SjvPpmc93WFCkf7FT-glJPkwPNg8m1eYI9w6rV-CMjx0EQ30w_v8cK37uw5A9Qarx_yJ7gddjVcaQ7qxIzIl39tKD3fhY6gc6QOUq9bMF4jLY1yn3eu.png) i.e. The expression e is of type T under the assumptions in Gamma, AND the domain of gamma is a subset of the domain of s. Then for  $\langle e,s \rangle \rightarrow \langle e',s'\rangle$, the domain of gamma is a subset of the domain of S AND the type is unchanged in e'. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V2a5kIFsh6g61wmDc-I6UpZWjZ0hK0LjXUXZfRS214lap4uus0afHjLg7nVBJ5T8lB_tB1IZjEWDazb0rwCfd3Pblo8QgAfplkDIcj0yonbsrXZDzDD-5mDJwCNTtk99.png) 
            - What is the safety theorem―Basically states well typed programs don't get stuck: 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bn5D8DStQPXLtxSTxcGJugDLZ_GOX6wWFGW3qwyIOZiu3I-cHlzw39y8oZj1AlPZ3WaIRfaPqBIKIHSosnJlM0NM5_DwkPxro7jsueoF2FdhDoBYOZMGAsC9RCqYyAHV.png) 
            - What are the type checking and type inference problems?  ↓ 
                - Given $\Gamma, e, T$ type checking decides if $\Gamma \vdash e:T$ is derivable  
                - Given $\Gamma, e$ type inference decides the type T in $\Gamma \vdash e:T$ if it's derivable or show there is no such type.
            - What is structural induction?  ↓ 
                - To prove a statement $\Phi$ about expressions in a language, it is sufficient to prove it over all leaves of all tree constructors in the language. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PQj8TAUbRs-mDTnkEvfaEc-kfCS4KOMXgVd5TSv1sdRT5RyPwTMnVLwiOf1NqHtRPJIjJwloOntA-OK3tO6D8CVZZRgD7rvJCJll-3kF5THNP_sbcAX7kylbAQmhlYa6.png)
NOTE - if one of our $e_1, e_2,...$ have and expression inside them **we can assume **$\Phi(e)$! 
                - The tree constructors are all the expressions, and the leaves are the expressions within the expressions e.g. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/n51vL-XzcfF6JK-LdnTBblSfahhNkDccoQ9b2boGtj0-lA6YiucWDoTtqDmeZWVSYFW8K3db5Dh14oX0hm4gP7Fd1a-a4KHUWcVNZUnHkh9cNFs1F2j69gPTV4fFv0oO.png) 
So for n, need to prove $\forall \Z. \Phi (n)$ - for b, need to prove $\forall k\in \{true, false\}. \Phi(k)$
For e;e need to prove $\forall e_1,e_2. \Phi(e_1) \land \Phi(e_2)$ 
etc.
            - How could you prove: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8697WgBoxCs5V-dwhjdfNp66Zk04tED2t7mWb69wPGu4uOv-eF42w5YalKNVyOh7wyp_rvR4BFprd1At7WRSYCBrQEh_3f2dJQHpE0wEV-SnOSRqsCnug9Hoy6bn2wgS.png)―Given e is a value, it must be one of {skip, n, b}. Look over all the rules, and note for all conclusion <e, s> ⇒ <e', s'> there is no rule where e is a value.
            - What is Rule induction?  ↓ 
                - Rule induction that given a property $\Phi(a)$ of elements and any set of rules that define a subset $S_r$ of A, to prove $\forall a \in S_r. \Phi(a)$ it is enough to prove that $$\{ a| \Phi(a) \} \ \ \ \text{is closed under the rules}$$

                - E.g. for each **CONCRETE INSTANCE **of the rules ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/P1haDTvj1IK-bFi-kGCHgn2JWyFmYiqzPN4I0Nr8NnD_KgM4joAIReTb4Qy8GJFD85_9gl8rqmAGIUtHrl7TapoS6ghrEN8Cr-_UG3duKm5XIloxgC7tLYBV3sx48Qkc.png) we **need to prove**: $$\Phi(h_1) \land ... \land \Phi(h_k) \implies \Phi(c)$$ 
                - A slight variant exists, where the rules inductively define the set $S_r$ 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-8nKIRRTeP08oSzHzlIvkgdX-z3Xwwce2DWLMKe6tlsq4kaB2DVDj8zbfv30beT1K_0p0K9UG_g2fdZcxCaqJvoO1QJrWew8W_W7TlNcESUOQK5BEFxlk2BlE4y73Sne.png) 
            - What is alpha conversion, and how do we calculate it?  ↓ 
                - Alpha conversion is a method of removing name conflicts in function definitions.
                - We would like to be able to rename the variable (and any occurrences of it in e) in a function assignment, e.g. in $\text{fn x :T } \rightarrow \text{e}$ 
We want to be able to replace x with anything we want, **as long as we don't change the binding graph.** 
                - To do so, we build the resulting abstract syntax tree with the new variable and see if it's unchanged from the syntax tree with the old. If the new syntax tree differs, then we've got a name clash.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WXNWBpyOTh-RPMwL_7PONjnlS0bxnFG6p8C03xWed9Qw_PxabCLD-2jrEdkRwJXRpb5_YDZV3ePUHLMDfUispoig0exkLZDmZ5XVDbqZ1DXvgqbBwgqRPThAB1_8BVJI.png) 
            - What would the abstract syntax tree for ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QT63uYn4BkZjk7Qu1tY0jw_ZFZxLlVQPp-DztMtayIT7fpNn2EOXqUacIZQAt49LR0XQw5K0ObWMXS3cCdEu2nfAPnSzP_AAZ92C0fXR8qC5dJFFocoe0zU-OBRyTQeg.png) look like?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-kGuIej1WvA4wk2L78etriqkw_cRFtZZhMBAotirUvQ7R9t-Lr5ifcStdaWXcq4fH7RcP0mM8GskTuQa7b1CaZBFcy4zgKFLDxd4D3FT9M-J7eQt2370tcFnuTWPSz9Y.png) NOTE - we view f(y,y) as a partial function application tree. E.g. First apply z on y, then apply y on the resulting function.
            - What are De Bruijn indices?―Number of fn .:T⇒ nodes we meet while climbing to our one. 
            - What are free variables? When is an expression **closed? **Give three definitions to generate them  ↓ 
                - Free variables are variables in a definition who are not bound by a fn x ⇒ ...
"Say the free variables of an expression e are the set of variables x for which there is an occurence of x free in e."  
                - An expression e is closed iff fv(e) = {}
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iG_fyA0Gy7grdGfSvmggYKa7Ue8zKY81ngwbop4vl5gVxxFbHaLTcbryC64esZMbE0WRDKIGAjUseoPIFEq8Xf73Rxw230eYvTNsVgfKloo8F8A0Kucqrts6hgwQPOhx.png) 
There are many more:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/a5W9bn7WFU-2DvQGVAHQMSFFof9IKnN-HFXhQdUdoX4qgX9FeLb4y9rWM7gcqJiz6rbWSr2xDOpvnN_Cp3xtR6-DahplLNAy_eqBWjOJPq-maqkJHp4rHMAT6df9hRTn.png) 
            - What does ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-xhJi9CKqwF5ohkorEVt4TTbT5pwP4UTgzyFl-Djd_mK1w20-gNwoEu-IAdk7fTmE8jO5GGOzDzhJP-6HpP6zcGL7826aNcwkyfa62i_NPF6HBsy3WGdlz2Q9O3jCR5g.png) give you?―It gives you the result of substituting e for every free occurrence of x in $e'$. **NOTE: May need to rename variables to get a good renaming, as in example 3 below.**
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yAn5FUjMhWOj5mAn7XVe5G-sL2zMQZdH5ik66aB0Qq_c9f_5sq3N650LlKn-DdtGA3ZnYkPlfQl4YuhxJXfS3Ag6rHJ8BSs7WYx_ZFH1ukyPjq6TwD38ULefWBCGGI3f.png) 
            - Describe the 3 (discussed) ways of function argument evaluation ↓ 
                - Call by value, evaluate function expression to fn .. ⇒, then evaluate the argument to a value and **then **substitute. 
                - Call by name, evaluate function expression to fn ... ⇒, then subtitute the argument into the function. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UsWGQq5ZwyWU2GV95_fCAf2jPLlc7c_jf76jCzID2xk1Nt4_RMixZxvTVO8Ut0yuhJfY5hsDInzNYav_2Qh5eLaJzXcU9uy_lISUCUh2-KLKpgYiCrVkRXxr61NzHf1w.png) 
                - Full-Beta, evaluate the function or the argument, as soon as the function expression is evaluated down into a fn:... ⇒ then substitute.
            - How must we change $\Gamma$ to allow for variables?―Before we only had $\Gamma_{loc}$ representing the possible types of locations, but now we must account for the possible types of variables in some $\Gamma_{var}$. Note that Gamma is the union of both.
This includes x:int, x: int⇒int etc.  
            - Explain these:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zmgENwoOjtSRE0IbZQ7X9I2qECKpB7ZNT1JtcMz9cRY6dHL36GyZ9BQ4q2klC0W8t75XvR2rhVI22ZsohFVE-WEsg1ZGOursTAab9pMgwM6vyKQubHQoppvmKM9ckXn0.png) 
 ↓ 
                - (fn) is saying, if I'm applying some x to some e, the types are as stated **if** the result of e given x:T is that e is of type T'. 
                - (app) is saying, An application of e2 to e1 has a type T' **if **e1 is a function that takes Ts to T' s and e2 is a type T. 
            - What is the normalization theorem?―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AOK7Zlyqk6EfI20FaDd8EfVvL1psbkDdBXTqay4B67RTxvEx1taTQ0tEAR5xWBUMsAcIoRXf2pecNnEpvLrwXUS88IrTZ2HnFr3C1b7StF561RBZkkXQzFG4Eg_igL95.png) 
            - What is ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/24YwxJ5ATq6Y2rbEDDEy3FYE2AUAoSnMDMu0xN7kb7oTvBPifVRzHFPvi7CuRTlr7m3yyi87MgQYrQyYocPQ7ABe4_QYbnu5BU9I4xQS44NiIfAFSW072duAez99r5EN.png) syntactic sugar for?―(fn x:T ⇒ e2) e1
            - Why do we not use this ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DDFqwQ909AoVGEaOO4XKAPRVzI9C3FU5dlm05YbfuAOM-mnJlx8S7sGfPFLDcmPtIQtWRVSnWJzNT-gXzV8hhYJdxS9umbD1EetMWMQ-7vJ09T_PG0nrteK32KLcTYN9.png) to define recursive functions?―Because we can get infinite data structures, but because we're using call by value (not call by name) we'll have to do infinite work before we can use them:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PMzxlbgQyCdyUDjDy4V5O5vdtztZodkfmjcP0vrp8nE1BVbLfLuIV6CGRiYUPvOqpG9EbpB8gwaC2Rr61StPt3uGbRrtrkLqa74UVW8_6g2cVbmNY5gq0HC4NdbPe_7C.png)
We only want to allow recursive definitions of **functions, **not weird infinite data-structures - so we specialize our let rec fn to only allow for function input.
            - What is this saying: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/94kgNR1zF1TeZ0raED9CnCLej63BejH0CfdyOeGFamu6j3b8eTVeqTYsRgDXs8F45St8J2fyLLZDZr5ZPXeC0oPkyXgGKzfPNVifwB67X0453OSQAWa9wWb5If_JXpVl.png)  ↓ 
                - First part means, if we bind x to a function type and y has the same type as the input. Then the result of the function ($e_1$), should be the same type as the return type of that function.  
                - Second part is saying, if x is the function as described - then when subbed into $e_2$ we get the $T$ we would expect. 
            - What does this code do: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SLTMYgMcv1YdZhtkItM0pjlYy7UNhj00LwzYcnjomR0dLFke1vZDG56tqbXsotU4k0bNTNC4QJygqnTagaAaiA5sJ3Juj3to2I2zeRivT2Wdxuj92bv6sBPm_MyfIYN4.png) 
NOTE that **the definition of f isn't that important.**―This takes a function f, and finds the smallest number z s.t. f(z) <= 0. 
            - Explain this, I fucking dare you
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HyLWMoVd6wYvkodTpQWTLLwIuDlbiOOeRGFEPiZvTuSQ0FXgXxa89xx1jmHM_LavHEESNN8jSmPaDVpCIj7Y8fBXz-Von2i4enUNfPn1-in9jIDluTM5c7ZPE6bFEpK4.png)―If e is a Sum (Top line), if the real type stored is $x:T_1$ then substitute that into e1 - if the real type stored is $y:T_2$ on the other hand, substitute that into $e_2$. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8JCr-f2i5Wu2IXmqcSpdqZOu5AIFDpZmA6MjUP_ir3W10UWJMAnowNCVw9DRqCISIS9HD0j6-A6lLHeksYZFLpRuVb1odQRRQzdYqVHtuzmpfC-pp2LKWmugH4eIKIeB.png) 
            - Describe these three equivalences in the Curry-Howard correspondence:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/iBv8YLPpYUCOCfLCQPLZqVCH85-XwQLj1mCfZpCFs6mIlZ8Jt2IIqquD3aEe31ApNYC0s71dW9WIPAiVTuCUjSy5nK_K05Saq9f-_duFarxa9t5BoPOpfOqeL55Rc5L7.png) 
 ↓ 
                - (var) Says if you assume P - then you can prove P.
                - (fn) If you assume x is of type T, then you can use that to **prove **that e is of type T'. 
In other words assume P and show P' 
                - (app) If e1 is of type T⇒T', then when we apply a T to it, we get a T'. E.g. if we have P implies P' and P. Then we must have P'.
            - What is this saying ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/i2JDmBgsxaToq_IwICqE6_MEvD3c8OjymIbkabeb0Eo4vftoHmYv_2Ln8c8iLoA7K1cUWoZu0ThYv7dHALDA9_mQYk1nqGrwf-_RH0bBkFKRrVau3T7D8ORSJB27wkn2.png)―This is saying we evaluate all the expressions in our record before we can use it. Moving left to right, we evaluate it all haha!
            - Why is the location of a reference typed? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mpHvxqyNuBAVY7ERGHNeUBCHSGUNXKfE0SiNggcJ14aWxUo8MypI31ht0kgCUVTx_1Kz2J6u892GAcVHPZyulWX9C6t816L1za6jWQAHJ42_uExDqNBtMMJ-d9gTY3le.png)No other value is―Because we want to be able to return and pass these around, need to check if it's correctly typed. We want to decompose a e ref, down to a location - like we decompose addition down to an int.
            - What in god's name is this saying:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/2Ysd9Mj6Utk66IITzgP0f8d4Sylwg6aN7xcp4Ca13EJpYKZi2VLOzg0MN0qx55D5i_f5TM56h2Dwbv7IC0wysnjI82mZfXoGLxyufpNPj7TjMRnpj5uY2VvCUruvzkQ_.png)―$s$ exists under the assumptions $\Gamma$, if all the locations of f are of type ref according to $\Gamma$- and they are of the same type according to s. 
E.g. all the types of locations mentioned in gamma are compatible with those in s.
            - What is this saying:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/260M0_xJ_XP8J1-s4QsI_Y94UH-uB-QngJb970-30FI6r_VDeLh02eI3NTC_0kKXbkq4hTtMxgoK6QxhiHS65DS8AKCMHxtpb8Q3c1YGbUkEIJOoKW0njE9w9DB_hU7S.png)―When we advance, our gamma needs to change as we store more things. So $\Gamma'$ is the new locations added by this transition. 
            - What is this saying:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gC-CSXA_xVT5DoRU3KB1uPzDySONqpeW2RD-WurosZrWot8mE2vzeg9QHge4TZzdhRxhZWv9rf7T36-Ldt9O1F95e49lDremDSDPwZlo6KJKvVgDakSliPwEwjyMWPsw.png)―It's saying we take $\Gamma \vdash s$ to mean s is a well typed store, if they have the same domains (same reference names) AND for all of the locations in the domain of $s$ they have the same types. 
            - How do you type this? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/eMoUmEe2lBynzG4BBzB6qdrRahtV6H1xiSubbPqtHmbVf6VrC0bkwcLDvHAtjktNSHgJYR3LdrmnsxtZ7a7SEHw9JCLJpFMv1Y6jy_8WXt-FROwDHXc5S1KuvlXeoSjV.png)―You can't without polymorphism, even though we're giving the function an argument with **more **information than it needs ({p:int, q:int}) the function is specifically looking for {p:int}.
            - What does this mean![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7mKRu62sVSjq84FzeHgQfrL3VTWThwMPwRJT7tFBSlQvZ6BuQReju40s6af60LnuAZe06RQZK9LfgbxL2WCgk3rP0QrE5lA9yAgmezBNa-2Br2tv8LNnLnnM4rH_v0D1.png), then explain the subsumption rule ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/r9s0UVVgEOT67H2DRTmLfLGFZeD0BaNBEa0g9MJuyY1VlXmL7KlzCJwsFmWtK2tFujBMSjziFrroGFpFzvxqmU-38G7XnesPyijmGUuKSbmA77KRCbV2W8nfe1k-8Qqs.png)  ↓ 
                - The subtype relation means that T holds more information than T'. E.g. {p:int, q:int} `<:` {p:int} (I know it's annoying that it's less than...)
                - The subsumption rule says that if we have an object of type T, where T is a subtype of T' - then we can use that type T in place of T'. E.g. we can use Dog in all the places the Animal class can be used.
            - Explain this if you're so smart
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QoN1zYPl_id5ctmepYafvFk9Hk44RDav4J70D_GBj0wHO-A98Fu-L7g7v8AxwyR4bugvlPrK123TG29gRqku8GC1IInxAuZAuSwffYVxL9KqaXnEkLES4HeJvwkvWbHh.png)
 ↓ 
                - The right half is straight forward, if a function T1 ⇒ T2 is a subtype of T1' ⇒ T2' - then then output T2 must be a subtype of T2'. E.g. if our function is a subtype of another, it must output MORE information than the other function
                - The left half says, that our input must have lesser or equal information than our parent function. 
Say we had a function int: double_value(int) and we augmented it so it also outputs how long it took to compute:  (int, float): double_value(int) - This is a subtype of double value, **however **if we augmented it to also take the time to prepare the input:
(int, float): double_value( (int, float) ) 
This is no longer a subtype! Consider, that this can no longer be used where int: double_value(int) could be - we can pick off the float output and use that, but we don't have a float to input!
            - What's the justification for this typing rule? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/SnbaQ5631RRuGwlu_SB53QPtV_3AvWLFRgPR37-Vi20oPR0OjaTClfHwD62EOrsN565cCqdq4JUkvCPU85MS6Yt0N1Vk66QgIWoohMRx5lymWof8JtU3w9BS9EyJzqWD.png)―If T ref is a subtype of T' ref, then we can use T ref as a T' ref. Then if someone stores a T' ref into a T ref (when it's being treated as a T' ref) then we need T' to be a subset of T for that store to succeed.
            - When are two expressions the same?―If you can replace one by the other throughout any program without affecting the result
E.g. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/WV1nOzM7-JXpFaSb86AvOAO4s-LwHNkOXky3pa7dLqY47kbptQCnbpey8tfSr4cmXvzI2eKKv0yT59naf2SETBCEjwYoWL5JLKh1RI0UnANlgAHWG1cX2u8aVj3mWwOZ.png) NOT THE SAME
We can't smack them into an arbitrary program context and get the same result:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jKk0F-jKwXgg__U3m0SovYjDWmtzUDg4GST2s_-RA8bQv8-xjHzM7s7Ki_YPBYqgEJg6rt1TgzGFOcQ36tG6rX3LkIeyN7UzXObloyuMkht6S8vzWq390h8zN9wTz_DZ.png) 
            - What does this mean? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JHSdqkHoD5o3io8fuCbuwqedkl9tp0D-qEirYooWhxjal4h3p3gKUX5kEbemIgnp-OKltZAr96Tz4t1_d64SbDbcDywOahuschac8JoxKGO-TFOyh5Zfq2cTSnUZj0Jq.png)―If two programs are equivalent, then either they go into an infinite loop - OR they resolve to the same value. This does mean any infinitely looping programs are the "same".
            - What are these congruences useful for? 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dmOIhkV1NgFH4-7KNNSxxgkiKrdLVTNyTbJBVtrz9yhLiDQbMH-wLOLgvmk67mV_IyUIWnlXOrErhuXBv4fq0oA-Riwua3dYnotWmWOCdMViwuksf5vJtCjNNLkfjKdG.png)―These define all the places we can plug in an expression, whenever we plug in two congruent expressions - they **must **result in the same output and type. 
            - How do we prove congruence of two programs? ↓ 
                - We need to prove, that when we have two congruent expressions $e_1$ and $e_2$ that either both loop forever, or both evaluate to values with equal stores - We prove that if C[e1] is infinite, then C[e2] is infinite. And if C[e1] is finite, then so is C[e2] and they finish with the same values.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/c2ZMEtWWszgazG-3cl7GIz4zGOT-pykDYdLgNUUErfZxbCf6XCyknSNwXY6as3UmB4Mj8WYB7XQ5dutGIeiSguq4laS-_Rt25QhnvkM3sBv8rXcYa5PrLkhUdSkzMLcH.png) 
        - 
    - Data Science
        - Supervision 1 Work
            1. 
                - ```python
import numpy as np
import matplotlib.pyplot as plt

def circle_func(x):
	y = ((1 - x**2)**0.5) * np.random.choice([-1, 1], p=[.5, .5]) + np.random.uniform(-0.03, 0.03)
	return x,y

def smile_func(x):
	x = x/2
	y = x**2-0.8+ np.random.uniform(-0.03, 0.03)
	return x,y

def eye_func(x, left):
	x = x/20
	if left:
		x -= 0.4
	else:
		x += 0.4
	y = x*0+0.3 + np.random.uniform(-0.03, 0.03)
	return x,y


def rxy():
	functions = [circle_func, smile_func, lambda x: eye_func(x, True), lambda x: eye_func(x, False)]
	function = functions[np.random.choice([0,1,2,3])]
	return function(np.random.uniform(-1, 1))

results = np.concatenate([rxy() for x in range(1000)]).reshape([1000,2])
print(results)

fig,((ax_x,dummy),(ax_xy,ax_y)) = plt.subplots(2,2, figsize=(4,4), sharex='col', sharey='row', gridspec_kw=dict(height_ratios=[1,2], width_ratios=[2,1]))
dummy.remove()
ax_xy.scatter(results[:,0], results[:,1], s=3, alpha=.1)
ax_x.hist(results[:, 0], density=True, bins=60) # fill in the ???
ax_y.hist(results[:, 1], density=True, bins=60, orientation='horizontal') # fill in the ???
plt.show()
``` 
            2. 
                - density func:
                    - $\int_{0}^{u}{u\cdot(1-u)du} = u^2/2 - u^3/3$ 
                - cumulative distribution function:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5RCG5z7hsBmrF-QFWJFCBf4JNmoCJWWx1qb5NumaUsGp05deuEiDNdkSuJLW2PQmSACOmx8S-k1pBEO1jmKnZGBPbRQ-EKVs2a7Oaabi-_-Z4AFpPJW26YzZLt1ZzFnt.png) 
            3. 
                - pdf = $$\frac{d}{d\theta}(\text{cdf}) = 1_{\theta \ge b_{0}} \cdot (\alpha \cdot \frac{1}{\theta}\cdot (\frac{b_{0}}{\theta})^\alpha )$$ 
                - b.) 
                    - $$Pr_\Theta(\theta) = 1_{\theta \ge b_{0}} \cdot (\alpha \cdot \frac{1}{\theta}\cdot (\frac{b_{0}}{\theta})^\alpha )$$ 
                    - $$Pr(x_1, x_2,...,x_n | \Theta=\theta) = \left( \frac{1}{\theta} \right)^n$$ 
                    - $$Pr(\theta | x_1, x_2, ..., x_n) = 1_{\theta \ge b_{0}} \text{Pareto}(k, \alpha+n)$$ $\text{let} \ c = (\alpha + n) k^{\alpha + n}$  Then $Pr(\theta | x_1, x_2, ..., x_n) = 1_{\theta \ge b_{0}} \ \  c \ \ \frac{1}{\theta} \cdot (\frac{1}{\theta} ^{\alpha + n})$ 
                - c.)
                    - $P(\Theta \le \theta) = 0.95$ ⇒ $0.95 = 1 - (\frac{k}{hi})^{(\alpha+n)}$ ⇒ $hi = (0.05)^{-\frac{1}{\alpha + n}} \cdot k$ 
            4. 
                - 
            5. 
                - $X \sim Bin(n, \theta)$  then $Pr(\theta | x=0) = (1-\theta)^n$  
                - $P(\theta | x=0) = \kappa \cdot(Pr(\theta)) \cdot (1 - \theta)^n$ 
                - $1 / \kappa = \int_0^{1/2}{\epsilon (1-\theta)^nd\theta} + \int_{1/2}^{1}{\epsilon (1-\theta)^nd\theta}$ $\rightarrow \kappa = (n+1) / \epsilon$ 
                - $P(\Theta \le 0.5 | x=0) = \kappa\int_0^{1/2}{\epsilon (1 - \theta)^nd\theta} = 1 - \left( \frac{1}{2} \right)^{n+1}$ 
                - This equals a half when n = 0, if epsilon = 0 our results would have been nonsense and the probability would be zero. 
            6. 
                - 
            - 
            - 
            - 
        - Supervision 3 Work
            -  _**Question 1:**_  We are given a dataset x1, . . . , xn which we believe is drawn from Normal(µ, σ2 ) where µ and σ are unknown.
                - a.) Find the maximum likelihood estimators µˆ and σˆ: 
$\hat\mu = \frac{1}{n} \sum_i x$ , $\hat \sigma = \frac{1}{n} \sum_i x^2 - \hat\mu^2$ 
                - b.) Find a 95% confidence interval for σˆ, using parametric resampling: ```python
 # x = [x1, x2, ...]
mean, std = np.mean(x), np.std(x) 
n = len(x)

def h(x):
	return np.std(x)

def sample():
	return np.random.normal(mean, std, n)


t = np.array([h(sample()) for x in range(10000)])

interval = np.quantile(t, [0.025, 0.975])
print(interval)
```
            -  _**Question 2:**_   
                - a.) Report a 95% confidence interval for νˆ − µˆ, using parametric sampling: ```python
x = np.array([3,1,5])
y = np.array([2,3])

null_val = np.mean(np.concatenate([x,y]))

def h(x1,y1):
	return -np.mean(x1) + np.mean(y1)

def sample():
	return np.random.poisson(null_val, size=3), np.random.poisson(null_val, size=2)

t = np.array([h(*sample()) for x in range(1000)])
interval = np.quantile(t, [0.025, 0.975])
print("Observed difference in means", np.mean(y) - np.mean(x))
print(interval)

# Observed difference in means -0.5
# [-3.          3.33333333]
```
                - b.) **The above code AND: **  ```python
t_ = np.mean(y) - np.mean(x)
print( 2 * min( np.mean(t_ <= t ) , np.mean( t_ >= t) ))

# 0.801
``` I chose two sided because the difference between the two items can be positive or negative, and whether the difference is positive or negative is important to report. We would like to know whether one chief is having a significantly better or worse impact.
                - c.) ^^Not sure about this, could we go through^^ 
            -  _**Question 3:**_ 
                - a.) ```python
import numpy as np
import pandas
import matplotlib.pyplot as plt
import sklearn.linear_model
import scipy.stats


# Load the dataset
url = 'https://www.cl.cam.ac.uk/teaching/2021/DataSci/data/climate.csv'
climate = pandas.read_csv(url)
climate = climate.loc[(climate.station=='Cambridge') & (climate.yyyy>=1985)].copy()
t = climate.yyyy + (climate.mm-1)/12
temp = (climate.tmin + climate.tmax)/2
# Fit a simple model, and plot it

π = np.pi
X = np.column_stack([np.sin(2*π*t), np.cos(2*π*t), t-2000])
model = sklearn.linear_model.LinearRegression()
model.fit(X, temp)

tnew = np.linspace(1985, 2025, (2025-1985)*12+1)
Xnew = np.column_stack([np.sin(2*π*tnew), np.cos(2*π*tnew), tnew-2000])
tempnew = model.predict(Xnew)


sigma = np.std(temp)

def sample():
	return np.random.normal(tempnew, sigma)

def h(x):
	# The increase in temp between the first and second halves of the dataset averaged
	return (np.mean(x[len(x)//2 : len(x)-1]) - np.mean(x[0: len(x)//2])) / len(x)


samples = np.array([h(sample()) for x in range(10000)])

plt.hist(samples, density=True)
plt.show()
interval = np.quantile(samples, [0.025, 0.975])
print(interval)
``` 
                - outputs: [-0.00038061  0.00329347] which equates to a temperature change of between [-0.4663143317809455, 3.971734353796922] per century.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/G_vvYKWsUWgTdYvAraIN937T7jMUPxJNw3D4J3TBmz3nNBU-JTH7auSCnNNQ5iXccjaU35iQLwfdIXLwOEKOyCo9njrktDsGFCkn_rq7S1kOekWhRvvWFM0VGx6whilm.png) 
                - 
                - b.) ```python
import numpy as np
import pandas
import matplotlib.pyplot as plt
import sklearn.linear_model
import scipy.stats


# Load the dataset
url = 'https://www.cl.cam.ac.uk/teaching/2021/DataSci/data/climate.csv'
climate = pandas.read_csv(url)
climate = climate.loc[(climate.station=='Cambridge') & (climate.yyyy>=1985)].copy()
t = climate.yyyy + (climate.mm-1)/12
temp = (climate.tmin + climate.tmax)/2


# Fit a simple model, and plot it
π = np.pi

tnew = np.linspace(1985, 2025, (2025-1985)*12+1)

# Null hypothesis that the dates are the same, 
# so one variable to be fit is between 2010-2020 OR 1985-1990

datesTnew = ((1985 <= tnew)*(tnew < 1990)+(2010 <= tnew)*(tnew < 2020), (1990 <= tnew)*(tnew< 2000),
             (2000 <= tnew)* (tnew< 2010), (2020 <= tnew)*(tnew <= 2025))

Xnew = np.column_stack([np.sin(2*π*tnew), np.cos(2*π*tnew), *datesTnew])
tempnew = model.predict(Xnew)
print(model.coef_)
## Result : [-1.06969483 -6.55184889  0.61248728  0.61731992  1.01231992  1.77490753] 

sigma = np.std(temp)

def sample():
    return np.random.normal(tempnew, sigma)

def h(x):
    # The difference between the 1980s and 2010s
    year80s = x[0  * 12:   5 * 12]
    year10s = x[25 * 12 : 35 * 12]
    
    inc80s = ( np.mean( np.split(year80s, 2)[0] ) - np.mean( np.split(year80s, 2)[1] ) ) / len(year80s)
    inc10s = ( np.mean( np.split(year10s, 2)[0] ) - np.mean( np.split(year10s, 2)[1] ) ) / len(year10s)
    return inc10s - inc80s

samples = np.array([h(sample()) for x in range(10000)])

plt.hist(samples, density=True)
plt.show()
interval = np.quantile(samples, [0.025, 0.975])
print([x for x in interval])

real_diff = h(temp)
print(2 * np.min([ np.mean( samples <= real_diff ), np.mean( samples >= real_diff ) ] ))

# result is 0.3566
# 0.3566 > 0.025 - so we accept the null hypothesis
```
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cghRRf1V5S_SBfXGXm3z2enSqJJTBVaVsGimVxqxyFDgShejwOGxpplY3p3TJAtCtYy7roFLeMVgiQ3oZMQJtU-ryvqcMICADe7Yj6ieR2eAocYi6qvgJtE1YDPep0ON.png) 
            - 
            -  _**Question 4:**_ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hYVpdF3g_616zJwKqv979ygzaZOcIulZKc00b9rLC1Q0XfK95UD5FAD1jEM8M_9oY7E_XvZkQZKxynieI8yBYM9FnhwdJmsbCM5OCRB0GyuceMWn4bfnS6JPZB7V2arN.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/buFolL0zHPl78VhEl4Phop6IY4uJk4Ac9lUSJKuUuRLbwKL6oxwf89zKdcsPEMmuA_3amLUO60VeEHNEGdCBB8Fcqfp8paXwlMQr9LX1_UHtiPrQzZ7KFNtbM45rSxB-.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/DXf6ni8P8txwwpykxN7UTe8MH86jgdI5DhYhIQitVMSubEMUOyjpPjACyDAXG2qsnmc716I4m-6ywj9P94LEnV8H_zpdZaCq-OsM5dQBRTzlGg42id-QSJqeAMCfPEqy.png) 
            - 
            -  _**Question 5:**_  
                - Consider that the value of theta (success) that makes a run of failures most likely is the lowest possible value, in this case 0.5. 
                - $$(1/2)^n \le 0.05$$$$n \ge \ln(0.05)/\ln(0.5) = 4.32...$$
$$n\ge5$$ 
            -  _**Question 6:**_ 
                - A recent paper Historical language records reveal a surge of cognitive distortions in recent decades by Bollen et al., [https://www.pnas.org/content/118/30/e2102061118.full,](https://www.pnas.org/content/118/30/e2102061118.full,) claims that depression-linked turns of phrase have become more prevalent in recent decades. This paper reports both confidence intervals and null hypotheses. Explain how it is computes them, in particular (1) the readout statistic, (2) the sampling method.
                - The readout statistic is the number of n-grams each year that were labelled as indicative of cognitive distortion, "normalized" by dividing by the number of books published each year.
                - The sampling method was examining millions of books within the Google Books database and calculating the readout statistic. When generating the Null data that formed the null hypothesis they generated 10000 sets of 241 randomly chosen n-grams for each year.
                - The null hypothesis would then be that the readout statistic of the values sampled from Google books is the same as the Null data.
                - Confidence intervals were calculated by generating 10000 different random samples of CDS engrams from the google database for each year - the interval is then between the lowest and highest percentage of CDS detected from those 10000 random samples.
                - longitudinal prevalence of hundreds of short sequences of one to five words (n-grams), labeled cognitive distortion schemata (CDS), that were designed by a team of CBT experts, computational linguists, and bilingual native speakers and externally validated by a panel of CBT experts  
                - To account for changes in publication volume, for each CDS n-gram we define its prevalence in a given year as the number of times it occurred that year in the Google Books data divided by the total volume published  
                - against a null model of 10,000 sets of 241 randomly chosen n-gram  
                - sets of random n-grams were sampled from all n-grams in the respective English, Spanish, and German Google n-gram corpus such that they have the same number of 1- to 5-gram  
        - 
        - **Assorted Flashcards**
            - How do you solve $$P(X^2 \le Y)$$―$$P(X \in [-\sqrt y , \sqrt y])$$
$$P(X \le \sqrt y) - P(X \le -\sqrt y)$$
Note the **square brackets. **Meaning X is between those values. 
            - State the law of total Probabilities―$$P(A) = \sum_i P(A \ | \ B_i)\ \cdot  \ P(B_i)$$
If you can't find a way to pull out a component, can be useful to range over all the values. Very useful for Gaussian mixed models. 
            - If I have some gaussian mixed models $x_1 \sim Norm(\mu_1, \sigma^2_1), \ ... \ , x_n \sim Norm(\mu_n, \sigma^2_n)$ and the cat function $y \sim Cat([p_1, ..., p_n])$ what is the probability mass function?―$$Pr(x) = \sum_i^n p_n \cdot k \cdot e^{(-0.5 \cdot \frac{x-\mu_i}{\sigma_i})^2}$$
I.e. just the sum of the probability densities of each normal function, times it's probability. 
            - ```php
X = Norm(a,b)
Y = math.ciel(X)
```How would you find the pdf of Y?―Note that Y now has discrete values, and the probability 0 < Y < 1 is $$\int_0^1 \text{pdf}_X(x) \ dx$$
We'd then go from there.
            - If P is some transition matrix, what is $P(X_n = j \ | \ X_0 = i)$?―$$P(X_n = j \ | \ X_0 = i) = [P^n]_{ij}$$I.e. we raise the matrix to some power, and select out the desired item.
            - What are Parametric and non-Parametric modelling? ↓ 
                -  _Parametric_  ⇒ Guess a distribution for the data, then input arguments calculated from measured statistics (e.g. $\lambda$ = mean for Poisson) and then sample from that distribution. 
                -  _Non-parametric_  ⇒ Instead sample from the dataset itself (useful when there are no probability distributions that fit the dataset, think Deep Neural nets and images ).
            - What is the p‒test in hypothesis testing?―The probability of the result or something more extreme.
            - What's the difference between Hypothesis testing and Parametric sampling?―Hypothesis testing assumes the same means, while parametric sampling assumes different means... WHAT DOES THIS MEAN?!?!?!?!
            - 
        - 
    - Programming in C & C++
        - 
        - Supervision 3
            1. ** 2015 Paper 3 Question 1:**   
                - a.) It encourages the compiler to immediately evaluate the function inline. However, it gives no guarantee that the compiler will actually do that. Can waste space if an inline function is reused many times, less space efficient than creating a stand alone function to be run.
                - b.) ```cpp
 #include <tgmath.h>
 int receive_int() {
    unsigned int result = 0;
    for (int i=31; i>=0; i-- ) {
        result += receive_bit() * pow(2, i);
    }
    return result;
}
```
                - c.) ```cpp
template <class T, int len>
T receive(void) {
    T result = 0;
    for (int i = 0; i < len; i++) {
        T bit = receive_bit();
        result += bit * pow(2, i);
    }
    return result;
};

ans = receive<short, 8>;
ans = receive<unsigned long,32>;
``` d.) 
                    - Line 6: buf is a value on the stack, thus the value returned will be lost once the function returns.
                    - Line 4: fuel is never initialized
                    - If Message is not 1 or 2 the function will not return a value, when it's supposed to return a char
                    - Line 5: THRUST will overrun buf, as buf doesn not have space for the /0 that ends the string
            2. **2015 Paper 3 Question 2:**
                - a.) The differences between C pointers and C++ references. [Hint: Consider issues of syntax, initialisation, mutation and safety in your answer.] [5 marks]
                    - Pointers are created using the * syntax, while references use the & syntax: 
                    - ```cpp
int x[] = {1,3,5,7};
int* ptr = &x[0];
int& ref = x[0]; 
```
                    - References act as aliases to the data item in questions, meaning they can only affect the value they are initialized to reference - references cannot be changed to reference a different data item. On the other hand pointers act as an address to the data item, an address which can be changed to point to somewhere else in memory:  
                    - ```cpp
ptr++;
printf("%i ", *ptr); // outputs 3 as ptr is now pointing to the second array item
ref++;
printf("%i ", ref); // outputs 2, as this incremented the 1st array item 
```
                    - Where references point to is an immutable feature, because can only change the value they point to they are much more safe than pointers - arithmetic of pointers can be done in error, resulting in the changing of arbitrary bits in memory.
                    - ```cpp
ptr+=10; // pointer now points to an arbitrary place in memory
printf("%i ", *ptr); // unkown output
ref+=10; // Increments the 1st array value by 10
printf("%i ", ref); // outputs 12 
```
                - b.) extern "C" {} tells the compiler that the enclosed code should be linked as C, not C++. Declaration and definitions can then be grouped inside the scope. This has the limitation when combined with C++ name mangling, i.e. C++ uses name mangling to allow for default arguments and overloading for functions - this gives each possible combination its own symbol name. If the C function name clashes with an overloaded function, a compile time error will occur. 
                - c.) Implementation defined behaviour means the creators of the compiler have documented the behaviour of the compiler when facing certain incorrect code, and the compiler will adhere to that behaviour. Unspecified behaviour means the C compiler can do whatever it wants and there is no specified behaviour. An example of implementation defined behaviour is the size of all data types char, short int etc. Examples of unspecified behaviour include how inline functions are handled, the order that operators like ++i i++ are evaluated when combined. ^^This loosely specified behaviour allows for more freedom for optimizations by the compiler.^^ - not sure about this
                - d.) Interactive debuggers give you a large range of tools for fast debugging, including stopping the program if assert conditions are not met, get the value of variables during running, stepping through the program, getting the trace of function calls.  A breakpoint gives the line of code where application will pause, a watchpoint allows you to set a data item such that the program will pause if it changes. The symbol table keeps track of the location of variables and stack offset for function callstack inspection.   
            3. **2013 Paper 3 Question 3:** 
                - b.) ```cpp
 class T {
    const int n;
    public:
    T (int n=0) : n(n) {
        printf("%i", n);
    }

    virtual ~T () {
        printf("%i", n);
    }
};
```
                - Fields and constructors cannot have the virtual tag. Virtual destructors are useful for when a class is derived from, and when the static class varies from the dynamic class with a non-virtual destructor undefined behaviour can occur. 
                - ii.)   T Objects are allocated to the heap using new, and removed using delete ```cpp
 T value = new T(1);
 delete value;
```Delete runs the destructor and then deallocates from the heap. New allocates to the heap and runs the constructor. Stack constructors are run when a scope is entered, and destructors are run on exit. Static store is used by writing static C x. Virtual is essential for destructors when a class is derived from. Try finally ensures the finally block is always run at the end of a block, similarly stack allocated objects run their destructors when they go out of scope.
            4. **2012 Paper 3 Question 3:**
                - a.) 
                    - i.) What is the difference between a local and global variable in C? (Consider variable scope, storage and initialisation.)
                        - A local variable is one who can only be accessed within the current scope, after the end of the scope the allocated memory is removed. 
                        - A global variable is one who can be accessed anywhere in the program, they are initialized to zero and consume storage throughout the program.
                    - ii.) What are the properties of a static member variable in a C++ class?   
                        - A static member variable only has one instance of the variable, rather than one instance per variable. 
                - b.) 
                    - i.) The section of memory the pointer addresses can be changed using pointer arithmetic: ```cpp
 int * p1, p2; // integer and int pointer declared not two int pointers
 
 int sam = *p1; // pointer uninitialized 
```
                    - ii.) A pointer can be used to point at an array, and you can use array syntax with pointers - however a pointer is a variable (you can reassign it), while an array name is not.
                - d.) 
                    - i.) void * can point to anything, any data item. ```cpp
void sort(void *arr, int nitems, int size, bool (*compar)(const void *, const void*));
```
                    - ii.) void * has no type checking in C, C++ helps this using template functions:  ```cpp
template <class myType> 
myType GetMax (myType a, myType b) {  
	return (a>b?a:b); 
}  
```
                - e.)
                    - i.) We can "copy" instances using simple assignment, meaning all the values are copied - however if some of the values are pointers this may not be the desired behaviour. Thus, a copy constructor could solve that problem by properly dealing with those items.
                    - ```cpp
Dog::Dog(const Dog& old_dog) {
	bark = old_dog.bark;
	name = new char[5];
}
``` ii.) 
As in i.) when one class instance is assigned to another, variables are overwritten and this behaviour may not always be desired.
```cpp
Test& operator = (const Test &t) {
    cout<<"Assignment operator called "<<endl;
    return *this;
} 
``` 
            5. **2009 Paper 3 Question 1:**  
                - e.) Pointer arithmetic is the manipulation of the pointer address, the main (good) use is to manipulate an array using pointers - however there is no bounds checking so precautions must be taken: 
                - ```cpp
int sam[3] = {1,2,3};
int *ptr = sam;

printf("%i", *ptr); // print 1
printf("%i", *(ptr+2)); // prints 3
``` 
                - d.) ```cpp
class dog {

    int age;
    const char* name;
    public:
    
    dog (int age, const char *name) : age(age), name(name) {
        printf("Constructor run");
    }

    void bark(char* msg) {
        printf("%s", msg);
    }

};

int main() {
    const char * name = "Apollo";
    dog* Apollo = new dog(5, name);
    Apollo->bark(name);
    return 1;
}
``` 
                - c.)  New and delete are features of the language that call an objects constructor or destructor - malloc() and free() are functions, and are not features of the language but are provided from a library. Malloc and free manipulate a large data structure (a heap) to allocate data for variables, while new and delete need not use this external data structure.
                - f.)   Catches take a single argument and allow for the escape of a code block to a predefined location if an error occurs```
int main () {   
	try {     
		throw 10;   
	}   
	catch (int e) {     
		cout << "Exception number " << e << '\n';   
	}   
	return 0; 
}  
```
            - 
        - Supervision 2
            1. Arenas are a useful tool for amortizing allocated memory discovery, and have the side effect of potentially more efficient cache usage through the introduction of an array for item storage. I would use one when I have a data structure that may contain cyclic sections or sections where a given item is pointed to twice from another item (DAG) - in which case traversing the structure myself at the end becomes complex & error prone, and can result in memory leaks if not carefully thought through. Arenas trade-off complexity with memory usage, as we must allocate a large array of items (the size being the maximum number of items the program could use) to eventually deallocate. An example control flow would be creating a graph, every time I create a node I add it to the arena (wherein we already specified the max possible number of items) incrementing the current value in the arena - then when finished with my data structure I free the arenas elements array and free the arena itself.
            2. In mark and sweep garbage collection we store an list of "root" nodes (items that are alive, and we'd like to keep alive) and an list all nodes (these may be the lists). In the mark phase we iterate through all the root nodes, and mark all nodes reachable from each root node (i.e. depth first exploration, stopping when we hit a marked node). Then in the sweep phase, we step through our list of all the nodes and free any unmarked nodes and unmark any marked ones. When we next run the garbage collector the nodes still alive will form our roots.
                - a.) A conservative garbage collector is one who scans the execution stack, and upon finding a value that **looks like **a pointer to the heap - if there is an object at that pointer, the collector must mark it. This conservative estimation is that this is a pointer to the heap and not (say) an integer value. This is necessary many reasons, including:
                    1. C lets you easily convert from values to pointers, so we can't know if in future the programmer will use that int as a pointer to an item in heap memory.
                    2. The garbage collector should **never **alter the execution of the code, and storing extra blocks of useless memory is better than deleting a useful block. Especially considering that if the value on the call stack is not a pointer, it is likely to change at which point the memory can be freed. 
                - b.) Garbage collection solves the issue of cyclic data structures that reference counting cannot - under reference counting, two cyclic items pointing to each other can maintain a pointer count of 1 each even if there is no way of accessing either item (all pointers to those items has been removed) - thus these marooned items cant be freed resulting in a memory leak. Garbage collection stores all the nodes, and will find these items to be unmarked in the sweep phase - thus they will be freed.
            3. Show how a struct of arrays performs better than an array of structs when traversing the elements of the form ```c
struct entry { int id; double val; };
typedef struct entry Entry;

struct struct_of_arrays {
	int *id_array;
	double *val_array;
};

Entry *array_of_struct = malloc(sizeof(Entry) * NUM_ITEMS);

struct struct_of_arrays Struct_of_Arrays;
Struct_of_Arrays -> id_array = malloc(sizeof(int) * NUM_ITEMS);
Struct_of_Arrays -> val_array = malloc(sizeof(double) * NUM_ITEMS);
```
                - For simply iterating through the array of struct, we have an int of size 4 bytes and a double of size 8 bytes - this will then be padded to size 16 bytes. So we can fit 4 entries into a single cache line before getting a miss (whether we're storing an int & a double or only an int/double) - alternatively if we iterate through the id_array and then the val_array, we first have 4 byte ints to iterate through - resulting in 16 items before getting a cache miss - and secondly 8 byte items, resulting in 8 items before a cache miss. 
                - $\text{array of structs}: \frac{n}{4} \text{ cache misses}$ 
                - $\text{struct of arrays}: \frac{n}{8} + \frac{n}{16} = \frac{3n}{16} \text{ cache misses}$ 
                - So as $\frac{3n}{16} < \frac{n}{4} = \frac{4n}{16}$ we'll have less cache misses in our second solution, and as cache misses are hundreds of times more costly than arithmetic operations - our struct of arrays will perform better.
            4. Describe loop blocking and when it's useful:
                - Loop blocking is a technique for deconstructing accesses of large contiguous data structures into smaller chunks which can be stored in cache lines. The first access of each chunk will result in a cache miss, but subsequent accesses wont. In short it attempts to introduce spatial locality of data, for fast accesses.
                - The technique is useful when a given array access scheme jumps around a lot, and does not return to a chunk of memory for a long time (at which point the cache line can have been cleared). Alternatively, your method of jumping could cause conflicts within the cache and force eviction of prior cached lines. In general, loop blocking is useful for items with poor spatial locality.
            5. [1998 Paper 6 Question 6](y1998p6q6.pdf.md)
                - a.)
                    - Memory corruption 
                    - Hard to read programs 
                    - Security liability
                - 
                    - Low level control
                    - 
                - b.)
                    - Forgetting to deallocate sensitive data?
                    - Memory leaks
                - 
            6. [2010 Paper 3 Question 6](y2010p3q6.pdf.md) 
                - a) 
                    - ```c
typedef struct node* Node;
struct node {
    int value;
    Node xor_pointer;
};
Node head;
Node xor_addresses(Node a, Node b) {
    return (Node) ((long long)a ^ (long long)b);
}
void add_value(int value) {
    Node new_node = malloc(sizeof(Node));
    new_node->value = value;
    new_node->xor_pointer = head;
    head->xor_pointer = xor_addresses(head->xor_pointer, new_node);
    head = new_node;
}
Node get_next(Node prev, Node current) {
    return xor_addresses(prev, current->xor_pointer);
}
void traverse() {
    if (head==NULL) return;
    Node current = head->xor_pointer;
    Node prev = head;
    printf("%i  ", head->value);

    while (current != NULL) {
        printf("%i  ", current->value);
        if (current->xor_pointer == 0)
            break;
        Node temp_prev = current;
        current = get_next(prev, current);
        prev = temp_prev;
    } 
    printf("\n");
}

void delete(int value_to_del) {
    if (head==NULL) return;
    Node current = head->xor_pointer;
    Node prev = head;
    
    if (head->value == value_to_del) {
        if (current->xor_pointer != 0) {
            current->xor_pointer = get_next(head, current);
        }
        free(head);
        return;
    }

    while (current != NULL) {
        if (current->xor_pointer == 0) {
            if (current -> value == value_to_del) {
                prev->xor_pointer = 0;
                free(current);
                return;
            }
        }
        if (current -> value == value_to_del) {

            Node next = get_next(prev, current);
            Node prev_prev = xor_addresses(prev->xor_pointer, current);
            prev->xor_pointer = xor_addresses(prev_prev, next);
            Node next_next = xor_addresses(current, next->xor_pointer);
            next->xor_pointer = xor_addresses(next_next, prev);
            free(current);
            return;
        }
        Node temp_prev = current;
        current = get_next(prev, current);
        prev = temp_prev;
    } 
    printf("Node not found to delete\n");
}

``` 
                    - b.)    Comment on this form of linked list. Consider the comparative speed, memory overheads, maintenance and other advantages or disadvantages of the XOR doubly-linked list approach when compared with an approach that stores both previous and next pointers  
                    - 
                    - In this form of doubly-linked list, each node takes up less space - while before they store two pointers and a payload now they store only one , resulting in less overall memory usage of the new data structure. (16 bytes vs 24) For large lists, one list being two thirds the size of another while accomplishing the same thing could be important.
                    - However, if you want to hold specific nodes to edit later - you need to hold that node **and **the previous node if you want to be able to traverse from your node and edit preceding nodes - this makes it harder to maintain, as management of individual nodes is more complex. Additionally, traversing the list is more expensive in the XOR doubly-linked list as we must compute an XOR every time (which is admittedly a relatively cheap operation). 
                    - You could make the argument the XOR doubly-linked list is more secure, as you can pass your node value to another function safe in the knowledge it cannot destroy any other of your nodes as it will have no way of traversing to them. 
            7. [1996 Paper 5 Question 5](y1996p5q5.pdf.md) :
                - a.) Pre-processor macros and conditional compilation:
                    - ```c
#define BIT64 1

#if BIT64==0
#define BIG_INT (64*1024*1024)
printf("%i", BIG_INT);
#else
#define BIG_INT (1024*1024)
#endif

// This defines a macro BIT64 set to 1, and chooses different definitions of BIG_INT depending on the value of said macro
``` 
                - b.)
                    - ```c
char t = 'a';
char *p2 = &t;
int *res = (int*) p2;

// We created t, which holds the a character. Then we instantiated a char pointer to t. Then we created an int pointer res, and cast the char pointer to an int pointer.
``` 
                - c.)
                    - ```c
// This is a single line comment
/*
	This is a multi-line comment
	!!!
*/
``` 
                - f.)
                    - ```c
jmp_buf current_env;    
int sam = 0;
int val = setjmp(current_env);
printf("%i\n", val);
longjmp(current_env, sam++);

// This code infinitely loops printing 0, 1,2,3...
// setjmp copies the PC and stack pointer into the jmp_buf current_env, then we print sam and finally we longjmp back up to int val = setjmp(current_env); val will then be overwritten with the value of sam+!
```
                - g.)
                    - ```c
unsigned int sam = 3;
switch (sam) {
    
    case 0:
        printf("Sam less than 2");
        break;
    case 1:
        printf("Sam less than 2");
        break;
    default:
        printf("Sam more than 2 ;( ");
        break;
}
// if the unsigned int sam is 0 or 1 we print "Sam less than 2", otherwise we print "Sam more than 2 ;( ".
// In this case we'll print the latter, as sam is 3. Each constant case is checked against the value in the switch()  braces and a case is selected. 
// The breaks ensure the default case doesn't always run.
``` 
            8. [2014 Paper 3 Question 3](y2014p3q3.pdf.md)   :
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zB0WVJroIQK0RkHQzho8zvjIfCkmXtlmIL3jLz1ZOLw0MoLHOFDLFaEUh1PaKLG-bc64iVhJIajoLCoCy2b996jK4MoffBw6nDR-nU2P_UYxEe8qrzNow4mU46s9QqRk.png)
                - ```c
char revbits(char to_reverse) {
    int working = (int) to_reverse;
	int result;
    for (int exp=7; exp>-1; exp--) {
        if (working > 1<<exp) {
            working -= 1<<exp;
            result += 1<<(7-exp);
        }
    }
    return (char) result;
}
``` ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4EncOulylcP3ibS2i2YvFWOnzfLIxKEKnPaaiubqq7GDBEapF3kAEAU-uD7XBSla7UjDwumB_HkKu4FrEu1z6Zt9XdJ1EG6EnsNg07bjh9XbeYN6QInE3JQbCpm6AdPo.png)
                - ```c
void revbytes(char *ls, int num_bytes) {
    int left = 0, right = num_bytes-1;
    while (left <= right) {
        if (left == right) {
            ls[left] = revbits(ls[left]);
            break;
        } else {
            char temp = ls[left];
            ls[left] = revbits(ls[right]);
            ls[right] = revbits(temp);
            left++, right--;
        }
    }
}
``` ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5CvOkCE8ymJEeAFOsAjUVCQ44LCbCUtbJYWKdAgIN0OS8u2Wsy8ILFqk3zp-DPTbnJzLqlTcGVHd5dTnEuRc-4ql_tRA0umkx1Z9W4pm4vhHkDiAUYf7cgRiqiUI5SfJ.png)
                    - The problem here is the file is left open after the result is returned, we should change the block to:
                    - ```c
if (...) fclose(p); return ERR_MALFORMED;
``` 
            9. [1995 Paper 5 Question 5](y1995p5q5.pdf.md)  
                - This is an attempt at an implementation of quicksort.
                - ```c
typedef unsigned long int thing;
// Bad unilluminating variable name
``````c
 #define swap(p,q) v = p; p = q; q = v;
 // the type of v is not defined, this will result in an error.
```
                - ```c
		/**********************
int i, j; * Declare variobles! *
thing v; **********************/
// int i,j and thing v will be commented out here. Also incorrect spelling of variables
``` 
                - ```c
i = left, j = write;
// i & j are not given types
``` 
                - ```c
 while (a[++i] < v};
 // Wrong ending bracket, should be  while (a[++i] < v) 
```
                - ```c
while (a[++i] < v};	
while (a[--j] >= v);
if (i < j) swap(a[i], a[j]);
else break;

// I believe what they intended was:
while (a[++i] < v} {
	while (a[--j] >= v) {
		if (i < j) swap(a[i], a[j]);
		else break;
	}
}

// What they achieved simply repeatedly increments i until a[i] >= v, and repeatedly increments j until a[j]<v and then swaps a[i] & a[j]

// ALSO these should be a[i++]... and a[j--]... . Otherwise we dont test the initial values of i & j.
``` ```c
 write would more sensibly be named right
```
            - 
            - Questions from lectures:
                - In the lecture on reference counting, the lecturer builds a binary tree using:
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/crzic95YRyiryiMHGIrmxmqkDggUe_2KbJnaftk-5YUTWrhbDsP0rUPfufcy8XmrHUAHD9C9DPDpkqALR3EPC4UDY5wVP-WUnHm3WYEhxJX-Ea59BIvdWIrXP6XKJJO9.png)
                - But wouldn't this mean, If I edit a value on the tree (other than the root) I'm actually editing two? Given that both left & right point to the same node. Sure the tree is build, but it can't be used.
            - 
            - 
            - $$\text{speedup}(n) = n(1-B)+B$$ 
        - Supervision 1
            1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5x-kpFtSmurzNUmXPlR8GMTKt44S-pGI_uXQn-loC5FTlBbwH2KnTOZb_8vHNtz5Vc-B7ENcAojGyI83lmpHfPa1uVKKFQiiso5afgZZSAndShPRGx_1n1jctwLtBL13.png) 
                - 'a' is a char while "a" forms a string literal - e.g. an array of chars terminated with a null terminator \0.
            2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Y7TUSDPht8rMMmjwyibGk-4zzDDtqFry6U0sB0wSGHN80olxqx8IhSL4w7q1B7AwdfL5s1F1G8LzJ8q7-K3oTPmuVAZMovFSPG6aKrPGL5mZ2dLldl2lZEglvvYQf7oj.png) 
                - Yes, it will terminate when j equals 5 (e.g. the 5th ASCII character) as long as the two chars were initialized to 0 (which is not guaranteed). This is because you can store integer values in chars, ranging from -128 to 127 for unsigned chars.
            3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dpZ64aPO1RH5e4EsS1UpUmsF6S1j8sYlwLx6vDShfHV1sW0kweO6ow9QUln0VP0NK6dzaTv2HQGT_siYVBxZQugXD5dBNPaOHMVYXAvK5T_8rvmGEmV0otOOn9oYFKxz.png)
                - ```c
#define SWAP(t,x,y) {\
    t temp = x;\
    x = y;\
    y = temp;\
}
```
            4. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wnEQh3sjj-ggBtFu8O9dNmiI2bL6F-ycmM394KL46Q4W-zJ1YH1L8zb5AuhRQgO0yH7tmlkZoS4jhEaKhz0CZSQcIHphGvCgeGCD5LGCuKrC4Cx7S9oxORSzpGNZE18s.png) 
                - No, the i++ will be evaluated twice - meaning the x in the second line of the macro will differ from the x in the third line of the macro (unless the values of v[i+1] and v[i+2] are the same). Similarly, if f(x) changes when it's called twice we will be getting different indices of w.
            5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/29dC0HQ66WGsn2vo69u4gNIJZt9N4FnfT5RwFJfM_G3BW7d5EhdsZOHsXWNjWacNu5zL96DZhIyb0C6NbtTEcqJ-TlSKnzxtwO9zn0fVU-ErJJFrKkkTJH3OY9HJb7no.png) 
                - ```c
#define SWAP(t,x,y) {\
    x = x - y;\
    y = y + x;\
    x = -x + y;\
}
``` 
            6. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VjH7bsEoeEXOb-ZAO4st3yXVKrJqqTgta_w8kMyod9Oe22Y2SY3BN4_UwFKmCzzzfdD_XCnzJG4-JQsuy9qVOjbjp3QFCvNPX9JwYgL0iIb2bJSPIhuJLUjEDjsW6djw.png)
                - p[-2] means the value two items before the pointer, this is legal if p is a pointer inside an array - this works because arrays allocate a contiguous block of memory which we can simply step along (pointer-wise) to reach earlier array-items.
            7. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6xCzQuVGM16QjzvbI4VY4CytzsorrFvjZX1148C4R1ovPU0H4YfSVTLPf1cagxhM-sD31wpTXg6cKaq74aQ609n_mIrRaPIb0Yvmv8tjBgN0IUPrbDjxPksgy8rh1VM-.png)  
                - ```c
char *strfind(const char *to_find, const char *to_search) {

    for (int i=0; i <= strlen(to_search) - strlen(to_find); i++ ) {
        int bookmark = 0;
        while (to_search[i+bookmark] == to_find[bookmark]) {
            if (bookmark == strlen(to_find)-1) {
                return to_search[i];
            }
            bookmark++;
        }
    }

    return NULL;
}
``` 
            8. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GtHkEKbpOG6jIjweOng_l6W05H7Yu9StIWUwwxs9dLB2QzAVtBTakVMQh-pHkARbLFo5t3z56QsppajKkhummkk_929JjfaKqROSQEgcZnq0Z_E6z2HzmF_wMr1mqUGD.png) 
                - A const pointer to an int is a pointer that cannot be changed, e.g. it will always point to that integer. However, the integer value itself can be changed. A pointer to a const int means the pointer can be changed to point at something else but the integer value cannot be changed. For a const pointer to a const int, neither the pointer nor the integer value can change.
            9. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ux0pai4I1dl1vDxBhD-cTy9Pz5Ne3eDRwJRRZ6_oW7PPjGjn5gxRXK5Yci7-xFVq4OFPnbgim5O5YHtj-Atp0MF37r5LXuplWnJQLl4xKYwVvp2RaesqucxNl1jgu8zW.png)
                - You could pass the values as const:
                - ```c
int adds_wont_change(const int *x, const int *y) {
    return *x+*y;
}
``` However, this is only an indication not a promise - the function still has it within its power to alter the arguments using casts.
            10. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/q7tzntYJoJxSzhSjxKKL5xo7tQqMM2aUb8ggmcPB4hgSru1O59WOwTIIP62lL9UZ0YPkGiR0WsTifUx0OSi5me7cNjbveENoAqi5HehC-Vkt1tGajaBGdTSkVhekzIGE.png)
                - ```c
char* read_a_file(char input_filename[]) {
    FILE *file;
    file = fopen(input_filename, "r");
    char *string = malloc(1001);
    int memory_len = 1000;
    int currently_used = 0;
    if (file) {

        char c;
        while ((c = getc(file)) != EOF) {
            if (currently_used >= memory_len) {
                memory_len += 1000;
                string = realloc(string, memory_len);
            }
            string[currently_used] = c;
            currently_used++;
        }
        string[currently_used] = '\0';

    }

    fclose(file);
    return string;
}
``` 
            11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0P3QCnLO7m_QReMJWnZiOuxdyR3x8rUtd4bSxrgQch_t8UEhDy3_iGE_cLCbN7043bbQXt9NcOorpBdzmfdQnEzNhkW0RsMTM0Ltx9cSEdIhb1jvO9vaDtXgTKXoCGka.png)
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gcBE6wQaCcIKAs4I7o-7BUREOglWeWiNw8BVM06fB5iiiNPfsSRYKNJn0vki2qk-RDt2nyizBGi96ckZmwg_rQFMd10Tci3VUG2wwnunH84ZH-_MHy6VY6QWxUhE4njR.png)
                - Func1 can pass the pointer to the array to bar as the array still exists while bar runs, however when Func1 attempts to return the pointer to the array it's memory on the stack will be deallocated and thus any local variables will be lost and the values the pointer points to will be undefined - that is it's very possible they will be overwritten.
            12. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KmKDW7D5NUYnv6HW7bY0Ut9L2F_PSp9sxF8ykkzky4_dUrWqcETQTVvt38Ziv905iqB3iSvV7SQEiPUOhrVvgJ79DOcg_jc1y26c4jvSACgavfpB3Sdz3ZP4AHY3UU-C.png)
                - Declaration simply tells the compiler a variable with the given name is going to be defined at some point, while definition allocates an area of memory for the variable. 
            13. 
                - a.) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/BlbZtBHf-NMCqx0Ni45FvW9jsJN0z5SnOn0pjG_FusfpndxTwr2s-jl7bfzlokLtRs-Q0rR3NqUjvoXWEm5YZkOonm8F1twD90e2am_nDGl_2sn6oatalYCCy3Zahj_l.png) 
                - **i is the integer value 78 0c 00 00 - which is  c78 which is 8 + 7*16 + 12 * 256 = 3192
                - p⇒c[2] is 62 in hex = 6*16 + 2 - slightly confused by this one, how does the compiler know to move 2 bytes along (as if its working with a char) rather than 9 bytes along (as if it was working with a struct i2c)
                - &(*pps)[1] is 0x18 + 2 = 16+8+2 = 26 (we move 2 forwards because we're dealingiwth a short)
                - ++p⇒i is 3192 + 1 = 3193 
                - 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/01AJtT87kPJuaTX5C5XZt2fkDMlszM_KcOj76VYkPP3spld9TxWz8igbTte2mVcT__CsI1CFlFlr5dQEdpgf-iLHbBo6NlIEVf1o_opvopjYa6F9XEK7M8kOF47i33A5.png)
                    - First we cast our manager pointer to an employee pointer, however when we call wage(e) it sill uses the wage calculating function wage_man as the address not wage_em (we never changed the function being pointed to in the cast) - this then casts our pointer back to a manager pointer and calculates 40*10 + 20 = 420.
            14. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8zVLbpTXRupf0NULVKpgctjp9VkjS4ZcHNDQLuTRUyCGgd-edbhLPclwFXnuh2uXkjhKEDkIJdy5lWAaQEGJWZsfd_psK0fXIA_-BxK-hqwe3y9Ljza6RhcTgKYN287h.png)
                    - ```c
#define CONCAT(a, b) (a b)
```
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/tic3LFyhReYVg9QlQVNVKS7tIwEUZBzjUdDYyiQSwuZ9_n2oEAijrte48htdQ-JcRmPa7VhPCys-1hnYCqOysIGcx4ATPZnLFITqbksPDrIto3T51OM49qsvJWNfTpJj.png)
                    - Line 3 would not work, as CONCAT only works by leveraging the fact that string literals next to each other get concatenated in c - e.g. "a" "b" ⇒ "ab". All CONCAT does is paste the values next to each other and let the language do the rest - however CONCAT(b, a) will result in CONCAT("UoCCL", a) and the compiler cannot simply infer the value of a to combine the strings (not a string literal). 
                    - Line 4 would not work, as j is not a pointer and you are thus taking the integer value of the pointer that concat(a,b) returns. 
                    - concat(a,b) allocates memory on the heap and creates a list of chars, while CONCAT simply places two string literals next to each other (uses stack memory). concat(a,b) returns a pointer to the char array while CONCAT(a,b) will evaluate to the combined string literals. 
            15. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Yc7pDYou5sDFsk8G-vXRMbYZJZkvIvoPnxYzVJzVgAFYuEB1gHaD_VDxY8yvyAernjZfJxRStzCKWnlxhKLebEBiAt38UsEs5HBe0iDRIrJeeAJE7wnMXcHI_ZDczi3L.png)
                    - 500 bytes: (4 + 1 bytes) * 100. sizeof(struct Elem) =  5 bytes. long is 32 bits - compiler supports unaligned access, unlike all below.
                    - 800 bytes: 32 bit machine, the long is 4 bytes, char is 1 byte. sizeof(struct Elem) =  8 bytes - but as 32 bit machine have to use two 4 byte words. Resulting in 100 * (4 + 4) = 800. 
                    - 1200 bytes:  ^^48 bit machine, the long is 6 bytes, char is 1 byte, sizeof(struct Elem) =  12 bytes - but as 48 bit machine have to use two 4 byte words. Resulting in 100 * (6 + 6) = 1200. ^^ - possible answer but more likely: long 64 bits but aligned to 32 bits - 4+4+4 = 12
                    - 1600 bytes: 64 bit machine, the long is 8 bytes, char is 1 byte sizeof(struct Elem) =  16 bytes- but as 64 bit machine have to use two 8 byte words. Resulting in 100 * (8 + 8) = 1600. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ep4ntJAbb4n94rCUys5-sCXlO1A_qHTJLLNhp1VaSOwwGa6LU1mKBgnyYGPDlAocg7j39QT7M7vUoPh_zTSCQKRoMdoaB5ne8E74h4aC1Mc6_P7-HdZsak0E_be6VYwQ.png) 
                    - The fundamental changed is converting the file that was created by a compiler using unaligned access to one that does not support unaligned access (no need for the added complexity when memory so abundant).  Also assumed little-endian.
                    - ```c
struct Elem { signed long val; char flags; } v[NITEMS];
char temp[5*NITEMS]; // Each byte in the 5 byte line is going to become it's own item
fread(file, 1, size_of(temp), temp); // First we read the file and get every byte as a char value in our temp array
for (int i; i<size_of(result); i++) {
	
	v[i].val = temp[5*i] | temp[5*i+1]<<8 | temp[5*i+2]<<16 | temp[5*i+3]<<24; // This line combines them using bitwise ors - consider 00001010 | 1010000, combines the values as the zeroes are ignored
	v[i].flags = temp[5*i+4]; // last value is an actual char as we want it
}

``` We could simply have a flag to compute this for or not depending on if we're using this outdated format or not.
            - 
        -  _**Lecture 1**_ 
            - Primitive Types in C ↓ 
                - What are the three primitive types?―Numbers, Characters and pointers
                - Are there primitives of composite types in C?―NO
            - The **Stack **and **static locals** {{are built in}}, the **heap **is implemented {{by a library}}. 
            - Sizing of various types ↓ 
                1. Char―≥8 bits
                2. Int―≥16 bits
                3. Float―6 Decimal digits of precision
                4. Double―Double precision
            - Type operators meaning ↓ 
                1. unsigned―Makes the value unsigned
                2. short―Synonymous to short int, varies but is at least 16 bits
                3. long―8 bytes
                4. const―Informs the compiler that this value will not be changed, can still be changed using pointers though
                5. volatile―Means the storage can change at anytime, compiler must check it every time it's used
            - How do you specify different types of number in C? ↓ 
                - long―123L
                - float―123e10F OR 12.5F
                - double―123e10 or 1.4
                - octal―053
                - hex―0x54
                - 
            - **Enumeration**
                - ```c
enum boolean {TRUE, FALSE};
enum override {TRUE=1, FALSE=5, T=5}
``` One can define Booleans, they are indexed from 0 by default - but this can be overridden. 
                - What items in a enum need to be distinct and what don't―Names must be distinct but values need not be.
            - **Declaration**
                - Variables must be declared before they are definition, where definition means giving them storage. They can be declared, defined and initiated inline.```c
 int i = 5;
 char a, b, c;
```
                - What's the different between Declaring, defining and initiating a variable? ↓ 
                    - Declaring―Telling the compiler this variable name will be used
                    - Defining―Setting aside storage for a variable
                    - Initiating―Putting a value in that variable
                - What does the extern keyword do?―It declares but doesn't define a variable, means the variable will be defined elsewhere - i.e. we allocate it no storage.
                - What does the **static keyword** do in regards to
                    - **Static functions**―Usually functions are global, however static functions can **only be accessed within the file they're declared in** 
                    - **Static variables**―Static local variables **don't lose their contents when they go out of scope** - so functions can reuse their values when called a multiple time. Static global variables are only seen in the file they're defined in
                - 
            - **ALL OPERATORS RETURN A RESULT INCLUDING ASSIGNMENT**!```c
 int y;
 int x = (y = 3);
 // x = 3
```
            - **Type Conversion**:
                - Type conversion occurs when a binary operator takes in two elements with varying sizes. The operator will return a value with the same size as the larger of the two elements - e.g. short + int ⇒ int.
                - However, narrowing is possible.```c
int x = 1234;
char y;
y = x + 1;
// y is overflowed and is the last 8 bits of x+1, in this case -45 in denary.

// CASTING:
y = (char) 1234;
``` 
            - **Expressions and statements**
                - What is an expression?―An expression is a formula in which two or more operands are combined with an operator.
                - What is a statement―A statement is an Expression ended by a semicolon
                - What type and value will this expression take on?```c
int x;
short y;
x = 5, y = 3
```―The expression has type short and value 3. (The rightmost expression)
            - 
            - **Arrays and strings**
                - Strings or arrays are created using this syntax:```c
 int x[10];
```
                - Give 3 facts about string arrays ↓ 
                    - They must end in "/o"
                    - No bounds checking is performed
                    - The compiler places them on a contiguous chunk of memory
                - What does the following result in and why does it work?```c
 char x[] = "abc" "def";
 printf("%s", x);
```―This results in abcdef, it works because string concatenation is done by default. "abc" and "def" are set to strings using double quotes. This happens at compile time
            - **goto statement**
                - Works but shouldn't be used```c
 some_label:
 	printf("We used a goto")
 goto some_lable;
```
            - 
        -  _**Lecture 2 (Only address space layout)**_   
            - 
            - **Address space layout** 
                - 
                - The **four most important areas of memory** within a **compiled x86 C** program―The **Stack**, the **heap**, the **static variables** and the **C binary code**.
                - Describe the **layout **of the **heap**, the static **variables**, the **stack **and the **C binary** code within the address space of a c**ompiled x86 C program**.―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9EqclGaeJ229axupOmXVqqvMy9SUdPUX7V3UUJKfqAvlQamJKCqsY20bbll3HJaaplmHBKojGNlm-veoZGeWqEKPswm8cEwA_HSec_wpoL4PW054VXI79WQoWA_A92Yu.png) 
Start at 0xffff ffff the top of the address space
The stack grows downwards
The heap Grows upwards
0x0 is often mapped to an illegal address to cause a seg fault if accessed
                - Describe the **features **of the** heap **―The heap is **manually managed**, using malloc and free - it is **generally larger than the stack**.
                - Describe the **features** of the **stack **―The stack is **managed by the compiler** and holds temporary local** variables** **declared in the body of a function** which are freed when they go out of scope. It **grows downwards on the address space**. It grows and shrinks as function calls push and pop their values.
                - Describe the **features **of the **data segment **―The data segment holds **global and static variables** who have a value.  
                - Describe the **features **of the **BSS**―The **BSS **stores **uninitialized **(don't have a value yet) local** **or global variables. Some or all of the bss is set to 0s - this is platform dependent. 
            - **Unspecified behaviour is **―behaviour where the C standard give's 2 or more options of implementations - the implementation chose can be decided by the compiler. It gives more freedom to optimise code for a given architecture. Some examples are whether to implement inline, evaluation order of function arguments, order and contiguity of memory in the heap. Memory layout of storage of function arguments.
            - **Undefined behaviour is**―behaviour not described by the C standard, when a compiler is faced with such behaviour it can do **anything it likes**. An example is modifying a string literal (string literals are in read only memory) or i++ + ++i.
            - 
            - 
        -  _**Lecture 3 (Only unions)**_   
            - 
            - **Unions**
                - A union variable is a variable can store {{one of multiple types}}, the size of a union variable is equal to the {{size of it's largest member}}, the type retrieved must be {{the last value set }}. The syntax for fetching from a union is {{the same as for structs (⇒ and .)}}. The syntax for defining a union is {{ union u {int i; char p; short x;};}} The type stored within a union can change {{during the execution of the program}}.
            - 
            - **Bit-fields**
                - Bit fields are used for {{low-level control over bits of memory}}. They are useful when {{memory is limited}}. Bit fields are defined within {{structs}}. The syntax for bit fields is {{struct fred{int x : 4; int y : 10;};}}  The details of bit fields is very {{implementation specific}}. Bit field members do not have {{addresses}}.
            - 
            - 
        -  _**Lecture 10:**_  
            - C++ is said to be: 
                - Better than C
                - Supports data abstraction
                - Supports OOP
                - Supports generic programming
                - Much is familiar with Java with subtle differences
            - Use C or C++ ↓ 
                - Don't want two conflicting IO libraries active
                - Using a standalone library coded in C is fine
                - Code with different metaphors in C & C++
                - C code may not expect an exception to bypass their tidy-up code ?
                - DECIDE AT THE START OF A PROJECT
            - C++ vs Java ↓ 
                - Speed or safety
                - More vs fewer features
            - Java trying to follow C++ with value types - types as values (like int or string) not wrapped in classes
            - **Types:**
                - A lot like C types, but additionally: 
                    - Character literals 'a' type char (int in c) 
                    - New bool type
                    - Reference types: New type constructor &
                    - enum types are disticnt, not just synonyms for integers
                    - New type constructor class 
                    - Names for enum, class, struct and union can be used directly as types - e.g. struct sam{...} can just use sam not struct sam
                    - Member functions (method) can specify this to be const - can say this method does not mess with contents fo this
                - Auto and thread_local:
                    - auto now means, the type of the initializing expression - like type inference```cpp
 auto sam = 5;
```
                    - thread_local is an additional storage class e.g. only one thread sees that same value, opposite of static
                - C++ booleans:
                    - bool types true (1) and false(0) when cast to integer.
                - C++ enumerations:
                    - ```cpp
enum flag {is_keyword=1, is_static=2, ...}
``` Defines a new type where you can use it's name: flag f = is_keyword
                    - Implicit type conversion **not allowed**: ```cpp
f = 5; // WRONG
f = flag(5); // ALLOWED, enum secretly is a bitmap
``` 5 is allowed because bitmaps have explicit max and min values based on the max / min binary values contained in the.
                - References:
                    - Alternative name (alias) for a variable
                    - Generally used for specifying parameters to functions and return values as well as overloaded operators.
                    - Reference declared with &:```cpp
 int i[] = {1,3};
 int *ptri = &i[0];
 int &refi = i[0]; // NEW
```
                    - Must be initialized when it's declared!  
                    - You cannot change what a reference refers to after creation. E.g.: ```cpp
 refi++; // Results in i[0]=2
 ptri++; // Results in ptri point to 3
```
                    - Can think of reference types as pointers **with implicit use of * each time.** 
                - References in function arguments:
                    - When used as a function parameter, the value is not copied: ```cpp
 void foo(int& i) {i++;}
 
 //Same as
 
 void fooTwo(int* i) {*i++;}
```
                    - Declare a reference as const, when no modification takes place. 
                    - It can be noticeably more efficient to pass a large struct by reference than by value.
                    - Implicit type conversion into a temporary occurs for const references but errors otherwise: ```cpp
 float fun1 {float&};
 float fun2 {const float&};
 void test() {
 	double pi = 3.14159;
 	fun1(pi); // ERRORS 
 	fun2(pi); // ALLOWED because it knows the value is not going to be changed. Implicity type converts to float. 
 }
 
``` 
                - Overloaded functions:
                    - Works just like java, functions with varying argument type but same name.
                    - Type conversion is used to find the best match, but that isn't always possible: ```cpp
 void f(double);
 void f(long);
 void test() {
 	f(1.0);
 	f(1L);
 	f(1); // Fails, f(double) or f(long) ?
 }
```
                    - Can also overload built-in operators, such as assignment and equality
                - Scoping and overloading:
                    - Overloading does not apply to functions declared in different scopes. ```cpp
 void f(int);
 
 void test() {
 	void f(double);
 	f(1); // calls f(double);
 }
```
                - Default functions arguments: Uses overloading, creating two separate functions.
                    - ```cpp
double log(double v, double base=10.0);
// Like python, non-default cannot follow default:
double log(double base=10.0, double v); // NOT ALLOWED

// A DECLARATION does not need to name the variable:
double log(double v, double=10.0);
// Obviously when I actually DEFINE the function I would need to do:

double log(double v, double a) 
{... // do some stuff};
// where log(1) same as log(1, 10)


// But beware of lexical interactions between * & = 
void f(char*=0); // Wrong *= is assignment
``` 
            - **Namespace:**
                - Related data can be grouped together in a namespace,  not the same as a class as we can't create an object of the namespace type - just a logical grouping of values & functions.
                - ```cpp
namespace Stack{//header file
	void push(char);
	char pop();
}

namespace Stack {//implementation
	const int max_size = 100;
	char s[max_sizez];
	int top = 0;
	
	void push(char c) { ... }
	char pop() { ... }
}

void f() {//Usage
	Stack::push('c');
}
``` Ensures we don't have clashes of external functions, namespace formalizes naming conventions (gm_openscreen meaning graphics manager openscreen for example). 
                - ```cpp
using namespace Stack; // imports everything to the scope

int main() {
	pop();
	push('a');
}
``` More like java packages than modules in java.
            - Using Namespace: 
                - Scope and expresses logical program structure - collect together related pieces of code.
                - A namespace without a name limits the scope of vars, functions and classes within it to the local execution unit.
                - Can declare the same namespace in multiple source files.
                - Can be defined more than once.
                - Global function main() cannot be inside a namespace.
            - Linking C & C++ code: 
                - extern "C" specifies that the declaration should be linked as C NOT C++ Code: ```cpp
 extern "C" int f();
 
 extern "C" {
 	int globalvar;
 	int f();
 	void g(int);
 }
```
                - 'Name munging' for overloaded functions.  A C compiler typically create a linker symbol '_f' for the f above, this gives the compiler a namespace the programmer cant use (funcs beginning with _). A c++ compiler generates '__Z1fv' function of length 1 that takes a void argumeny.
                - Function calling sequences can differ, e.g. exceptions.
                - If we want to write a library in C, and specify it to be importable into both C & C++: ```cpp
 #ifdef __cplusplus
 	extern "C" void myfn(int, bool);
 #else
 	include <stdbool.h> //No boolean in C
 	extern void myfn(int, bool);
 #endif
```
                - Care must be taken with pointers to functions and linkage - if I pass a C++ function to a extern "C" piece of code, could get errors.
        -  _**Lecture 11:**_ 
            - **Classes and objects in C++**:
                - ^^C++ classes are somewhat like java.^^
                - ^^**Two**^^^^ main components^^ of classes―^^Data members^^ and ^^member functions^^ which act on the data. Both data members and member functions can be static.
                - The^^ 3 access controls^^ of C++ members are―^^private, protected and public^^ 
                - **Class and struct are almost synonyms** in C++, the only difference is―class members are by default private while struct members are private by default.
                - ^^Classes ^^are ^^created ^^with―^^**class or struct keywords**^^**:** 
                    - ^^Struct^^ ^^members default to ^^―^^public^^ access 
                    - ^^class members default to ^^―^^ private^^. 
                - A ^^constructor ^^is simply a―^^Member function with the same name as the class^^ 
                - C++ supports overloading on both―constructors and member functions
                - A **destructor **is named with―the same name as the class prefixed with a **tilde **(~)**.** 
                - Big differences from Java:
                    - ^^Values of class types are^^―^^ ^^^^**not references to objects**^^**, but**^^** the objects themselves**^^**. **
                        - So we ^^access members with C-style . (dot)^^ ( using -> more convenient when we have pointer to objects). 
                    - We ^^can create an object of class C,^^ two ways  ↓ 
                        - ^^On the stack by declaring a variable C x;^^
                        - ^^On the heap: new C() ^^^^**which returns a pointer to C.**^^ 
                    - If a function is ^^**statically resolved**^^** **it means―the code to execute for a given function name is ^^**generated at compile time (or linked at link time) not runtime**^^.
                    - If a function is ^^**dynamically resolved **^^it means―the code to be executed will be ^^**determined at run-time**^^. 
                    - ^^Member functions by default are resolved ^^―^^**statically**^^. For java-like code ^^**declare them virtual.**^^ 
                    - The virtual tag and the dynamic resolution allows for―runtime polymorphism.
                    - ^^Member functions can be ^^^^**declared **^^^^{{**inside a class**}}^^^^** **^^^^but ^^^^**defined **^^^^{{**outside it using : : **}}^^^^  ^^ 
                    - C++ uses {{new }}to allocate and {{delete }}to de-allocate. No garbage collector.
                - Example (emphasising differences from Java):
                    - ```cpp
class Complex {
	double re, im;
	public:
		Complex(double r=0.0, double i=0.0);
};

Complex::Complex(double r, double i) : re(r), im(i) {
	// This is the preferred form of constructor initialization
	// NECESSARY FOR CONSTANTS
}

Complex::Complex(double r, double i) {
	re=r, im=i;  // DEPRECATED initilization by assignment
}

int main() {
	Complex c (2.0), d, e (1, 5.0);
	return 0;
} // local objects c,d,e are deallocated on scope exit!!
  // IMPORTANT - STACK ALLOCATION
```
                - The preferred form of **constructor** **initialization in C++ **is (somehow). **It MUST BE USED WHEN**...―```cpp
 Complex::Complex(double r, double i) : re(r), im(i) {...}
 
 // You MUST use it when itializing
 // const and reference members
```
                - In java, **constructors only **{{**initialize heap storage**}}** **(which has to be pointed to), only way to update is {{x.f = updated_val}}; 
                - In C++ because objects values are "first-class-citizens"―there are more update behaviours
                    - In "C x;" x is initialized using―The default constructor   
                    - In "C x = y;" x is initialized using―The copy constructor
                    - We need to worry about what "x = y" does. 
                    - We split class definitions into separate behaviours and control them to―Preserve **class invariants **(If I can define an object, with no members initialized - certain invariants may not hold) and **object encapsulation** (All the behaviour of the class should be held within the class)
                - **Default Constructor ** 
                    - Default constructors are called when―you type "C x;" or if you do "new C();" i.e. with no arguments.
                    - If no default constructor is specified―The compiler creates one, with little to no initialization.
                    - To disallow users to use the default constructor we―define the default constructor and set it to private.
                - **Destructors **
                    - destructor are called―when a stack-allocated object goes out of scope **INCLUDING when an exception causes this to happen**, when a heap allocated object is deleted
                    - There can only be {{one}} destructor for a class
                    - Make destructors **virtual** when―The class has subtypes or super-types - as we'll want to inherit the destructor
                    - Stack allocated objects, with {{destructors}}, are a good way of freeing memory after the scope is exited.
                - **Copy Constructors**
                    - ```cpp
// Initialization methods:
Complex c(1,2);
// VS
Complex d = c; // Copy constructor evoked
``` 
                    - To augment the default copy constructor use the following syntax―```cpp
class Complex {
	Complex (const Complex& c) {...} 
}
// we don't pass a value
``` This is useful when I have member variables with pointers in for example. Don't just wanna copy everything
                    - To **disallow **copying of objects―Make the copy constructor **Private!** Note, can still use assignment );
                    - ^^IMPORTANT NOTE:^^ Assignment (d = c) differs from invoking the copy constructor: Complex d = c. **Does not** use the copy constructor.
                    - What does copying an object using Complex x = y; do by **default? **―Simply copies any non-static member variables, no constructor called! 
                    - 
                - **Assignment operator**
                    - By **default **when the assignment operator is used―all the **non-static** members of a class are **overwritten **(x = y;). 
                        - This may not be desirable if the class contains pointers, when I copy a dog I want it to have a pointer to its own dog bowl?
                    - You can implement your own assignment operator this syntax (for the class Complex)―```cpp
Complex& Complex :: operator=(Complex& c) {...}
// We take the input to the right hand and return a reference
// e.g in x = y, c = y
``` 
                    - We use **reference types** in the assignment operator―Because  if we passed by value the **copy constructor would have to be invoked,** which would be slower. It would also be slower because we would be passing more data.
                - **Constant member Functions**
                    - **Member functions** can be declared **const **―This prevents the function from modifying any object members.
                    - The syntax for constant member functions is (for a function real in the Complex class )―```cpp
 double Complex::real() const {
 	return this->re;
 }
 // Note that if you declare beforehand you need to include the const:
 double real() const;
```
                - **Arrays and heap allocation**
                    - If we want to create an array of objects, the class needs a {{default constructor}}.
                    - To create and delete objects on the heap, we use this syntax―```cpp
 Complex* c = new Complex(1.0);
 // To delete them we use
 delete c;
 // This invokes the object destructor !!
```
                    - We **need **a method for **array heap deletion** because―C doesn't distinguish between a **pointer to an object**, and a **pointer to an array of objects**. 
                    - Array heap deletion is done using the following syntax―```cpp
 delete[] c;
```
                    - Deleting objects using the array heap deletion invokes―the object destructor on each object.
                - **Operators and Virtual (11.2)**
                    - **The "this" pointer**
                        - 'this' is used much like self in python (while in python you need to explicitly pass it, C++ does that behind the scenes). Useful for many tasks. Such as overloading in the body of a function:
                        - ```cpp
&Complex Complex::operator*=(Complex input) {
	this->re *= input.real();
	this->im *= input.imag();
	return *this;
	// Note this returns a reference NOT the object itself
}
``` 
                        - Remember, at its core this is a {{POINTER}}.
                    - **Class instances as member variables:**
                        - Consider a class with objects as member variables Complex a, how do we initialize said objects? I.e. how do we call the constructor?―```cpp
class Example {
	Complex a;
	Complex b;
	Example(double im, double re) : a(1.0, 0.0), b(im,re) {
		...
	}
};
``` 
                    - **Temporary Objects**
                        - Jesus Christ. 
                        - Temporary objects exist for the duration of a {{full expression}}, after which they are lost.
                        - What is wrong with ```cpp
string a("abd"), b("def");
 const char* SCARY = (a+b).c_str(); // c_str converts a c++ string to a c string
```―Temporary objects are things such as: ```cpp
 string a("dsadsa"), b("dsadfsadsaadsa");
 // THE TEMPORARY OBJECT BELOW IS FORMED FROM (a+b)!!!
 const char* SCARY = (a+b).c_str();
 // c_str() just returns a pointer to the objects string value
 // HOWEVER, because its temporary the value is lost!!!
 // SCARY don't got nothin' in it
```
                    - **Friends**
                        - Within our class, we can define another class to be our **friend, **this means―Code within the other class, can **access the private and protected members** of our class: ```cpp
class A {
	friend B;
	private:
		int myPrivateNumber = 3;
};
class B {
	static doStuff(A someObject) {
		// Because their friends, they share the number
		A.myPrivateNumber;
	}
}
```  
                        - We can even define non-member functions to be friends, this means―that functions defined elsewhere can access our private methods: ```cpp
 class a {
 	friend void outputTheNumber();
 	private: 
 		const static int myPrivateNumber = 3;
 }
 
void outputTheNumber() {
	std::cout << a::myPrivateNumber << std::endl; 
}
```
                        - Note: Friendship is **not symmetric** 
                    - **Operators**
                        - **Operator Overloading** 
                            - C++ allows for {{operator }}overloading, this is syntactic sugar.
                            - It can be done outside the body of the class, using the following syntax―```cpp
bool operator==(Complex a, Complex b)
	return a.real() == b.real()
		&& a.imag() == b.imag();
``` 
                            - Or it can be done inside the class, in which case we can use the following syntax―```cpp
 bool Complex::operator==(Complex a) {
 	return re == a.real() && im == a.imag(); 
 }
```
                            - Operator overloading can be done on almost all operators.
                        - **Streams**
                            - Streams output the {{left argument}}, this allows for {{chaining }}of streams.
                            - ```cpp
std::cout << "Like this" << std::endl;
``` 
                            - We can use overloading with streams like the built in type using either syntax below: The difference is:―```cpp
const char* s = "Hello World";
cout.operator<<(s);
cout.operator<<(std::endl, s);
// The << operator is overloaded, if we pass one value it behaves differently to two (in this case it would pass &s[0])
```
                    - **Inheritance** 
                        - C++ inheritance works much like java
                        - The syntax for C++ inheritance is―```cpp
class Animal {
	int legs;
	public:
		Animal(int l) : legs(l) {}
};
class Dog : public Animal {
	int ears;
	// Could have lost 1+ ears
	public:
		Dog(int e) : Animal(4), ears(e) {}
};
``` 
                    - **Virtual Functions** 
                        - What will the following code output?```cpp
class Animal {
    public:
        void makeNoise() {
            std::cout << "A noise!" << std::endl;
        }
};
class Dog : public Animal {
    public:
        void makeNoise() {
            std::cout << "BARK" << std::endl;
        }
};

void makeAnimalBark(Animal* a) {
    a->makeNoise();
}

int main() {
    Animal* a = new Animal;
    Dog* d = new Dog;
    makeAnimalBark(a);
    makeAnimalBark(d);
}
```―The problem is, makeAnimalBark isn't virtual, so the output will be - "Bark" "A noise!". Note this is **only **the case if we pass a pointer - if makeAnimalBark took the value it would work.
                        - Non virtual member functions depend on the {{static type}} of the arguments. 
                        - We need the virtual keyword because―a pointer to a subclass can be cast to the base class, then the base class cannot see the overridden function. 
                        - To get polymorphic behaviour we must―define the function as virtual in the superclass. Then it will be dynamically evaluated at runtime.
                        - **Non-virtual** member functions are called depending on {{the static type }}of the variable, pointer or reference. Since a pointer to a derived class can be cast to a {{pointer to a base class}}, calls at base class do not {{see the overridden function}}. To get polymorphic behaviour, {{declare the function virtual}} in the {{superclass}}. 
                        - To enabe **virtual functions **the C compiler must―generate a "virtual function table" or vtable. This table contains the function to call for **each object instance**. This adds **run-time overhead **as every function call **must go via the vtable.** 
                        - Why does C++ give the option of none virtual overridden functions?―It's a **trade off of performance vs Programmer conceptualization** - dynamically** type checking at run-time can be slow**, so if it's not explicitly needed we don't want to do it. Instead of a function call in machine code, its an indirect function call - While at first glance this is not much slower, the **effect on the cache and branch predictor can be large** 
                        - **Enabling Virtual Functions**
                            - To enable virtual functions, C++ uses―a vtable or virtual function table. These store a pointer to the specific function to call for every object instance. They are slower.
                            - C++ vtables also encode RTTI - runtime type information about the class in question. Can ask if an object has the same type as another.
                    - **Multiple Inheritance and Casts (11.3)**
                        - **Abstract Classes** 
                            - Works like java but with a different syntax 
                            - In C++ it is verboten to {{instantiate }}an abstract class.
                            - What is the syntax for C++ abstract classes―```cpp
 class shape {
 	public:
 		virtual void drawTheShape() = 0;
 }
 
 // Inherit it as normal
 class Triangle {
 	public:
 		void drawTheShape () {...};
 } 
```
                            - When can a derived class be instantiated?―When all the abstract functions are implemented. If some of them are, you cannot instantiate the class. 
                        - **Multiple Inheritance**
                            - In C++ you may inherit from multiple classes, if you have a name clash you must...―```cpp
class Car {
	public: void noise() {cout << "Beep";}
};
class Bike {
	public: void noise() {cout << "Toot";}
};
class Cabike : public Bike, public Car {};

// Explicit Naming is required
Cabike.Car::noise();
// or
Cabike.Bike::noise();
```
                            - The Diamond problem with multiple inheritance―Is when a subclass contains two instances of another class. E.g. two sets of the same variables. It can be achieved like so ```cpp
 class A {int someInt;};
 class B : public A {};
 class C : public A {};
 class D : public B, public C {};
 //We can do the following:
 D dInstance;
 dInstance::B.someInt = 3;
 dInstance::C.someIne = 4; 
```
                            - If we have a case of the diamond problem in C++―All variables from the "top" of the diamond, must be chosen explicitly in order to be used. E.g. we need to know which A class to choose from if we have two instances.
                            - **Virtual base classes**
                                - Virtual base classes allow for only {{one instance}} of the "top" class within inherited classes. 
                                - Virtual base classes mean that―any class that **inherits **from multiple classes **containing the same virtual base class**, will share that class instance without ambiguity.
                                - The syntax for virtual base classes is simply ```cpp
 class A {public: int a};
 class B : virtual public A {};
 class C : virtual public A {};
 class D : public B, public C {};
 
 // Means we can do:
 D d;
 cout << d.a;
```
                        - **Casts**
                            - ```cpp
double* p;
int i = (int)*p; // fine
int j = *(int*)p; // Undefined - we've lied about the type of the pointer and then got the value of the supposedly int pointer
```
                            - In C++ the role of casts and constructors can overlap, casts can be seen as implicit calls to the constructor. Give an example with Complex―```cpp
 double x = 0.1;
 Complex s = x; // Because there is a constructor that take a single double
 
 // Similar to this: (which simply does the cast)
 int a = int(x);
 int b = x; // Implicit cast!
 
```
                            - To disallow ```cpp
 double x = 0.1;
 Complex a = x;
``` we must―Declare the constructor **explicit.** Implicit vs explicit casts.
                            - If I want to allow casts from a class type to a default type I do the following―Overload the operator of the type we wish to cast to, e.g.: ```cpp
Complex i(0,1);
double x = (double)i; // TYPE ERROR

Complex {
	double operator double () {
		return a->re;
	} 
} 
``` 
                            - **New forms of casts in C++** 
                                - Problems with C-style casts include  ↓ 
                                    - They do no type checking
                                    - They are hard to find in the code
                                - Describe what these do ```cpp
dynamic_cast<T>(e)
static_cast<T>(e)
reinterpret_cast<T>(e)
const_cast<T>(e)
```―```cpp
dynamic_cast<T>(e)
// This uses RTTI and performs runtime checks
// when casting pointers within an inheritance 
// hierarchy
Car car;
dynamic_cast<Vehicle&>(car);

static_cast<T>(e)
// This is very similar to C, does it's best effort
// at compile time: static_cast<int>(3.14)

reinterpret_cast<T>(e)
// Explicitely flags re-use / reinterpiration of bit pattern

const_cast<T>(e)
// remove const or volatile from a type, allowing you to edit it as you please
// Specifically for const pointers
```
                        - 
                        - 
                        - 
                        - 
                - 
        -  _**Lecture 12:**_ 
            - **Exceptions and RAII**
                -  _Exceptions_ 
                - Done just like java, but **throw object values** not object references - the reason for this is―if you **run out of storage**, a reference requires the creation of an object in storage... 
                - The **principal of exceptions** is a given piece of code (**a library**) may  _encounter an error and not know what to do with it_  - the user code may know how to handle it.
                - One portion of code **throw**s an exception, another **catch**es it.
                - If an exception is thrown, the **call stack** is―unwound until a function that can handle the exception is found
                - An uncaught exception results in the program **terminating**.
                - **Throwing Exceptions**
                    - Exceptions in C++ are just {{normal values}}, matched by type. Often a {{class}} is used to define a particular error type.
                    - An instance of the class can then be thrown, caught and possibly rethrown. The syntax for these is―```cpp
 class myError() {
 	public:
 		int X;
 		myError(int x) : X(x) {}
 };
 
 void f() { throw myError(10); }
 
 try {
 	f();
 }
 catch (myError) {
 	//handle the error
 	throw; // re-throw
 } 
```
                    - The thrown type can carry information ```cpp
 try {f();}
 catch (myError instance) {
 	std::cout << instance.X; // outputs 10
 	// We could simply make myError a struct so all members are public
 }
```
                    - The syntax for catching multiple errors is the following (also what does catch(...) do?)―```cpp
 try {...}
 catch (errorA) {...}
 catch (errorB) {...}
 catch (...) {} // is a wildcard that catches all exceptions - discouraged, what have I caught?
```
                    - Class hierarchies can be used to express errors―e.g. someError > myError. However, this requires runtime-type-information!
                - **Exceptions and local variables**
                    - When an exception is thrown, that **stack is unwound** this **differs **from **stepping down the stack** as―all  _local variables we meet call their destructor_ . This plays the role of try - finally (in java finally frees memory)
                    - It is **good practise** to wrap locks, open file handles, heap memory etc. in **stack allocated objects** - this is because―when the stack is  _unwound the destructor of the stack allocated object_  will be called and all the  _memory can be freed. _  
                    - RAII is―**Resource acquisition is initialisation** (this is a terrible name), actually means  _memory is freed once the object is out of scope_  - done by  _wrapping resources in stack allocated objects_ .
            - **Templates**
                - Templates support **metaprogramming**, this is where―code can be  _evaluated at compile time_  rather than run time
                - Templates support **generic programming**, this is where― _types are_   _parameters _ to a program
                - Generic programming in **void * pointers** has the **disadvantage**―that we lost type-checking
                - **Class templates**
                    - The syntax for defining and instantiating a class template is―```cpp
 template<typename T> class Stack { ... };
 // Or alternatively, this is the same
 template<class T> class Stack { ... };
 
 // We can the instantiate the Stack
 Stack<int> stack = ...;
 
 // the template parameter T could be any C++ type - hence preferring typename to class
```
                    - Stack could then be implemented like: ```cpp
 template<typename T> class Stack { 
 	struct Item {
 		T val; // the important bit
 		Item* next;
 		Item(T v) : val(v), next(0) {}
 	}
 	...
 	public:
 		void push(T val);
 		T pop();
 };
```
                - **Template richer details** 
                    - What is the syntax for setting a specific template type?―```cpp
template<int i> class ... 
```
                    - How do you give a template several parameters?―```cpp
 template<typename T, int i> class ...
```
                    - How do you declare a subsequent argument with a template argument?―```cpp
 template<typename T, T x> class...
```
                    - What's the syntax for a template function with a default value?―```cpp
template<typename T, int x=100> class ...
```
                - **Templates behave like macros**
                    - Templated classes are **type checked** when―the template is instantiated. 
                    - Template **definitions are often placed** in the―header file, because if we had it in one file and another file used it - we'd end up having to recompile a load of files whenever we updated the template. Additionally, it makes separate compilation impossible.
                    - The **difference between java and C++ templates** is―** Java does type erasure** setting all the types to Object, while C**++ works like a macro** where the type is replaced and the new function for that type is added to the binary 
                - **Templated specialisation**
                    - What does **Template specialisation allows** **us to do** and what is the **syntax**?―It allows us to define **different definitions of a class** depending on the type parameter passed. 
The syntax is: ```cpp
struct Test{};

template<typename T> class someClass {
    void stuff() {std::cout << "HI!" << std::endl;}
};
// NOTE, the missing typename T is ON PURPOSE
// You must have empty angle brackets
template<> class someClass <Test> {
    void stuff() {std::cout << "NO!!" << std::endl;}
};
```
                - **Templated functions**
                    - The syntax for defining and instantiating a template class is―this:```cpp
template<typename T> void sort(T arr[], const unsigned int& len);

// The type of the template is then inferred from the argument types:
int sam[] = {4, 1, 2};
sort(sam, 3);
sort<int>(a,3); 
``` ```cpp
 
```
                    - Unlike template classes, template functions have {{type inference}}. 
                    - Two benefits and a negative of using **templates for functions**  ↓ 
                        -  _Better type checking_  than using void *
                        -  _Larger binaries_  if multiple different types of sort() are invoked
                        -  _Potentially faster code_  **than runtime type inference** as we don't have vtables for functions - we know the type of the function at compile time
                    - **Overloading templated functions** 
                        - Templated functions can be overloaded with {{templated }}and {{non-templated}} functions. Resolving an overloaded function call uses the "most {{specialised}}" function call
                - **Template specialisation enables metaprogramming** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_qsNY9_ag-ZhMMnJoBIlTBcdNHf3yUahT-AMm2TonL3ay1_mtpzUixn0ACOUbvzuRBBUliHrc1qG9hED_MVdo29srt_WOUI7DZfbgABrzZ47XkYigIPhHplmm7HBr46h.png) 
                    - Meaning templates are a Turing complete compile-time programming language! However the type you seek to evaluates value must be known at compile time - like enum or static
                - 
                - 
            - 
        - 
        - **Assorted Flashcards** **for C** 
            - What can the following code result in: ```php
#include <limits.h>
#include <stdio.h>

int main(void) {
	printf("%d\n", (INT_MAX + 1) < 0);
	return 0;
}
```―Don't let them trick you! INT_MAX + 1 results in an overflow, which is undefined behaviour so **anything can happen.** 
            - How do you use an enum?―```c
 // First declare it
 enum boolean = {true=1, false=0};
 // Then create an enum variable that can range over those values
 enum boolean some_value;
 some_value = true;
```
            - What's the different between Declaring, defining and initiating a variable? ↓ 
                - Declaring―Telling the compiler this variable name will be used
                - Defining―Setting aside storage for a variable
                - Initiating―Putting a value in that variable
            - What does the extern keyword do?―It declares but doesn't define a variable, means the variable will be defined elsewhere - i.e. we allocate it no storage.
            - What does the **static keyword** do in regards to
                - **Static functions**―Usually functions are global, however static functions can **only be accessed within the file they're declared in**
                - **Static variables**―Static local variables **don't lose their contents when they go out of scope** - so functions can reuse their values when called a multiple time. Static global variables are only seen in the file they're defined in
            - How are variables passed to functions―Pass by value. 
            - Object files consist of machine code and a list of what?  ↓ 
                - Defined or exported symbols, representing global variables or function names.
                - Declared symbols, e.g. extern variables, or unimplemented functions. Declared but not defined.
            - What does a linker do, and how?  ↓ 
                - A linker combines multiple object files into one executable
                - It does this by combining into a binary, and then adjusting absolute addresses. It also resolves all undefined symbols.  
            - Why are headers needed and what are they useful for?  ↓ 
                - Headers are needed because we want to be able to compile different files at different times and combine them later - but without a header we don't have **declarations **of those functions. So headers can  supply the declarations of functions and variables.
                - They can be used for pre-processor macros.
            - **Address space layout**
                - The **four most important areas of memory** within a **compiled x86 C** program―The **Stack**, the **heap**, the **static variables** and the **C binary code**.
                - Describe the **layout **of the **heap**, the static **variables**, the **stack **and the **C binary** code within the address space of a c**ompiled x86 C program**.―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9EqclGaeJ229axupOmXVqqvMy9SUdPUX7V3UUJKfqAvlQamJKCqsY20bbll3HJaaplmHBKojGNlm-veoZGeWqEKPswm8cEwA_HSec_wpoL4PW054VXI79WQoWA_A92Yu.png)  Start at 0xffff ffff the top of the address space The stack grows downwards The heap Grows upwards 0x0 is often mapped to an illegal address to cause a seg fault if accessed
                - Describe the **features **of the** heap **―** **The heap is **manually managed**, using malloc and free - it is **generally larger than the stack**.
                - Describe the **features** of the **stack **―The stack is **managed by the compiler** and holds temporary local** variables** **declared in the body of a function** which are freed when they go out of scope. It **grows downwards on the address space**. It grows and shrinks as function calls push and pop their values.
                - Describe the **features **of the **data segment **―The data segment holds **global and static variables** who have a value.
                - Describe the **features **of the **BSS **―The **BSS **stores **uninitialized **(don't have a value yet) local** **or global variables. Some or all of the bss is set to 0s - this is platform dependent.
            - **Unspecified behaviour is **―behaviour where the C standard give's 2 or more options of implementations - the implementation chose can be decided by the compiler. It gives more freedom to optimise code for a given architecture. Some examples are whether to implement inline, evaluation order of function arguments, order and contiguity of memory in the heap. Memory layout of storage of function arguments.
            - **Undefined behaviour is **―behaviour not described by the C standard, when a compiler is faced with such behaviour it can do **anything it likes**. An example is modifying a string literal (string literals are in read only memory) or i++ + ++i.
            - Functions and variables can be extern or static, what is the default - what does this mean in the global and static scope for both  ↓ 
                - Functions and variables marked static can't be exported as symbols in the global scope and used in external files. The default is extern, e.g. other files can reference them.
                - Variables marked static keep their value in-between function calls.
            - Describe how the #include directive is used, and how it can be used to generate macros  ↓ 
                - The include directive performs text replacement. E.g. ```c
#define TEST 4.432131
// Note that no semicolon is needed
```
                - It can be used to create macros like this baby:```c
 #define MAX(A,B) ((A) > (B) ? (A) : (B))
 // Need to be careful to put brackets around everying
 // Because any old shite can be replaced in there
``` Note that # before replacement text places it in double quotes, e.g:```c
 #define STRINGIFY(A) #A
```
            - What is array[10] (selecting the 10th array value) equivalent to in pointer arithmetic?―```c
int array[] = {1,2,3,4,5,6,7,8,9,10,11,12}
*(array+10)
//  Note you can treat all pointers to array indexes like this E.G:
int* x = &array[1];
printf("%i", x[2]); // outputs 4
``` 
            - Describe argc and argv, what are they?  ↓ 
                - argc gives the length of the argv list = number of arguments + 1 
                - Argv points to a list of strings, first containing the program name then all the args.
            - How do you pass functions as arguments to other functions―```c
void run_func(int x(int, int)) { 
	printf("%i", x(1, 2)); 
}
int compare(int a, int b) { return MAX(a, b); }

run_funct(&compare)
```
            - Describe the void* pointer―Allows pointing to any type of memory, but not legally functions. Big hole in the type system.
            - What are const and volatile variables?  ↓ 
                - const variables cannot be changed after definition 
                - volatile variables signal that the value could change through hardware - prevent unsafe compiler optimizations.
            - What is Duff's device? What's the point of it?―A method of copying from a memory buffer to an IO device, we iterate over the memory and store a certain number of bytes specified by count:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VqtmdKsQkC1KaufZPQKg_MC8keklC-xIxxV_fFtsoyr2xMotNzwbACWhV-S8GaFG-s_YNl9Lv2hnJjD2HL21UZTaJQW6fR2QkcOfQF2dvFz0BMDvpek6OICapoSx2M1n.png)
Duff's device is a method of loop unwinding, we perform multiple computations before we need to do a branch prediction / test if `--n>0. It falls through the do cases, to the correct case and then works downwards.` 
            - Describe ASan―ASan (address sanitizer) - the leading cause of errors in c is memory corruption. ASan aims to prevent array out of bounds selection, double frees, accessing freed memory, memory leaks and accessing local memory when it's gone.
Add's runtime overhead, so only use while developing. (~2x)
Doesn't catch all errors, i.e. uninitialized memory access.
Compile with -fsanitize=address
Need to recompile code with it.
            - What does MSan do?―Catches uninitialized memory accesses unlike ASan. 
Complie with  -fsanitize=memory
Very expensive! 2-3x slowdown.
Need to recompile code with it.
            - Describe UBSan―Catches undefined behaviour. E.g. division by zero, dereferencing null pointer, **unsigned **integer overflow.
Need to recompile code with it.
Modest overhead, but doesn't catch all bugs. **Seriously consider **using in production
            - Describe Valgrind―A binary that detects undefined behaviour. Adds substantial overhead.
            - Why do you need a visited tag to free a tree?  ↓ 
                - If you recursively free your children and then yourself - if both branches point to the same child a double free will occur.
                - Instead we need to mark and sweep, recursively walk over the tree and add any un"visited" nodes to a list. Then walk over the list and free all the values therein.
            - What is an arena?  ↓ 
                - Instead of recursively freeing tree data structures (or similar) initialize an arena of a certain size, and add each tree to a list within the arena 
                - When we want to free the memory, just free the arena list and then the arena itself.
                - Allows us to make arbitrary graphs without accidental multiple frees.
            - Describe reference counting and how it works―Each node stores the number of "references" to it. We only delete a node when it has no pointers to it (can't be accessed anymore). 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XtX80RyThPaoDIdusNCI6s0iQJpPuZeJLCvlaikx9PJIqqTke3l_e6GmF8NusuKS2rsAmb4yjj0lPXTPx6QYbNKXhYxGZKI1PudzHulTpkWDiSa0zSbU47e-SHv43DCv.png) 
In this graph, n2 needs to be deleted. So we decrement n from the left then the right. We then find n=0 so we recursively free n's children and then free(n).
            - How would you implement dec_ref() for reference counting?  ↓ 
                - ```c
void dec_ref(Node* node) {
	if (node != NULL) {
		node->rc--;
		if (node->rc <= 0) {
			dec_ref(node->left);
			dec_ref(node->right);
			free(node);
		}
	}
}
``` 
            - How do you help prevent errors with reference counting, and why do cycles pose an issue?  ↓ 
                - Careful getters and setters that do the work of increasing and decreasing reference count:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lG6PFf0W5W6M19NFc_FFSw5AmnmsfVY8-zIBveUfBdqbcDyM_cbh7rTkJ3JD3iTjGJE_jzqIae1DX5wnyEpm8NZHL_pEZxyTYmuZEyBKy4u0DhFYMHaFLVcZc1_kMzb0.png) 
                - Even if no other memory points to a cycle, they'll all still have non-zero reference and will stick around in memory:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IGawu447EgCLuDcXsAwMeEIhS8GLIi8hAeD5rMwCpMD4UXFt6nio7CgqTMMENCudH44UD5L-ObA-yzVaOC7qI07rv50AUn-VD0vHcRcyF_Us4BxQuV71T0RL-AQED9jX.png) 
Will both have an rc of 1 even though nothing points to them.
            - Describe mark and sweep for gc  ↓ 
                - We create an allocator with nodes and roots. We add nodes to the node linked list whenever we create them. Nodes are given a mark bit.
                - Mark stage: Then occasionally we iterate over the root nodes and find all the nodes reachable from the roots and **mark them**. 
                - Sweep stage: iterate over the node list and delete all unmarked nodes.
            - Describe what happens in a cache miss  ↓ 
                - The CPU looks up the value in memory, and stores it and the next 64 bytes it in a cache line. 
                - The (address, value) pairs are stored in the cache. Pointers are expensive **because **cache misses are expensive. 
            - What's the difference between intrusive and non-intrusive lists?―Intrusive lists store the data with the list node - rather than having a pointer to some data storage. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_R4lLTSnAORejlRt76NJcyfHa3RTD_2SIVqi1n4Y6tlVsINxUGj7WFSOd7qkpupnLtl_-a5CXclBPNg0x-8gxJuoKDEIeFgeDBOvKUP2EJ9eKOBIF-hBltahYnRKzBUC.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KJvq7K4WPNpTU3jCR_F8Qxldi9IDZHmW5KfOsVWd4SAcSjvnD05zvxwTfGIP4mDqJ3n62Oezc5ig_PEODRqls3vi1xhdpPDfAAWx-nuBY6obTmUIZ1pQTM1RxPURxqtt.png) 
            - Describe list of structs to array of structs―Following pointers on linked list is slow, but linked lists give us dynamic size adjustment. 
Convert your linked list to an array, better cache coherency as we can load lots of items into the cache at once. 
**Need to know size of array beforehand.** 
            - Describe Array of Structs to Struct of arrays  ↓ 
                - If we only want to iterate over one element in a struct, it can be slow to do so as we're loading garbage into the cache line. 
So create a data vector that stores lists of each element
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KrCJi3nhdGwkw37jM0wA40iLnDtmH5fEfPW48w5B2CYt2zD0RI-vi2tdUw4FXhk6syw-O-ysck1tF99Nx3L9ebJZ-CiqVIUkOt4GFt7MOO8CmJlxWV54lEGxz-bsIFW7.png) VS![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yTchK_wqPnhrWBJGhaXRg26lXr1-EjzCsKQOxn2sGfi1KnVr9TDlVM99cWCFJ1V8sZ5aRA5OLmRdCJCnj_TFMeGy3zKhHEjE0AQUU0JJ3_f9a9pYfTs-Ty5aoU7lcquy.png) 
            - Describe what's wrong with this code: ```c
float A[MAX, MAX], B[MAX, MAX]
for (i=0; i< MAX; i++) {
  for (j=0; j< MAX; j++) {
    A[i,j] = A[i,j] + B[j, i];
  }
}
```  ↓ 
                - We iterate over rows of A and columns of B. This is fine for A, as the rows are laid out contiguously:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AeFlGbVYSJM_qMocaYfEU-JPCoMtwn73Cb-0G1O_jhzdZxSp425Pf6arfpB1-giUBP6Jwsz2b_wBk58O64IZ-fo9gp706PF5nMLapdslKDjjWOri4ZMaBODpvFy6XwTu.png)
However, for B we're jumping columns - so by the time we can use the cache for the next item in a row of B, it will likely have been evicted by all the cache-line's generated by A. 
                - We can solve this by making it so a cache miss on one matrix lookup brings data that the other matrix can use.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/z_12bNa40dYDuyhchyDgjhLPt_439oCY9bG_zQDbDEFiITCZJoNVXavs8sBu-6vO17PaYMvycVF1F0bhD52jsPppYvnvLyOkzHp44UHvYbvNbWDH0t3kQ9t4-e_mP33Z.png)
```c
float A[MAX, MAX], B[MAX, MAX];
for (i=0; i< MAX; i+=block_size) {
  for (j=0; j< MAX; j+=block_size) {
    for (ii=i; ii<i+block_size; ii++) {
      for (jj=j; jj<j+block_size; jj++) {
        A[ii,jj] = A[ii,jj] + B[jj, ii];
      }
    }
  }
}

``` 
            - What are regression tests, and where do they fit in the debugging process?―First we note a bug in a unit test. From there we locate the offending code and correct and recompile it. Finally we run a regression test to ensure our update hasn't messed anything else up - e.g. checks if other unrelated unit tests now fail. 
            - How can you use the pre-processor to tidy up source code during debugging―```c
 #define DEBUG 0
 #define print_debug(A, B) {
 	if (DEBUG) {
 		printf(A);
 		printf(B);
 		fflush(stdout);
 	}
 }
 // So if we don't want to debug, all the print_debug calls get 
 // deleted in the object file
``` ```c
 
```
            - How can we find defects other than printing?―Use asserts - ```c
assert(hp != NULL)
```Makes the error message much nicer, and we can quickly find the source of the bug. 
            - What are interpretive debuggers and direct debuggers?  ↓ 
                - Interpretive debuggers execute code statement by statement and allow you to view memory throughout.
                - Direct debuggers require you to place a break point, and stop execution when you reach there and allow you to step forwards. Allows you to inspect program memory. 
            - How does the debugger know which memory is where?―The compiler emits a symbol table, which records the "name" of the variable/function in binary and the associated memory location. E.g. 0x100000f72 could be the printf function.
The debugger then emits more debugging data in the memory so we know which function is which.
This debugging information can also be used to match commands executed with the PC to know which line we're on.
            - 
            - 
        - **Assorted Flashcards for C++**
            - How do you define an enum variable in C++, and what to ways are there to change it's value later?  ↓ 
                - ```c
// Note no = after enum name in C OR C++
enum boolean {TRUE=1, FALSE=0};
enum boolean sam = FALSE;

sam = boolean(1);
sam = boolean(2300);
sam = TRUE;
``` 
            - What are references and what are they useful for?―References are like pointers, with an implicit * added for each use. They allow you to pass by reference, without allowing you to mess around with pointer arithmetic. 
Useful for functions, where you pass a reference to the value you want it to change.
            - Describe the use of const with references, and how it effects type conversion  ↓ 
                - const informs the compiler that the value shouldn't change, and will type check accordingly.
                - const variables also get type converted implicitely, e.g.: ```c
 void func1(const float& sam) {...}
 void func2(float& sam) {...}
 double pi = 3.1415912331324;
 func1(pi); // WORKS float -> double
 func2(pi); // FAILS
```
            - What happens if you overload a function in a different scope?  ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6gCIFGOFBLZuWW1xxZOAviFB7fJ8jJlhAtbhVH3y0AAMCMQCBdcFMvL27dcP5KlpI8pw_Ci8zumxKlUVZrNHJAkE5ihIgzKm7ZCwKaIE__yWRVOFkLDMXIZrcw4_4C5K.png) 
            - Describe how namespaces are used, how do you retrieve specific items from them? Finally describe what you would place in the header file   ↓ 
                - Related data and functions can be grouped in a namespace: ```c
 namespace Stack {
 	int stack_size = 100;
 	int pop() {...}
 	void push() {...}
 	...
 }
```
                - We access items within, by either importing the whole namespace or using `::` to select items. ```c
 Stack::pop(); // 
 if (Stack::stack_size == 3) {...}
 
 using Stack::pop(); //imports Stack
 using namespace Stack; // imports everything
```
                - We stick definitions in the header: ```c
namespace Stack {
 	int stack_size;
 	int pop();
 	void push();
 	... // More definitions
}
``` 
            - What is a namespace?―A namespace is a way of logically collecting related pieces of code, it also allows for managing scope. E.g. values are scoped within their namespace.
You can define the same namespace multiple times.
            - What is the use of extern "C", why do we need it? ↓ 
                - extern "C" allows you to specify parts of the code which are written in C. e.g. ```c
 extern "C" {
 	#include <"some_c_library.h">
 }
```
                - This solves the name-munging issue, because C & C++ give different symbol names to functions. While the C compiler just generates _f for a function, C++ will generate `__Z1fv` to allow for things like multiple definitions of with different argument types - what C++ does for overloaded functions is called name munging.
            - If a library is written in C, how can you allow the library.h header function to be imported by both C & C++ code?  ↓ 
                - Use the #ifdef ```c
#ifdef __cplusplus
	extern "C" void some_func(int);
#else 
#	 include <stdbool.h>
	extern void some_func(int);
#endif
``` 
            - What's wrong with this code?![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V9Jk74YQsYumjpJ8sTZAvr2yMZBex3zvVQfGNzIF9mN6gsSXu01i8OdH_paQDmh9A1MP1gvs_4tM9zS3b2agExHmoi3K0A3pX4TUV_FTVnhokXeCkkvyE1DX9Lkr1mtN.png)―We've written C code that takes a compare function for sorting. And we then pass it a **C++ **compare function - this won't work as the C++ compare has a different entry sequence than C. So likely will fail.  
            - What are static member of a class? How do you define them?―Don't vary **per class. NOT PER OBJECT!!!** 
They must be declared **in **the class and declared **outside **of the class: ```c
class Some_Class {
   public:
    static int sam;
    void output() { cout << sam; }
};
int Some_Class::sam = 3;
// Cant define them inside the class okay!
``` 
            - Are values of a certain class references to the class? And are member functions resolved statically or dynamically? ↓ 
                - No, they are the class themselves.
                - Member functions are resolved statically by default, but we can get Java-style resolution using `virtual.` 
            - How are structs copied/assigned?―Either bit copied, or the result is left unassigned.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VUaxQP6qlTiRTse41Vbl38zQDQlt-V4ccWVbpnyPW1AojQJeJMHv15r3ZAKqJmsPRTP5SYecu6ICvBajGXpLzvzAZ1Y5tplVV3DcXC-XRaORYv9cm5KKNvXn2GRM_KKL.png) 
            - How do you disable default constructors?―```c
 class some_class {
 	private: some_class() {}
 };
``` Make it private!
            - What does the default copy constructor do, when is it called and how do you override it?  ↓ 
                - By default, the copy constructor just copies all the fields
                - The copy constructor is called when you define an undefined object with another object: ```c
 MyClass x = ...;
 MyClass y = x;
```
                - Override the copy constructor for a class MyClass using: ```c
 MyClass::MyClass(const MyClass& x) {...}
```
            - What does the assignment constructor do by default, why might that not be desirable and how do we override it?  ↓ 
                - By default the assignment constructor overwrites all non-static members.
                - That might not be desirable, as we might want to clean up some state of the object (e.g. points to some large object in memory). 
                - Override using the following:```c
Complex& Complex::operator=(const Complex& c) {...}
``` 
            - What does declaring a member function constant do?―This means the member function cannot edit any of the contained state: ```c
 double Complex::real() const {
 	// cant modify the complex number in any way
 	return re;
 }
```
            - When can you create a class array like Complex[5], and how do you delete that array?―When the class has a default constructor.
You delete that array using ```c
 delete[] array; 
 // This runs the destructor on all the elements in the array
 // Then deletes the array.
```
            - How do you overload built in operators?―```c
 bool Complex::operator==(Complex b) {
 	return re==b.real() && im==b.imag();
 }
```
            - What are temporary objects?―A temporary object is an object without a name, i.e. an object not bound to anything. A temporary object cannot be bound to a non const reference.
Temporary objects can crop up when functions return objects, e.g.:```c
string a("A "), b("string");
const char *s1 = a.c_str();        // OK
const char *s2 = (a + b).c_str();  // Wrong
```
            - What are the two uses of Friend in classes?  ↓ 
                - Declare functions or operators as friends so that they can access your private fields and methods.```c
 class Matrix {
 	...
 	friend Vector operator*(const Matrix&, const Vector&);
 	...
 };

```
                - Declare other classes as friends ```c
 class X {
 	...
 	friend class Y;
 };
```
            - Would an object of type bicycle be able to access wheels?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dmYyblFLPyK-D8gbCvbbPK0E04_4DeRz7cnujKuyI-ovmphwzAkRzRhX-O1AcrWOLw3VqkyN3voae4ic_j1zz2EbYr04xjrBF_p8AwnBiAIuIP7ymHWZLCGGb6jFxQdh.png)―No bro. Wheels is private, we can't get at it. We could do the following though:
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QUymn6Nps420kbCbB9gVng4k5kKnmkOLV-wusylbZT2oTfr1HJP44M--dBbHOxqnZ2snAxAicaND5a739uinm2_o-jLjyMeUUetjTf0RjyLzDSMM6NSfq8KBSca9Hvh1.png) 
And then we could access wheels using get_wheels().
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Uo7oYk2fU-eELpUrdTBUQxMmfuqnhJOWrhgcKfA7KnHlQrJbgh_9rp9bSTx5XBolfrjAD4EOITvDvX4shuWh0UZMkHPGxw5SuGe5d4pQ-nvwyqI93QBHVl_sUmS1rDkv.png)
What would this print, if both vehicles and bicycles have a maxSpeed function (bikes = 12, vehicles =60), **and why**  ↓ 
                - This would print 60 12. 
                - This is because C++ doesn't use java type vtable function selection by default - instead the function relies on the static type of the object. 
To get java-style, you have to declare a function virtual.
            - How are virtual functions made possible?―The compiler generates a vtable, this points to the correct function for every object instance.
These indirect function calls are slower than direct calls.
            - What do virtual functions allow for?―Non-virtual member functions are called depending on the static type of the variable, pointer or reference. Since a pointer to a derived class can be cast to a pointer to a base class, calls at base class do not see the overridden function. To get polymorphic behaviour, declare the function virtual in the superclass:  
            - What is an abstract class in C++, how do you define one?  ↓ 
                - An abstract class is a class with one or more abstract methods. They are needed because sometimes a base class simply isn't definable (how do you define an Animal?). When you inherit from an abstract class, you may implement one or more of the methods - only when you have **implemented ALL of the methods** can the class be instantiated into an object. 
                - ```c
class Shape {
	public:
		int virtual sides() = 0;
};
``` 
            - How do you deal with function name clash when a class inherits from multiple parent classes?―Specify exactly which class implementation you'd like to use E.g. For a class ShapeAnimal which inherits from Shape and Animal - and inherits size() ```c
 ShapeAnimal x;
 x.Shape::size();
```
            - Is this (Multiple instances of base class) legal? If so how do I access B's version of A? Finally, how could we change this so we had only one instance of the base class?
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5D7MLqn2xRZGQtpGrduAOyeefEc5cRrI3w5KRtxPtVHCAUHCaxbp6-po7CYO2XYHF8lf3qjwGra0v8w-U7L7VbyukDyMEuAn_68VMjPEYpXO1_DjO6_vQe54vBfgCuY0.png)  ↓ 
                - This is legal! (EXCEPT VAR SHOULD BE PUBLIC TO USE) We store to versions of A, because B and C could change them in different ways
                - ```c
D d;
d.B::var;
d.C::var;
``` 
                - If we made A virtual. E.g. convert to: ```c
 class A {
   public:
    int var;
};
class B : public virtual A {};
class C : public virtual A {};
class D : public B, public C {};
```
            - How do casts play a similar role to constructors? How can enforce that casts from a Complex to a double must be explicit?  ↓ 
                - When casting from a type to a class, we have to construct a new object from the given type. E.g. ```c
double Y = 3.14;
Complex x = Complex(Y); //Normal
Complex x = Y; //Implicite cast
``` 
                - Overload double() in the class declaration: ```c
 class Complex {
 	...
 	explicit operator double() const () {
 		return real;
 	}
 
 };
```
            - What are the downsides of C++ casts, and what does C++ provide to combat this?  ↓ 
                - Hard to find and classify in a text editor AND they do no type checking.
                - C++ offers multiple different types of casts for different scenarios which are easier to search for and can provide type checking.
                - ```c
dynamic_cast<T>(e); // Does runtime type checking when casting pointers
static_cast<int>(3.14); // Normal C casting, quick
const_cast<int>(const_int); // Lets you remove const (or volatile) from a type, even though the type system says you can't
reinterpret_cast<some_struct>(some_other_struct); // Reinterprets a bit pattern as another type.
```
            - Why is casting to a supertype with C-style casts like this dangerous with multiple inheritance? ```c
static_cast<Class *>(pointer);
//equivalently:
(Class *)pointer;
```―Because under multiple inheritance, we might need to change the underlying data structure to cast it to a parent. In Java this would require no work, but as we could be storing multiple copies of a multipley inherited type - we might need to get rid of one. 
We would also need to check all the virtual function definitions are correct.
            - What is stack unwinding, and how does it relate to RAII? What happens to the call stack when an exception is thrown? ↓ 
                - When the stack is unwinding, stack allocated objects (that aren't const or volatile) that have been created within the try{} block have their destructors called. However, any heap allocated objects won't have their memory cleaned up. 
Thus, RAII wraps heap allocated objects in stack allocated ones - so when they go out of scope they are removed. The constructors of those heap allocated objects do the necessary allocation, and the destructors do the necessary freeing. Note that stack unwinding happens at the end of {} blocks as well.
                - The stack is unwound until we find a function which can handle the exception.
            - What can you throw as errors in C++?―You can throw any type, and then match the type in the catch block ```c
try {
    someClass c = someClass();
    throw(c);
} catch (SomeClass err) {
    cout << err;
}

//Or you can catch a double - any old shit works

try {
    double x = 3.14;
    throw(x);
} catch (double error) {
    cout << error;
}
```
            - How do you multiple exceptions, and finally catch any exceptions?  ↓ 
                - ```c
try {//something}
catch(Err1 e) {}
catch(Err2 e) {}
catch(...) {}

// The catch(...) catches all errors
``` 
            - If you're using class hierarchies to represent different types of errors, what do the functions associated with catching them need to be?―They need to be virtual, i.e. you need run time type information to know which type of function you should be running for the error. Because we'll catch the **parent class **and run a function that the child class augments.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QpV1OxWlPhhuA_jZCB9DeeDIPrhaO9wgwfDn7xgmWbUpWCLpxpgCqPtAENl3sryvXqeiBmQjy6X4LLUeNGt2LZA_KOOQXIjY5U_KDa-ElpbqUNw-MYAfAQkLOxja2MEX.png) 
            - Describe templates, how do you template a class or a function? How do they differ from Java Generics?  ↓ 
                - Templates allow you to do generic programming, where a set of functions and data structures can be repurposed to work on a variety of types. They allow you to specify type **and **value for a given type - e.g. we specify the type of the array AND it's max length below in SomeClass below. We can use the values to specify anything we like, as in SomeOtherClass
                - ```c
template<typename T> void sort(T arr[], int size) {
...}
template<typename T, int max> class SomeClass {
	public:
		T[max] arr;
};
template<class T, int max> class SomeOtherClass {
	public:
		T val;
		int array[max]; 
};


//Note that we can write class in the space of typename,
// makes no bloody difference mate!! haha!!
``` 
                - Java Generics require parameters to be Java reference types. In C++ parameters may be of other types, e.g. integers, compare: ```c
template<Class c, int n> struct Buffer { C[n] buf; int size; } 
class Buffer { public C[] buf; };
``` 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/v-2hvHxzmcwdzIQCZL1q9Ju2uFCIGAglL6aULboUOQtcXdBRFLgqYg2SSSv73hw57QC9t-W5pTWIuq8OhUKOe0_U02wbAgG-J1iK5jL-lut1XKgbUGuL05KDRBwig7O_.png) 
                - C++ also includes template specialisation, where we can write code which is used on a specific type - Java don't have this. E.g. We might want the code to work one way in general, but do something different when encountering int's: ```c
template <typename T>
void fun(T a) {
    cout << "The main template fun(): " << a << endl;
}

template <>
void fun(int a) {
    cout << "Specialized Template for int type: " << a << endl;
}

// This will behave differently for int's than any other types
```
                - In C++ we can specialize on int, doubles etc while in Java the special type cannot be a primitive type.
            - How do templates behave like macros?―At compile time, the T in the class or function get's replaced with the relevant type. This results in a larger binary, as the compiler needs to create a new definition for each instantiation.
            - How does a template function know what type it's using when it's called? How is this an improvement on void*? ↓ 
                - It infers it from the arguments, using ML style type inference.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sgw36WlbT8mwxVnm39zcv99MLFSDZaUF0w0-veKL6p-eykQuVRsCLULAm8ZJ46Ne9JScArshS5Qy9-WJZCgndItp7DxUWsCj0vvMei1O2e-ywo6Vg64w2CrGL-9PmzrZ.png) 
                - Better than void*: ↓ 
                    - Allows for type inference 
                    - Possibly faster code (no function pointers in vtables)
                    - **However**, does result in larger binaries 
            - Give three examples of cases where a C program can vary in execution on different hardware. What is the benefit of this ↓ 
                - sizeof applied to 32 vs 64 bit pointers - both give 1
                - Stack direction - which can affect parameter evalutation
                - Big vs little endian
                - Primary advantages are efficiency arising from not having to respect uniformity and machine-specific low-level access.  
            - 
        - 
        - **Combined Flashcards**
            - What can the following code result in: 
            - ```php
#include 
#include 

int main(void) {
	printf("%d\n", (INT_MAX + 1) < 0);
	return 0;
}
```
            - ―Don't let them trick you! INT_MAX + 1 results in an overflow, which is undefined behaviour so **anything can happen.**
            - How do you use an enum?―
            - ```c
// First declare it
 enum boolean = {true=1, false=0};
 // Then create an enum variable that can range over those values
 enum boolean some_value;
 some_value = true;
```
            - What's the different between Declaring, defining and initiating a variable? ↓ 
                - Declaring―Telling the compiler this variable name will be used
                - Defining―Setting aside storage for a variable
                - Initiating―Putting a value in that variable
            - What does the extern keyword do?―It declares but doesn't define a variable, means the variable will be defined elsewhere - i.e. we allocate it no storage.
            - What does the **static keyword** do in regards to
                - **Static functions**―Usually functions are global, however static functions can **only be accessed within the file they're declared in**
                - **Static variables**―Static local variables **don't lose their contents when they go out of scope** - so functions can reuse their values when called a multiple time. Static global variables are only seen in the file they're defined in
            - How are variables passed to functions―Pass by value.
            - Object files consist of machine code and a list of what? ↓ 
                - Defined or exported symbols, representing global variables or function names.
                - Declared symbols, e.g. extern variables, or unimplemented functions. Declared but not defined.
            - What does a linker do, and how? ↓ 
                - A linker combines multiple object files into one executable
                - It does this by combining into a binary, and then adjusting absolute addresses. It also resolves all undefined symbols.
            - Why are headers needed and what are they useful for? ↓ 
                - Headers are needed because we want to be able to compile different files at different times and combine them later - but without a header we don't have **declarations **of those functions. So headers can  supply the declarations of functions and variables.
                - They can be used for pre-processor macros.
            - **Address space layout**
                - The **four most important areas of memory** within a **compiled x86 C** program―The **Stack**, the **heap**, the **static variables** and the **C binary code**.
                - Describe the **layout **of the **heap**, the static **variables**, the **stack **and the **C binary** code within the address space of a c**ompiled x86 C program**.―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9EqclGaeJ229axupOmXVqqvMy9SUdPUX7V3UUJKfqAvlQamJKCqsY20bbll3HJaaplmHBKojGNlm-veoZGeWqEKPswm8cEwA_HSec_wpoL4PW054VXI79WQoWA_A92Yu.png)  Start at 0xffff ffff the top of the address space The stack grows downwards The heap Grows upwards 0x0 is often mapped to an illegal address to cause a seg fault if accessed
                - Describe the **features **of the** heap **―** **The heap is **manually managed**, using malloc and free - it is **generally larger than the stack**.
                - Describe the **features** of the **stack **―The stack is **managed by the compiler** and holds temporary local** variables** **declared in the body of a function** which are freed when they go out of scope. It **grows downwards on the address space**. It grows and shrinks as function calls push and pop their values.
                - Describe the **features **of the **data segment **―The data segment holds **global and static variables** who have a value.
                - Describe the **features **of the **BSS **―The **BSS **stores **uninitialized **(don't have a value yet) local** **or global variables. Some or all of the bss is set to 0s - this is platform dependent.
            - **Unspecified behaviour is **―behaviour where the C standard give's 2 or more options of implementations - the implementation chose can be decided by the compiler. It gives more freedom to optimise code for a given architecture. Some examples are whether to implement inline, evaluation order of function arguments, order and contiguity of memory in the heap. Memory layout of storage of function arguments.
            - **Undefined behaviour is **―behaviour not described by the C standard, when a compiler is faced with such behaviour it can do **anything it likes**. An example is modifying a string literal (string literals are in read only memory) or i++ + ++i.
            - Functions and variables can be extern or static, what is the default - what does this mean in the global and static scope for both ↓ 
                - Functions and variables marked static can't be exported as symbols in the global scope and used in external files. The default is extern, e.g. other files can reference them.
                - Variables marked static keep their value in-between function calls.
            - Describe how the #include directive is used, and how it can be used to generate macros ↓ 
                - The include directive performs text replacement. E.g.
                - ```c
#define TEST 4.432131
// Note that no semicolon is needed
```
                - It can be used to create macros like this baby:
                - ```c
#define MAX(A,B) ((A) > (B) ? (A) : (B))
 // Need to be careful to put brackets around everying
 // Because any old shite can be replaced in there
```
                - Note that # before replacement text places it in double quotes, e.g:
                - ```c
#define STRINGIFY(A) #A
```
            - What is array[10] (selecting the 10th array value) equivalent to in pointer arithmetic?―
            - ```c
int array[] = {1,2,3,4,5,6,7,8,9,10,11,12}
*(array+10)
//  Note you can treat all pointers to array indexes like this E.G:
int* x = &array[1];
printf("%i", x[2]); // outputs 4
```
            - Describe argc and argv, what are they? ↓ 
                - argc gives the length of the argv list = number of arguments + 1
                - Argv points to a list of strings, first containing the program name then all the args.
            - How do you pass functions as arguments to other functions―
            - ```c
void run_func(int x(int, int)) { 
	printf("%i", x(1, 2)); 
}
int compare(int a, int b) { return MAX(a, b); }

run_funct(&compare)
```
            - Describe the void* pointer―Allows pointing to any type of memory, but not legally functions. Big hole in the type system.
            - What are const and volatile variables? ↓ 
                - const variables cannot be changed after definition
                - volatile variables signal that the value could change through hardware - prevent unsafe compiler optimizations.
            - What is Duff's device? What's the point of it?―A method of copying from a memory buffer to an IO device, we iterate over the memory and store a certain number of bytes specified by count: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VqtmdKsQkC1KaufZPQKg_MC8keklC-xIxxV_fFtsoyr2xMotNzwbACWhV-S8GaFG-s_YNl9Lv2hnJjD2HL21UZTaJQW6fR2QkcOfQF2dvFz0BMDvpek6OICapoSx2M1n.png) Duff's device is a method of loop unwinding, we perform multiple computations before we need to do a branch prediction / test if `--n>0. It falls through the do cases, to the correct case and then works downwards.`  
            - Describe ASan―ASan (address sanitizer) - the leading cause of errors in c is memory corruption. ASan aims to prevent array out of bounds selection, double frees, accessing freed memory, memory leaks and accessing local memory when it's gone. Add's runtime overhead, so only use while developing. (~2x) Doesn't catch all errors, i.e. uninitialized memory access. Compile with -fsanitize=address Need to recompile code with it.
            - What does MSan do?―Catches uninitialized memory accesses unlike ASan.  Complie with  -fsanitize=memory Very expensive! 2-3x slowdown. Need to recompile code with it.
            - Describe UBSan―Catches undefined behaviour. E.g. division by zero, dereferencing null pointer, **unsigned **integer overflow. Need to recompile code with it. Modest overhead, but doesn't catch all bugs. **Seriously consider **using in production
            - Describe Valgrind―A binary that detects undefined behaviour. Adds substantial overhead.
            - Why do you need a visited tag to free a tree? ↓ 
                - If you recursively free your children and then yourself - if both branches point to the same child a double free will occur.
                - Instead we need to mark and sweep, recursively walk over the tree and add any un"visited" nodes to a list. Then walk over the list and free all the values therein.
            - What is an arena? ↓ 
                - Instead of recursively freeing tree data structures (or similar) initialize an arena of a certain size, and add each tree to a list within the arena
                - When we want to free the memory, just free the arena list and then the arena itself.
                - Allows us to make arbitrary graphs without accidental multiple frees.
            - Describe reference counting and how it works―Each node stores the number of "references" to it. We only delete a node when it has no pointers to it (can't be accessed anymore).  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XtX80RyThPaoDIdusNCI6s0iQJpPuZeJLCvlaikx9PJIqqTke3l_e6GmF8NusuKS2rsAmb4yjj0lPXTPx6QYbNKXhYxGZKI1PudzHulTpkWDiSa0zSbU47e-SHv43DCv.png)  In this graph, n2 needs to be deleted. So we decrement n from the left then the right. We then find n=0 so we recursively free n's children and then free(n).
            - How would you implement dec_ref() for reference counting? ↓ 
                - ```c
void dec_ref(Node* node) {
	if (node != NULL) {
		node->rc--;
		if (node->rc <= 0) {
			dec_ref(node->left);
			dec_ref(node->right);
			free(node);
		}
	}
}
```
            - How do you help prevent errors with reference counting, and why do cycles pose an issue? ↓ 
                - Careful getters and setters that do the work of increasing and decreasing reference count: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/lG6PFf0W5W6M19NFc_FFSw5AmnmsfVY8-zIBveUfBdqbcDyM_cbh7rTkJ3JD3iTjGJE_jzqIae1DX5wnyEpm8NZHL_pEZxyTYmuZEyBKy4u0DhFYMHaFLVcZc1_kMzb0.png)
                - Even if no other memory points to a cycle, they'll all still have non-zero reference and will stick around in memory: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IGawu447EgCLuDcXsAwMeEIhS8GLIi8hAeD5rMwCpMD4UXFt6nio7CgqTMMENCudH44UD5L-ObA-yzVaOC7qI07rv50AUn-VD0vHcRcyF_Us4BxQuV71T0RL-AQED9jX.png)  Will both have an rc of 1 even though nothing points to them.
            - Describe mark and sweep for gc ↓ 
                - We create an allocator with nodes and roots. We add nodes to the node linked list whenever we create them. Nodes are given a mark bit.
                - Mark stage: Then occasionally we iterate over the root nodes and find all the nodes reachable from the roots and **mark them**.
                - Sweep stage: iterate over the node list and delete all unmarked nodes.
            - Describe what happens in a cache miss ↓ 
                - The CPU looks up the value in memory, and stores it and the next 64 bytes it in a cache line.
                - The (address, value) pairs are stored in the cache. Pointers are expensive **because **cache misses are expensive.
            - What's the difference between intrusive and non-intrusive lists?―Intrusive lists store the data with the list node - rather than having a pointer to some data storage.  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_R4lLTSnAORejlRt76NJcyfHa3RTD_2SIVqi1n4Y6tlVsINxUGj7WFSOd7qkpupnLtl_-a5CXclBPNg0x-8gxJuoKDEIeFgeDBOvKUP2EJ9eKOBIF-hBltahYnRKzBUC.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KJvq7K4WPNpTU3jCR_F8Qxldi9IDZHmW5KfOsVWd4SAcSjvnD05zvxwTfGIP4mDqJ3n62Oezc5ig_PEODRqls3vi1xhdpPDfAAWx-nuBY6obTmUIZ1pQTM1RxPURxqtt.png)
            - Describe list of structs to array of structs―Following pointers on linked list is slow, but linked lists give us dynamic size adjustment.  Convert your linked list to an array, better cache coherency as we can load lots of items into the cache at once.  **Need to know size of array beforehand.**
            - Describe Array of Structs to Struct of arrays ↓ 
                - If we only want to iterate over one element in a struct, it can be slow to do so as we're loading garbage into the cache line.  So create a data vector that stores lists of each element
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/KrCJi3nhdGwkw37jM0wA40iLnDtmH5fEfPW48w5B2CYt2zD0RI-vi2tdUw4FXhk6syw-O-ysck1tF99Nx3L9ebJZ-CiqVIUkOt4GFt7MOO8CmJlxWV54lEGxz-bsIFW7.png) VS![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yTchK_wqPnhrWBJGhaXRg26lXr1-EjzCsKQOxn2sGfi1KnVr9TDlVM99cWCFJ1V8sZ5aRA5OLmRdCJCnj_TFMeGy3zKhHEjE0AQUU0JJ3_f9a9pYfTs-Ty5aoU7lcquy.png)  
            - Describe what's wrong with this code:
            - ```c
float A[MAX, MAX], B[MAX, MAX]
for (i=0; i< MAX; i++) {
  for (j=0; j< MAX; j++) {
    A[i,j] = A[i,j] + B[j, i];
  }
}
```
            -  ↓ 
                - We iterate over rows of A and columns of B. This is fine for A, as the rows are laid out contiguously: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AeFlGbVYSJM_qMocaYfEU-JPCoMtwn73Cb-0G1O_jhzdZxSp425Pf6arfpB1-giUBP6Jwsz2b_wBk58O64IZ-fo9gp706PF5nMLapdslKDjjWOri4ZMaBODpvFy6XwTu.png) However, for B we're jumping columns - so by the time we can use the cache for the next item in a row of B, it will likely have been evicted by all the cache-line's generated by A.
                - We can solve this by making it so a cache miss on one matrix lookup brings data that the other matrix can use. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/z_12bNa40dYDuyhchyDgjhLPt_439oCY9bG_zQDbDEFiITCZJoNVXavs8sBu-6vO17PaYMvycVF1F0bhD52jsPppYvnvLyOkzHp44UHvYbvNbWDH0t3kQ9t4-e_mP33Z.png)
                - ```c
float A[MAX, MAX], B[MAX, MAX];
for (i=0; i< MAX; i+=block_size) {
  for (j=0; j< MAX; j+=block_size) {
    for (ii=i; ii
```
                - ` `
            - `What are regression tests, and where do they fit in the debugging process?→First we note a bug in a unit test. From there we locate the offending code and correct and recompile it. Finally we run a regression test to ensure our update hasn't messed anything else up - e.g. checks if other unrelated unit tests now fail. `
            - `How can you use the pre-processor to tidy up source code during debugging→`
            - ```c
#define DEBUG 0
 #define print_debug(A, B) {
 	if (DEBUG) {
 		printf(A);
 		printf(B);
 		fflush(stdout);
 	}
 }
 // So if we don't want to debug, all the print_debug calls get 
 // deleted in the object file
```
            - 
            - `How can we find defects other than printing?→Use asserts - `
            - ```c
assert(hp != NULL)
```
            - Makes the error message much nicer, and we can quickly find the source of the bug.
            - `What are interpretive debuggers and direct debuggers? `
            - `How does the debugger know which memory is where?→The compiler emits a symbol table, which records the "name" of the variable/function in binary and the associated memory location. E.g. 0x100000f72 could be the printf function. The debugger then emits more debugging data in the memory so we know which function is which. This debugging information can also be used to match commands executed with the PC to know which line we're on.`
            - `  `
            - How do you define an enum variable in C++, and what to ways are there to change it's value later?  ↓ 
                - ```c
// Note no = after enum name in C OR C++
enum boolean {TRUE=1, FALSE=0};
enum boolean sam = FALSE;

sam = boolean(1);
sam = boolean(2300);
sam = TRUE;
```
            - What are references and what are they useful for?―References are like pointers, with an implicit * added for each use. They allow you to pass by reference, without allowing you to mess around with pointer arithmetic.  Useful for functions, where you pass a reference to the value you want it to change.
            - Describe the use of const with references, and how it effects type conversion ↓ 
                - const informs the compiler that the value shouldn't change, and will type check accordingly.
                - const variables also get type converted implicitely, e.g.:
                - ```c
void func1(const float& sam) {...}
 void func2(float& sam) {...}
 double pi = 3.1415912331324;
 func1(pi); // WORKS float -> double
 func2(pi); // FAILS
```
            - What happens if you overload a function in a different scope? ↓ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6gCIFGOFBLZuWW1xxZOAviFB7fJ8jJlhAtbhVH3y0AAMCMQCBdcFMvL27dcP5KlpI8pw_Ci8zumxKlUVZrNHJAkE5ihIgzKm7ZCwKaIE__yWRVOFkLDMXIZrcw4_4C5K.png)  
            - Describe how namespaces are used, how do you retrieve specific items from them? Finally describe what you would place in the header file ↓ 
                - Related data and functions can be grouped in a namespace:
                - ```c
namespace Stack {
 	int stack_size = 100;
 	int pop() {...}
 	void push() {...}
 	...
 }
```
                - We access items within, by either importing the whole namespace or using `::` to select items.
                - ```c
Stack::pop(); // 
 if (Stack::stack_size == 3) {...}
 
 using Stack::pop(); //imports Stack
 using namespace Stack; // imports everything
```
                - We stick definitions in the header:
                - ```c
namespace Stack {
 	int stack_size;
 	int pop();
 	void push();
 	... // More definitions
}
```
            - What is a namespace?―A namespace is a way of logically collecting related pieces of code, it also allows for managing scope. E.g. values are scoped within their namespace. You can define the same namespace multiple times.
            - What is the use of extern "C", why do we need it? ↓ 
                - extern "C" allows you to specify parts of the code which are written in C. e.g.
                - ```c
extern "C" {
 	#include <"some_c_library.h">
 }
```
                - This solves the name-munging issue, because C & C++ give different symbol names to functions. While the C compiler just generates _f for a function, C++ will generate `__Z1fv` to allow for things like multiple definitions of with different argument types - what C++ does for overloaded functions is called name munging.
            - If a library is written in C, how can you allow the library.h header function to be imported by both C & C++ code? ↓ 
                - Use the #ifdef
                - ```c
#ifdef __cplusplus
	extern "C" void some_func(int);
#else 
#	 include 
	extern void some_func(int);
#endif
```
            - What's wrong with this code?![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V9Jk74YQsYumjpJ8sTZAvr2yMZBex3zvVQfGNzIF9mN6gsSXu01i8OdH_paQDmh9A1MP1gvs_4tM9zS3b2agExHmoi3K0A3pX4TUV_FTVnhokXeCkkvyE1DX9Lkr1mtN.png)―We've written C code that takes a compare function for sorting. And we then pass it a **C++ **compare function - this won't work as the C++ compare has a different entry sequence than C. So likely will fail.
            - What are static member of a class? How do you define them?―Don't vary **per class. NOT PER OBJECT!!!**  They must be declared **in **the class and declared **outside **of the class:
            - ```c
class Some_Class {
   public:
    static int sam;
    void output() { cout << sam; }
};
int Some_Class::sam = 3;
// Cant define them inside the class okay!
```
            - Are values of a certain class references to the class? And are member functions resolved statically or dynamically? ↓ 
                - No, they are the class themselves.
                - Member functions are resolved statically by default, but we can get Java-style resolution using `virtual.`
            - How are structs copied/assigned?―Either bit copied, or the result is left unassigned.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VUaxQP6qlTiRTse41Vbl38zQDQlt-V4ccWVbpnyPW1AojQJeJMHv15r3ZAKqJmsPRTP5SYecu6ICvBajGXpLzvzAZ1Y5tplVV3DcXC-XRaORYv9cm5KKNvXn2GRM_KKL.png)  
            - How do you disable default constructors?―
            - ```c
class some_class {
 	private: some_class() {}
 };
```
            - Make it private!
            - What does the default copy constructor do, when is it called and how do you override it? ↓ 
                - By default, the copy constructor just copies all the fields
                - The copy constructor is called when you define an undefined object with another object:
                - ```c
MyClass x = ...;
 MyClass y = x;
```
                - Override the copy constructor for a class MyClass using:
                - ```c
MyClass::MyClass(const MyClass& x) {...}
```
            - What does the assignment constructor do by default, why might that not be desirable and how do we override it? ↓ 
                - By default the assignment constructor overwrites all non-static members.
                - That might not be desirable, as we might want to clean up some state of the object (e.g. points to some large object in memory).
                - Override using the following:
                - ```c
Complex& Complex::operator=(const Complex& c) {...}
```
            - What does declaring a member function constant do?―This means the member function cannot edit any of the contained state:
            - ```c
double Complex::real() const {
 	// cant modify the complex number in any way
 	return re;
 }
```
            - When can you create a class array like Complex[5], and how do you delete that array?―When the class has a default constructor. You delete that array using
            - ```c
delete[] array; 
 // This runs the destructor on all the elements in the array
 // Then deletes the array.
```
            - How do you overload built in operators?―
            - ```c
bool Complex::operator==(Complex b) {
 	return re==b.real() && im==b.imag();
 }
```
            - What are temporary objects?―A temporary object is an object without a name, i.e. an object not bound to anything. A temporary object cannot be bound to a non const reference. Temporary objects can crop up when functions return objects, e.g.:
            - ```c
string a("A "), b("string");
const char *s1 = a.c_str();        // OK
const char *s2 = (a + b).c_str();  // Wrong
```
            - What are the two uses of Friend in classes? ↓ 
                - Declare functions or operators as friends so that they can access your private fields and methods.
                - ```c
class Matrix {
 	...
 	friend Vector operator*(const Matrix&, const Vector&);
 	...
 };
```
                - Declare other classes as friends
                - ```c
class X {
 	...
 	friend class Y;
 };
```
            - Would an object of type bicycle be able to access wheels? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dmYyblFLPyK-D8gbCvbbPK0E04_4DeRz7cnujKuyI-ovmphwzAkRzRhX-O1AcrWOLw3VqkyN3voae4ic_j1zz2EbYr04xjrBF_p8AwnBiAIuIP7ymHWZLCGGb6jFxQdh.png)―No bro. Wheels is private, we can't get at it. We could do the following though: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QUymn6Nps420kbCbB9gVng4k5kKnmkOLV-wusylbZT2oTfr1HJP44M--dBbHOxqnZ2snAxAicaND5a739uinm2_o-jLjyMeUUetjTf0RjyLzDSMM6NSfq8KBSca9Hvh1.png)  And then we could access wheels using get_wheels().
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Uo7oYk2fU-eELpUrdTBUQxMmfuqnhJOWrhgcKfA7KnHlQrJbgh_9rp9bSTx5XBolfrjAD4EOITvDvX4shuWh0UZMkHPGxw5SuGe5d4pQ-nvwyqI93QBHVl_sUmS1rDkv.png) What would this print, if both vehicles and bicycles have a maxSpeed function (bikes = 12, vehicles =60), **and why** ↓ 
                - This would print 60 12.
                - This is because C++ doesn't use java type vtable function selection by default - instead the function relies on the static type of the object.  To get java-style, you have to declare a function virtual.
            - How are virtual functions made possible?―The compiler generates a vtable, this points to the correct function for every object instance. These indirect function calls are slower than direct calls.
            - What do virtual functions allow for?―Non-virtual member functions are called depending on the static type of the variable, pointer or reference. Since a pointer to a derived class can be cast to a pointer to a base class, calls at base class do not see the overridden function. To get polymorphic behaviour, declare the function virtual in the superclass:
            - What is an abstract class in C++, how do you define one? ↓ 
                - An abstract class is a class with one or more abstract methods. They are needed because sometimes a base class simply isn't definable (how do you define an Animal?). When you inherit from an abstract class, you may implement one or more of the methods - only when you have **implemented ALL of the methods** can the class be instantiated into an object.
                - ```c
class Shape {
	public:
		int virtual sides() = 0;
};
```
            - How do you deal with function name clash when a class inherits from multiple parent classes?―Specify exactly which class implementation you'd like to use E.g. For a class ShapeAnimal which inherits from Shape and Animal - and inherits size()
            - ```c
ShapeAnimal x;
 x.Shape::size();
```
            - Is this (Multiple instances of base class) legal? If so how do I access B's version of A? Finally, how could we change this so we had only one instance of the base class? ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5D7MLqn2xRZGQtpGrduAOyeefEc5cRrI3w5KRtxPtVHCAUHCaxbp6-po7CYO2XYHF8lf3qjwGra0v8w-U7L7VbyukDyMEuAn_68VMjPEYpXO1_DjO6_vQe54vBfgCuY0.png) ↓ 
                - This is legal! (EXCEPT VAR SHOULD BE PUBLIC TO USE) We store to versions of A, because B and C could change them in different ways
                - ```c
D d;
d.B::var;
d.C::var;
```
                - If we made A virtual. E.g. convert to:
                - ```c
class A {
   public:
    int var;
};
class B : public virtual A {};
class C : public virtual A {};
class D : public B, public C {};
```
            - How do casts play a similar role to constructors? How can enforce that casts from a Complex to a double must be explicit? ↓ 
                - When casting from a type to a class, we have to construct a new object from the given type. E.g.
                - ```c
double Y = 3.14;
Complex x = Complex(Y); //Normal
Complex x = Y; //Implicite cast
```
                - Overload double() in the class declaration:
                - ```c
class Complex {
 	...
 	explicit operator double() const () {
 		return real;
 	}
 
 };
```
            - What are the downsides of C++ casts, and what does C++ provide to combat this? ↓ 
                - Hard to find and classify in a text editor AND they do no type checking.
                - C++ offers multiple different types of casts for different scenarios which are easier to search for and can provide type checking.
                - ```c
dynamic_cast(e); // Does runtime type checking when casting pointers
static_cast(3.14); // Normal C casting, quick
const_cast(const_int); // Lets you remove const (or volatile) from a type, even though the type system says you can't
reinterpret_cast(some_other_struct); // Reinterprets a bit pattern as another type.
```
            - Why is casting to a supertype with C-style casts like this dangerous with multiple inheritance?
            - ```c
static_cast(pointer);
//equivalently:
(Class *)pointer;
```
            - ―Because under multiple inheritance, we might need to change the underlying data structure to cast it to a parent. In Java this would require no work, but as we could be storing multiple copies of a multipley inherited type - we might need to get rid of one.  We would also need to check all the virtual function definitions are correct.
            - What is stack unwinding, and how does it relate to RAII? What happens to the call stack when an exception is thrown? ↓ 
                - When the stack is unwinding, stack allocated objects (that aren't const or volatile) that have been created within the try{} block have their destructors called. However, any heap allocated objects won't have their memory cleaned up.  Thus, RAII wraps heap allocated objects in stack allocated ones - so when they go out of scope they are removed. The constructors of those heap allocated objects do the necessary allocation, and the destructors do the necessary freeing. Note that stack unwinding happens at the end of {} blocks as well.
                - The stack is unwound until we find a function which can handle the exception.
            - What can you throw as errors in C++?―You can throw any type, and then match the type in the catch block
            - ```c
try {
    someClass c = someClass();
    throw(c);
} catch (SomeClass err) {
    cout << err;
}

//Or you can catch a double - any old shit works

try {
    double x = 3.14;
    throw(x);
} catch (double error) {
    cout << error;
}
```
            - How do you multiple exceptions, and finally catch any exceptions? ↓ 
                - ```c
try {//something}
catch(Err1 e) {}
catch(Err2 e) {}
catch(...) {}

// The catch(...) catches all errors
```
            - If you're using class hierarchies to represent different types of errors, what do the functions associated with catching them need to be?―They need to be virtual, i.e. you need run time type information to know which type of function you should be running for the error. Because we'll catch the **parent class **and run a function that the child class augments. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/QpV1OxWlPhhuA_jZCB9DeeDIPrhaO9wgwfDn7xgmWbUpWCLpxpgCqPtAENl3sryvXqeiBmQjy6X4LLUeNGt2LZA_KOOQXIjY5U_KDa-ElpbqUNw-MYAfAQkLOxja2MEX.png)  
            - Describe templates, how do you template a class or a function? How do they differ from Java Generics? ↓ 
                - Templates allow you to do generic programming, where a set of functions and data structures can be repurposed to work on a variety of types. They allow you to specify type **and **value for a given type - e.g. we specify the type of the array AND it's max length below in SomeClass below. We can use the values to specify anything we like, as in SomeOtherClass
                - ```c
template void sort(T arr[], int size) {
...}
template class SomeClass {
	public:
		T[max] arr;
};
template class SomeOtherClass {
	public:
		T val;
		int array[max]; 
};


//Note that we can write class in the space of typename,
// makes no bloody difference mate!! haha!!
```
                - Java Generics require parameters to be Java reference types. In C++ parameters may be of other types, e.g. integers, compare:
                - ```c
template struct Buffer { C[n] buf; int size; } 
class Buffer { public C[] buf; };
```
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/v-2hvHxzmcwdzIQCZL1q9Ju2uFCIGAglL6aULboUOQtcXdBRFLgqYg2SSSv73hw57QC9t-W5pTWIuq8OhUKOe0_U02wbAgG-J1iK5jL-lut1XKgbUGuL05KDRBwig7O_.png)  
                - C++ also includes template specialisation, where we can write code which is used on a specific type - Java don't have this. E.g. We might want the code to work one way in general, but do something different when encountering int's:
                - ```c
template 
void fun(T a) {
    cout << "The main template fun(): " << a << endl;
}

template <>
void fun(int a) {
    cout << "Specialized Template for int type: " << a << endl;
}

// This will behave differently for int's than any other types
```
                - In C++ we can specialize on int, doubles etc while in Java the special type cannot be a primitive type.
            - How do templates behave like macros?―At compile time, the T in the class or function get's replaced with the relevant type. This results in a larger binary, as the compiler needs to create a new definition for each instantiation.
            - How does a template function know what type it's using when it's called? How is this an improvement on void*? ↓ 
                - It infers it from the arguments, using ML style type inference. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sgw36WlbT8mwxVnm39zcv99MLFSDZaUF0w0-veKL6p-eykQuVRsCLULAm8ZJ46Ne9JScArshS5Qy9-WJZCgndItp7DxUWsCj0vvMei1O2e-ywo6Vg64w2CrGL-9PmzrZ.png)  
                - Better than void*: ↓ 
                    - Allows for type inference
                    - Possibly faster code (no function pointers in vtables)
                    - **However**, does result in larger binaries
            - Give three examples of cases where a C program can vary in execution on different hardware. What is the benefit of this ↓ 
                - sizeof applied to 32 vs 64 bit pointers - both give 1
                - Stack direction - which can affect parameter evalutation
                - Big vs little endian
                - Primary advantages are efficiency arising from not having to respect uniformity and machine-specific low-level access.
        - 
        - 
    - Further Graphics
        - Supervision 2
            - 
            - 13. 
            - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/17Edkai7g7Fd5qebWHcQ8u-c8mqJ2t8Fs2Ps0S0XNiNz-twUM2aCW9oIReBYPPF2Cto8FtoPALxoC4LxgpSmCdjF9_jYSw8tvh9oxWqE9eDXMeb-25IcpWVuPCf42kkW.png) 
            - 14.  
                - a.) Rigging is the process of adding joints and bones between said joints, and placing them within the model. The bones are given a weights that decide the area of effect of the bones, and the bones & joints form a hierarchy (a graph) that is used to filter down transformations from one bone to other connected bones. 
                - b.) i.) $T_f = T(1/2) + I (1/2)$ 
                    - $x' = T_f(x)$ 
                    - ii.) $T_f = T(\frac{1}{1+\sqrt2}) + I(\frac{\sqrt2}{1+\sqrt2})$  OR $T_f = T(\frac{\sqrt2}{1+\sqrt2}) + I(\frac{1}{1+\sqrt2})$ 
                    - $x ' = T_f(x)$ 
            - 15.
                - a.) Dual quaternions allow us to represent translations and transformations in the same value - this makes animation much easier, before if one was to perform a translation & a rotation - careful attention would have to be payed that they were at the same rate (as we always translate around a point! We don't want our characters arm to rotate around where it was 30 frames ago) while with dual quaternions we get that for free.
                - b.) It's more computationally costly to use quaternions than linear blend skinning. (Not by a huge amount though)
                - Linear blend skinning can be repurposed with ease to 2D animation (or any number of dimensions, but so far we've stuck to 2 or 3 I await a compelling 1d tale), as the process is simply averaging transformations said process makes no demands about the dimensionality of the transformations. On the other hand, quaternions do not make the jump from 3d to 2d so handily - if we only have i & j we don't have the property ijk = -1 to differentiate them from imaginary numbers (ii = jj = ij = -1 is true for i = j = sqrt(-1) ) and just  i & j don't form a basis with which to perform animations.
            - 16.)
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Mq6Ih2CBkUzLCkQyVPcARUSPbWA6pB8Tx2ap3czxbNB39-2BElzVEn-sQqUY2Abm2zJV7mPGLGoUryKQhjmg7CdBsroRlPL1VLb3dvK0cJ0XTQPVHHQzjVrJs84SUWmx.png) 
                - We can separate them into three dual quaternions, one rotation about the z axis, on translation along the x axis with zero rotation and finally a translation along the y axis with zero rotation. Finally, if we multiply the three quaternions the resulting quaternion will represent our translation.
            - 
            1. ) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/w07UOHSZFJMNCuTGrCebgQaTJV7bJwcW8lc7f3lkThFZ9tvE24CUQy14UjfmU-vqgixnNwzUYgd2Rk0h58wPwTalUJxfvxAYa-hLaoGcvdfSxOvGQumLsnyiGlJaLG2H.png) 
                - Caustics - The interaction of light & curved surfaces or glass - e.g. the refraction of light. 
                - Subsurface scattering - Light entering and being scattered by a translucent material, e.g. skin.
                - Soft shadows - point lights cannot create soft shadows, as the incident intensity is the same everywhere (varying only with distance & angle) - there are not points in which light from multiple  points on a light source combine and a gradient of luminance is formed. 
                - >1 bounce lighting - light that arrives after performing 2 or more bounces is not accounted for. 
            2. In areas of low curvature, less sampling needs to be done as the effect of reflections and bouncing will be less pronounced. In areas of high curvature we should have more samples, as there is likely to be more occlusion of objects and more light bouncing effects.  
            3. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/13sI92Gd6ULRrF3ccPF88UmC8s1hGEqwULrVuPoak71HfJUjMn6D7XHAlHHjXgdk90XoI3P1xnGUd_2N5jAE4Qz3klTtLoto7vfoBu1AmZQgqY7GT9wmxvjcHZjkdki5.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OezAp8d-MEVVCvNOfirN596uGuWLFVCq-Qg469KNo8-qjZs-dQBnLijynE-hDCBtH4-veMjI8wafwqHl1ulMM-65UFO81bz-DlRNfgguqThRLWfV3Lr4-kethFFQ5BPk.png) 
            4. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wLzNg5gjNt3K68OaClfqbigNmPNV1-RdDY6KrQ0XOSSVr9m1HtRmrghguA5E7wOKx0SqNXOkot5n8MkJCmMEbVvta_N6SoFV-nYRTXAFJ-djLIY9CqYjYROLcXJlLSc6.png) 
                - c.) b shows that using importance sampling, we can still get a high quality approximation while sampling a smaller area - in reality we use monte carlo integration rather than analytical integration. 
                - d.) Using cosine we sample more light values at a greater angle to the surface, giving perpendicular light a higher weight. We assume that light is coming from all angles for this to work, however if light is coming from a more acute angle - less of it will be sampled resulting in a lower quality image.
            - 
        - Supervision 1
            1. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gTK4JW5ryukfyXXqdHoX4VyrjOWKeMBIZR0MErPyy_mHWLsDjfYI4zrgxLoRfwEXncPqwwfL72zuQswpGmhrs_N-qTprQFaoxHUWpdUPJ19TiARF_nwV6yK5JSa4Afkv.png) 
                - Parametric surfaces are created using a function f which operates on sets $X \subseteq R^m$ and $Y \subseteq R^n$mapping set X onto set Y: $f : X \rightarrow Y$. Whereas Implicit surfaces are created using a (distinct) function f, where a point $x \in R^k$ lies on the surface if $f(x)=0$. 
                - While both use a function f to decide the resulting surface, the parametric function gives us a way of creating points while the implicit function gives us a way of testing points.
                - Advantageous components:
                    - Implicit functions give us an easy way to check if a point is inside, outside or resting on a surface ($f(x) < 0$, $f(x) > 0$, $f(x)=0$), the parametric function gives us no such method.
                    - Parametric functions give us a method of generating points on the surface (any point on our domain X can be mapped to our range Y), Implicit functions require us to check points to find one resting on the curve.
                    - Parametric surfaces allow for easy computing analytic point wise differentials, while Implicit functions do not.
                - Implicit surfaces would be suited more for ray tracing applications, when checking if a ray impacts a surface is the norm - in particular, implicit surfaces can be useful for visualizing mathematical formulas and the conjunction of multiple formulae (computing $f_1(x) + f_2(x)=0$for two such formulae).
                - Parametric surfaces (most commonly Bezier surfaces) are used for 3d modelling and sculpting, however the surface would undergo a second process of being converted from a parametric surface to a normal mesh that can be rendered using rasterization.
                - Point set surfaces differ from parametric and implicit surfaces in a number of ways ↓ 
                    1. They are generated from real world data.
                    2. They can be used for direct rendering using rasterization with dishes rather than triangles.
                    3. They are not analytically differentiable like parametric surfaces.
                    4. Formed by taking points and examining other points in a region and forming a proxy surface and then checking if the given point lies on that surface.
            2. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/7GDDM58Km_D6S_B7eTNJRuJuvQZ2lcJOW9WMCy-vyKsvkWTCPlVnMA6ULHFbsRn96NOYlogLBgaD02NrPdWYGVujgdOh2Tqld1J27kRYT0EL28IH24B7GaUblTqK91q-.png) 
                - $x^2+y^2=e^{2t}$
                - $R = e^t$
                - This describes a spiral centred at (0,0) where the distance from the origin is $e^t$
                - 
            3. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZmkyinQzH326IJwFAzKQAtsa4DjUaZkSKgdGN2ILCYoWxNMSz5LfKPKDRhxI_gCOzrpjNX9XzgBFrSJiE0U-q9q4g_AeCGpt8esliS1FG8NREOTPRZmrnrXCzhnFudMq.png) 
                - a.) First you must compute $S_u = \frac {\partial (s(u,v))}{\partial u}$ and $S_v = \frac {\partial (s(u,v))}{\partial v}$ , one can then compute the normal via $\frac{S_u \times S_v}{||S_u \times S_v||}$.
                - b.) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jWzZl4lN7321QOkwuLl-rQjLyrCTQHHloFpCA7i31xJ_aiViYTlSBWgQyh430XaZCzVQv66zT4atPR-jzFKdo7K03icYTVX3q89WQ2nMKXqS7V0XdJ91BT71WGRyLY7v.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VRgybaadKrIWnFcRLL4KuG_nZMVq3eWkG6IL2aQutOuyYrgkyEvqiFJU3oT9xTxH0x2R38Xxel-F-ld7kyFgLW0TZZU2xa_AmUc8RwNGFJxE3sQEZETk4hW9PkO_sv3H.png) 
            4. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8UIPYfQEqMSbTmQI5-FBIbJ3mtNHi6yluVkNxBaGrWKOV4ToxB-e_ludB-kOIn7TCdZatDLxcfuDn0nKUG8cba9JGVYW53vTW4zqYDOWv0gesXcwuPRq0u60MoGIUHuf.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4sG-KtYTLnDXew39MLnWTljXM61KRrHhOyT_C5lSh3n9Md2ceefb3bBHHYowjiMzHZBdc5k3UTxMvcUreaIc7IonOk7PBVFy3yzNxMWlExbjp4LdhqwUbhPb4S7n5a8i.png) 
                - 
            5. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XOvvZeCJvrhpTcf7nXIMF8k55A6mrKyG3U296WFcv6gSIkPOHkH2Rc602pUZH_Whj4Lj79-n9FjqHOAxdkqtHkHJVl9ZxW8L5qDGP6d1HBFnar1KZ11BscqFF1tl2WdS.png) 
                - This implicit function will comprise all (x,y) coordinates where either x, y or both x&y are zero, meaning the function will be a plus sign on the xy plane. The result will be at (0,0) there are infinite possible surface normals, while at every other point there are two equally plausible surface norms.
            6. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_Avg0u7PgJxITQwfaoK-ZxNT52GGyof6YJk5QVE2BQfM5c-Yblz20LZ2GAdY4Ataq4mGQTFU-a_MaFFfvf9iVgHvOmqToxKhKC7QR_ayMi_JHBQoteu2v9_IpU64ziYx.png) 
                - Triangle meshes store two separate lists, a list of vertices (containing the x, y and z of each vertex) and a list of faces containing **indices** of sets of three vertices. E.g:
                - v = [(2,1,4), (2,4,6), (1,4,6), (2,4,5)]
                - f = [0, 1, 2, 0, 1, 3]
                - From these lists surface normals and other factors are calculated later.
                - b.) The geometry would be the list of vertices, while the topology is the faces - while the topology deals with the more abstract concept of the connections between vertices, the geometry is the actual coordinates in $R^3$.
            7. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5b-NrE_NjGIA3t1Pie8OKt4e2vKrQb0aGEiVYC18feWaJh1s4lBqocECCpVNjNl_kwKR7TgVZvI4ohGBSyx6JDtNIiWWCQAL3keyYAyPjwOiSm0iBdf--8-p2QTxT7wV.png) 
                - For normal triangular meshes this is vital for a number of reasons ↓ 
                    1. The order of the neighbouring vertices decides the direction of the surface normal, without that ordering the resulting vertex can be facing the wrong way.
                    2. The choice of neighbouring vertices decides the size and direction of each face.
                    3. The neighbouring vertices of a given vertex cannot simply be calculated by finding the 2 closest vertices, using this method can result in areas of the mesh being devoid of triangles (a see through part of the mesh) or alternatively an area where triangles overlap. 
                - Point set surfaces instead do away with triangular meshes and use dishes oriented in the direction of the normal. With a large enough number of dishes, we can cover the whole surface and remove the need for storing neighbouring vertices.#
            8. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-VeCFokgTj5THyvZ9IIAPBfs_rDbc2vueDR3P-iZKsbBo85CCQRpSbltC7kceuyif3ffjF3SdUKohuqzmg2NaaFNWw6MMhX426EWBs3ckHEEeNzNbU5r5Wk_zIcKXFe7.png)  
                - A manifold is a topological space that is locally Euclidean, that is for every point there's a neighbourhood around that point that is topologically the same as a closed ball in $R^n$. This differs from a manifold with boundaries, where every point is either topologically the same as the closed ball or a half ball in $R^n$.
            9. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/PEM-naJb74Gs19Jh3tbbGf2pnLbzQiIt9rIYBLAV4Bm8XlmA5QrjfRs-XJIO8331tIU_0KcwatDz0JKNb5bsf_SFNwup9jx5DvQMkV1MxrUlo281wdNat3crFfkZt3pL.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/nbpdkz3g0QTGfwXYz_2uyTwCzjPTci0hfo3j38PyEvqyPA088yUhPZ5S8DYrtRSILq_vxGpcjNg3QkMwnv9-36llrfMzauxSAe6suBcpPtRlTBnX8wVFVC2XpyvvoG00.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/owCO8hXdTgMd1Uu6nRgpsMYjlfdPbQauA2SNjhsFi1qT1KChWZiOPWQ2wc5lGVQVMQfdRKSeiCi2lVIamb2ajAhP8GWy0CXh2qxqp4VqS5VpasWB9bJvmHrx62VmNRU4.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/HWlUsLlt6unQe7NVpUwo4q0Gc5-_adujByQFIgxpjRBtUIkqtYtoSZD4PsLTo83IXYPrZJz6VV1TXFel9HN352HXyVBeMcMXFmX7ZLz2DNAjQHozIymb-KxK7D4UyiOL.png) 
                - 
            10. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uIcH7WGA54QIVhJ0azN-JgKybCDazS3nb53Q8fSnOopK2AxZLIDjzNsZ8VpCt9qxZ7HhT50ZzvhMiKJ2Q7rWt_E34F9u_1Rrt8J9_pg8SHGHp-QrlBvN1sC46gpxcP5G.png)![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_MYCKA-U6uo18yOOH0vg0MJCh-VbzUD6JEaBhkdeMkUAuIFH7rWS059UxTsrSIjNBY3opRO67MSX7fzCVwzptVrt_8P5eDMYc_Bqa4NNvjThGIKDg6RhF692uBzCV3iV.png) 
            11. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XXtkOh1iTv2VMWTab58JYFEVXFb0HN5cExyDfPZfweVMW7f-nE2JzM6UBNkxSJXBkftd9ZKZl27snfG1dDvMMdfygheG4SRalotI6yU5B46hgRzMJAUQGI6Geyy3yzsi.png) 
            - 
            - 
            - 
            - 
            - 
            - 
            - 
            - 
        - **Lecture 1 Geometry Representations**
            - What are the two main sources of 3D geometry? ↓ 
                1. Camera sampling (Point clouds) 
                2. Digital 3D modelling 
            - **Considerations for 3D geometry**
                - Storage
                - Acquisition of shapes
                - Rendering of shapes 
                - Editing shapes
                - Creation of shapes
            - **Parametric Curves and surfaces**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jij8LnlRdQqRvRBAWGGdAQMBmBAFtnPIX84u1QnPQlrCKIOQJnD1KbTRNX_glroP69oKsNKhXOxi2qyMepdHfb5THuZ-07L1y9AX7YuqIzediVK3zAVFe-NmwQ3Zo6m9.png) 
                - What are the three fundamental equations for parametric curves ↓ 
                    1. $f : X \rightarrow Y$
                    2. $X \subseteq R^m$ 
                    3. $Y \subseteq R^n$ 
                - Where  __usually __ m < n and infinite samples of the function result in the whole geometry.
                - **Planar Curve**
                    - What are the m and n values for a planar curve, and give an examples function ↓ 
                        - m = 1, n = 2
                        - $s(t) = (x(t), y(t))$
                        - $r(\cos(t), \sin(t)) \space\space\space t \in [0, 2\pi)$ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/f2zAZKGcOtm5cobCTsjFhv6Fdm2jafuCJtEazRN8u1fwJ-e9yv5kPMD2VnxBSWfibY_v5A0z5U25qKn968rSEQSoLLgcS-WlC503hNYuG9Jh5b6R0Bw6lWPaEtU2jpaU.png) 
                    - 
                - **Bezier Curve**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/G_qXB6PERNCbBzvO_5ofEPkcZqZFNcDgss5N4PEJVEToDvw1xg3rlBXbOhEpkB5WGi2vVuIbiEib8fR3WkzywVfW-yDihEDZLk6dR69RHs9kkcb7UV_a6svTZ0dsUKFV.png) 
                    - $s(t) = \sum_{i=0}^{n}{P_i B_n^i(t)}$ 
                    - $B_n^i(t)={n \choose i}t^i(1-t)^{n-1}$ 
                    - Allows for moving smoothly from point to point
                - **Bezier Surface**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZE9Z9UBBbLbpiGj7UYd_gZSWf4HHEub6Iy-TWItU3QlrIOG8lGMYJ88XNuqV1tkLO5g7oZjcl2yQ3-PG_SQIaGAeSRLNXd9Dm_mUloD7Yyxb2l5pPC57N7sGLddAKmaz.png) 
                    - $$s(u,v)=\sum^m_{i=0} {\sum^n_{j=0}} 
 \space P_{i,j} \space B^i_m(u) 
\space B^j_n(v)$$
                    - Where B is shown above and P is the height of the control point of each vertex
                    - A Bezier surface will always lie within the convex hull formed by its control points
                - **Normal and Tangent Planes:**
                    - Give the equations used to calculate the basis vectors and normal vector for a parametric surface ↓ 
                        - $S_u = \frac {\partial (s(u,v))}{\partial u}$, $S_v = \frac {\partial (s(u,v))}{\partial v}$
                        - 
                        - $\frac{S_u \times \ S_v}{||S_u \times \ S_v||}$ ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/W0TDCq4d8uKp1i4ptIwB4wG8Py776569voOeqwE7HOAHqgZZaUPDZP1UraYIbiGfYAnrbnfVn7igdp5jIkBk3bUNu7BPxu1MVWxn8UKeFuK_QjoVzgOrqCm4rk3Klk-x.png) 
                - **Volumetric Representations**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/aFvD3btV7B1EOl8_jCMjS4vvfbnDY2LWxNnfD92VeckX4W_4Ot5HcSN6IKF_zCESGAGAJNJsngr2EWqySoex2RoWPyZ4F0LQIhelvG00OOGt56pDBpqC-xwoAZeLfFD9.png) 
                    - $X\subseteq R^3 , Y \subseteq R^1$
                    - Forms "density fields", useful for medical Data
            - **Benefits and downsides of Parametric Curves and Surface ** ↓ 
                - Benefits ↓ 
                    - Easy to generate points on the surface
                    - Nice point wise differentiation
                    - Easy to control
                - Downsides ↓ 
                    - Hard to reverse-engineer surface
                    - Hard to decide inside-outside surface
                    - Hard to decide if on the surface
            - **Polygonal Meshes**
                - Connected points that form a piecewise linear approximation to the surface
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/pVRbFTJiQ_QCs6i4Y2_KVqFIlF1n5sOjiJUwECTh8Q0OvPRz104EIuSfphvZzmsxnem5MnmDMlP8p2bPcy8ryFn6wYD8cGll_AEfCN99ozHuK-kN_QyLeLqXuckNysxI.png) 
            - **Implicit Curves and surfaces**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OSyZL75cz9VCR7NvHHYyt6cgxA0xiF5C_u2ZT_qyb3PRulP0uzR6tO_6ftdws0WHs_aeJf3hrDffa-uPV9Z2CgFcu8lQT0v4XW1cqKxz_U7HJB-6MSxcbYvDCffYIl7n.png) 
                - What are implicit Curves?―Curves that satisfy a given property $f.$
                - What are the two Fundamental equations of implicit curves and surfaces ↓ 
                    1. $$f: R^m \rightarrow R$$
                    2. $$S = \{x \in R^2 \space| \space f(x) = 0 \}$$ 
                - What three things can our implicit function tell us? And what is this useful for? ↓ 
                    - $f(x) > 0$  Then we're outside our surface
                    - $f(x) = 0$  Then we're on our surface
                    - $f(x) < 0$  Then we're inside our surface 
                    - Useful for collision detection
                - Example usage:
                    - Give the implicit function for a circle―$f(x) = x^2 + y^2 - r^2$
                    - How do you find the surface normal of an implicit function? ↓ 
                        1. First calculate grad of f, for example $\nabla f(x,y,z) = (\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z})^T$ 
                        2. Then normalize the resulting vector
                    - How would we find the surface normal of the implicit function of a sphere? ↓ 
                        1. First note that the implicit function would be $f(x,y,z) = x^2 + y^2 + z^2 - r^2$ 
                        2. Then take the grad of f, $\nabla f(x,y,z) = (2x, 2y, 2z)^T$
                        3. Finally normalize the resulting vector
                - What are the pros and cons of implicit surfaces? ↓ 
                    1. Pros ↓ 
                        - Easy to Know inside / outside / on Surface
                        - Easy to combine surfaces
                    2. Cons ↓ 
                        - Not suited for real time rendering
                        - Hard to generate points on the surface
                        - Limited set of surfaces (for finite functions)
            - **Point Set Surfaces**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ezsxBHc9t5yBc3GfDoiccHryfozIxDjLE0beSaveN-VUt20FKhBkAs5eExIE-WxU_eiVIDWLodZpPCx_36B9SR0uV72ZJHl2OuTGf8zNaLc86vYCDi3F_FVQV2RFOMKl.png) 
                - Point cloud ⇒ a surface, end with the analytic form
                - What type of data can you use for point-set surfaces?―Only point wise data (position, colour and sometimes normals).
                - Approximate measures ⇒ Smooth surfaces
                - What is the process of determining if a point is on a point set surface? ↓ 
                    - First examine a region around the query point and map a simple proxy surface (line, plane, hyperplane) to that region![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LVdEODyX7e5rr0D7IF1K5ENp7bN0Kyw8pclpQI6MfUzQYeFxTzxaXwRJcISTG2WXVc0263NC9bHnLz1I_s_PS6HIc1Hn3R8T5qUr-WgaHwTbkLGBqw7fjI_z9muuF2uH.png) 
                    - Then if the point lies on that line it is on the surface
                - How can we project onto our point set surface?―Using our proxy surface, we can get the line between said surface and our point and then project it onto our shape. Using this we are guaranteed to end up on the surface.
                - What is the resulting function after generating a point set surface?―The result is an implicit function ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/b-PQYvFpJ5nOnDjLgeClezXc7nPGedb19FXDjcDJWKB4kWYIbghJQpzk80BlZ0thAfuLJ-knQPv3kSJzpA-hFdAhF9i7FT4vne5YUlO7olHcjeb5mrTHb7p_K5A_j4Dr.png)
                - Give three important features of Point Set surfaces ↓ 
                    - They are robust to noise.
                    - You can do direct rendering with them - can do rasterization using disks and surface normals around the points, rather than triangle meshes disks are used.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/hyf4-cGTIQB6M2_d20tHFIOEzJvtBcr7Zgfan8pnO_GBVSlOHPq8BNUSCxImeIDVsfhtz7od8HgcDY_Y7wBmPPV0wiUEh3y6gBNHfUaFvHzOESlZ1W9_yauMI6OsPCa_.png) .
                    - You can convert them to meshes.
                - What are the Pros of Point set surfaces? ↓ 
                    - Easy to determine if inside/outside the surface
                    - Easy to generate points on the surface
                    - Easy to determine if on the surface
                    - Can use real world data - robust to noise
                    - Can render in real time
                - What are the cons of point set surfaces?―Not efficient to use in some modelling tasks
        - **Lecture 2** **Discrete Differential Geometry** 
            - **Manifolds**
                - What is a manifold? ↓ 
                    - A manifold is a topological space that is locally Euclidean (around every point there's a neighbourhood that's topologically the same as a closed ball in $R^n$) 
                - What is a closed 2-manifold?―A surface is a closed 2-manifold if it is locally homeomorphic to a plane everywhere
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/dKte5l_PI2Zm2NUj4i-Z275X5hPPeV15rfocqZmS4pNznAKURVu-dJQ2rAU7xMNx2qlXRw_CLYmWsIrF8KmhCQPr1XGGEMbbHj9Pmt7-7trIAjl1wahOzEvawX__l_4u.png) 
                - What does homeomorphic mean?―One surface being homeomorphic to another surface, means it can be deformed (without piercing or pinching the surface) to become that second surface.
                - Math definition: 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/51gnM6JUfXL6wRogOH_bI-CTnPszmLiWWgdsmrRPopAai2XtfQNxsRA7iOgBdkiCa-0VrIV5i9ShHb5oXojk7G2DE0WZQmX3xXW0L1TUE7ZjZvsWmpBS-RkFGHi9YF2s.png) 
                    - I.e. we create a volume sphere and get the intersection of the sphere and the surface and we can map it to a circle.
                - Manifolds with Boundaries:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/f2sNy5DHFQ7BmN09_acYPmqzWsLvEGCdqgS9iV3wZNBBAQQUVMT4ME-vUoYFStvFbVnmHlfLXVX6HIAdol28njMdslDyhepZIAIxn2geKpKkvIp2aITuRpK37fU_s1Nu.png) 
                    - Each boundary point is homeomorphic to a half disk
                - We treat local areas on the shape as mappings to a 2d plane, we can then compute differentials. We get a continuous 1-1 mapping:
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3Tz91ygPntWjdga7fwAFjx81uL3qA3c1t13TsPymjw-mfTnaWO3xYQ4xO0KXuR5NhuNVGSVfS2d8GLjz0NrFSMI2j2ZGapybMTT-pwzw5oMVF-cj-Y8ijaJNyf6q0w6p.png) 
                - 
            - **Local Coordinates**
                - After mapping from an area of the curve to a 2d plane, we can define local coordinate systems and thus a surface normal.
                - $$p(u,v) = \begin{bmatrix} x(u,v) \\ y(u,v) \\ z(u,v)  \end{bmatrix}$$
                - $$p_u = \frac{\partial p(u,v)}{\partial u}$$ 
                - $$p_v = \frac{\partial p(u,v)}{\partial v}$$
                - Having created this orthonormal basis, which is a linear approximation to the surface - we can then find the surface normal $n = {\hat{p_u}\times \hat{p_v}}$ where  $\hat{p_u} = \frac{p_u}{||p_u||}$ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JaLVopTxOR2dzfUFnUOAOtId0SwnHmuJmT-7lhnt8yN2DJAjWt_wtUdElqImTuZj0gOI5yp8Cia9yXs5ZRUbQCU0TXOOfD6FsEH0aISXFn9pb41wauxQFsdRp4r4L-Ms.png) 
                - We can then define a vector t rotated within the local coordinate system $$\hat{t} = \cos(\phi) \space \hat{p_u} + \sin(\phi) \space \hat{p_v}$$
                - Finally we can use the plane defined by t and n which will cut the surface:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/-8Brlr1ugBaqXwEtdburKdWwts5IXK0KGgKbn3JTXIkCuBsuALdoLB-HJtlPx9gVII5CYpRLMP2RKb_8N5sgKdCvDA71542HKTaTYdAjrYe-BZSKmbS3JbhLBINtZCEZ.png) 
                - The curve $\gamma$ is the intersection between the curve and the surface, ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/B-hT4tHdYddzp1HPoRVNY0Sk0zJvW7pxz1QU3aHbpGz0ZUxT8cBJXYttuWf-vVuY4E69oB21phun1HRg6SuThqqaMbL9iA_q3Ol15hFj7gFww_hI7bKujdxHLz8HqBTi.png) 
                - What is this curvature we use for minimum and maximum curvature calculations? ↓ 
                    - The curvature is the change in the tangent lines of the function as we move along it: $$||\frac{dT}{ds}||$$
                    - Which is the second derivative.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/8EL3m2BKkI4-UtrtZGo2GDfHjMyNC-d7qJMKBCBS5_yz-HVrEPAsVnFXHwhlUwkZHANreEdZVGid5-uIEwaBcvFnqR78IsvKridxLnHBXt8pNc2tFi3ey4ZblmatvC8b.png) 
                - What are the principal Curvatures? ↓ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zZFXEjt9KTY2MuWviuyzubq7nOxf_dddcS-iYeMJSJIX_O7bA5kcs8V-LEruq0dxKkcO6VNAKQec0ydo5f9huOYiLjoYKW5m34irU67gDY3WITlo-vq0LMAuy_5HsUmX.png) 
                - What is the mean curvature? ↓ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uI9S-7wP_kjtF1oI7_N8nF77BGS9FclFmtA2voIl9QU5qvMIAj0bnLKTLLcQMTEBZ6KTAU2yGCHuesvHm6qa6uNOUAksFQfKS2Boor5cLkUwycNlhjCaD-M12JwSrOy5.png) 
                - What is the Gaussian Curvature?
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/o_Of_U-l_rzIc_3dsrGGLIYZl-jFKCSXe7CMOq7Tv-5QbSl2F7eEzU2_emGPVC541PXjfc5DbNAzonYQD8Xzo3B-CAKN1ojRsnADJiW9zCHamXlLx1wdc29bgBDg0AIk.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qFKiqndLatwB-2qb8juCneDmGFXkBxx3RHtzZMeLIjm6KPKlTVtSheQJ_SPB0dJNuGuwfm8RTHTxe0hdHLuFUUXsV8RV9sW4u1eIQd2h5qEntL2riDd9c-nF6QUU35Xv.png) 
                - What is Euler's Theorem? ↓ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/znH-YE5uWUdRs5GdzTaPML-Buo2lQr7pdPjhaGS5PodRGR0Zhtw9KtKbQC9xYuiULnQqIaBjXcNzCul6Mb7anjnxG_JwSHmavEqZRW7BLhWzVcH3aLpspPerOjC8Bhkj.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bkQksDnoG9sHaytQuyOCfQ9BG44Nw1-It0AFWYaLUHGiwPHrILob9f5rTwc-UwZfvXeKovInsNag_oD4ZnyS_K1MKHJczu4tLotflOfABWSrRfcCmGOMYXQwTxonm-QP.png) 
            - **Local Shape by Curvature:**
                - Isotropic : Same in all directions
                    - Facts about Spherical ↓ 
                        - k1, k2 > 0, k1=k2
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/FXocmZ9XYMUx3J4DnvFroQRfK_jpMQESHrLrGV7r3UX11vX4nr7kWRtEX8ff9gHWRPjoCXtxNUTUVqXYmp21lu63eW7Dc5zRD80mTldzbdEExc9QJCMfmb2LGvHgnZpN.png) 
                    - Facts about **Planar** ↓ 
                        - k1, k2 = 0
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UXK5d_EUdwEUhlAAV5jaJ0ZzN3QfBKikVGFUiAIbXKvm5fNZ9urNR3Zbe3zl3TdDF0bQ154zHoCVL9l6c_sRK-UP8eR7z3UJQEUfJxRZeQP2jyRgdL1RrD-oP_aeiBZm.png) 
                - Anistropic : 2 distinct principal directions
                    - Facts about elliptic ↓ 
                        - k1 > 0, k2 > 0
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/01C4IoMzLHL7XbEetHy9hOFKX-09xE6GDIBQabk1hQRnznxdnX3c2xpTOrU8f4vnur9IdlUjkPzbLaUjP6tQzGjm85BfknmvwIpVlSRKqY3i2XLqiYzByNWCBsUrHat7.png) 
                    - Facts about parabolic ↓ 
                        - k1 = 0, k2 > 0
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/l_M41qvVCPcHecuIqpu2eSHL2K18NgRPTJqGk3pjVyNrH80jKdNtp8rbqobl4KlLhJwd9N9Y-UmQteMGKX9RjH6DDLLABaJvh2qcwwIs4aYpl5pvNx_-W4FONFZ501tP.png) 
                    - Facts about hyperbolic ↓ 
                        - k1 < 0, k2 > 0
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TLMhicO-U_9gxvd_t7-n6su7GwssPb5gPXqF6D8jBSqafojBsoo2_1go-LkNay2dgbUyLhMuI_I35Df-nj9eTFMLFawOaqpofYT13UXhpzrXxClFU0BqvFpasOvVtpgu.png) 
            - **Discrete Differential Geometry**
                - What two main approaches are there for approximating surface normal & curvature? ↓ 
                    - Local surface approximation
                    - Global surface approximation : discrete Laplace-Beltrami
                - What is the Laplace operator? Describe using its composite parts ↓ 
                    - $f : R\rightarrow R^3$ $\Delta f : R\rightarrow R^3$ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AQHspVFkjdkY5T4ATL_BfZKdol8X_jMbzpuLIjbUuKxcf6Oo9tCuV4DF7a4coqV884PPL-ZuWo9K03tHeseRp3D4abrrdaZpPoIsHbXAg3Rv7Wap-4296ID9uncwVxHb.png) 
                    - Grad f points towards the areas of most rapid increase, e.g. pointing towards a peak and away from a trough![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Cp5sUp1Hglr13hoB9ygBDhUrilQ9bG29O20JunrwdmmCrY_Aj2QOWdAvWlFyabxHXB9DZggBIqabgNCrlk8_jRg9q7K22hk0MFnR6ktGcegzlnmRQIcK1cEeXGQvBT-r.png) 
                    - divergence can be imagine to be if we dropped particles and imagine how they would behave under the vector field, positive divergence meaning they would move out of the area and negative meaning they would move into the area.
                    - So the Laplace operator can be thought of as a 3d differential, higher if the curve is increasing and lower if it's decreasing in an area.
                - What is the equation for divergence? ↓ 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/LnvQlR7K5uT3b4I8jx-vuUE1HxoOwDx2SJLvpXCeQhWo1hXyngmN_KeybHpBtPNkxJRDb0Nt30GCYnKoRKPZCdrFS91NUZeLl3Ksp8VXUoGtnUu6b8MVvmy-5IFpePFF.png) 
                - What is the Laplace-Beltrami operator? ↓ 
                    - The laplace beltrami is the extension of the laplace operator to manifold surfaces.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/YdVLZ1lEJZ9Op8zdiQyq3hw1JdjASQ6LSmwPLXbzTQ7XRgKOp8VxaaRqD8bo7s6xU3SYZBLfszxVo4HeFqiJxhGJb-OgNE-9irDsr7gFBrfMbWqDc94rLP4IbMx__P_P.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/sK3lbCjN0RoQpKxLtelEvmg76R0hYeT7VN_UzuYMNrmmRSO_GCT_cGk3RpnM90cX7oNC7_Nnb2EKkKubwdazvWRabafL4GTizZ8T0Pe0KVL0dER8s_8NAYNIEqwz8qpn.png) 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/icIUVjGxKotBfFMTmkn5KlfQAOSbeYJhF0q-L382TejUVBsRX1D9EtJbUIlSjwfQsFzZjxoSRUiBZ1vp9dAV_RXzGU8Z1TPwLfO3zq-ik-auC30qpDIEoFwqLjmtRS9F.png)
                - The Laplace-Beltrami for coordinate functions gives us -2 times the mean curvature times the surface normal. This is useful as we can calculate the Laplace-Beltrami discreetly and then use that to calculate the surface normal.
                - **Discrete Laplace-Beltrami:**
                    - Method 1:
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mJlIrYRU2cGwqnA_93w1-6enQHprSmwvnFO-sCxo-pjtU6nmRuatH_cXcgkJle9fFdeFQvtRpcx7P7GXBAQW459Nv1-9Zqosop9eiJsGk6MYHgipTlbrbOS3AorXAEJR.png) ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JiZp0sH3O03p-BLspz-B9xdanb7G6o4ewv8lxHu_uvL_DLo0KmTu_yJZMGTJHatHeBVKoaV7wZhtUIP6pd6zO7uK4wDg4VAejEix7w8_mjeOD-H6d4C4D2PMgzo1QgLq.png) 
                        - The first method of calculating the Laplace-Beltrami is to calculate the average vector from a given point to all it's neighbours.
                        - Resulting in:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/IZd6ZDPxYXxMUwir1wc1ozsRmDAS0kj991y1VryOoxd9_YRZmUTc13bcNeV0eypOVHSbvTaRU_y_MGiNmlqyHnVpJS8FnTL41N20YEPVb8twbFEFrvl7yKuI5PpXNG32.png) 
                    - Method 2:
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3JHJT7Qjw9p_4Cdb4ZCv6fIZJqNlR1Pkw96JrtIG2b6CxzFaGjYOs5jTcffMWnJbrQQiXBqbDkTH-JZfx0vY4QQmRnFHL5RKZUW2qYuXgwWa1XPV72pTqPoC9H3xmGHe.png) 
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Kj_TKwMNKF7tIRV3pZWpJybJD9MNftNvHDilcnmXGJY37r1BLjukV5ABnUlyH6CCTKvIXQkYvPv9_pllWlAmiXzALGG-Km7LDaUKu9vlV0zDGxdVVBzn9W_syqU4t-CG.png) 
                        - First take your neighbourhood and flatten it to a plane - then find the circumcenters (or just place the point on the edge if the angle is more than $\pi/2$) 
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/coHWS9QvP0MY3wzL4WUmItishrY7ZDgBwZG0UxMNPtCRuTyQRZAz1W_E-PYBqChf7bLXgXbag64QykG9dXk3jH303anW8DI_kBagt8xeL_UuVswtNWoCPmxEBxL7Lutj.png) 
                        - We then get the weights which is the area inside the triangles:
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/rH9vm-MWTQv0PYxKOJIHC6wgrJTMN1HmHcmIxLAcLsSkOO9xbJpFnwhs2FOIvluPkJE_wMi7qOGSNIPt-MCWJCdQsyWtN7ekEwJJMsjpHbEbnheTe2dvx1_uim7kcSSI.png) 
                        - We can then compute:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/t4VYeXmxmvcIvYdZB31dwCImYhbr3l99RF0EypNX_nlLza4n4M2PK_OtXoV34GMqokBvQhZE2dUkrD55b85kAvDCPjyDrRr_9uN-zVRnZnhoixvOUf5scICT_DMNd_6i.png) 
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/D1X9bGGmh6f7AaUXpVjB_zROuWvwBXu98EF92mptAPmYyAF51si5aYMAOz2okeODANFw5EbES_QZ8luji2C6A4nHSCkTtlbHAw4MpOmVnnjnz6TgpxaVH8WwakPufh0W.png) 
        - 
    - Distributed Systems
        - 
        - ^^ _Distributed Systems_ ^^ _ _  
        - **Distributed Systems Lecture 1**
            - **Introduction**
                - What 4 advantages are there to make a system **distributed**?  ↓ 
                    - Some Systems are **inherently distributed** (text messaging).
                    - For better **reliability **- if one node fails others can be used
                    - For better **performance **- different nodes for different parts of the world 
                    - To solve **Large problems **- some problems consist of such a huge amount of data, can't fit on one computer.
                - The problem with distributed systems is that processes can {{crash }}and {{communications }}can fail without us {{knowing}}. Additionally, these may happen {{non-deterministically. }} 
                - We want **Fault Tolerance, **a system should continue working even if it faces these problems. 
            - **Computer Networking**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/J4ZxKhqnf7YPMc5Ea8liL9bMYQS-goUHpgeoYlVCrKv7VTkhfIle7j8MwYyoAPuOubzU79fQ5RZxTlDG74x2GtG5fd12tWrjFjdZ8LkE9qxWOodDrXj3pIubVuBOE0Ne.png) 
                - The fundamental abstraction of distributed systems is that of {{nodes }}sending {{messages }}to each other.
                - **Latency: **Is―the time it takes for a message to arrive 
                - **Bandwidth: **Is―The data volume per unit time
                - **Client-server comms over the web:**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/6IhRlUSXdP3733UVQmOFVDHC6Y0SLe-fYyKuwmLbL3b2U5a2oy4D7ZPz0nHz3m1t06uB3w_2pTNhRk2qpGDvSoLsQpaN92fCXiIZzljH8icC1Qndznxoklb3M_CdU0Df.png) 
                    - URLs are separated into the {{server name}} and the {{path of the page}} you'd like to get.
            - **RPC (Remote Procedure Call)**
                - Consider an online shop communicating with a payment service:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NHXB6R_B2KKd0WN4Dpvtf-FS0i_-AZwnXGdIDp-4KeagopAQLGHJdKnebhFw-cyNVYqG20tL2suIEBVbuKa7_l5sN7OtQ2-A53JtIsVMwGEaIr2-G8yAuLXLB5OzsoV9.png) 
                - We can have a function applied to the shops card object, that is processed on another node/s (that of the payment service). What looks like a function call, is **translated to a network request. ** 
                - **RPC **is used to―invoke a function call from your local machine, on a **different machine** via **network communication**.
                - RPC's are implemented using a **RPC framework:** 
                    - RPC frameworks implements **stubs**, which are―function definitions with the same type and arguments as the function to be called via RPC. This stub function sends a message to the other node to process the payment.
                    - The RPC framework "**marshals**" and "**unmarshals**" the arguments, this means―it encodes the arguments of the stub so they can be sent over the network, then on the other end the args are reencoded into the function:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/r037lljqIJLOb5QtnsdTRQFyTEq8ssiKFEVmqAV4vYTAhU1BleC9nB8lqX9fcHYH1Y9i0aaPShY4UuPiNLGOOjnppR4QRSBrY-L7djycaZ1vuuIvlWO_AoOhgYd7rpmM.png) 
                    - The return value is then sent back, via the same process.![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3fJb_xRoqYCt3dK-TfmYos_wLSknPOsok2cuONek9VDV2yCb_PhIoxuDDhLMbTMX7rvHTUa6KYJJYoBcAB6SOaqktjRaobFagTDvg39xb5-sQ8dAkriVULQGXoWD0j2e.png) 
                - We would like our RPC call to look the same as a {{local function call}}. This is **Location transparency, **the location of resources is hidden. 
                - **RPC in enterprise systems**
                    - RPC is used in **enterprise systems** because―these systems can become so large that they cannot be run on a single computer. 
                    - A "**Service oriented Architecture**" (SOA)―is the architecture in which a **large service is broken down into microservices** on multiple nodes which **communicate via RPC.** 
                    - If multiple services within SOA are **running different languages**, we use―Interoperability (**datatype conversion**) and IDLs (Interface Definition Language).
                    - An IDL (**Interface definition language**) is a―Language independent API specification. Method of ensuring datatypes are stored in a method not specific to any one programming language.  
                    - Example IDL: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/0xdtpuDkEuhCU8penCtWhT3yg4iFSQacbIje6oM4eGYy5K-eQRmFuyFQ7oE1txO74kASiw2cYLWza3bW8Ho_A9Ur1gMwi_U-gk95VJY_GhJL2GuRgF4IgJ9PpafguiKQ.png) 
            - 
            - 
            - 
            - 
        - **Distributed Systems Lecture 2** **(Models of distributed systems)** 
            - **The two Generals Problem:** 
                - Consider two armies, if they **attack together they win** - but if either one **attacks alone they will lose**. ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kZF5kAjLXMdskp7Es7wh7db6UkMY_9NZcFf9DvSpP-6zUwEsFYgDhPIpmv9ovYPdIQwryWGSfXEzul_ZeP-_trYhNxI-asW1L4n7bEtV62xzcnLhcC1BrwMoEJndrbZj.png) 
                - The two generals can only **communicate via messengers**, however the **messengers may be captured** and the  _**sender could not know**_  (except if they receive a response).
                - Initial message delivered, but the response is captured: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bP57WAkbwWs9MDQXFH0vELMgsOf0iZkhPpGCCu2cYZXMwBbw0BcAZGgMpinj8FVjILtbJtjaWE77MbaPaEcPw4UNaQiW7X86i4TjGhQqxyze-gddSQENt1dJ-Yb57bNI.png) 
This is indistinguishable from the following (**from general 1's POV**): ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Ey46dnl7hwQePgXZ1o7bHuVw7OV6dgmdaS3mxrncvAibJNFQMW2JzRp0Hjg3CHDJdpgQJe1ks_lNrCWzAa0v5pvvzqe3NpjyUCiXLeskxHn_4bkAF0GDD-8UEPlzP54Y.png) 
                - **In the two Generals problem, General 1 has the following two choices**  ↓ 
                    - **Choice 1**: **General 1 always attacks**, in this case they may **send lots of messengers to increase the probability of receipt** - then  _if the message is received General 2 knows it's safe to attack_  (even without sending a response).  __**However**__  __, __ if the message isn't received General 1 will die. 
                    - **Choice 2: General 1 attacks if a positive response is received**, in this case General 2 is safe **if** a response arrives  __but __  _General 2 is in Choice 1 when they send the positive response._  
                - This can result in an **infinite chain back and forth of communications** where **no absolute certainty of an attack is reached.** 
This is the problem of **No common knowledge **in DS which is―when the only way of knowing something is to communicate it. 
                - An example of the two generals is the following:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CfPVn-fTG7HNM1XhiINgF1iSMSKSHqv5Rny771BO2iMwu7RG4OxInE0oxC2IjB-5Gx98WFGcN6o2UB-bAvPjpe_fCoomhEBPbPBpRM0qZph8ADP66ZqlNx3rs9kE7IiS.png) 
The reason that this differs from the Two General problem is that―The **charge is a revocable action**, we can always return to the starting point.
            - **The Byzantine Generals Problem:**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/kVjnfDY9vy2AyF3x7MfD3YRsM_q6WT92dlh1O5oVermmNCANiw2qsOklQ7t9MwAEvRVMI8T9RSns63Oxj1ZLVqKrPlOnvNVfpGGtZbJzSsMiyZEUKDmymk_B4C_K77kG.png) 
                - Within the Byzantine Generals problem we make the assumption that communications are {{reliable}} but some of the generals are {{traitors.}} 
                - We further make the assumptions that {{up to }}$f${{ generals are}} malicious, that traitorous generals {{may collude and know who the other traitorous generals are}} and that honest generals don't know {{who the traitorous ones are.}} We then require that the honest generals must agree on a plan. 
                - **Generals may lie**:
 ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5y7MCi0wsHxY59MPzWPIY-KL9gZc7jv7vo3MtTd6mxd-w5A8cbXB2dVuqGqFRn7tXBDkPwuSroBGKrMrS6APOTSaJBc47XpUQ7MXSuhSUPoqF40YQTYjbmRoSn0ehD3M.png) 
General 3 cannot tell who is lying!
                - **Theorem**:  _We need _ $3f + 1$ _ honest generals to tolerate _ $f$ _ traitorous generals._  I.e. $< \frac{1}{3}$ may be malicious 
                - **Cryptography: **Digital signatures help, as we can prove a certain party sent a given message, however the problem is still hard.
                -  _Real life agreement_ :
 ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OxXWMFBndgJuLV8Z1-F3b7M6MusMgTuaDnq4kdDu1NCuYCwNFYLcf2ZWcy0x7MREMxDxTAFlZBvRqp2KYAy7vk9N5wUx_LGgLiiYJkQp5ge17R3NzXory9ZLFYnxV946.png) 
Customers can act fraudulently, online shops could be fraudulent etc. (could have asymmetric relationship where the payments service is trusted).
            - **System models**
                - We have seen the **two generals problem** in which the {{communication medium}} was faulty and the** Byzantine generals** problem in which {{the nodes}} were faulty. In real networks **both can be faulty**!
                - **Networks are unreliable**, can be damaged by nature.
                - **System Model: Network behaviour**
                    - Assume a **bidirectional point-to-point communication** between two nodes. The **three models of such a link are**―a **perfect **link, a **fair-loss** link and an **arbitrary **link.
                    - A **perfect link** is―a link where no packets are lost, reordered or damaged.
                    - A **fair-loss** **link **is―a link in which some packets can be lost or reordered, however we make the assumption that **if we send a packet enough times** it **will be delivered**.
                    - An **arbitrary link** is―a link in which anything can happen. We model this as having **an adversary acting on our communications**. They can replay, block or edit packets as they please.
                    - A **Network Partition** is when a **link **between two nodes is **disconnected for a period of time.** 
                    - ^^A ^^^^ _fair loss link_ ^^^^ can be converted to a ^^^^ _perfect link_ ^^^^ using^^―^^Continuously resending, and deduplicating at the other end. ^^ 
                    - ^^An ^^^^ _arbitrary link_ ^^^^  can (*almost) be converted to a ^^^^ _Fair-loss_ ^^^^ link using^^―^^TLS. An internet protocol to guarantee successful communication has not been tampered with. 
This is only arbitrary, as the adversary could block all packets.^^ 
                - **System model: node behaviour**
                    - Under the assumption that each node executes a given architecture, the three types of nodes are―**Crash-stop**, **Crash-recovery **and **Byzantine**.
                    - A **Crash-stop** node means―the **node could crash** at any time and **never re-join the network** (dropping phone in toilet). 
                    - A **Crash-recovery** node means―The **node could crash** at any time,** lose its memory** state but it **will re-join** the network at some point. 
                    - A **Byzantine node** means―A node that **doesn't follow the algorithm** (although it could pretend to).
                    - A node is either **correct **or **faulty.** 
                - **System model: synchrony (timing) assumptions**
                    - The three types of **synchrony assumptions** about **nodes and networks **are―**Synchronous**, **Partially synchronous** and **Asynchronous**.
                    - A **Synchronous connection** means―Message **latency is no greater than an upper bound**. Nodes execute the algorithm at a **known speed**.
                    - A **Partially synchronous **connection means―communication has **(finite) periods of asynchronicity **but is synchronous otherwise.
                    - A **Asynchronous **connection means―Messages can be **delayed an arbitrary amount of time**, nodes can be suspended an arbitrary amount of time. 
                    - Real networks behave in a partially synchronous manner, under such a system an algorithm designed for a synchronous network could fail catastrophically.
                    - We can have many **real life violations of synchrony**, within  _**message latency**_  we can have: 
{{message loss}} requiring retry - removing any hope of an upper bound on latency
{{Congestion }}causing queueing
Network/route configuration, meaning a packet could get stuck for long periods of time.

                    - Similarly we can have changes in node execution speed:
{{OS scheduling}} resulting in a thread being suspended.
{{Stop-the-world}} garbage collection pauses.
Page faults, swap, thrashing (constant page faults).
                    - **Real-time operating systems** (RTOS) can give some scheduling guarantees - however most DS don't use RTOS.
            - **Availability**
                - Online services being offline = losing money. 
                - We can **measure uptimes** using the fraction of time the service is operating correctly. For this we can **use "nines**" 
'Two nines' = 99% up ⇒ down 3.7 days/year
'Three nines' = 99.9% up ⇒ down 8.8 hours/year
...
                - **Service-Level Objective (SLO),** the period of times the service will be up and the response times. "99.9% of requests get a response within 200ms"
                - **Service-Level Agreement** (SLA), a contract specifying some SLO ⇒ there will be penalties for failure to meet the SLO.
                - **High availability: ****Fault Tolerance:** 
                    - We have a **Failure **of the system, in which the system as a whole stops working. We have **Faults **where a node is faulty or communication with that node is hampered.  
                    - **Fault tolerance** is the design of a system so―a given number of faults does **not **result in a failure.
                    - A **Single-point-of-failure **(SPOF) is―a **single point** in the system where a **fault will result in failure**. 
                - A **Failure Detector **is an algorithm that―detects if a given node is faulty.
A **Perfect failure detector **is an algorithm that → says a given node is faulty **IFF **it has crashed. 
                - The **typical implementation** of a failure detector is to―**send **a message to the node, then **wait **a set amount of time for a response. IF the node doesn't respond in that time it will be assumed to have crashed.
                    - The problem with this implementation of a failure detector is that―we can't know if that's because the node has crashed, the message was lost or the message/node was only very delayed.
                - **Failure detection in partially synchronous systems**
                    - We can only build a **perfect failure detector** in a―**synchronous**, **crash-stop** system with **reliable **links.
                    - Instead we have a **Eventually perfect failure detector **this can―**temporarily **label a working node node as crashed or **temporarily **label a crashed node as working. **But, **it will **always eventually reach the truth** of the labelling. 
                    - This reflects the fact that detection is not instantaneous **and **we can have long timeouts from a working node. 
        - **Distributed Systems Lecture 3 (Time)** 
            - **Physical Time**
                - Distributed need systems to measure time, used for:
                    - Scheduling
                    - Performance measurements
                    - Log files
                    - Data with time validity (e.g. cache entries, TTL)
                - The difference between a **logical **and **physical** **clock **is―Physical clocks count **number of seconds** elapsed while logical clocks count **events **(e.g. messages sent) 
                - **Quartz Clocks**
                    - Quartz crystals can be engineered to vibrate at a particular **resonant frequency**, this frequency can then be detected (and fed back into the crystal again to keep the vibrating going). 
                    - We use this **quartz vibration** by―counting the number of cycles to measure elapsed time. As we know $f$ 
                    - Clock drift is measured in parts per million, meaning 1ppm = 32s/year of drift. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/acy_5LTVfZi7tnDFZQCnv__uIjFbqSiIwq8P9U5BQXY2cNJN_RXcJM9g1BVOQjjT9FwYNIKdhyhX248FmQyvO9sf7C7HX4nmYpXFVWvK-3_GpHMASP-kA3Al6KhMy0f-.png) 
                - **Atomic clocks**
                    - Caesium-133 has a given **resonance** we can measure - about 9 GHz . The second is defined by 9192631770 periods of that signal. We are of by 1 second every 3 million years
                - **GPS as time source**
                    - 31 Satellites in space broadcast their **location** and the **time **from their atomic clocks. We then pick that up, and can calculate the time taken for the signal to arrive (via c) and thus get the time.
                    - We do need to correct for atmospheric effects and suchlike.
                - **Coordinated Universal Time (UTC)** 
                    - **Greenwich Mean Time **is defined by―noon when the sun is in the south, as seen from the Greenwich meridian
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/R9jUYQZGK9nZ6IIhjhW_voek4fxcitDPk3Z3yWTRZj4hvYUVxeEFkbBKxIp1khhsXIy1YwU9mFeTkWVNR9tfhkVwGoKuz0MgWIt7384d0evYj6KJCVM3w2IsCIT7qFv5.png) 
                    - **International Atomic Time (TAI (based on French)) is **― time based on Caesium resonant frequency 
                    - **Problem: **Speed of Earth's rotation is not constant
                    - Because of the disagreement between GMT and TAI, UTC is―TAI with corrections to account for Earth rotation.
                - **Leap Seconds**
                    - A leap second is―a second that can be inserted or removed (typically) twice a year
                    - Every year on 30 June and 31 December at 23:59:59 UTC, one of 3 things happen  ↓ 
                        - The clock jumps forward to 00:00:00 without waiting a second (a **negative **leap second) 
                        - The clock continues to 00:00:00 after a second as normal
                        - The clock continues to 23:59:60 after a second, adding a second (a **positive **leap second) 
                    - Leap seconds are announced several months in advanced
                - **Most common timestamps**
                    - **Unix time: **Which is―the number of seconds since 1 Jan 1970 00:00:00 UTC  _not counting leap seconds_  
                    - **ISO 8601: **Which is―year, month, day, hour, minute, second and time-zone offset relative to UTC. E.g. 2020-11-09T09:50:17+00:00
                    - Conversion between the two requires **Gregorian calendar** to calculate leap years and **knowledge of past and future leap seconds** 
                - Most software ignores leap seconds, however OS and DistSys require them.
                - **Smearing **is―The  _spreading out_  of a leap second  _over a whole day_ . This helps prevent software that doesn't manage leap seconds from crashing when encountering a discontinuity of a second.
            - **Clock Synchronisation**
                - Computers track physical time/UTC with a quartz clocks - and due to clock drift the error gradually increases.
                - **Clock skew** is the―difference between two clocks at a point in time 
                - A **solution **to clock skew is―periodically get the time from a server with an accurate time (based on an atomic clock/ GPS). Using the **NTP **protocol.
                - **Network Time Protocol (NTP)**
                    - An **NTP server** is―A server to give an  _accurate time source_  for computers to sync with. Many OS vendors run NTP servers and configure their OS to use them. 
                    - **Hierarchy of clock servers** are arranged into **strata, **these are― __
Stratum 0__ : atomic clock or GPS receiver. 
 __Stratum 1__ : Something synced with Stratum 0 device
 __Stratum 2__ : Something synced with Stratum 1 device
                    - NTP servers may query {{multiple clock servers}}, discard outliers and average the rest. Furthermore, servers are {{queried multiple times}} to remove network error
                    - Using NTP we can reduces clock skew to a few {{milliseconds }}in good network conditions, but can be much worse over a {{bad network}} .
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/3H78pNX0DSOHMqLDwyVPqkjGFU7zmOV7K0fZkHoGgXtkzVZAm7wjLcoEQttsBlj3Hrz4FkSwU39_HL7Ev8iQ5-vxPvQlrTV2aG0Uz4DBV2l7p856O5XpanEJArqHOIc2.png) 
                        - The round trip network delay would be―$\delta = (t_4 - t_1) - (t_3 - t_2)$ 
                        - We can't find the time taken for the request and response individually because―the two clocks aren't synchronised. We can only get the time difference between two timestamps of the same clock. 
                        - The **estimated** the **server time** when **client receives the response** would be―$t_3 + \frac{\delta}{2}$ Because  _ __we assume the delay each way is half the total__ _ .
                        - The estimated clock skew would be―$$\theta = t_3 + \delta/2 - t_4$$ 
                - **Correcting Clock Skew**
                    - Once the client has estimated the clock skew $\theta$, there are **three options** for changing the time  ↓ 
                        - If $\theta < 125ms$, **slew **the clock. Speed up or slow down the clock very slightly (around 50ppm) so it's correct after a period of roughly 5 mins.
                        - If  $125ms \leq \theta \lt 1000s,$ step the clock - i.e. suddenly reset the clock to the server estimate. 
                        - If  $\theta \geq 1000s$, panic and let the human resolve it.
                    - What's wrong with this code? ```cpp
start_time = System.time()
code_to_profile()
print("Function took", System.time() - start_time)
```AND, what is the solution?― _NTP could have stepped backwards_  while code_to_profile() was running - resulting in a negative time taken or too high of a time.  _Solve this by  using a monotonic clock, who still have slewing but will never jump backwards_  
                - What are **Time-of-day** and **Monotonic clocks** and **how do they differ**?―Time-of-day clocks is the  _time since some fixed date_ . Monotonic clocks are the  _time since some arbitrary point_  (e.g. since system booted up). 
The difference is that Time-of-day clocks can  _suddenly jump forwards_  or backwards subject to leap second adjustments, monotonic clocks  _simply go forward_  at some (near) fixed rate. 
Additionally Time-of-day clocks can be  _synchronised across multiple nodes_ , monotonic clocks  _cannot _ (only good for measuring elapsed time on 1 node).
            - **Ordering of messages**
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/cSyRVfDprWQX6kkONyGuwzXN2cN0oyfX6oT83kiZLRpY4bOkHQ9lOXbG_D-03xvyuC8B0azFM9uvHw7Hj-wBD_IOpw0j4tNwiCrL28Yox_ow4OqhZpM2ERHovfopgoFu.png) 
                - The **problem **with using timestamp ordering―is that $t_2 < t_1$is  still possible if the  _clock skew is greater than the network latency._  
                - **The happens-before relation**
                    - An **event **is something happening at {{one node}}. 
                    - We say event a **happens before **event b ( $a \rightarrow b$ ) iff  ↓ 
                        - a & b occurred at the  __**same node**__  and a occurred before b in the local execution order.
                        - event a is the **sending** of some **message m,** and event b is the **receipt of said message** (establishing causality)
                        - There exists an event $c$ s.t. $a \rightarrow c \ \text{ and } \ c \rightarrow b$ . Transitive closure!
                    - The **happens-before relation is a partial order** - it is possible that neither a or b occur before one another (**i.e. they are unrelated, doesn't mean they occurred at the same time) **this is written―$a||b$** ** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Bd6o0t7rZ1n8gzSYN0RPPgRQ-0aFu86YR9Wo9EaJDut_cwcndGwgL4ezC2i7DkZo5Ubp0Vma60xmCyP-z5RpbSZEo5C9ann8FL4-JWlOWaD7eTw5jUUabr3rb1uOTdaa.png) 
                - **Causality**
                    - When $a \rightarrow b$, a  __might have caused __ b 
                    - When $a||b$, a  __cannot have caused__  b 
                    - Happens-before relations encode **potential causality.**  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/E91bglfXDom_vwusocHwkGxcTDNMEX7Moxuhp-TSmcOwQBQSHlCAQmz19vRpVbCNDCsUnbsroqMQYgVVx19c46wt4vhTq1Ri2FbvYSdBOOZgASW6b1C-C2ALIPFo9r19.png) 
            - 
            - 
            - 
        - **Distributed Systems Lecture 4 (Time)** 
            - **Logical Time**
                - Logical clocks are designed to **capture causal dependencies** $(e_1 \rightarrow e_2) \implies (T(e_1)  < T(e_2) )$ 
                - **Lamport clocks algorithm**
                    - The Lamport clock algorithm is―```python
# for every node:
t := 0

on event:
	t += 1

send_message():
	t+=1 
	message = (t, m)
	send (message)
	
receive_message(M):
	t', m = M
	t := max(t, t') + 1
	deliver m # to application 
```
                    - Within the Lamport clock algorithm, **L(e)** is―the  _time after_  an the  _increment due to e_ .
                    - The Lamport scheme has the following Properties  ↓ 
                        - if $a \rightarrow b$ then $L(a) < L(b)$ 
                        - However, $L(a) < L(b)$ does **not **imply $a \rightarrow b$ . We could also have $a||b$. 
                        - We can have $L(a) = L(b)$  
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/NWzGP1UyEkHkO4gREgLixeoi8cOAM4abaB3se7r0ImB-uzVNIeJLEEEilhXwyPSYFctCqAc8cLQLGqg2iXnPG5HF_yYSeGBjEAiTAUxkYYBLtQWAWq5JqrzjIa__JHhu.png) 
                    - We can form a unique identifier for an event by―combining the name of the node (the event occurred at) and the time the event occurred $ID = (N(node), L(e))$. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/xg2IfyouuRbVa9FbkOdHsZXyJrWZxa92DLDPqCaeqaBZR37C6_wCYtchKhkZaF1LKEjOHs1N8x3PyIv-OF-XxQr8SfrNiTL26-8Kc2Qfox0K7qERfYkVDVtK73NpHwmw.png) 
                    - The main **problem with Lamport clocks** is―if we have timestamps L(a) and L(b) ^^we can't tell if ^^$a \rightarrow b$^^ or ^^$a||b$^^ .^^  _ __Remember, a||b simply means they're unrelated! If no messages have been exchanged all events are concurrent .__ _  __** **__ To solve this we need vector clocks. 
                - **Vector Clocks** 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/UvnFvkZTVzGPxEWZjr_kMUAUiA7FcxrCIors0myTDQknWQy0MOakHVv5DjhY0pPpkSIOxF37OGZ7cqINEulpWsY8VMVsTHrhChFYieuysBBZlfJpbEkqsvS5lL4yem04.png) 
                    - The algorithm for **merging vector clocks** is―```python
 T = [0] * n
 i = index of us
 
 on_event():
 	T[i] += 1
 
 send_message(m):
 	T[i] += 1
 	send( (T, m) )
 
 receive_message(M):
 	T', m = M
 	# Max of each element
 	T = [max(a,b) for a,b in zip(T, T')]
 	T[i] += 1
 	deliver m to app
```
                    - Example vector clock arrangement:![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Nr5EZypRAEEhXIQ3kVwQIrAtEEzY7-1YKCseaafPouBz8U9SArWl5NBxnYxQ3E1DpzsTK0SW2zXUkMJ6qeaWYvFCBPj4Vv9vAHDxLtiFGC0w6xzAIX0AxjIhzxwrDRwd.png) 
                    - The vector timestamp of event e represents―e and all it's causal dependencies: $$t = \{e\} \ \cup \ \{a \ | \  a\rightarrow e\}$$  
So $<2, 2, 0>$ represents the first two events from a, the first 2 events from b and no events on c.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/jFFIw1x1E-_MHi9JcaPCEKgEPWcijXTumy-uCOmOWnKEh71Kj14VxJa0iETImwR0bE3qfHN_3vPgy6eXGfP15rhqUhXkak-Iou5cYI6cN6pmwg9CZgfn0wNNlMJuI95r.png) 
                    - Two events are **concurrent in vector clocks** iff―**Some **events in T happened before events in T' **and **some events occurred after events in T'. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/fhN2SFw_h1aP_p7Qcn7UesaVszsVJ1kru10VOP5nlT890pjRlorhlOqw9B5dGM_DcWj7OAQb2rH12_9VM1BYQnevf-mC_886oGi05m1S6IeXHdc-Om81nVkytey9s-TF.png) 
            - **Broadcast ordering**
                - **Broadcast protocols**
                    - Broadcast is **group communication** where  ↓ 
                        - One node sends a message, but all nodes in the group deliver messages
                        - Groups can be a fixed or variable size
                        - If one node is faulty, the remaining group members carry on
                    - Group communication **can be designed** to be {{best-effort}} (messages may be dropped) or {{reliable }}(non-faulty nodes deliver every message by retransmitting dropped messages). There is no {{upper bound}} on message latency, as we use an Asynchronous/partially synchronous timing model.
                    - The layout of a broadcast system is―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/mFs8TN1pTuSMYFTopeZB2CUFSaNOk2UVEs0gL8tcAuDdaJ1GFrg-gwSi5vUp1M-SvvrldgftFPs3ME__MzkOS4qXyRkFubKjHa6FQzd5bYKziVR0Vn8KHVcD7QaJG9hu.png) 
                    - The broadcast algorithm may wait to deliver a message to the application, because―we wish the messages to arrive in a certain order
                - **FIFO broadcast**
                    - Note that when a node broadcasts a message, it also sends it to {{itself}}.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/I8jo0cSS3gODTf6w8D-mqHvxH6IBkmHggRtWq7ZQ27V5108wBpOfUFy-f6iFOPAgFvy-xQp4AidZD7C1calXQ5p-qEngwFMCc8X8IREnv5zzoYSww9hYtWmapqTBp2Zb.png) 
                    - For **FIFO broadcasts **we **require that**―**messages sent from a given node** are  _delivered in the order they were sent_ . Messages sent from different nodes have no required ordering.
                    - Valid orderings of the above diagram are then $$(m_1, m_3, m_2) || (m_1, m_2, m_3) ||(m_2, m_1, m_3)$$ 
                - **Causal broadcast**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/L1nUAnI60q5QqXN8NehbVWovcNwsWgdNcwup_XbfUwGOx-93_iv4GtGP5E_b19fPyGA9SxZC81O5d5FmZTfsJGNX6f-M_wkVxHfnZloOIqmfxL0hY8tOXzgDfChYqMw6.png) 
                    - For **Causal broadcasts **we require that―Causally related events are delivered in causal order, concurrent events can be delivered in any order. 
                    - The valid orders here are (m1, m3, m2) or (m1, m2 m3). 
                    - The **difference **between **Causal **and **FIFO**―If FIFO we could  _technically have m1, m2, m3_ . In Causal broadcasts this would not be allowed. Or m2, m1, m3.
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/I8jo0cSS3gODTf6w8D-mqHvxH6IBkmHggRtWq7ZQ27V5108wBpOfUFy-f6iFOPAgFvy-xQp4AidZD7C1calXQ5p-qEngwFMCc8X8IREnv5zzoYSww9hYtWmapqTBp2Zb.png) 
                - **Total order broadcast**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JG3S3CbaHrwr0rjbwr8YSPGYh6GWcWdCw9q_Dt68yE8YD47hQlqUDWyyR6uOeZx-V0qgaufPQlakuX1RNi_zzdC7SRN-ce1ZlUOB9aSbmVIZuuppV0gX5nOdkwNoNUkU.png) 
                    - For **Total order broadcast ** we require―that all nodes deliver the messages in the **same order.** This  _includes the nodes delivery to itself!_  
                    - The above ordering is for the example m1, m2, m3, but we could just have easily have said  m1, m3, m2: ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/G782ZOFwPUarYj_VHKvoWeHGWkbal8CP8CDza7d5sze5ffFJcnNtmgsUzVj1HvJsjnZtkoE4t0Svhhvf9d-Fug9YQ-x17gBueGzyuzJ0TtUQsUfX0J0meyQAk4v8-jEJ.png) 
                - **FIFO total order-broadcast:**
                    - **Fifo total order-broadcast requires **―** **That all messages are delivered in the same order **and **messages from a given node are delivered in the order they were sent
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JLfDCSOtxO_AKEZA9k300iA46WVFHDVBzEUHdfxH2KpbRXALgOjd9Hm1L60e9Jle3lEBqCJ2FLwp08e_Bg1mYDRxoEUVVzEusDhrNLCXjnQ4aRzuYXBJT2xuA5dxeuw7.png) 
            - **Broadcast algorithms**
                - There are two sections for devising a broadcast algorithm  ↓ 
                    - Ensuring the **best-effort connection becomes reliable** (retransmitting dropped messages)
Enforce **delivery order atop of the reliable connection** 
                - What is the **problem **with simply retransmitting and deduplicating dropped messages?―A  _node may crash_  in the middle of retransmitting a message, in which case not all nodes in the group will have received the message 
                - **Eager reliable broadcast**
                    - Eager reliable broadcast is―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/P3SNOBLC-Ooeys3gf9H7Qj0ZdDIu890t306QOWR0iqkivcEUNQE7tDaYU0LksM93348Hg3O__KEcRTbsTUpjmMjXGtwOJwLKmEhCdrDgkQbSb-pbnTVKMd4-Ja20jR5J.png) 
                    - The **problem **with **eager reliable broadcasts** is―for n nodes, we have $O(n^2)$ messages being sent. 
                - **Gossip protocols** 
                    - Gossip protocols works by―![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/AzHyQZqzTUIfVER7QY9jaTCTx-lgQzOZlK8nHdNeWaYKIvhopEjZU7JzK87ameqhPIbJ0HjY3nyWJixFvnQiV4T7PLY-OaTSLRv5NHcDstyN0dTnLbX7JMBuJ-MWsLTM.png) 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_3X3m6GVxLKq8rUjorTbV_cZm4Sb0heFxEEyEPt1EO3EZbOX0o5r7U2QGz2FC9nT_oTen14u9eTrBZcTvud57w6f6uD8MvaFr1i1PTWg3ZgmDZ7hhZ1Q1n88MIVP7jSI.png) 
                    - Note: if a node has **already received a message **it doesn't send it again. 
                - **FIFO broadcast algorithm**
                    - The **FIFO broadcast algorithm** is as follows―```python
sendSeq, buffer, delivered = 0, [], [0,0,0...,0]
i = ourNodeNumber

send_message(m):
	send(i, sendSeq, m)
	sendSeq+=1

receive_message(msg):
	buffer.append(msg)
	for M in buffer:
		i', sendSeq, m = M
		if sendSeq == delivered [i']:
			send (m)
			delivered [i'] += 1	    
			buffer.remove(M)
```
                - **Causal broadcast algorithm**
                    - The **causal broadcast algorithm** is as follows―```python
 sendSeq, buffer, delivered = 0, [], [0,0,0...,0]
 i = ourNodeNumber
 
 send_message(m):
 	dependencies = buffer[:]
 	dependencies[i] = sendSeq
 	# Remember we send dependencies to ourself too
 	send( (i, dependencies, m) )
 	sendSeq += 1
 	
 receive_message(msg):
 	buffer.append(msg)
 	for M in buffer:
 		i', dependencies, m = M
 		if dependencies <= delivered:
 			delivered[i'] += 1
 			send(m)
 			buffer.remove(M)
```
                - **Total order broadcast algorithms**
                    - The **single leader** approach is done by  ↓ 
                        - Choosing a single node to be the leader 
                        - All nodes send their messages directly to the leader (FIFO)
                        - The leader sends a FIFO broadcast to all nodes
                    - What's the **problem **with the **single leader approach**―If the leader crashes no more message can be sent. Additionally, changing the leader safely can be hard
                    - The **Lamport clocks **approach is done by ↓ 
                        - Attaching a Lamport timestamp to every message 
                        - The order messages are delivered in the total order of the Lamport timestamps
                        - But -  _if we get a time stamp T, how do we know we won't in the future get a timestamp < T?_  We need to wait for a timestamp ≥ T from  _**EVERY**_  node! We **need to use FIFO links**
            - 
        - **Distributed Systems Lecture 5 (Replicas)**  
            - **Replication**
                - Replication is keeping a copy of the same data across multiple nodes - could be on a database, filesystem, cache etc.
                - A node that has a copy of the data is called a {{replica}} 
                - There are three main reasons you would want replicas  ↓ 
                    - To **spread load** across many replicas (can reboot or change a given node)
                    - If **some replicas are faulty**, others can still be used
                    - To **reduce latency** in areas far away from nodes
                - Replication is easy if data doesn't change, but becomes harder when it does change.
                - **RAID **is―a **Redundant Array **of **Independent Disks. **It's a method of replication within a single computer.  
                - **RAID** differs from replication of distributed system in two ways―RAID has a **single controller**, in DS each node **acts independently**. In Distributed systems nodes are distributed across the world not just within a single computer.
                - **Retrying state updates**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/zAXYaRsuUHc51Km9hbNbnKDDitWvhZ50d3qvoCidJLcm6qeAarPNzPcwvxJcwh6suaom_FCxkHPyNw1aYaIk5-F-BqE7Q66syhUD2JtC9lOAIbxznkqEZL96X64iaxGZ.png) 
                        - To deduplicate this request we would require―that the database stores all requests it's already seen 
                    - If the acknowledgement to adding a like to a post never arrives, what's the problem with sending it again?―It could be that the acknowledgement got lost on the way, resulting in two increments.
                - **Idempotence**
                    - A function f is idempotent if―$f(x) = f(f(x))$ 
                    - The idempotent alternative to incrementing a counter is―creating a set of likes and computing $\text{likeset} = \text{likeset} \cup \{userID\}$.  
                - **Retry-semantics** 
                    - **At-most-once **semantics means―the request is carried out at most once, as we don't retry the sending
                    - **At-least-once** semantics means―The request is carried out at least once, as we retry until we get a response. This can result in duplication
                    - **Exactly-once **semantics means―The request is carried out exactly once, through repetition and deduplication or idempotence.
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/GSRTLxW-vEf4NUqlonf0KbkzGiGE7w-i-tN96YitYC_7leB8q2d6phZmfmFrQCyAAewjT5zeqnyD9EjG4EmX92DPJjK841ZBJpmk0LAPDioiCDBL77Uiyr01RlHFH1YS.png) 
                    - What is **going wrong** here?―The request for the like is being sent again because the  _response was lost in the network_  - but in the meantime the user has unliked it (from a different computer) resulting in the  _unlike being cancelled._  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/uD7MftKfvEoC5LNNYhjyJt-DBpM1_ssxmcNI5GANhHTpQlIW1Xlxnw53rQqoENeT32-aYaWuVefWVsdiKwySbRCjpWVmHve1p6ab5d01cp0USZ-2O5ZGYTio8e6j7zHN.png) 
                    - What is the **problem here **―We would like overall operation add x then remove x to be detectably different than not adding x at all. In the above case we cannot tell the difference, so we **can't know which replica is correct**.
                - **Timestamps and tombstones**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/gikFIFeyKZoBUH03f_PMFynWpLzcInN7lzSoBpvWv1sDGsezP-H0Sve1OEcxW7a5cwhHWCFGywKNEJePi2OLdQUoVug6X2X82BYJZDWIl8BgO0F-6UQ4E7vaqeP3sKNr.png) 
                    - A **tombstone** is―a  _recording that an item was deleted_ , **even if the item is still held.** This is used to hold the fact that the item was once present in the database and has since been delete.
                    - Every record has a **tombstone, **and a **logical timestamp.** 
                    - Replicas use **tombstones **and **logical timestamps** to come to by―**occasionally communicating** with one another to **check for inconsistencies**. If such an inconsistency is detected a  _**anti-entropy**_  method is computed. The timestamps are compared to decide who's correct and reconcile state.
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/Xm41gzLVU0ErhY7SzQFYrxOtGB2mkoEfByN381ekrbHsn80I-k4fjuEGYG9GZ4LofTNezZ9DENA-dB-hKxZZWjuTANfA1TXebT0v4LKRRn5MRcUHGaQ-30Mr3G12GZH9.png) 
                - **Concurrent writes by different clients**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/69MpP4Pxk9RB8R8iIHmNCqbVW3VorxuevBfoCMMVuIVDgqo9AJ2wGe0cLTjKZGPCoeVnb2K-UeY5hvPYftc_IvY3vUt2hHgB3FjAKeQkJlEQf7t-DIWrd8M9XAq4NP3F.png) 
The two approaches for this problem are  ↓ 
                        - **Last writer wins **this uses timestamps with a total ordering (e.g. Lamport clocks) - we choose the option with the larger timestamp, and discard the other one. **Note: Data loss, consider 5 such events occuring **only 1 datapoint will be preserved 
                        - **Multi-value register** - use timestamps with a partial order (e.g. vector clocks) only replace one if one of the timestamps is strictly greater - if t_1 || t_2 we preserve both v1 and v2 (perhaps seek user involvement)
            - **Quorums ** 
                - **Probability of faults**
                    - A replica may be **unavailable, **assume the probability p of a replica being faulty is independent of all other faults. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/XzsAVTwbLE2zEm2HVLKSpuxHwmyeXU4XJBvaIIB55XfoWRqF1qv75w0o4voabdUcUjKa5Ln9Gr_ivmBphhQYwtCeuf7EsOoOqZt2sTYD3UXFX_tzdpapB22NuDTRfHF-.png) 
                    - More replicas ⇒ more likely {{at least one replica}} is faulty at a given time
                - **Read-after-write consistency**
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ZV20Kz4WJfsbC1A4_9jWVz_T_VxpPSqOy1snJ6OJEIzvM1eoW62m6A_DUgs46e7W6so5qlh91oECbbg6Tp5-OdOQkPxWA1QAcjrRtRwsu-VaQu1VR-K2FV6ENOYpapKv.png) 
                    - The cause of **read-after-write inconsistencies** is―when a client writes to one replica, then reads from another (and the **two have not been synced**). 
                    - One solution to **read-after-write** inconsistencies is only allowing {{reads/writes to all replicas}} - if one replica is offline, however {{we cant do any reads/writes}}. 
                    - **Quorum**
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/bKZieC-unJ2_3dE8Z9rCb3l3UjEZ-uKXpqesXSHJ9puS2MfsrL-ZWYprgf_dsSw2hZLCvuKUtxvLVZi8Au3p5rK2SLNmoQL8ph3W6O953DrelXRRN30iKJ2GAjoyYhmc.png) 
                        - A **Quorum **is―a group of replicas who we compare responses from to decide on correctness. 
                        - What are the **three requirements** for read/write **Quorums**?  ↓ 
                            - **Writes **are acknowledged by at **least w replicas ** 
                            - **Reads **are acknowledged by at **least r replicas** 
                            - **r + w > n **(Think  _pigeonhole principle_ )
                        - **Read/write quorums guarantee**―we'll  _always read the most recent write_ !  
                        - Typically form majority quorums
                    - **Read repair**
                        - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/TTTpPyP9EHF65J1DQ0v4KvzdtJ_cLFkv5TW_tNaU6UJyxo16qPIuE57oAKQtztbiKkm4umJi3ryBihS0iifNqH-DvHiujtZ9rJK8JfSBNZIdO1yeKbQZxUIdJSJQheZi.png) 
                        - If we **receive **what we find to be an **out of date value** (via Quorums) then **send the correct value** to all incorrect senders or any replica that didn't send a value.
            - **State machine replication**
                - State machine replication is about using broadcasts to facilitate replication
                - **The Process of state machine replication is as follows ** ↓ 
                    1. A FIFO-total order broadcast is used to communicate the state change to all replicas
                    2. When a node sends the broadcast it also updates it's own state (so nodes sending the broadcasts will also update)
                    3. Applying an update is deterministic
                - An **update being deterministic** in SMR refers to―the  _replicas acting as _  _**state machines**_ **,** they start in an  _initial fixed state_  (usually empty) and  _follow exactly the same state transitions_  in the same order and must then  _end up in the same state_ . 
                - The main limitation of SMR is―can't update state immediately, have to wait for the delivery through the broadcast (has to coordinate with other nodes to decide on order). 
                - Related ideas:
                    - Serializable transactions 
                    - Blockchains (total order broadcast in the chain), distributed ledgers, smart contracts
                - **Database leader replica** 
                    - A leader database replica ensures a total order broadcast
                    - Generally have the requirement that write requests can **only **be executed on the leader, read requests can occur on followers. The leader then makes these commits, and communicates these changes with the followers. 
                    - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/wNQ5uytq-Djq-0AMvdNtPDVwqO6qipwM-ZwWvCQ0llB-EblhOrX0TmFVQjtZOKh2qKFaLD-cbKFGztrTJdS4i0B_Y_2uP5C2vTAbmLLCPUQo6Icr-1s6-EX9jpTBpIhd.png) 
                - **Replication using causal (and weaker) broadcast**
                    - A replica **state update is commutative** iff―$g(f(x)) = f(g(x))$ where g and f are state updates.
                    - The** causal broadcast** requires that if a message happens before another, it is communicated first. The **requirement for the state update function** is then―that concurrent updates commute. This with the other requirement ensures determinism. This is a bit like serializing the message.
                    - For **reliable broadcasts** we would require that―the system is deterministic and that  _all messages commute._  
                    - For **best effort broadcasts** we would require that―deterministic, commutative, idempotent and tolerates message los
                - 
                - 
                - 
            - 
        - **Distributed Systems Lecture 6 (Consensus)**
            - **Consensus**
                - **Fault-tolerant total order broadcast**
                    - In our leader follower system, what happens if the leader crashes/becomes unavailable?
                    - **Manual failover: **This is―when a human operator manually changes the leader when it's detected the leader has failed. Will need to reconfigure follower nodes. This is fine for planned maintenance. The problem is humans are slow, can take a long time in unplanned outages (consider if this occurred at 3am)
                - **Consensus and total order broadcast**
                    - **Consensus is **―several  _nodes coming to agreement _ on a given value.
                    - In total-order-broadcasts this would be **the next message to deliver**. So if we can come to a consensus, TOB drops out. e.g. consensus and TOB formally equivalent
                    - **Paxos, Multi-Paxos **and **Raft **are consensus algorithms
                - **Consensus system models**
                    - Paxos, Raft, etc. assume a **partially synchronous, crash-recovery **system model. 
                    - We don't assume a asynchronous system because―there exists **no** consensus algorithm that will **always terminate**! Even in a simple crash-stop system.
                    - Paxos, Raft, etc. use clocks only for timeouts/failures however the correctness of the algorithm does not depend on timing.
                    - There also exist consensus algorithms for **Byzantine **system models (used in blockchains) 
                - **Leader election** 
                    - Use a {{**failure detector**}}** **based on time to determine a suspected leader crash. On a {{suspected crash}} we must then elect a new leader. Crucially, we want to prevent {{two leaders at the same time ("split-brain")!}} 
                    - Raft Ensures $\le$ 1 leader per **term **this means―The  _term is an integer variable_  that is  _incremented whenever an election begins_ . Raft ensure that at most 1 leader is elected per **term **and that each  _node votes at most once_  per term. The  _leader is then selected via a quorum._  The quorum gives us the fault tolerance
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oRKZVQPA2sewgXbqQXQuwNNxXS-hb89JPztSbjtVbzdVfHj2Ym0thNflC38IfB7DFepG9UiDi5zqttzWA3y_uEWDELnWIyMYUzLcXVUDXKAlG6Pnw4QKT9PUia4IYnRe.png) 
                - **Can we guarantee only 1 leader?** 
                    - The **system of 1 leader per term **doesn't guarantee 1 leader because―we could have a leader disconnected from it's followers, who is replaced without it's knowledge. So it's the leader of term t and there's another leader of term t+1. I.e. **this method only guarantees on leader per term.
 **![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/V3tUykKyDgLFsDYH6S5IrhXdZQC2D6ubQvp1thFpCZjTFlzCu2vXSTteYMr2Q3DtV4nWWzT84-g0WmATUL0TAToeDTJxZJCInlfXt2xODhLhHvHhT7LE2KYpSXnKPivr.png) 
                    - The solution to this problem of a leader being voted out without it's knowledge is―the leader ensures it can send messages via a quorum. 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/CHaFRGF--nZNN8hKVUQbJBTEehN0QFdy0H66cyAhIKONEOuPKt-LRQxotlsC_5hWZE6zGktq-hvjFjCcGptUh06SlQd94k8cxUqPbfTGXAKNFCC-eVGOEZpDlH6NA-yd.png) 
            - **Node state transitions in Raft**
                - The state transitions we will use are always within a certain term. 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oWqazBP_8nBcIola3uNH5oNL_j0GsbXTAyi9UhFPA0l_JlVCJbTrWk4KelPLQF3Dl_Pr-6bpmqNyzyQMHr4rEL-ASDVNnAoFuthUcVjViShxfQD6bJTk4IARODnl2kQR.png) 
                - Nodes that start-up or crash and then recover always start in the {{Follower state}}. However, we need some node to become a leader and it does this by transitioning to a {{candidate }}(when it suspects {{leader failure}}). If the node then receives enough votes{{ from quorum}}, it will become the leader. Alternatively, it may discover there's a {{new term}} and transition to a follower. Or the election may {{time-out}} in which case the election must be restarted with a {{higher term number}}.
            - **Raft pseudocode Explanations:**
                - ```autohotkey
;; Entering yourself as candidate

on initialisation do
	;; Note that the first 4 variables
	;; need to be stored on disk
	currentTerm := 0; votedFor := null
	log := hi; commitLength := 0
	;; Remaining vars can be lost in a crash
	currentRole := follower; currentLeader := null
	votesReceived := {}; sentLength := hi; ackedLength := hi
end on

on recovery from crash do
	currentRole := follower; currentLeader := null
	votesReceived := {}; sentLength := hi; ackedLength := hi
end on

on node nodeId suspects leader has failed, OR on election timeout do
	currentTerm := currentTerm + 1; currentRole := candidate
	;; nodes vote for themselves
	;; stores votes received as a set
	votedFor := nodeId; votesReceived := {nodeId}; lastTerm := 0
	;; I.e. if we aren't the first leader ever
	if log.length > 0 
		then lastTerm := log[log.length − 1].term;
	end if
	;; Tagged with VoteRequest
	msg := (VoteRequest, nodeId, currentTerm, log.length, lastTerm)
	for each node ∈ nodes: send msg to node
	start election timer
end on
``` 
                - In **RAFT** the **log** is―a list of  _messages with an associated term_ , the term is the term number that the leader sent the given message. It is the  _**total order of messages.**_ 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/VnP_X0y4qd74FjPvg_hresNYjUzjlgDUYiq6sHnVlGWZnzWMPvIAetoO8B7NBf-rY1_hKb43wUquGZ4RwjEl2As6e3wNnfPnJjmu5PiG0AlC7VoEC5w7yCEUJjRN1314.png) 
                - ```autohotkey
;; Voting for a new candidate 

;; c stands for candidate
on receiving (VoteRequest, cId, cTerm, cLogLength, cLogTerm)
at node nodeId do
	;; update our current term if
	;; votedFor=null indicates we've note voted for anyone
	if cTerm > currentTerm then
		currentTerm := cTerm; currentRole := follower
		votedFor := null
	end if
	lastTerm := 0
	if log.length > 0 then lastTerm := log[log.length − 1].term;
	end if
	;; Check if the candidates log is up to date with ours
	;; If their log's last term is greater than ours
	;; or it's equal with their log being at least
	;; as populated as ours
	logOk := (cLogTerm > lastTerm) ∨
			 (cLogTerm = lastTerm ∧ cLogLength ≥ log.length)
	;; if all the log checks are okay and we've not cast
	;; a vote for someone else then vote for this candidate
	if (cTerm = currentTerm) ∧ logOk ∧ votedFor ∈ {cId, null} then
		votedFor := cId
		send (VoteResponse, nodeId, currentTerm,true) to node cId
	else
		;; if we don't vote for them, we must tell them!
		send (VoteResponse, nodeId, currentTerm, false) to node cId
	end if
end on
``` 
                - ```autohotkey
;; Collecting votes at the candidate

on receiving (VoteResponse, voterId, term, granted) at nodeId do
	;; If we're behind in the term we'll have to 
	;; switch back to being a follower
	if currentRole = candidate ∧ term = currentTerm ∧ granted then
		;; idempotent update
		votesReceived := votesReceived ∪ {voterId}
		;; If we have a majority quorum we become the leader!
		if |votesReceived| ≥ cieling((|nodes| + 1)/2) then
			currentRole := leader; currentLeader := nodeId
			cancel election timer
			;; tell everyone we're the leader
			for each follower ∈ nodes \ {nodeId} do
				;; Initialize maps from each node
				;; to the number of messages sent to them
				;; and the number of messages they've 
				;; acknowledged
				sentLength[follower] := log.length
				ackedLength[follower] := 0
				ReplicateLog(nodeId, follower)
			end for
		end if
	else if term > currentTerm then
		currentTerm := term
		currentRole := follower
		votedFor := null
		cancel election timer
	end if
end on
``` 
                - ```autohotkey
;; Broadcasting messages

on request to broadcast msg at node nodeId 
	if currentRole = leader then
		;; add the message to the log which is simply the total
		;; order of messages
		append the record (msg : msg, term : currentTerm) to log
		ackedLength[nodeId] := log.length
		for each follower ∈ nodes \ {nodeId} do
			ReplicateLog(nodeId, follower )
		end for
	else
		;; If we aint the leader, forward the msg
		forward the request to currentLeader via a FIFO link
	end if
end on

periodically at node nodeId do
	;; This acts as a heartbeat, telling them the leader is alive
	;; this also ensures any messages that get lost will be 
	;; redelivered
	if currentRole = leader then
		for each follower ∈ nodes \ {nodeId} do
			ReplicateLog(nodeId, follower )
		end for
	end if
end do
``` 
                - ```autohotkey
;; The ReplicateLog function

function ReplicateLog(leaderId, followerId)
	;; prefixLen the number of log entries we think
	;; we've sent to a particular follower.
	;; suffix is all the entries we've yet to send
	prefixLen := sentLength[followerId]
	suffix := hlog[prefixLen], log[prefixLen + 1], . . . ,
	log[log.length − 1]i
	;; this gets the term number of the last log
	;; entry in the prefix
	;; e.g. the last log entry we think we've sent
	prefixTerm := 0
	if prefixLen > 0 then
		prefixTerm := log[prefixLen − 1].term
	end if
	send (LogRequest, leaderId, currentTerm, prefixLen,
	prefixTerm, commitLength, suffix ) to followerId
end function
``` 
                - ```autohotkey
;; Receiving a log request

on receiving (LogRequest, leaderId, term, prefixLen, prefixTerm,
	leaderCommit, suffix ) at node nodeId do
	if term > currentTerm then
		currentTerm := term; votedFor := null
		cancel election timer
	end if
	;; this is if we thought we were a candidate
	;; or if we thought we were the leader
	if term = currentTerm then
		currentRole := follower; currentLeader := leaderId
	end if
	;; if we aren't actually behind their log
	;; and either the prefix is empty
	;; and their prefix item is the same as what we've got
	logOk := (log.length ≥ prefixLen) ∧
	(prefixLen = 0 ∨ log[prefixLen − 1].term = prefixTerm)
	if term = currentTerm ∧ logOk then
		AppendEntries(prefixLen, leaderCommit, suffix )
		ack := prefixLen + suffix .length
		send (LogResponse, nodeId, currentTerm, ack,true) to leaderId
	else
		send (LogResponse, nodeId, currentTerm, 0, false) to leaderId
	end if
end on
``` 
                - What is the purpose of this code? ```autohotkey
 logOk := (log.length ≥ prefixLen) ∧
	(prefixLen = 0 ∨ log[prefixLen − 1].term = prefixTerm)
```―This is 
                - 
                - ```autohotkey
;; AppendEntries function

function AppendEntries(prefixLen, leaderCommit, suffix )
	if suffix .length > 0 ∧ log.length > prefixLen then
		index := min(log.length, prefixLen + suffix .length) − 1
		if log[index ].term 6= suffix [index − prefixLen].term then
			log := hlog[0], log[1], . . . , log[prefixLen − 1]i
		end if
	end if
	if prefixLen + suffix .length > log.length then
		for i := log.length − prefixLen to suffix .length − 1 do
			append suffix [i] to log
		end for
	end if
	if leaderCommit > commitLength then
		for i := commitLength to leaderCommit − 1 do
			deliver log[i].msg to the application
		end for
		commitLength := leaderCommit
	end if
end function
``` 
                - 
                - ```autohotkey
on receiving (LogResponse, follower , term, ack, success) at nodeId do
	if term = currentTerm ∧ currentRole = leader then
		if success = true ∧ ack ≥ ackedLength[follower ] then
			sentLength[follower ] := ack
			ackedLength[follower ] := ack
			CommitLogEntries()
		else if sentLength[follower ] > 0 then
			sentLength[follower ] := sentLength[follower ] − 1
			ReplicateLog(nodeId, follower )
	end if
	else if term > currentTerm then
	currentTerm := term
	currentRole := follower
	votedFor := null
	cancel election timer
	end if
end on
``` 
        - 
        - GO FROM HERE NEXT: [Distributed Systems 6.2: Raft - YouTube](https://youtu.be/uXEYuDwm7e4?list=PLeKd45zvjcDFUEv_ohr_HdUFe97RItdiB&t=946) 
        -  _Distributed Systems supervision 1 _ 
            -  _**Exercise 1**_ . A TCP connection allows two nodes to send each other arbitrarily long sequences of bytes. You decide that you want to send multiple requests and responses over the same TCP connection. What do you need to do in order to implement such a request-response protocol using TCP?
                - You could **wrap each request and response with a header** which would encode the length of the message (among other possible pieces of information), the header would have to accord to a set code that both nodes understood (e.g. it could have the first 4 bytes specifying the length of the header, the next 4 specifying the length of the whole packet perhaps more data specifying the type of the request). Then when a node receives a stream of bytes, it can find the length of each individual message by examining the header - then if there are more bytes after the header they can know that is another message (whose header will be examined).
            -  _**Exercise 2**_ . How is RPC different from a local function call? Is location transparency achievable?
                - An RPC call is different in a few ways ↓ 
                    - The function is not executed on your local machine
                    - The arguments of an RPC must first be marshalled to be sent over the network
                    - RPCs make use of an API to facilitate their use
                - Location transparency (the idea that the location of a resource (whether it be on our local computer or on another node) is achievable under perfect conditions (impossibly fast WiFi or having local resources slowed down to achieve such transparency) however in reality the lag between forging and communicating over a network connection is detectable and is much greater than the lag of local file being opened is large. So the very quick loading of a file would indicate a local file.
            -  _**Exercise 3.**_   Say you have a client-server RPC system in which a client repeats an RPC request until it receives a response. How could the server deduplicate the requests?
                - One solution would be to attach a request number and a repeat number to each request. So if I a request "GET : "img:coolpic.png"", it could be sent multiple times like this:
            "req:1, rep:1, GET : "img:coolpic.png""      "req:1, rep:2, GET : "img:coolpic.png"" ...
Then a second request "STORE : "img:coolerpic.jpeg"", could be sent like:
   "req:2, rep:1, STORE : "img:coolerpic.jpeg""        "req:2, rep:2, STORE : "img:coolerpic.jpeg""

This would allow for easy deduplicating in order of req then rep
            -  _**Exercise 4**_ . Reliable network links allow messages to be reordered. Give pseudocode for an algorithm that strengthens the properties of a reliable point-to-point link such that messages are received in the order they were sent (this is called a FIFO link), assuming an asynchronous crash-stop system model. 
                - ```python
buffer = []
received, messages_incoming = 0, 0
time = time.monotonic()
# read_message() blocks while waiting for a message
# Wait a max of 10 seconds before exiting the while loop
while (time.monotonic()-time < 10000 and msg = read_message()):
	time = time.monotonic()
    received += 1
    messages_incoming = msg.messages_incoming
    buffer.append(msg)

    if received == messages_incoming:
        break

if time.monotonic() - time > 10000:
	send_failure_message()
	return []
else:
	# Sort based on the message number
	buffer.sort(lambda x : x.number)
	return buffer 
```
            -  _**Exercise 5**_ . How do we need to change the algorithm from Exercise 4 if we assume a crash-recovery model instead of a crash-stop model?  
                - We would need to implement a mechanism for informing the receiver/sender that we have crashed and lost the data stored in our memory, in the two cases: 
                - **Sender node crashes: **We don't know how long the period of unresponsiveness will last, so we can't simply keep waiting until the node comes back online. Instead the receiver should cache the messages received so far in some non-volatile memory. Then when the sender wakes up again, a unique ID of the message should be sent, the recipient can then indicate how many (if any) messages were received and the sender can resume sending where they left off. 
                - **Recipient node crashes: **Once the recipient wakes up, it will need to signal the resending of the entire incoming message - on the senders side a non-volatile storage of outgoing messages will need to be held or a method of backtracking execution so the message can be sent again.
            -  _**Exercise 6**_ . Describe some problems that may arise from leap second smearing.
                - Floating point accuracy: The smearing of 1/86400 in binary form will introduce a very small error, and that error will be repeated 86400 times every time this update is done - if a small low bit floating point representation is used, the error introduced will defeat the purpose of the whole exercise. 
                - This is more reason for software vendors to simply ignore the problem. While this is not a problem  now, bugs mirroring Y2K could start to appear in the (far) future which go undetected.
                - This makes bugs harder to detect, as desync occurs over many hours rather than at one instant - while the latter would be noticeable in logs, the former would be very difficult to sus out.
                - Desync problems can arise if one node is doing smearing and another isn't. 
            -  _**Exercise 7.**_  What is the maximum possible error in the NTP client’s estimate of skew with regard to one particular server, assuming that both nodes correctly follow the protocol?
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/qpQ_ydxHmeLCcJOH6RsYAsXfSQmhKyB1tFdamdF6Ap_bDPQSH3D9yXDiDWlMRhPCDIbkBbsV34oweAqelXOk2YakrBsEOBexbuDNPmUFzd2RpaSGhmlB3zKHzVrmj3e5.png) 
                - delta = (t4 - t1) - (t3 - t2) = total network delay
                - skew = (t3 + delta/2) - t4 ^^ Question: should the skew not be the absolute value of this?^^ 
                - This estimate is worst, when the estimate of the time taken for the second response is worst - i.e. when request 2 took the minimum time (according to the speed of light & the distance) $\tau$ and the response took  (t4 - t1) - (t3 - t2) - $\tau$, resulting in a true value of: $$(t_3 + \tau) - t_4  = (t_3 - t_4) + \tau$$ 
                - and an estimated value of:
                - $$(t_3 + ((t_4 - t_1) - (t_3 - t_1))/2) \ = \ \frac{t_2 - t_1 + t_3 - t_4}{2}$$ 
                - Resulting in an error of:
                - $$\frac{t_2 - t_1 + t_3 - t_4}{2}  - ((t_3 - t_4) + \tau)$$ 
                - 
                - $$\text{error} = \frac{t_2-t_1-t_3+t_4}{2} - \tau = \delta/2 - \tau$$ 
            -  _**Exercise 8:**_   ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/5S3daW4zY8nipJDU9bb6QDZFwpAKv76GLWXklLBsLwNMaHVyXCyqi6beHbSePSUh2wUUqfIM089PwNg7KdgKAG393iZn0TG3vKoFUqd6uZlbpIj28GT5HfxMznzEsjyk.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/JZ0cqETpk4kB-8uo8RsxSXte3C9NVDfOw4vemdbEKxinYe3CqfOPdSUNb_Fpyd4-ye6MCznEIu-9sZu06atSqyFY7bbC1aTgvSUTUTXT9mFmE5HTbSF5PSAVbnrb2wkH.png) 
            -  _**Exercise 9.**_  ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/yjzPiqfzh56oOnjdrWniK1-rmUzLvrJVHdmIi3wGYvHrNK61hUGjfCo6hw7JQp6f_L5YYwSlqfsN8hscm798IJxxy9ynwJuNREyNIPIdegj_vVikP0lJGqiVY31FzpHB.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/ob9D3CB9suoCvYxZxqxdjPsKhfoPPSYm6DlccDXCh0NtAPdvEKZA7Lly3ra6n6EQ8nrb-eQAqp-ly0gw__HevRFKuj9ebM1cP9wxXqeeExDvTyWgi-ry8nKXL0kJ1kY9.png) 
            - **Exercise 10.** Given the sequence of messages in the following execution, show the Lamport timestamps at each send or receive event   
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4atqIBUEAzm7OncyN5qB3j5Z5XjQtc_OHDZgMdXZh6kXNeqKApIIRpARrwbyAHUyX7k7ndM-H0MBpStyrugFtkC4DMVZEVYv2pTPR9uWBOaXYXUGmwbk1reIC3dx1sE2.png) 
            - ^^ _**Exercise 11**_ ^^^^. Not really sure what im doing in this Q^^ 
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/OLpHgGNm5MfltmNel8M5Q5lLaLiOvEi-XeYkJSwWR2d7kXOaSbkgkSRhko_Iat92Wrqx24q4XCLZlBOuaCfxNSdmG60OZoL9OyAZd8aFGEzVQs2X26dJVDRGVZhjhzk1.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/oBARg9P1D24HOK5JpsjKfxt9BYToaiGQaEFssa4ymDfFEdCvwPFRyS1POKECnRvToCUUSUDiGleDPpD1--KUBhU6sgaQqXCITyKlJIKliumPf_oMLkMtWVPrL2PwqsPV.png) 
![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/_yytoqeaDujPLnHDbTmbdQ8mL45y-VCzC7OtvC2qnqKA8ofMwyZq15n7C4nYTpYnzbyjKVGghpq51wFQGApk_Zsmi4sMKo7jf3lGLupIBvMobBOH_MVgEeECiIBzpoqp.png) 
            -  _**Exercise 12**_ . Given the same sequence of messages as in Exercise 10, show the vector clocks at each send or receive event.  
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9jwOOpv8Z8WqVwxq7ynfW03XwQFEn7ipkP88FMsmB5DkrGrmrNBuwEUhIDojkOzdAeBx17jEOVmlWrU2whx6-qnXAjz4jqukHzSSGc3F-r53v3Rg82YAzsXevXp8Bh-Z.png) 
            - 
            - 
            - 
            - 
            - 
        -  _Distributed Systems supervision 2_   
            - 
            -  _**Exercise 13**_ . Using the Lamport and vector timestamps calculated in Exercise 10 and 12, state whether or not the following events can be determined to have a happens-before relationship.   
                - ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/4atqIBUEAzm7OncyN5qB3j5Z5XjQtc_OHDZgMdXZh6kXNeqKApIIRpARrwbyAHUyX7k7ndM-H0MBpStyrugFtkC4DMVZEVYv2pTPR9uWBOaXYXUGmwbk1reIC3dx1sE2.png)    ![](local:///home/mali/remnote/remnote-614c8a3b6997e6001643dfce/files/9jwOOpv8Z8WqVwxq7ynfW03XwQFEn7ipkP88FMsmB5DkrGrmrNBuwEUhIDojkOzdAeBx17jEOVmlWrU2whx6-qnXAjz4jqukHzSSGc3F-r53v3Rg82YAzsXevXp8Bh-Z.png)  
                - Lamport:  
                    - Send(m2) ⇒ send(m3) - Yes, because they occurred at the same node, and L(m2) < L(m3) ⇒ $a \rightarrow b$ 
                    - Send(m3) ⇒ send(m5) - No, because they didn't occur on the same node, it's not a message from a to b and there's no chain $a \rightarrow x_1 \rightarrow ... \rightarrow x_n \rightarrow b$ . $a||b$ 
                    - Send(m5) ⇒ send(m9) - Yes, because we have the chain of events 4 (send m5) ⇒ 5 ⇒ 6 ⇒ 7 ⇒ 8 (send m9) - we can easily prove the happens-before chain is correct as they are all on the same node and all have L(x) < L(x+1) (they are in order in the execution order)
                - Vector: 
                    - Send(m2) ⇒ send(m3) - Yes because all values of the vector clock are lesser or equal
                    - Send(m3) ⇒ send(m5) - No, they are concurrent as some values are lesser and some are greater between the two vector clocks
                    - Send(m5) ⇒ send(m9) - Yes, because all values of the vector clock are lesser or equal
            -  _**Exercise 14:**_    We have seen several types of physical clocks (time-of-day clocks with NTP, monotonic clocks) and logical clocks. For each of the following uses of time, explain which type of clock is the most appropriate: ^^process scheduling^^; I/O; ^^distributed filesystem consistency^^; ^^cryptographic certificate validity^^; concurrent database updates.  
                - **Process Scheduling**: A monotonic timing clock, as each process will be apportioned a time quantum in which they can be processed - It should be monotonic as we don't want any sudden jumps backwards due to NTP corrections. While a logical clock consisting of clock cycles could be considered, this could result in some jobs takin inordinate amounts of time (consider I/O) as they require few clock cycles but take a long time - thus time should be used. 
                - ^^**I/O**^^^^: ???^^ 
                - **Distributed filesystem consistency**: Logical vector clocks (with tombstones), as we want a total order of events to ensure we can compare replicas and decide with certainty who is correct.
                - **Cryptographic certificate validity**: Physical time-of-day clocks with NTP should be used. Physical time because the certificate must be valid for a set of physical days. Time-of-day with NTP because we want the time to be human understandable and because it is the most ubiquitous form of time-keeping. 
                - **Concurrent database updates**: Logical vector clocks. We wish to know with certainty which event arrived last, and we'll choose using FIFO - if an update was issued after it should overwrite. Logical vector clocks provide this. We won't use time, due to clock-drift and leap-second issues. 
            - ^^ _**Exercise 15:**_ ^^^^ Prove that causal broadcast also satisfies the requirements of FIFO broadcast, and that FIFO-total order broadcast also satisfies the requirements of causal broadcast.^^ 
                - 
                --------------------- Portal ---------------------
 -- Avoided infinite recursion --             -  _**Exercise 16:**_ . Give pseudocode for an algorithm that implements FIFO-total order broadcast using Lamport clocks. You may assume that each node has a unique ID, and that the set of all node IDs is known. Further assume that the underlying network provides reliable FIFO broadcast.  
                - ```python
timestamp = 0
buffer = [ [(None, 0)] ] * N # Initialize all messages, the message is None and the time is 0. Note that each node has it's own FIFO queue, storing messages and timestamps 

def send(message):
    timestamp += 1
    broadcast( tuple(message, timestamp, myNodeNumber) )

def receive((message, msg_t, nodeNumber)): # pattern match on tuple
    timestamp += 1
    if buffer[nodeNumber][0] == (None, 0): # if we aren't holding a message from this node
        buffer[nodeNumber][0] =  ( message, msg_t )
    else:
    	# otherwise add it to the node Queue
        (buffer[nodeNumber]).append( ( message, msg_t) )

def deliver():
    nodeIndex = buffer.getMin()
    item = buffer[itemIndex][0]

    for nodeBuffer in buffer:
        # We know this has the smallest lamport timestamp because it's FIFO:
        message = nodeBuffer[0]

        if message != item:
            if !(message.time < item.time):
                return False # Go back to waiting for a response

    deliver_to_software(item.message)
    # Either promote the next item in the node queue to the head OR
    # Set the item to have lamport 0, so next time we must wait for a value
    buffer[nodeIndex].deleteItem(index=0)
    if len(buffer[nodeIndex] == 0):
        (nodeBuffer[nodeIndex]).append( (None, 0) ) 
    timestamp += 1
    return True

while (input = listen()): # blocks until we get input
    receive(input)
    deliver() 
```
            -  _**Exercise 17:**_  Apache Cassandra, a widely-used distributed database, uses a replication approach similar to the one described here. However, it uses physical timestamps instead of logical timestamps, as discussed here: [ ](https://www.datastax.com/blog/why-cassandra-doesnt-need-vector-clocks)[https://www.datastax.com/](https://www.datastax.com/blog/why-cassandra-doesnt-need-vector-clocks)[blog/ 2013/ 09/why-cassandra-doesnt-need-vector-clocks.](https://www.datastax.com/blog/why-cassandra-doesnt-need-vector-clocks) Write a critique of this blog post. What do you think of its arguments and why? What facts are missing from it? What recommendation would you make to someone considering using Cassandra?
                - The blog post describes problems in Performance, manages siblings and Vector clocks which they seek to solve
                    - With regards to **Performance** their implementation will be faster for single field updates - however it may be slower for entire object updates. Consider, in a vector clock system if we go to update an object we need to iterate through a vector clock of size R (number of replicas) - in their system we need to iterate through a "vector clock" of size F (number of fields) as each field has a counter associated with it. So if we wish to update more than R fields in their implementation, that will be slower than in the vector clock implementation. 
                    - With regards to **managing siblings** they discuss how LWW can result in lost data, yet their system uses LWW (within specific fields) the only difference is that the overwritten data **may** be smaller depending on how your objects are constructed - as you may just have individual fields overwritten and not the entire object.
                    - With regards to **Vector clocks** they say: "Vector clocks are good at helping clients with simple merges like the above user object, but it's important to understand that vector clocks only tell you that a conflict occurred, and not how to resolve it;" - This is a feature not a bug, we **want** user intervention in certain situations in which it's **impossible** to decide what they want - the writer communicates this as a problem, while it results in data being as correct as can be. The downside is the user has to spend time to make this determination, however that is a trade-off  and not a strictly-worse scenario.
                - The blog post makes no mention of leap-seconds, and their impact on timestamp ordering (they provide a dead-link as explanation of how ties are resolved), additionally there is no mention of how they account for clock synchronisation and clock drift which is a large part of the reason for logical vector clocks.
                - This system could be faster for systems whose objects have few fields, and where updates are usually performed on only a few fields at a time. If someone was considering using Cassandra I would urge them to use monotonic physical timers (to protect from leap second problems) and ensure clients are close together (ideally in a single site) and using the same time synchronisation  server (to ensure the tightest clock synchrony and protect from clock-drift).
            - 
            - 
        - 
        - 
        - 
        - 
- 
- 
- 
- 
- 
